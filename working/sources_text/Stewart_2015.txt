<<<PAGE=1>>>
547
Evidence & Policy • vol 11 • no 4 • 547–57 • © Policy Press 2015 • #EVPOL 
Print ISSN 1744 2648 • Online ISSN 1744 2656 • http://dx.doi.org/10.1332/174426414X1417545274793 
This article is distributed under the terms of the Creative Commons Attribution-
NonCommercial 4.0 license (http://creativecommons.org/licenses/by-nc/4.0/) which 
permits adaptation, alteration, reproduction and distribution for non-commercial use, 
without further permission provided the original work is attributed. The derivative works 
do not need to be licensed on the same terms.
practice
A theory of change for capacity building for the 
use of research evidence by decision makers in 
southern Africa
Ruth Stewart, ruths@uj.ac.za, 
University of Johannesburg, South Africa 
The effective use of public policy to reduce poverty and inequality in southern Africa requires an 
increased use of research evidence to inform decision making. There is an absence of clear evidence 
as to how best to encourage evidence-informed decision making, and how to build capacity 
among decision makers in the use of research. This paper proposes a demand-focused approach 
for increasing the use of evidence in policy, presenting strategies supporting ‘pull’ activities and 
closer linkages and exchanges between producers and users. The paper shares for discussion a 
people-focused theory of change for building capacity to use research evidence amongst policy 
makers in southern Africa.
key words research use • knowledge transition • evidence-informed policy • capacity building
Why is there a need to increase the use of research evidence to 
enable reductions in poverty and inequality? 
The worldwide recession has led to pressure on limited resources and increased 
demands for ensuring public funding is used more effectively. This has coupled with 
an increase in demand for public accountability, with citizens demanding greater 
transparency in government decision-making (DFID, 2011). Under these financial 
and public pressures government is ‘reinventing’ itself with a trend towards more cost-
efficient government, supported by national performance monitoring and evaluation 
systems, particularly within newly established middle-income economies (Mayne 
and Zapico-Goñi, 2007). 
Within the southern Africa context there is an additional and overriding need for 
solutions that address both poverty and inequality (Thorbecke, 2013; UNDP , 2013). 
In this, one of the poorest regions of the world, governments struggle to deliver even 
basic services for education, health and housing. The statistics speak for themselves: 
almost half the population of sub-Saharan Africa lives on less than a dollar a day. 
Unauthenticated | Downloaded 11/24/24 08:17 PM UTC
<<<PAGE=2>>>
Ruth Stewart
548
Compounded by the worldwide recession, government funding is extremely limited 
in southern Africa and reliance on donor aid is high. World Bank statistics show that 
per capita overseas donor aid is over $50 in Sub-Saharan Africa, relative to $10 per 
capita in South Asia and a worldwide average of $20 per capita (World Bank, 2013a). 
Furthermore, in the context of government corruption, ensuring good governance 
and best use of these funds is of particular importance. Coupled with increasing 
pressure on donor agencies to provide evidence of their impact to their own citizens, 
this has led to an increased emphasis on research and aid effectiveness in development
  
(Banerjee and Duflo, 2011; Cohen and Easterly, 2009; Conway et al, 2010).
The imperatives are therefore mounting for public policy decision making that 
effectively addresses the challenges of poverty and inequality, in accountable and 
evidenced ways. It is in this context that the appropriate use of ‘evidence’ by decision 
makers has the potential to increase the impact of government programmes and avoid 
wasting limited resources on ineffectual interventions, achieving the best possible 
value for money, at the same time as improving the accountability of government. 
While this may seem a lofty ideal, it is increasingly the goal of programmes designed 
to increase the use of evidence in policy making and implementation (Cherney and 
Head, 2011; Jones et al, 2013; Lipsey and Noonan, 2009; Newman et al, 2013).
What has been done to encourage evidence-based decision making
With its origins in health care, the concept of evidence-based decision making has been 
around since the 1980s. Popularised within national policy by the Blair government 
in the UK (Cabinet Office, 1999), the drive to base decisions on evidence, and to 
evaluate the effectiveness of those same decisions using evidence is increasingly 
applied, and debated, in international development (Court and Y oung, 2003; CGD, 
2006; Clemens and Demombynes, 2013; Eyben et al, 2013). 
Over the last two decades a number of activities and initiatives to support evidence-
informed policy making have been put in place across Southern Africa (Broadbent, 
2012; du T oit, 2012). These include initiatives for increasing the policy relevance 
of research agendas such as the Development Research Uptake in Sub-Saharan 
Africa (DRUSSA)
 programme.  Funded by the UK’s Department for International 
Development (DFID), DRUSSA provides direct support to universities in sub-Saharan 
Africa to improve participation in and impact on policy and practice. Along similar 
lines, the World Bank’s Development Impact Evaluation Initiative (DIME) seeks to 
promote and improve evaluations of development programmes. Other organisations, 
such as the Campbell, Cochrane and Environmental Evidence collaborations, focus 
on the production of structured summaries of available evidence to inform decision 
making (systematic reviews).  All three collaborations now include development groups 
of various forms. In addition there are a number of programmes that aim to get high 
quality evidence into policy and practice, such as the World Health Organization’s 
Evidence Informed Policy Network (EVIPNet), and the Overseas Development 
Institute’s Research and Policy In Development (RAPID) programme.
Many of these activities for increasing the use of evidence in policy focus on the 
capacity to conduct and disseminate policy-relevant research rather than on capacity 
to use evidence, that is, they are ‘push’ activities (driven from the research community), 
the limitations of which are well documented (Lavis et al, 2003; Milne et al, 2014; 
Nutley et al, 2007). There remains a need to support ‘pull’ activities (those stemming 
Unauthenticated | Downloaded 11/24/24 08:17 PM UTC
<<<PAGE=3>>>
A theory of change for capacity building
549
from potential users of research) (Newman et al, 2012), as well as linkage and exchange 
activities (interactive activities building relationships between research producers and 
users) (Murthy et al, 2012).
What do we know about ‘what works’ in increasing the use of 
research evidence?
The barriers to increasing the use of research by decision makers are well understood. 
These have been nicely summarised in a DFID systematic review (Clar et al, 2011) 
and include:
• Individual-level barriers including lack of experience and capacity for assessing 
evidence, mutual mistrust, and negative attitudes towards change and research
• Organisational level barriers, such as an unsupportive culture, competing interests, 
frequent staff turnover, interest group pressure on decision makers, issues of 
censorship and control, ‘anti-intellectualism’ in government against use of research, 
the importance of indigenous knowledge, religion  and cultural differences
• Relationship and communication barriers, including poor choices of messenger, 
information overload, the use of traditional, academic language, the lack of 
actionable messages 
• Timing issues, such as the differences in decision makers’ and researchers’ time 
frames and the lack of time to make decisions
However, how to overcome these barriers is not well established and we do not know 
what works. Even in health care evidence for how best to build capacity is limited. 
The systematic reviews that have addressed these questions consistently show that 
we have no good evidence for the effectiveness of any of these approaches (Clar 
et al, 2011; Murthy et al, 2012; Flodgren et al, 2012; Horsley et al, 2011; Hemsley-
Brown and Sharp, 2003; Stewart and Oliver, 2006). The best quality evidence comes 
from a Cochrane systematic review (Horsley et al, 2011), which suggests training in 
how to critique research (known as ‘critical appraisal skills’) leads to modest gains in 
practitioner knowledge and behaviour. However, closer examination of these training 
initiatives suggests they are of limited relevance, focusing on medical professionals 
and employing neither problem-based nor participatory approaches (Stewart and 
Oliver, 2006).
We know that capacity building needs to be problem-based, participatory, prolonged 
and supportive, including more than just training. Evidence from systematic reviews 
support the use of both participatory and problem-based learning. They suggest 
that capacity building within the workplace (most commonly known as ‘continuing 
professional development’ or CPD) which is collaborative (at least two professionals 
working together) and sustained (over a minimum of 12 weeks) enhances motivation 
and confidence of participants, compared to studies of individually-oriented sustained 
CPD which show modest impacts (Cordingley et al, 2003; 2005a; 2005b, 2007). 
Positive impacts of collaborative sustained CPD were associated with: the use of 
external specialists; feedback to participants by facilitators and encouragement to 
develop peer-support systems; being based in the place of work; scope for teacher 
participants to identify their own CPD focus, starting points and pace; inclusion of 
practitioners in applying and refining the new knowledge and skills they gain, and 
Unauthenticated | Downloaded 11/24/24 08:17 PM UTC
<<<PAGE=4>>>
Ruth Stewart
550
experimenting with ways of integrating them into their own practice; an emphasis 
on peer support; and the provision of ongoing specialist support included modelling, 
mentoring, workshops, observation and feedback, coaching, and planned and informal 
meetings for discussion. It is also relevant that current drives to train health care 
professionals for evidence-based practice in the 21st century focus on transformative 
learning, delivered via consortiums of experts, drawing on global resources adapted 
to local contexts (Frenk et al, 2010).
Capacity building in evidence use is essentially seeking to change the behaviour of 
decision makers, and we do know that facilitating behaviour change requires multiple 
approaches, strong networks linking organisations, and actual joint working across these 
consortiums. Supporting behaviour change requires complex systems and multiple 
processes of change that together contribute to new embedded ways of working 
(Greenhalgh et al, 2004). It must include more than purely training, incorporating a 
range of approaches (NICE, 2007). 
Evaluations of programmes implemented in southern Africa also highlight the 
importance of good facilitation, trusting relationships, clarity of purpose and a 
problem-based approach. As early as 2001, a team from the University of Johannesburg, 
along with the Institute of Education’s EPPI-Centre (London), delivered a series 
of workshops funded by DFID in evidence-informed decision making for HIV 
prevention, for policy makers and practitioners across the Southern African 
Development Community (SADC) region (Ellison et al, 2001; Stewart, 2001). Our 
evaluation of these workshops highlighted the need to recognise that the evidence-
based approach, with its emphasis on research, may appear foreign, challenging, and 
even threatening, to both individuals and their decision-making systems (Stewart 
et al, 2005; Stewart, 2007). We found that while decision makers need to be able to 
understand and critique research, expectations that decision makers will conduct 
research themselves must be avoided. We also found that care needs to be taken in how 
the approach is presented, that space needs to be provided for discussion and debate of 
the approach, and that other forms of knowledge need to be recognised and valued. 
Participants need follow-up support if they are to put learning into practice. Good 
facilitation, trusting relationships, clarity of purpose, and a problem-based approach 
were found to be essential foundations for capacity-building activities (Stewart (ed), 
2001; Stewart, 2007).
We also know that capacity building must be combined with opportunities and 
motivations (Michie et al, 2011). Facilitating such opportunities is a particular challenge 
as even individual incentives require a level of institutional buy-in, and changes in 
practice require what Greenhalgh and colleagues describe as ‘systems readiness for 
change’ (2004). The policy-making process is shaped by a large number of factors 
(Nutley et al, 2007), not least being both personal and party politics, and individual and 
institutional belief systems (Newman et al, 2012). The complex processes governing 
policy making, including both formal and informal systems, vary according to cultural, 
economic and political norms – the political economy. While it is not always possible 
to influence these systems, those wishing to increase the use of evidence do need to 
understand the specific contexts in which decision makers operate if capacity building 
is to lead to change in practice.
There is a body of research that critiques the assumptions behind evidence-informed 
decision making, highlighting the potential for politicisation of research generation 
and research use. While we cannot do justice to these critiques here, it is important 
Unauthenticated | Downloaded 11/24/24 08:17 PM UTC
<<<PAGE=5>>>
A theory of change for capacity building
551
to acknowledge that relevant research is not always available or accessible, and that a 
lot of research is subjective, and of poor quality. Whilst capacity building in critical 
appraisal goes some way to address this issue by enabling decision makers to identify 
biases within any given piece of research, the potential for decision makers themselves 
to use research to support their own political needs is much harder to address (Jones 
et al, 2013). Even where good quality research does exist and is used by decision 
makers, historical, political, economic and social complexity means that more effective 
policies are not necessarily put in place, nor implemented (Newman et al, 2012). 
Last but not least, even where increased use of research evidence in decision 
making is enabled, this does not necessarily lead to the desired goals of either greater 
accountability and transparency, or of poverty reduction (Jones et al, 2013). The use 
of research can facilitate greater transparency, but must be accompanied by other 
initiatives such as an increased drive for public scrutiny, and the introduction of the 
necessary procedures to enable this improved public access to both the processes and 
the products of policy making.
Having explored briefly the drivers and constraints for increased use of research 
in southern Africa, the barriers to research uptake, and the evidence on how to 
facilitate greater use of research evidence, the question arises of which approach, or 
combination of approaches, are worth testing out.
People-centred approaches for facilitating change 
One common thread appears to run through the available evidence discussed above 
on how best to build capacity amongst decision makers in the use of research, namely 
person-centred approaches. This paper therefore proposes a people-focused theory 
of change for building capacity to use research evidence among policy makers, with 
five key elements: 
1: Building sustainable relationships
We propose that capacity-building activities should be delivered through a consortium 
of partners, drawing on and strengthening existing networks. As well as involving 
local experts with experience of using research evidence activities, the available 
community of practice can be expanded through opportunities for apprenticeships 
and shadowing which build up experience. By working through existing networks, 
including policy makers, research producers and research-use facilitators, capacity 
building should be sustainable. 
2: Building relationships specifically with national governments
National governments, and in particular those government agencies which cut 
across ministries with cross-government remits for activities such as monitoring and 
evaluation, have considerable influence. For example, in South Africa, the Evaluation 
and Research Unit within the Department for Planning, Monitoring and Evaluation 
is leading the way in increasing the commissioning and use of evaluations across 
government. By working through internal agencies such as these there is considerable 
potential for influence.
Unauthenticated | Downloaded 11/24/24 08:17 PM UTC
<<<PAGE=6>>>
Ruth Stewart
552
3: Using relationships to build organisational and systems change, as well as 
individual capacity
Research use relies on organisations and systems as well as individuals. This includes 
the need to understand the political economy in which decision makers are operating 
and, as much as is feasible, to address barriers and offer incentives for change. While it 
is often simpler to target individuals with capacity-building activities such as training, 
there is also a need to support end-beneficiary organisations in improving systems to 
enable research use. This could be achieved through problem-based training, mentoring 
and secondments, working with participants to help overcome barriers, whether 
at individual, organisational or systems levels. These may include issues of access to 
research, the absence or limited quality of information services, systems for data and 
knowledge management, incentives for encouraging research use, the recognition 
of related professional competencies, and the profile of researchers in government. 
While some institutional factors can be addressed, others will remain outside the 
scope of any change management programme, and such constraints should be noted. 
4: Ensuring the right people and agencies are targeted 
By working with partners within governments, and taking time and effort to engage 
with their priorities, it should be possible to ensure that capacity-building activities are 
targeted at individuals and teams most likely to: a) have the opportunity to increase 
their use of research evidence; b) have the baseline skills, for example in monitoring 
and evaluation; and c) have the motivation to alter their working practices to take 
into account research evidence (Michie et al, 2011). 
5: Ensuring partner commitment and post-programme sustainability
Sustainability is perhaps one of the greatest challenges when trying to increase the use 
of research evidence, and requires considerable investment in relationship building. 
It requires commitment to building sustainable capacity in research use. Different 
approaches to ensuring such commitment might include asking end-beneficiaries 
to invest in the programme in some, or all, of the following ways: helping to identify 
and prioritise specific target groups for capacity-building initiatives; releasing staff  
for training and other capacity-building initiatives, where possible in teams to 
increase the likelihood of application; identifying staff who are more experienced 
in research use who might be contracted to act as mentors or host secondments 
for other policy partners; supporting terms of reference for mentoring, including 
ensuring those receiving mentoring have an allocated time each week for this, and 
have specific research-use projects which can be facilitated through the mentoring 
relationship; and providing rooms for training activities. In addition, all capacity-
building activities should be embedded within existing professional development 
and human resources systems when possible. By working with existing networks and 
in-country organisations in the delivery of the programme, we hypothesise that it is 
possible to build up a community of practice with partnerships that continue after 
the lifetime of a project. 
Unauthenticated | Downloaded 11/24/24 08:17 PM UTC
<<<PAGE=7>>>
A theory of change for capacity building
553
A theory of change incorporating these five person-centred 
approaches
As outlined previously, the challenges of poverty and inequality are manifested 
so acutely in southern Africa (see the ‘Problem’ as illustrated in Figure 1). We are 
proposing a theory of change in order to enhance capacity among civil servants 
in accessing, appraising and using available research evidence in making social and 
economic policy decisions, so as to increase the use of research evidence in decision 
making: our ultimate goal being to contribute to reductions in poverty and inequality 
(see ‘Desired outcome and impact’ in Figure 1). The following ‘Current needs’ have 
thus far been identified: namely that most research-use initiatives have been largely 
‘supply-side’ and most have been restricted to the health sector; that capacity-building 
activities exist, but remain limited in scope with little focus on application of skills; 
and that most activities have been limited to capacity in monitoring activities and 
the use of generated data in policy and planning.
We propose a programme of work to build capacity among civil servants that 
incorporates these five person-centred approaches into a mentoring-based model 
(see our ‘Strategy’ in Figure 1).
1. Context-specific work plans will be informed by detailed situational and landscape 
assessments
2. Training workshops and seminars will raise awareness and enhance capacity
3. An integrated mentorship programme will enhance application of learning
4. Work placements will enable experiential learning and build relationships
5. In addition, all activities will be embedded within the Africa Evidence Network 
(see Box 1)
These proposals will be further strengthened by five key factors, which reinforce 
the foundation for this person-focused approach (described as ‘Influential factors’ 
in Figure 1):
• The programme of work will be implemented by a southern-led consortium 
with extensive experience across Africa
• We have the support of high-level champions within governments and within 
our consortium
• We are working with departments and ministries with overarching responsibility 
for monitoring, evaluation, research and planning across government sectors
• There is a drive from donors and increasingly within governments for greater 
use of evidence to demonstrate ‘development effectiveness’
• We have strong collaborative partnerships within our consortium, and via a wider 
a regional community of practice: the Africa Evidence Network.
Last but not least, a number of assumptions underlie this theory of change and need 
to be considered in implementing our change strategy. They will also be assessed as 
part of the wider programme evaluation. Summarised in Figure 1 under ‘Assumptions’, 
these are the assumptions that:
Unauthenticated | Downloaded 11/24/24 08:17 PM UTC
<<<PAGE=8>>>
1
DESIRED OUTCOME 
AND IMPACT
Enhanced capacity 
among civil servants 
to user esearch 
evidence in making 
policy decisions .
Increased use of 
research-evidence in 
decision-making 
contributing to 
reductions in poverty 
and inequality.
STRATEGY
To build capacity among civil servants in southern Africa in 
accessing, appraising and using available research evidence 
through employing five person-centered approaches.
ASSUMPTIONS
That it is feasible to increase demand and build-
capacity, leading to increased use of evidence. 
That we can build the relationships needed between 
research users, producers and intermediaries. 
INFLUENTIAL FACTORS
We are an experienced,
southern-led consortium 
with the support of high-level 
champions within key 
departments.
There is a drive for greater 
use of evidence to 
demonstrate ‘aid 
effectiveness’.
We have strong collaborative 
partnerships.
THE PROBLEM
Southern Africa includes some of the worlds most 
unequal and impoverished communities, providing 
an imperative for greater use of research-evidence if 
decision-making is to contribute to reductions in 
poverty and inequality. 
CURRENT NEEDS
Research-use initiatives have been limited and 
although capacity-building activities exist they have 
been narrow in terms of audience, scope and 
approach.  
Figure 1: Theory of change
Ruth Stewart
554
• It is feasible to build capacity in research use among decision makers, generating 
demand for research evidence (‘pull’) which is currently, at best, latent demand
• Capacity-building does lead to increased use of research evidence beyond the 
activities of the programme
• Our strategies will enable sustainable capacity building if delivered in partnership 
with local networks and embedded within the Africa Evidence Network
• Relationships built through the programme will be meaningful, productive and 
sustainable.
 Box 1: The Africa Evidence Network  
(www.africaevidencenetwork.org)
The Africa Evidence Network is a community of people who work in Africa and have an 
interest in evidence, its production (in particular but not exclusively through systematic 
reviews) and use in decision making. The Network includes researchers, practitioners and 
policy makers from universities, NGOs and governments. 
The Network came into being following the International Initiative for Impact and 
Evaluation and the Campbell Collaboration’s mini-colloquium in Dhaka Bangladesh in 
December 2012. There were a number of delegates from Africa attending from a range 
of backgrounds with varying links to different systematic review and evidence-based 
decision-making organisations. Following a meeting of all of the African delegates it was 
decided it would be helpful to have a network to share information, experiences and ideas 
in the belief that in working together the Network can help to make evidence-informed 
policy and practice a reality across the region. 
Unauthenticated | Downloaded 11/24/24 08:17 PM UTC
<<<PAGE=9>>>
A theory of change for capacity building
555
Conclusion
In the absence of clear evidence as to how best to build capacity to use evidence 
in decision making, we have proposed a person-centred approach. This will be 
delivered as part of a programme of work led by the University of Johannesburg 
and funded by the UK’s DFID under their Building Capacity to Use Research 
Evidence (BCURE) Programme. The proposed theory of change will be translated 
into a detailed implementation plan and realised in one of the poorest countries in 
the world, Malawi, and one of the most unequal, South Africa. This work will be 
supported by an internal monitoring programme and an externally commissioned 
evaluation. We hope to report on progress over the coming years.
We invite others to reflect on our proposed theory, feed in their reflections and 
experiences, and join the Africa Evidence Network (www.africaevidencenetwork.
org). Furthermore others are welcome to build on and adapt our theory of change for 
their own contexts and environments. We believe that the approach outlined in this 
paper has the potential to deliver real and sustainable increases in the use of research 
evidence in decision making through its emphasis on relationships and networks.
References
Banerjee, A, Duflo, E, 2011, Poor economics: A radical rethinking of the way to fight global 
poverty, New Y ork: Public Affairs
Broadbent, E, 2012, Politics of research-based evidence in African policy debates: Synthesis 
of case study findings, Evidence-based Policy in Development Network, http://
mwananchi-africa.org
Cabinet Office, 1999, Modernising government, Norwich: The Stationery Office
CGD (Center for Global Development), 2006, When will we ever learn? Changing lives 
through impact evaluation, Evaluation Gap Working Group, Washington DC: CGD
Cherney, A, Head, B, 2011, Supporting the knowledge-to-action process: A systems-
thinking approach, Evidence & Policy 7, 4, 471–88
Clar, C, Campbell, S, Lisa, D, Wendy, G, 2011, What are the effects of interventions to 
improve the uptake of evidence from health research into policy in low and middle-income 
countries?, London: DFID
Clemens, M, Demombynes, G, 2013, The new transparency in development economics: 
Lessons from the millennium villages controversy, CGD Working Paper 342, Washington, 
DC: Center for Global Development
Cohen, J, Easterly, W (eds), 2009, What works in development? Thinking big and thinking 
small, Washington DC: Brookings Institution
Conway, G, Waage, J, Delaney, S, 2010, Science and innovation for development, London: 
UK Collaborative on Development Sciences
Cordingley, P , Bell, M, Rundell, B, Evans, D, 2003, The impact of collaborative CPD 
on classroom teaching and learning, London: EPPI-Centre 
Cordingley, P , Bell, M, Thomason, S, Firth, A, 2005a, The impact of collaborative 
continuing professional development (CPD) on classroom teaching and learning, 
London: EPPI-Centre
Cordingley, P , Bell, M, Evans, D, Firth, A, 2005b, What do teacher impact data tell us 
about collaborative CPD?, London: EPPI-Centre
Unauthenticated | Downloaded 11/24/24 08:17 PM UTC
<<<PAGE=10>>>
Ruth Stewart
556
Cordingley, P , Bell, M, Isham, C, Evans, D, Firth, A, 2007, What do specialists do in 
CPD programmes for which there is evidence of positive outcomes for pupils and 
teachers?, London: EPPI-Centre
Court, J, Y oung, J, 2003, Bridging research and policy: Insights from 50 case studies, ODI 
Working Paper 213, London: Overseas Development Institute 
DFID (Department for International Development), 2011, UK Aid: Changing lives 
delivering results, London: DFID
du T oit, A, 2012,  Making sense of ‘evidence’: Notes on the discursive politics of research and 
pro-poor policy making, Working Paper 21, PLAAS, Cape T own: University of the 
Western Cape
Ellison, G, Wiggins, M, Stewart, R, Thomas, J, 2001, The HIVSA Training Manual, 
London: Social Science Research Unit, Institute of Education, University of London  
Eyben, R, Guijt, I, Roche, C, Shutt, C, Whitty, B, 2013, The politics of evidence, 
Conference Report, Sussex: Institute for Development Studies
Flodgren, G, Rojas-Reyes, MX, Cole, N, Foxcroft, DR, 2012, Effectiveness of 
organisational infrastructures to promote evidence-based nursing practice, Cochrane 
Database of Systematic Reviews, DOI:10.1002/14651858.CD002212.pub2
Frenk, J, Chen L, Bhutta, ZA, Cohen J, Crisp, N, Evans, T, Fineberg, H, 2010, Health 
professionals for a new century: Transforming education to strengthen health systems 
in an interdependent world, The Lancet 376, 9756, 1923–58 
Greenhalgh, T, Robert, G, Macfarlane, F , Bate, P , Kyriakidou, O, 2004, Diffusion of 
innovations in service organizations: Systematic review and recommendations, 
Milbank Quarterly 82, 4, 581–629
Hemsley-Brown, J, Sharp, C, 2003, The use of research to improve professional practice: 
A systematic review, Oxford Review of Education, 29, 4, 449–470
Horsley, T, Hyde, C, Santesso, N, Parkes, J, Milne, R, Stewart, R, 2011, T eaching critical 
appraisal skills in healthcare settings, Cochrane Database of Systematic Review, 9, 11, 
DOI:10.1002/14651858.CD001270.pub2
Jones, H, Jones, N, Shaxson, L, Walker, D, 2013, Knowledge, policy and power in 
international development: A practical framework for improving policy, ODI 
background note, London: Overseas Development Institute
Lavis, JN, Robterson, D, Woodside, JM, McLeod, CB, Abelson, J, 2003, How can 
research organisations more effectively transfer knowledge to decision makers, 
Milbank Quarterly 81, 2, 221–48 
Lipsey, MW , Noonan, E, 2009, Better evidence for a better world, International Initiative 
for Impact Evaluation (3ie), Working Paper 2, New Delhi: 3ie
Mayne, J, Zapico-Goñi, E (eds), 2007, Monitoring performance in the public sector: Future 
directions from international experience, New Jersey: Transaction Publishers
Michie, S, van Stralen, MM, West, R, 2011, The behaviour change wheel: A new 
method for characterising and designing behaviour change interventions, 
Implementation Science 6, 42, DOI: 10.1186/1748-5908-6-42
Milne, BJ, Lay-Y ee, R, McLay, J,  T obias, M, Tuohy, P , Armstrong, A, Lynn, R, Pearson, 
J, Mannion, O, Davies, P , 2014, A collaborative approach to bridging the research-
policy gap through the development of policy advice software, Evidence & Policy 
10, 1, 127-136
Unauthenticated | Downloaded 11/24/24 08:17 PM UTC
<<<PAGE=11>>>
A theory of change for capacity building
557
Murthy, L, Shepperd, S, Clarke, MJ, Garner, SE, Lavis, JN, Perrier, L, Roberts, NW , 
Straus, SE, 2012, Interventions to improve the use of systematic reviews in decision-
making by health system managers, policy makers and clinicians, Cochrane Database 
of Systematic Reviews, 12, 9, DOI:10.1002/14651858.CD009401.pub2
Newman, K, Fisher, C, Shaxson, L, 2012, Stimulating demand for research evidence: 
What role for capacity building, IDS Bulletin 43, 5, 17–24  
Newman, K, Capillo, A, Famurewa, A, Nath, C, Siyanbola, W , 2013, What is the 
evidence on evidence informed policymaking? Lessons from the International Conference on 
Evidence Informed Policy Making, Oxford: International Network for the Availability 
of Scientific Publications (INASP)
NICE (National Institute for Health Care and Excellence), 2007, The most appropriate 
means of generic and specific interventions to support attitude and behaviour 
change at population and community levels, Public Health Guidance 6
Nutley, SM, Walter, I, Davies, HTO, 2007, Using evidence: How research can inform public 
services, Bristol: Policy Press
Stewart, R (ed), 2001, The HIVSA Project Report, London: Social Science Research 
Unit, Institute of Education, University of London
Stewart, R, 2007, Expertise and multi-disciplinary training for evidence-informed 
decision-making, PhD Thesis, University of London
Stewart, R, Oliver, S, 2006, Reviewing the potential for critical appraisal training to 
cater for professional practice, Medical Teacher 28, 2, 74–9
Stewart R, Wiggins, M, Thomas, J, Oliver, S, Brunton, G, Ellison, G, 2005, Exploring 
the evidence-practice gap: A workshop report on mixed and participatory training 
for HIV prevention in southern Africa, Education for Health 18, 2, 224–35
Thorbecke, E, 2013, the interrelationship linking growth, inequality and poverty in 
sub-Saharan Africa, Journal of African Economics 22, 1, 15–48
UNDP (United Nations Development Program), 2013, Equity, inequality, and human 
development in a post-2015 framework, New Y ork: UNDP
Unauthenticated | Downloaded 11/24/24 08:17 PM UTC