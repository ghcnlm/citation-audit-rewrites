<<<PAGE=1>>>
Vol.:(0123456789)
Advances in Health Sciences Education
https://doi.org/10.1007/s10459-018-9837-y
1 3
REVIEW
Training transfer: a systematic review of the impact of inner 
setting factors
Carrie B. Jackson1 · Laurel A. Brabson1 · Lauren B. Quetsch1 · Amy D. Herschell1
Received: 26 December 2017 / Accepted: 1 June 2018 
© Springer Nature B.V. 2018
Abstract
Consistent with Baldwin and Ford’s model (Pers Psychol 41(1):63–105, 1988), training 
transfer is defined as the generalization of learning from a training to everyday practice 
in the workplace. The purpose of this review was to examine the influence of work-envi -
ronment factors, one component of the model hypothesized to influence training trans -
fer within behavioral health. An electronic literature search guided by the Consolidated 
Framework for Implementation Research’s inner setting domain was conducted was con -
ducted on Medline OVID, Medline EMBASE, and PsycINFO databases. Of 9184 unique 
articles, 169 full-text versions of articles were screened for eligibility, yielding 26 articles 
meeting inclusion criteria. Results from the 26 studies revealed that overall, having more 
positive networks and communication, culture, implementation climate, and readiness for 
implementation can facilitate training transfer. Although few studies have examined the 
impact of inner setting factors on training transfer, these results suggest organizational con-
text is important to consider with training efforts. These findings have important implica -
tions for individuals in the broader health professions educational field.
Keywords Training · Implementation science · Inner setting · Evidence-based treatments
Implementation within context
The behavioral health field has experienced significant improvements in recent decades 
with an increasing number of studies devoted to the implementation of evidence-based 
treatments (EBTs) in community settings (Kazdin 2008). Behavioral health refers to a 
wide range of mental health and substance abuse services delivered in a variety of settings, 
including primary care, community mental health clinics, independent providers, hospitals, 
and schools (Reiter et  al. 2018; SAMHSA 2017). Research has now begun to focus on 
identifying contextual influences (i.e., organizational and individual factors) that facilitate 
the implementation of EBTs within these various settings (Novins et  al. 2013). Several 
reviews and conceptual frameworks have highlighted the need to examine implementa -
tion processes in relation to the system in which they are embedded (Glisson and Williams 
 * Carrie B. Jackson 
 cbjackson@mix.wvu.edu
1 West Virginia University, Morgantown, WV, USA
<<<PAGE=2>>>
C. B. Jackson et al.
1 3
2015; Wandersman et al. 2012). Understanding the complex relationships between contex-
tual factors and implementation is an important step in improving the uptake of EBTs in 
usual care.
Training transfer
One factor central to the successful implementation of an innovation within an organiza-
tion is training transfer, or the “degree to which trainees effectively apply the knowledge, 
skills, and attitudes gained in a training context to the job” (Baldwin and Ford 1988, p. 
63). Importantly, while factors impacting the implementation process have previously been 
explored in the literature, none have yet examined how key factors impact training transfer 
in behavioral health settings. Training transfer problems are significant for organizations 
participating in cost- and time-intensive trainings, given that the costs incurred by trainings 
may not improve training transfer (e.g., use of an intervention or client outcomes; Blume 
et al. 2010; Grossman and Salas 2011). While training outcomes are typically evaluated by 
measuring changes in therapist knowledge and skill, examining workplace behavior fol-
lowing training may provide a more direct analysis of the success of a training (Beidas and 
Kendall 2010).
Baldwin and Ford’s training transfer model (1988) hypothesized that the transfer pro-
cess occurs due to three training-input factors: training design, individual trainee charac-
teristics, and work-environment factors. Training design includes the content of training 
and components involved in a training protocol (e.g., controlled experimental settings vs. 
organizational training programs). Individual trainee characteristics include a trainee’s 
demographics, skills, and personality (e.g., age, ability, level of motivation, flexibility). 
Lastly, work-environment factors, commonly considered organizational factors, include 
organizational climate, supervisory support, and opportunities to utilize newly learned 
skills on the job (e.g., perceptions of support for innovative behavior, performance appre-
ciation, attitudes of boss).
Training input factors in behavioral health settings
Considerable progress has been made in studying the training design and individual trainee 
characteristic components of training-input factors (e.g., Harned et  al. 2013; Herschell 
et al. 2010). For example, research on training design suggests that intensive multi-com-
ponent trainings are more effective in improving therapist behavior and client outcomes 
than brief workshops (Beidas et al. 2012; Herschell et al. 2010). Additional research has 
indicated that trainee characteristics, such as years of experience, attitudes towards EBTs, 
and licensure affect transfer (Harned et  al. 2013). Despite consistent findings related to 
training design and trainee characteristics, studies within the field of behavioral health 
have presented conflicting evidence on work-environment factors. While several studies 
have provided support for these factors at promoting training transfer (e.g., Beidas et al. 
2014; Ditty et al. 2015), additional research has concluded that work-environment factors 
are of little importance in comparison to individual trainee characteristics (Harned et al. 
2013). Additionally, a review by Novins et al. (2013) concluded that organizational factors 
require more research to understand their role in the implementation process. Although 
prior research has primarily focused on the importance of training design and individual
<<<PAGE=3>>>
Training transfer: a systematic review of the impact of inner…
1 3
trainee characteristics, examining work-environment factors is important for understanding 
how the training transfer process may occur within a given organization.
Consolidated framework for implementation research
The Consolidated Framework for Implementation Research (CFIR; Damschroder et  al. 
2009) has been used by researchers in an effort to elucidate the study of implementation 
constructs and to more adequately capture the multidimensional nature of implementation 
science (Damschroder et  al. 2009; Damschroder et  al. 2011; Damschroder and Lowery 
2013). Although several conceptual models exist that could have been used to guide the 
current review (e.g., Aarons et al. 2011; Powell et al. 2015), the CFIR was chosen as it 
provides a comprehensive, consistent taxonomy and clearly defined constructs which aid 
in synthesizing implementation studies, and identifying gaps within the current literature. 
Additionally, in a systematic review of instruments assessing CFIR’s domains, Lewis et al. 
(2015) identified measures for the inner setting domain that have demonstrated various lev-
els of psychometric evidence. Therefore, the current review was guided by the CFIR model 
and accompanying instrumentation information from Lewis et al. (2015) in order to inter -
pret the results of included studies included.
The inner setting domain, one of the primary domains included in the CFIR, encom-
passes the work-environment factors hypothesized to influence training transfer and the 
implementation process. The inner setting domain consists of “structural, political, and 
cultural contexts through which the implementation process will proceed” (Damschroder 
et al. 2009, p. 5). Five constructs are included within the inner setting domain: structural 
characteristics, networks and communications, culture, implementation climate, and readi-
ness for implementation (Damschroder et al. 2009). Table 1 provides definitions of each of 
these inner setting constructs and their sub-constructs. Therefore, the current paper explic-
itly examines each of these constructs in an effort to adequately capture the work-environ-
ment factors.
Current review
Although several reviews have evaluated the inner setting domain, reviews have not yet 
examined the relation of these constructs to training transfer (Novins et al. 2013; Powell 
et  al. 2014). Additionally, given the inconsistent findings from previous research on the 
inner setting domain, the goals of this systematic review are to understand how inner set-
ting factors influence training transfer in behavioral health settings, and to identify gaps in 
the current literature that should be addressed.
Method
Search strategy
A systematic review was conducted through an initial search of Psychological 
Abstracts (PsycINFO), Medline EBSCO, and Medline OVID Medline databases. The 
search terms and strategy were developed by all authors. Search terms based upon the
<<<PAGE=4>>>
C. B. Jackson et al.
1 3
inner setting construct, as well as related terms were included. Additionally, the search 
terms were constricted to the field of behavioral and mental health to allow the search 
to be more manageable and increase its relevance to the population of interest. The 
search string utilized was: (readiness for implementation OR structural characteristics 
OR networks and communication OR social networks OR organizational culture OR 
implementation climate OR inner setting OR inner setting factors OR readiness for 
change OR organizational climate) AND (behavioral health OR mental health).
Following the search, titles and abstracts were first screened for eligibility by the 
first author, who is a doctoral student. When articles could not be excluded on the basis 
of a title and abstract screen, full-text versions of the articles were obtained. All of 
the potentially relevant articles identified were then screened for inclusion and exclu-
sion criteria by two of the authors, both of whom are doctoral students. When there 
was disagreement between the authors on if an article met inclusion/exclusion criteria, 
a consensus meeting took place, and disagreements were decided by an independent 
third author with doctoral-level qualifications.
Table 1  Consolidated framework for implementation research inner setting constructs and definitions
Inner setting construct Definition
Structural characteristics Age, maturity, and size
Social architecture, or the clustering of staff members into work groups
Networks and communication Composition and quality of relationships among individual staff members 
and teams across hierarchies
Culture Norms, values, and basic assumptions that govern daily operations
Implementation climate Capacity that an intervention will be fully supported and rewarded within 
an organization
Sub-constructs
 Tension for change-unrest felt by staff to change the current organiza-
tional structure
 Compatibility-perceived fit between administrator values and the integra-
tion of a program within an existing agency structure
 Relative priority-collective importance of implementation
 Organizational incentives and rewards-positive consequences (e.g., 
increased wages)
 Goals and feedback-communicating and providing feedback based on 
overarching goals
 Learning climate-team-oriented atmosphere in which all staff are valued
Readiness for implementation Tangible and immediate indicators of organizational commitment for 
implementation
Sub-constructs
 Leadership engagement-commitment of leaders within an organization
 Available resources-money, training, education, time to support imple-
mentation
 Access to information and knowledge-Information about incorporating 
an innovation is available
<<<PAGE=5>>>
Training transfer: a systematic review of the impact of inner…
1 3
Inclusion criteria
To be incorporated in the current paper, peer-reviewed articles had to include (a) an inner 
setting construct, (b) participants who identified as mental health staff, child welfare work -
ers, or substance abuse service providers, (c) an outcome variable specifically measuring 
generalization of learning to the workplace (e.g., adoption, fidelity, self-reported use), (d) 
primary data, and (e) English language. Articles were excluded if (a) they were unpub-
lished theses or dissertations, abstracts, or review papers, or (b) there was insufficient infor-
mation to determine whether inclusion/exclusion criteria were met. For the current review 
to be as comprehensive as possible, the authors did not include a date restriction on the 
review.
Coding of studies
The coding procedures were developed by CJ, LB, LQ, and AH. A data extraction form 
was developed by CJ, LQ, and LB. The included studies were divided equally by CJ and 
LB and were then coded. Interrater reliability was not coded, but the authors met regularly 
to discuss any questions and discrepancies related to coding.
The included studies were coded according to inner setting factor (e.g., implementation 
climate), measurement of inner setting factor, and training transfer outcome by two of the 
authors. Inner setting factor was coded based on the article’s description of the construct 
studied as it aligns with the CFIR definition, along with information about the assessment 
instrument used to measure this construct. The measurement of the addressed inner set-
ting factors was coded according to the assessment instrument identified by the authors. 
Prior to the review process, the authors discussed training transfer outcomes that captured 
generalization of learning to the workplace (i.e., knowledge, use, adherence to a treatment). 
Service quality and client outcomes were also included, as they serve as proxies for a pro-
vider’s direct behavior. A finite set of training transfer outcomes was not established prior 
to the review process, to allow for flexibility in outcomes examined; however, the authors 
met regularly to discuss whether the outcomes within a study qualified as being relevant to 
training transfer.
Results
Figure 1 displays the results of the literature search process. The initial search yielded 9184 
articles, from which 5736 titles and abstracts were screened, 169 full-text versions of arti-
cles were examined, yielding 26 articles meeting inclusion criteria.
Several articles included in the review addressed multiple inner setting constructs 
within the same study: six articles focused on structural characteristics (Bride et al. 2011; 
Ditty et al. 2015; Nelson and Steele 2007; Schoenwald et al. 2003, 2008, 2009), three on 
networks and communication (Cook et  al. 2015; Ditty et  al. 2015; Hanbury 2013), six 
on culture (Bonham et  al.  2014a, b; Bride et  al. 2011; Glisson et  al. 2008; Glisson and 
Green 2011; Green et al. 2014; Patterson Silver Wolf 2015), eight on implementation cli-
mate (Cook et al. 2015; Glisson and Hemmelgarn 1998; Muilenburg et al. 2014; Schoen-
wald et al. 2003, 2008, 2009; Taxman et al. 2008), and 13 on readiness for implementation 
(Adler et al. 2014; Asgary-Eden and Lee 2012; Beidas et al. 2014; Bonham et al. 2014a, b;
<<<PAGE=6>>>
C. B. Jackson et al.
1 3
Cook et al. 2015; Gifford et al. 2015; Green et al. 2014; Greener et al. 2007; Hamblen et al. 
2015; Harned et al. 2013; Lewis and Simons 2011; Lundgren et al. 2013; Mancini et al. 
2009). These studies examined a variety of training transfer outcomes with several studies 
including more than one training transfer outcome. Fifteen studies analyzed the use of an 
intervention, eight assessed fidelity, five evaluated client outcomes, three examined service 
quality, and two focused on penetration. Table  2 presents the identified articles and their 
inner setting construct and training transfer outcomes. Table  3 details how each inner set-
ting construct was measured in the included studies, according to the article’s description 
of measures.
Records after duplicates 
removed
(n = 5736)
ScreeningIncluded Eligibility Identification
Abstractss creened
(n = 5736)
Records excluded
(n = 5567)
Full-text articles 
assessed for eligibility
(n = 169)
Full-text articles 
excluded, with reasons
(n =1 43)
• Not generalization to 
workplace measure
(n = 76)
• Not behavioral health 
(n = 31)
• Review paper( n = 26)
• No inner setting 
variable (n = 8)
• Study protocol (n = 2)
Studies included in 
review
(n = 26)
Medline
(n = 7611)
PsycINFO
(n = 1573)
Fig. 1  PRISMA diagram depicted systematic search process
<<<PAGE=7>>>
Training transfer: a systematic review of the impact of inner…
1 3
Table 2  Inner setting constructs and training transfer outcomes measured across articles
Article Inner setting construct Outcomes
Structure Networks and 
communication
Culture Implementa-
tion climate
Readiness for 
implementation
Client outcomes Fidelity Penetration Service quality Use
Adler et al. (2014) X X
Asgary-Eden and Lee (2012) X X X
Beidas et al. (2014) X
a X
Bonham et al. (2014a, b) X X X
Bride et al. (2011) X X X
Cook et al. (2015) X X X X
Ditty et al. (2015) X X X X X
Gifford et al. (2015) X X X
Glisson and Green (2011) X Xa
Glisson and Hemmelgarn (1998) X X Xa
Glisson et al. (2008) X X
Green et al. (2014) X X X
Greener et al. (2007) X X
Hamblen et al. (2015) X X
Hanbury (2013) X X X
Harned et al. (2013) X Xa X
Lewis and Simons (2011) X X
Lundgren et al. (2013) X X
Mancini et al. (2009) X Xa
Muilenburg et al. (2014) X X
Nelson and Steele (2007) X X
Patterson Silver Wolf (2015) X Xa
Schoenwald et al. (2003) X X X X
<<<PAGE=8>>>
C. B. Jackson et al.
1 3
Table 2  (continued)
Article Inner setting construct Outcomes
Structure Networks and 
communication
Culture Implementa-
tion climate
Readiness for 
implementation
Client outcomes Fidelity Penetration Service quality Use
Schoenwald et al. (2008) X X X X
Schoenwald et al. (2009) X X X X
Taxman et al. (2008) X X
a
a Indicates this outcome was measured by an independent third rater
<<<PAGE=9>>>
Training transfer: a systematic review of the impact of inner…
1 3
Table 3  Measurement of inner setting constructs across included studies
Inner setting construct Measure Articles
Structure Participation in decision making (Hage and Aiken 1967); hierarchy of authority (Hall 1963); 
procedural and rule specification (Hall 1963)
Schoenwald et al. (2003)
Schoenwald et al. (2008)
Schoenwald et al. (2009)
Study-developed measure Bride et al. (2011)
Ditty et al. (2015)
Nelson and Steele (2007)
Networks and communications Organizational readiness for change-cohesion and communication (Lehman et al. 2002) Ditty et al. (2015)
Study-developed measure Cook et al. (2015)
Ditty et al. (2015)
Hanbury (2013)
Culture Children services survey Bonham et al. (2014a, b)
Green et al. (2014)
Organizational social context (Glisson et al. 2008) Glisson et al. (2008)
Glisson and Green (2011)
Patterson Silver Wolf (2015)
Study-developed measure Bride et al. (2011)
Taxman et al. (2008)
Implementation climate Psychological climate questionnaire Schoenwald et al. (2003)
Schoenwald et al. (2008)
Schoenwald et al. (2009)
Study-developed measure Cook et al. (2015)
Muilenburg et al. (2014)
<<<PAGE=10>>>
C. B. Jackson et al.
1 3
Table 3  (continued)
Inner setting construct Measure Articles
Readiness for implementation Multifactor leadership questionnaire Bonham et al. (2014a, b)
Green et al. (2014)
Organizational readiness for change (Lehman et al. 2012) Asgary-Eden and Lee (2012)
Beidas et al. (2014)
Gifford et al. (2015)
Greener et al. (2007)
Lewis and Simons (2011)
Lundgren et al. (2013)
Study developed measure Adler et al. (2014)
Cook et al. (2015)
Hamblen et al. (2015)
Harned et al. (2013)
Mancini et al. (2009)
<<<PAGE=11>>>
Training transfer: a systematic review of the impact of inner…
1 3
Structural characteristics
Structural characteristics include “the social architecture, age, maturity, and size of an 
organization” (Damschroder et al. 2009, p. 7). Six articles included in the current review 
examined various structural characteristics (Bride et al. 2011; Ditty et al. 2015; Nelson and 
Steele 2007; Schoenwald et  al. 2003, 2008, 2009). Structural characteristics were meas-
ured according to organization type (e.g., outpatient), clinical setting (e.g., university), 
and size of organization through the Participation in Decision Making measure (Hage and 
Aiken 1967), Hierarchy of Authority measure (Hall 1963), Procedural and Rule Specifica-
tion measure (Hall 1963), and study-developed measures. The included articles assessed 
a variety of training outcomes including fidelity, self-reported use, penetration, and client 
outcomes. Five of the six included studies did not find significant associations between 
structural characteristics and the aforementioned outcomes. Three studies noted that, while 
structure was related to client outcomes, this association was no longer significant when 
therapist fidelity was included in the model. Additionally, structure was not significantly 
related to fidelity in these studies (Schoenwald et al. 2003, 2008, 2009). One study found 
that structural characteristics such as a large team size and stand-alone programs reported 
significantly higher use of Dialectical-Behavior Therapy than organizations with smaller 
team sizes and teams nested within an organization (Ditty et al. 2015).
Networks and communication
Networks and communications is the CFIR inner setting factor that addresses the composi-
tion and quality of relationships among individual staff members and teams, and across 
hierarchies (Damschroder et al. 2009). Three articles in the current review analyzed net-
works and communication (Cook et al. 2015; Ditty et al. 2015; Hanbury 2013). Two of 
the included articles assessed the quality of networks (Cook et al. 2015; Ditty et al. 2015), 
while one of the articles assessed the quantity of networks (e.g., number of contacts with 
team members; Hanbury 2013). Study-developed measures and the Organizational Readi-
ness for Change-Cohesion and Communication subscale (Lehman et  al. 2002) were uti-
lized to identify if networks and communication had an effect on self-reported use of an 
intervention. These studies found quantitative evidence that quantity and quality of net-
works and communication were significantly associated with self-reported use. Qualitative 
evidence further supported the importance of strong teams and communication skills in 
influencing use of an intervention, with individuals reporting on the importance of relying 
on team members who also utilize the newly adopted intervention (Cook et al. 2015; Ditty 
et al. 2015).
Culture
Organizational culture is defined as the “norms, values, and basic assumptions” that 
govern daily operations (Damschroder et al. 2009, p. 8). Six articles in the current study 
examined organizational culture (Bonham et al.  2014a, b; Bride et al. 2011; Glisson and 
Green 2011; Glisson et al. 2008; Green et al. 2014; Patterson Silver Wolf 2015). Organi-
zational culture was measured utilizing the Child Services Survey (Glisson 2002), the
<<<PAGE=12>>>
C. B. Jackson et al.
1 3
Organizational Social Context measure (Glisson et al. 2008), and study-developed meas-
ures. The included studies assessed several training transfer outcomes including client out-
comes, service quality, and use. Five of the six studies found that a positive organizational 
culture was associated with greater training transfer according to client outcomes, service 
quality, or use (Bonham et al. 2014a, b; Bride et al. 2011; Glisson and Green 2011; Glisson 
et al. 2008; Green et al. 2014). Additionally, one study found that positive culture was asso-
ciated with greater long-term transfer, with higher sustainability rates (Glisson et al. 2008). 
One study also found that culture mediated the relationships between leadership, an aspect 
of readiness for implementation, and service quality (Green et al. 2014). While a majority 
of these studies found that culture was related to training transfer, one study did not find 
a significant relation between culture and use of an alcohol screening and substance use 
intervention (Patterson Silver Wolf 2015).
Implementation climate
Implementation climate is the capacity that an intervention will be fully supported and 
rewarded within an organization (Damschroder et al. 2009). Refer to Table  1 for informa-
tion about implementation climate’s sub-constructs including tension for change, compat-
ibility, relative priority, organizational incentives and rewards, goals and feedback, and 
learning climate. The current review identified seven studies that examined implementa-
tion climate (Cook et al. 2015; Glisson and Hemmelgarn 1998; Muilenburg et al. 2014; 
Schoenwald et  al. 2003, 2008, 2009; Taxman et  al. 2008). Implementation climate was 
assessed using the Psychological Climate Measure (James and Sells 1981) and study-
developed measures. These studies also examined several training transfer outcomes such 
as use, fidelity, and service quality. In all of these studies, implementation climate was 
significantly related to at least one of the training transfer outcome measures examined. 
For example, organizations with a positive implementation climate (e.g., high degree of 
compatibility, incentives and rewards) reported greater use, fidelity, and service quality. In 
three of these studies, implementation climate was not only related to fidelity, but also to 
client outcomes (Schoenwald et al. 2003, 2008, 2009). Qualitative evidence further sup-
ported the compatibility sub-construct of implementation climate, with providers perceiv -
ing the degree of fit of an intervention as an important factor in its use (Cook et al. 2015).
Readiness for implementation
Readiness for implementation, according to the CFIR, encompasses “tangible and immedi-
ate indicators of organizational commitment to its decision to implement an intervention” 
(Damschroder et al. 2009, p. 9). This review identified 13 articles examining the readiness 
for implementation construct that met inclusion and exclusion criteria (Adler et al. 2014; 
Asgary-Eden and Lee 2012; Beidas et al. 2014; Bonham et al.  2014a, b; Cook et al. 2015; 
Gifford et al. 2015; Green et al. 2014; Greener et al. 2007; Hamblen et al. 2015; Harned 
et al. 2013; Lewis and Simons 2011; Lundgren et al. 2013; Mancini et al. 2009). Readi-
ness for implementation was measured using the Multifactor Leadership Questionnaire 
(Bass and Avolio 1995), Texas Christian University-Organizational Readiness for Change 
(Institute of Behavioral Research, 2009), study-developed measures, and qualitative meth-
ods. Training transfer outcomes included fidelity, service quality, and use. Eleven of these
<<<PAGE=13>>>
Training transfer: a systematic review of the impact of inner…
1 3
articles found evidence in support of readiness for implementation on at least one training 
transfer outcomes, while two articles (Beidas et al. 2014; Cook et al. 2015) found that read-
iness for implementation was not related to training transfer. These articles studied several 
of the sub-constructs of readiness for implementation. The included studies cited training, 
adequate resources, adequate time, supervision, and leadership as being important factors 
related to training transfer. Qualitative results also supported these findings indicating that 
having available educational resources, such as treatment manuals, was important to imple-
mentation (Bonham et al. 2014a, b).
Discussion
The purpose of this review was to identify inner setting factors that may influence the 
effectiveness of trainings in behavioral health settings. Overall, our review found that rela-
tively little research has been conducted on the influence of work-environment factors on 
training transfer outcomes. Across numerous disciplines relevant to training transfer (e.g., 
adult learning, human resources), work-environment factors remain relatively understud-
ied. Despite the limited literature, our review found that work-environment factors have 
a significant impact on training effectiveness and should be considered during training 
development.
Our analysis of inner setting factors led to several conclusions. Importantly, a majority 
of studies included in the review suggest that positive organizational characteristics may 
be essential to training transfer, similar to findings from other fields (Tabak et al. 2012). 
Across studies, having higher quality networks and communication, more positive organi-
zational culture, implementation climate, and readiness for implementation were associ-
ated with a greater likelihood of training transfer. These results suggest that, when a cli-
nician feels supported by their organization, they are more likely to use a newly-learned 
intervention. Importantly, while many training models primarily target clinicians, it may 
help facilitate the effects of a training by also targeting organizational factors.
Articles included in this review did not support the impact of organizational structure 
on training transfer. This finding suggests organizations of varying sizes and types (e.g., 
private practice, community mental health, hospital) may be equally likely to have provid-
ers that use newly learned skills from a training. In combination with the positive findings 
of this review, it may be that more changeable aspects of an organization have a greater 
impact than the fixed organizational structure on training transfer. Organizational inter -
ventions, such as the Availability, Continuity, Response model, have been developed to 
address organizational barriers by improving the fit between an intervention and the con-
text in which it is implemented (Glisson and Schoenwald 2005). The use of such organiza-
tional interventions may be helpful in facilitating training transfer by simultaneously train-
ing direct service providers and reducing organizational barriers that prohibit the use of an 
intervention.
The results of this review have highlighted important measurement issues that are 
important to consider in the context of this review (Martinez et  al. 2014). This review 
found that training transfer is not a commonly studied outcome, and is often measured by 
clinician self-report. Although training transfer may be more difficult to examine than other 
types of training outcomes (e.g., knowledge and skill), accurate measurement of training 
transfer including direct observation of behavior is particularly pertinent to implementa-
tion science. This is important given that other fields have found a disconnect between
<<<PAGE=14>>>
C. B. Jackson et al.
1 3
post-training learning and actual behavior, with research suggesting that only 10% of 
knowledge acquired during a training is applied in the workplace (Grossman and Salas 
2011). Similarly, a meta-analysis of the effectiveness of trainings found a correlation 
between knowledge and transfer of only .22, and that the effect sizes associated with train-
ings were significantly reduced when workplace behavior was used as an outcome (Arthur 
et al. 2003; Grossman and Salas 2011). Given data from other fields, further research in 
behavioral health settings should examine the concordance between measurement of post-
training learning and workplace behavior as well as identify feasible measures of training 
transfer.
The current review has several strengths that contribute to a growing body of research 
on the contextual factors that influence implementation. Importantly, this review has high-
lighted the lack of research on inner setting factors and training transfer. Although the inner 
setting domain has a strong theoretical basis, this review was only able to identify 26 arti-
cles that met inclusion/exclusion criteria. Another strength of the current review is the use 
of the CFIR as a meta-theoretical framework to address these measurement and conceptual 
issues through clearly operationalized constructs (Damschroder et al. 2009). Utilizing this 
framework, the authors were able to identify areas of the inner setting that have previously 
been studied. Additionally, this review’s inclusion of the measurement of inner setting fac-
tors has revealed measurement issues in this area of study that should be considered in 
future research.
Although this review has several strengths, it also has notable limitations. The primary 
limitation of this review is the overall paucity of articles meeting inclusion/exclusion cri-
teria. The initial search yielded a large number of studies; however, many of these articles 
were excluded on the basis of lacking a training transfer outcome. Second, there was con-
siderable variability in the methodological rigor of the included studies. Although we did 
not directly assess the rigor of the included studies, there were significant methodological 
flaws in many of the included studies. Specifically, a large amount of the included studies 
used study-developed measures which lack psychometric evidence, and self-reported meas-
ures of training transfer. More methodologically-rigorous research studies that incorporate 
behavioral observations and assessment instruments with adequate psychometric evidence 
should be used to sufficiently capture the variety of inner setting constructs defined by the 
CFIR. Third, while the use of the CFIR strengthened the operationalization of the con-
structs in the review, the CFIR is only one of several theoretical frameworks that could 
have been chosen. Similar to other theoretical frameworks in implementation science, the 
CFIR has not yet been fully established empirically (Powell et al. 2014). Further, the use 
of the CFIR may have constricted the results of the current review, as it was limited to the 
terms defined by this framework. However, utilizing the CFIR as a framework for the pre-
sent review aided in understanding the current state of research.
In conclusion, the results of this review have drawn attention to an important area for 
further research, and the findings have important implications for organizations, train-
ers, and researchers involved in educating health professionals. This research is impor -
tant to organizations, given that the time and money invested in trainings may not reap 
the expected benefits of improved provider behavior and client outcomes. Similarly, 
trainers may need to consider these inner setting factors prior to initiating training, and 
engage in efforts to improve an organization’s readiness for training and implementation. 
As mentioned previously, the Availability, Responsiveness and Continuity intervention 
(ARC), which has demonstrated positive effects in supporting organizational implementa-
tion of EBTs is one method that may be beneficial to organizations (Glisson and Schoen-
wald 2005). If it is found that inner setting factors do significantly impact training transfer,
<<<PAGE=15>>>
Training transfer: a systematic review of the impact of inner…
1 3
interventions such as ARC might be a promising mechanism to facilitate training transfer. 
Further addressing this gap in research may be an important step in understanding addi-
tional factors that facilitate training transfer, and ultimately in improving the training of 
health professionals and provision of EBTs.
References
Aarons, G. A., Hurlburt, M., & Horwitz, S. M. (2011). Advancing a conceptual model of evidence-based 
practice implementation in public service sectors. Administration and Policy in Mental Health and 
Mental Health Services Research, 38(1), 4–23. https ://doi.org/10.1007/s1048 8-010-0327-7.
Adler, G., Pritchett, L. R., Kauth, M. R., & Nadorff, D. (2014). A pilot project to improve access to telepsy-
chotherapy at rural clinics. Telemedicine Journal and E-Health: The Official Journal of the American 
Telemedicine Association, 20(1), 83–85. https ://doi.org/10.1089/tmj.2013.0085.
Arthur, W., Jr., Bennett, W., Jr., Edens, P. S., & Bell, S. T. (2003). Effectiveness of training in organizations: 
A meta-analysis of design and evaluation features. Journal of Applied Psychology, 88(2), 234–245. 
https ://doi.org/10.1037/0021-9010.88.2.234.
Asgary-Eden, V., & Lee, C. M. (2012). Implementing an evidence-based parenting program in community 
agencies: What helps and what gets in the way? Administration and Policy in Mental Health and Men-
tal Health Services Research, 39(6), 478–488. https ://doi.org/10.1007/s1048 8-011-0371-y.
Baldwin, T. T., & Ford, J. K. (1988). Transfer of training: A review and directions for future research. Per -
sonnel Psychology, 41(1), 63–105.
Bass, B., & Avolio, B. (1995). MLQ multifactor leadership questionnaire. Menlo Park: Mind Garden.
Beidas, R. S., Edmunds, J., Ditty, M., Watkins, J., Walsh, L., Marcus, S., et al. (2014). Are inner context 
factors related to implementation outcomes in cognitive-behavioral therapy for youth anxiety? Admin-
istration and Policy in Mental Health and Mental Health Services Research. https ://doi.org/10.1007/
s1048 8-013-0529-x.
Beidas, R. S., Edmunds, J. M., Marcus, S. C., & Kendall, P. C. (2012). Training and consultation to pro-
mote implementation of an empirically supported treatment: A randomized trial. Psychiatric Services, 
63(7), 660–665. https ://doi.org/10.1176/appi.ps.20110 0401.
Beidas, R. S., & Kendall, P. C. (2010). Training therapists in evidence-based practice: A critical review 
of studies from a systems-contextual perspective. Clinical Psychology: Science and Practice, 17(1), 
1–30. https ://doi.org/10.1111/j.1468-2850.2009.01187 .x.
Blume, B. D., Ford, J. K., Baldwin, T. T., & Huang, J. L. (2010). Transfer of training: A meta-analytic. 
Review.. https ://doi.org/10.1177/01492 06309 35288 0.
Bonham, C. A., Sommerfeld, D., Willging, C., & Aarons, G. A. (2014a). Organizational factors influenc-
ing implementation of evidence-based practices for integrated treatment in behavioral health agencies. 
Psychiatry Journal. https ://doi.org/10.1155/2014/80298 3.
Bonham, C. A., Sommerfeld, D., Willging, C., & Aarons, G. A. (2014b). Organizational factors influenc-
ing implementation of evidence-based practices for integrated treatment in behavioral health agencies. 
Psychiatry Journal, 2014, 802983. https ://doi.org/10.1155/2014/80298 3.
Bride, B. E., Abraham, A. J., & Roman, P. M. (2011). Organizational factors associated with the use of 
contingency management in publicly funded substance abuse treatment centers. Journal of Substance 
Abuse Treatment, 40(1), 87–94. https ://doi.org/10.1016/j.jsat.2010.08.001.
Cook, J. M., Dinnen, S., Coyne, J. C., Thompson, R., Simiola, V., Ruzek, J., et al. (2015). Evaluation of an 
implementation model: A national investigation of VA residential programs. Administration and Policy 
in Mental Health and Mental Health Services Research, 42(2), 147–156. https ://doi.org/10.1007/s1048 
8-014-0555-3.
Damschroder, L. J., Aron, D. C., Keith, R. E., Kirsh, S. R., Alexander, J. A., & Lowery, J. C. (2009). Foster-
ing implementation of health services research findings into practice: A consolidated framework for 
advancing implementation science. Implementation Science. https ://doi.org/10.1186/1748-5908-4-50.
Damschroder, L. J., Goodrich, D. E., Robinson, C. H., Fletcher, C. E., & Lowery, J. C. (2011). A systematic 
exploration of differences in contextual factors related to implementing the MOVE! weight manage-
ment program in VA: A mixed methods study. BMC Health Services Research, 11, 248. https ://doi.
org/10.1186/1472-6963-11-248.
<<<PAGE=16>>>
C. B. Jackson et al.
1 3
Damschroder, L. J., & Lowery, J. C. (2013). Evaluation of a large-scale weight management program using the 
consolidated framework for implementation research (CFIR). Implementation Science, 8(1), 51. https ://
doi.org/10.1186/1748-5908-8-51.
Ditty, M. S., Landes, S. J., Doyle, A., & Beidas, R. S. (2015). It takes a village: A mixed method analysis 
of inner setting variables and dialectical behavior therapy implementation. Administration and Policy In 
Mental Health, 42(6), 672–681. https ://doi.org/10.1007/s1048 8-014-0602-0.
Gifford, E., Tavakoli, S., Wisdom, J., & Hamlett-Berry, K. (2015). Implementation of smoking cessation treat-
ment in VHA substance use disorder residential treatment programs. Psychiatric Services, 66(3), 295–
302. https ://doi.org/10.1176/appi.ps.20140 0008.
Glisson, C. (2002). The organizational context of children’s mental health services. Clinical Child and Family 
Psychology Review, 5(4), 233–253.
Glisson, C., & Green, P. (2011). Organizational climate, services, and outcomes in child welfare systems. Child 
Abuse and Neglect, 35(8), 582–591. https ://doi.org/10.1016/j.chiab u.2011.04.009.
Glisson, C., & Hemmelgarn, A. (1998). The effects of organizational climate and interorganizational coordina-
tion on the quality and outcomes of children’s service systems. Child Abuse and Neglect, 22(5), 401–421.
Glisson, C., & Schoenwald, S. K. (2005). The ARC organizational and community intervention strategy for 
implementing evidence-based children’s mental health treatments. Mental Health Services Research, 7(4), 
243–259.
Glisson, C., Schoenwald, S. K., Kelleher, K., Landsverk, J., Hoagwood, K. E., & Mayberg, S. (2008). Therapist 
turnover and new program sustainability in mental health clinics as a function of organizational culture, 
climate, and service structure. Administration and Policy In Mental Health, 35(1–2), 124–133. https ://doi.
org/10.1007/s1048 8-007-0152-9.
Glisson, C., & Williams, N. J. (2015). Assessing and changing organizational social contexts for effective men-
tal health services. Annual Review of Public Health, 36(1), 507–523. https ://doi.org/10.1146/annur ev-
publh ealth -03191 4-12243 5.
Green, A. E., Albanese, B. J., Cafri, G., & Aarons, G. A. (2014). Leadership, organizational climate, and work-
ing alliance in a children’s mental health service system. Community Mental Health Journal, 50(7), 771–
777. https ://doi.org/10.1007/s1059 7-013-9668-5.
Greener, J. M., Joe, G. W., Simpson, D. D., Rowan-Szal, G. A., & Lehman, W. E. K. (2007). Influence of organ-
izational functioning on client engagement in treatment. Journal of Substance Abuse Treatment, 33(2), 
139–147. https ://doi.org/10.1016/j.jsat.2006.12.025.
Grossman, R., & Salas, E. (2011). The transfer of training: What really matters. International Journal of Train-
ing and Development, 15(2), 103–120. https ://doi.org/10.1111/j.1468-2419.2011.00373 .x.
Hage, J., & Aiken, M. (1967). Relationship of centralization to other structural properties. Administrative Sci-
ence Quarterly, 12, 72–92.
Hall, R. H. (1963). The concept of bureaucracy: An empirical assessment. American Journal of Sociology, 
69(1), 32–40.
Hamblen, J. L., Bernardy, N. C., Sherrieb, K., Norris, F. H., Cook, J. M., Louis, C. A., et al. (2015). VA PTSD 
clinic director perspectives: How perceptions of readiness influence delivery of evidence-based PTSD 
treatment. Professional Psychology: Research and Practice, 46(2), 90–96. https ://doi.org/10.1037/a0038 
535.
Hanbury, A. (2013). The relative influence of team climate, team norms and social network norms on health 
professionals’ implementation of a national recommendation to offer service-users diagnosed with schiz-
ophrenia family intervention therapy. Psychology, Health and Medicine, 18(5), 619–625. https ://doi.
org/10.1080/13548 506.2013.76445 9.
Harned, M. S., Dimeff, L. A., Woodcock, E. A., & Contreras, I. (2013). Predicting adoption of exposure therapy 
in a randomized controlled dissemination trial. Journal of Anxiety Disorders, 27(8), 754–762. https ://doi.
org/10.1016/j.janxd is.2013.02.006.
Herschell, A. D., Kolko, D. J., Baumann, B. L., & Davis, A. C. (2010). The role of therapist training in the 
implementation of psychosocial treatments: A review and critique with recommendations. Clinical Psy-
chology Review, 30(4), 448–466. https ://doi.org/10.1016/j.cpr.2010.02.005.
James, L. R., & Sells, S. B. (1981). Psychological climate: Theoretical perspectives and empirical research. In: 
Toward a psychology of situations: An interactional perspective, pp. 275–295.
Kazdin, A. E. (2008). Evidence-based treatment and practice: New opportunities to bridge clinical research 
and practice, enhance the knowledge base, and improve patient care. The American Psychologist, 63(3), 
146–159. https ://doi.org/10.1037/0003-066X.63.3.146.
Lehman, W. E., Greener, J. M., Rowan-Szal, G. A., & Flynn, P. M. (2012). Organizational readiness for change 
in correctional and community substance abuse programs. Journal of Offender Rehabilitation, 51(1–2), 
96–114.
Lehman, W. E. K., Greener, J. M., & Simpson, D. D. (2002). Assessing organizational readiness for change. 
Journal of Substance Abuse Treatment, 22(4), 197–209. https ://doi.org/10.1016/S0740 -5472(02)00233 -7.
<<<PAGE=17>>>
Training transfer: a systematic review of the impact of inner…
1 3
Lewis, C. C., & Simons, A. D. (2011). A pilot study disseminating cognitive behavioral therapy for depres-
sion: Therapist factors and perceptions of barriers to implementation. Administration and Policy in 
Mental Health and Mental Health Services Research, 38(4), 324–334. https ://doi.org/10.1007/s1048 
8-011-0348-x.
Lewis, C. C., Stanick, C. F., Martinez, R. G., Weiner, B. J., Kim, M., Barwick, M., et al. (2015). The society 
for implementation research collaboration instrument review project: A methodology to promote rigorous 
evaluation. Implementation Science, 10(1), 2. https ://doi.org/10.1186/s1301 2-014-0193-x.
Lundgren, L., Amodeo, M., Chassler, D., Krull, I., & Sullivan, L. (2013). Organizational readiness for change 
in community-based addiction treatment programs and adherence in implementing evidence-based prac-
tices: A national study. Journal of Substance Abuse Treatment, 45(5), 457–465. https ://doi.org/10.1016/j.
jsat.2013.06.007.
Mancini, A. D., Moser, L. L., Whitley, R., McHugo, G. J., Bond, G. R., Finnerty, M. T., et al. (2009). Assertive 
community treatment: Facilitators and barriers to implementation in routine mental health settings. Psy-
chiatric Services, 60(2), 189–195. https ://doi.org/10.1176/appi.ps.60.2.189.
Martinez, R. G., Lewis, C. C., & Weiner, B. J. (2014). Instrumentation issues in implementation science. Imple-
mentation Science, 9, 118. https ://doi.org/10.1186/s1301 2-014-0118-8.
Muilenburg, J. L., Laschober, T. C., & Eby, L. T. (2014). Organizational factors as predictors of tobacco ces-
sation pharmacotherapy adoption in addiction treatment programs. Journal of Addiction Medicine, 8(1), 
59–65. https ://doi.org/10.1097/ADM.00000 00000 00000 8.
Nelson, T. D., & Steele, R. G. (2007). Predictors of practitioner self-reported use of evidence-based prac-
tices: practitioner training, clinical setting, and attitudes toward research. Administration and Policy 
in Mental Health and Mental Health Services Research, 34(4), 319–330. https ://doi.org/10.1007/s1048 
8-006-0111-x.
Novins, D. K., Green, A. E., Legha, R. K., & Aarons, G. A. (2013). Dissemination and implementation of 
evidence-based practices for child and adolescent mental health: A systematic review. Journal of the 
American Academy of Child and Adolescent Psychiatry, 52(10), 1009–1025. https ://doi.org/10.1016/j.
jaac.2013.07.012.
Patterson Silver Wolf, D. A. (2015). Factors influencing the implementation of a brief alcohol screening and 
educational intervention in social settings not specializing in addiction services. Social Work in Health 
Care, 54(4), 345–364. https ://doi.org/10.1080/00981 389.2015.10052 70.
Powell, B. J., Proctor, E. K., & Glass, J. E. (2014). A systematic review of strategies for implementing empiri-
cally supported mental health interventions. Research on Social Work Practice, 24(2), 192–212.
Powell, B. J., Waltz, T. J., Chinman, M. J., Damschroder, L. J., Smith, J. L., Matthieu, M. M., et al. (2015). 
A refined compilation of implementation strategies: Results from the expert recommendations for 
implementing change (ERIC) project. Implementation Science, 10(1), 21. https ://doi.org/10.1186/s1301 
2-015-0209-1.
Reiter, J. T., Dobmeyer, A. C., & Hunter, C. L. (2018). The primary care behavioral health (PCBH) model: An 
overview and operational definition. Journal of Clinical Psychology in Medical Settings, 25, 109–126. 
(online access).
Schoenwald, S. K., Carter, R. E., Chapman, J. E., & Sheidow, A. J. (2008). Therapist adherence and organiza-
tional effects on change in youth behavior problems one year after multisystemic therapy. Administration 
and Policy In Mental Health, 35(5), 379–394. https ://doi.org/10.1007/s1048 8-008-0181-z.
Schoenwald, S. K., Chapman, J. E., Sheidow, A. J., & Carter, R. E. (2009). Long-term youth criminal outcomes 
in MST transport: The impact of therapist adherence and organizational climate and structure. Journal of 
Clinical Child and Adolescent Psychology, 38(1), 91–105. https ://doi.org/10.1080/15374 41080 25753 88.
Schoenwald, S. K., Sheidow, A. J., Letourneau, E. J., & Liao, J. G. (2003). Transportability of multisystemic 
therapy: Evidence for multilevel influences. Mental Health Services Research, 5(4), 223–239.
Substance Abuse and Mental Health Services Administration [SAMHSA]. (2017). Behavioral health treatments 
and services. Retrieved from https ://www.samhs a.gov/treat ment. Accessed 17 May 2018.
Tabak, R. G., Khoong, E. C., Chambers, D. A., & Brownson, R. C. (2012). Bridging research and practice: 
Models for dissemination and implementation research. American Journal of Preventive Medicine, 43(3), 
337–350.
Taxman, F. S., Cropsey, K. L., Melnick, G., & Perdoni, M. L. (2008). COD services in community correctional 
settings: An examination of organizational factors that affect service delivery. Behavioral Sciences & the 
Law, 26(4), 435–455. https ://doi.org/10.1002/bsl.830.
Wandersman, A., Chien, V. H., & Katz, J. (2012). Toward an evidence-based system for innovation support 
for implementing innovations with quality: tools, training, technical assistance, and quality assurance/
quality improvement. American Journal of Community Psychology, 50(3–4), 445–459. https ://doi.
org/10.1007/s1046 4-012-9509-7.