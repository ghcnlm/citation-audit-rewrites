<<<PAGE=1>>>
http://www.aejonline.org Open Access
African Evaluation Journal  
ISSN: (Online) 2306-5133, (Print) 2310-4988
Page 1 of 12 Original Research
Read online:
Scan this QR 
code with your 
smart phone or 
mobile device 
to read online.
Authors:
Takunda Chirau1 
Ayabulela Dlakavu1,2 
Banele Masilela1,3 
Affiliations:
1Centre for Learning on 
Evaluation and Results – 
Anglophone Africa  
(CLEAR-AA), Faculty of 
Commerce, Law and 
Management, University 
of the Witwatersrand, 
Johannesburg, South Africa
2Department of Politics and 
International Relations, 
Faculty of Humanities, 
University of Johannesburg, 
Johannesburg, South Africa
3Department of Social 
Development, Gauteng 
Provincial Government, 
Johannesburg, South Africa
Corresponding author:
Ayabulela Dlakavu,
ayabulela.dlakavu@wits.ac.za
Dates:
Received: 06 Dec. 2021
Accepted: 24 Mar. 2022
Published: 28 Apr. 2022
How to cite this article:
Chirau, T., Dlakavu, A. & 
Masilela, B., 2022, 
‘Strengthening Anglophone 
Africa M&E systems: A 
CLEAR-AA perspective 
on guiding principles, 
challenges and emerging 
lessons’, African Evaluation 
Journal 10(1), a601. https://
doi.org/10.4102/aej.
v10i1.601
Introduction and context
The Centre for Learning on Evaluation and Results – Anglophone Africa (CLEAR-AA) is one of 
the six regional centres housed at academic institutions across the globe. The other CLEAR centres 
are in Senegal, Mexico, India, China and Brazil and are supported by the CLEAR global Initiative 
in Washington, DC. From 2011, CLEAR-AA has been working in English speaking African 
countries to strengthen various elements of monitoring and evaluation (M&E) systems – for 
example, developing M&E plans, national M&E policy, evaluation plan, evaluation guidelines 
and offering different kinds of training. The Centre’s guiding proposition (as reﬂected in its 
organisational Theory of Change) is that strengthening M&E leads to good governance, 
transparency and accountability for governments and public institutions by fostering a culture of 
evidence-based decision-making, which is an important contributor to improved service 
delivery and improved development outcomes. The paper explores the prevalent evaluation 
capacity development (ECD) practices worldwide and the African region and then situates 
CLEAR-AA’s own approach to ECD. Through this reﬂective exercise, as a further contribution 
Background: Evaluation capacity development (ECD) is evolving to adapt to 21st century 
governance and development contexts across the world. Consequently, the ECD community is 
seized with processes of developing, implementing and sharing best ECD practices that are 
able to build strong and resilient individual and institutional M&E capacities.
Objectives: The article seeks to contribute to the on-going discourse and practice 
regarding evaluation capacity development (ECD) approaches and interventions in 
Anglophone Africa, Africa, the Global South and global best practice. 
Method: The article’s methodology is essentially centred on action research pursued 
during the course of co-planning and designing ECD interventions across English-speaking 
African countries, empirical data as well as the authors’ experiences and insights gained 
from leading ECD interventions across African countries. 
Results: The Centre for Learning on Evaluation and Results – Anglophone Africa’s (CLEAR-AA) 
principle of partnering and engaging governments and development partners throughout 
the life cycle of ECD interventions is paramount to cultivating country-owned and led 
national monitoring and evaluation (M&E) systems that are sustainable and are able to facilitate 
a shift towards evidence-based decision-making. 
Conclusion: The value of this CLEAR-AA mission is that it offers the possibility of 
improving decision-making, policymaking and implementation and better service delivery 
and development outcomes in English-speaking Africa. While noting well-known 
M&E challenges that impact the success of ECD interventions in Africa, the article highlights 
forward-looking CLEAR-AA strategies that seek to improve the success and impact of its 
ECD interventions in Anglophone Africa. Such strategies include the identiﬁcation and use 
of M&E champions in each country; working to integrate the M&E function within public 
sector decision-making, development planning, implementation and budgeting processes; 
and building ECD partnerships with governments, non-governmental institutions and 
development partners who have intricate knowledge of country M&E systems.
Keywords: national evaluation systems; monitoring; evaluation; ownership; evidence; 
outcomes and development.
Strengthening Anglophone Africa M&E systems: 
A CLEAR-AA perspective on guiding principles, 
challenges and emerging lessons
Read online:
Scan this QR 
code with your 
smart phone or 
mobile device 
to read online.
Copyright: © 2022. The Authors. Licensee: AOSIS. This work is licensed under the Creative Commons Attribution License.
<<<PAGE=2>>>
Page 2 of 12 Original Research
http://www.aejonline.org Open Access
to this growing body of knowledge, this article ﬁlls important 
gaps in M&E systems capacity strengthening i n Africa, it 
feeds into literature on:
1. The driving factors for the demand for M&E capacity 
strengthening in a country based on CLEAR-AA’s 
experience and practice. 
2. The guiding principles and phases followed when initiating 
and implementing an ECD country programme, and the 
predominant approach is at the national level – working 
with either a government ministry, department or agency. 
3. Barriers to negotiating and implementing/strengthening 
country M&E systems. 
4. Emerging lessons from strengthening and implementing 
country M&E systems in Africa. In each section, we 
explain and describe what we are observing and learning. 
The article draws from the authors’ experiences in jointly 
leading country programmes to strengthen M&E in 
Tanzania, Uganda, Zambia, Ghana, Botswana, Kenya, 
Lesotho and Namibia. This experience of leading country 
M&E programmes has afforded the authors a unique 
insight into both the structure and purposes of countries’ 
M&E systems and the varied capacity proﬁles experienced 
within countries. The article also draws on action research 
approaches adopted by CLEAR-AA at the University of 
the Witwatersrand to build national M&E systems across 
the region. This paper therefore draws on peer learning 
and knowledge co-creation spaces that CLEAR-AA has 
facilitated with stakeholders of public sector M&E systems 
in English-speaking African countries. There are also 
personal reﬂections drawn from the authors’ experiences 
and informed opinions and at times, not based on empirical 
ﬁndings. As such, the paper should be treated as a 
contribution to larger ongoing strategic conversations 
about M&E capacity development approaches and best 
practice in Africa. 
Conceptualising monitoring and 
evaluation systems, evaluation 
capacity development, international 
best practice and trajectory globally 
and in Africa
Conceptually, a national M&E system is deﬁned as the 
collection of M&E frameworks that guide the commissioning 
and undertaking of M&E and the individual and 
institutional M&E capacity to undertake and use M&E 
information to inform development planning, policy-
making and decision-making (Chirau et al. 2020:2). It is 
therefore discernible that an M&E system exists when M&E, 
and use of evidence therefrom, has become institutionalised 
in an organisation or institution such as government. The 
United Nations (2012:7) afﬁrms the above deﬁnition by 
normatively asserting that an M&E system ought to develop 
an equilibrium between the supply of M&E information 
(i.e. undertaking programme M&Es) and the demand for 
M&E information by policymakers and other development 
decision-makers. Goldman et al. (2018:2) identiﬁes six 
constitutive elements of a functional public sector 
national or sectoral M&E system: 
1. The existence of an M&E policy that conceptualises M&E 
and assigns M&E roles to various public sector 
institutions.
2. Methodology – whereby development indicators are 
identiﬁed, criteria for selecting government interventions 
(development programmes) to be evaluated is deﬁned, 
and there is an identiﬁcation of data collection 
methodologies to be used for performance M&Es.
3. Deﬁning the M&E roles of the various public sector 
institutions (government ministries, departments, agencies 
and ofﬁces).
4. Individual and institutional M&E capacity in the public 
sector, including capacity building plans.
5. Integration of non-government institutions in the 
government-wide evaluation system: these include 
Parliament, non-governmental organisations and 
development partners (donors).
6. Quality of M&E evaluation products (reports) and their 
utility in decision-making, policymaking and budgeting.
Evaluation capacity development seeks to strengthen each 
of the six pillars of a public sector M&E system. Typically, 
ECD interventions seek to ensure the use of evaluation 
ﬁndings in development planning, policymaking, general 
decision-making and budgeting, using evaluative ﬁndings 
for organisational learning as well as accountability. A vital 
precondition for developing an evaluation system is demand 
from the relevant government stakeholder (oversight or 
sector ministry) because an evaluation system cannot be 
imposed (Mackay 1999:3).
Mackay (1999:2) deﬁnes ECD as a deliberate process of 
developing or strengthening national and/or sectoral 
evaluation systems. In essence, ECD is a social compact 
through which people, organisations and society join forces 
to strengthen, develop, adapt and maintain evaluation 
capacities over a period (Tarsilla 2014:1). The strengthening 
of individual and institutional evaluation capacities is 
intended to improve the supply and demand of evaluative 
evidence that strengthens the planning and implementation 
of development interventions, thereby ensuring better 
development outcomes. The ECD fraternity’s equal focus on 
both supply of and demand for M&E evidence is 
demonstrative of the evolution of ECD thinking globally, 
where ECD stakeholders have learnt that building individual 
M&E capacities strengthens M&E systems only when M&E 
institutions and architecture are also strengthened, such that 
these institutions and frameworks create demand for M&E 
activities and evidence (Anderson 2010:36). Stimulating 
demand for M&E is enabled in a number of ways: 
developing M&E infrastructure (i.e. M&E policies and other 
frameworks), forming and strengthening evaluation 
associations that champion M&E practice and evidence-use 
and empowering development beneﬁciaries to participate 
in the measurement of development outcomes.
<<<PAGE=3>>>
Page 3 of 12 Original Research
http://www.aejonline.org Open Access
Current state of evaluation capacity 
development interventions in Africa
Most ECD work in Africa has been unsystematic, donor-
funded and donor-centric and sought to improve the 
appraisal and performance of donor-funded programmes. 
These donor-driven ECD initiatives have had a short-term 
focus, such as evaluation trainings for a few public servants 
and technical assistance to selected ministries. Such short-
term ECD programmes do not strengthen evaluation 
systems, but rather the capacities of sampled or selected 
local staff and ministries (Tarsilla 2014:2). In essence, ECD 
in Africa is said to pursue donor interests and not necessarily 
strengthen African evaluation systems – they are not 
country-led and focused. Recent trends, however, 
demonstrate a gradual ECD move from small projects to 
national programmes and policies in order to inform policy 
decisions (Independent Evaluation Group, Online). 
The unsystematic nature of ECD initiatives by various 
international partners means that ECD in Africa requires 
greater coordination and partnerships among larger ECD 
funders. Major ECD funders in Africa include the World 
Bank, German Development Agency (GIZ), Foreign, 
Commonwealth and Development Ofﬁce and the United 
Nations network. Stakeholders ought to coordinate their 
ECD interventions to avoid duplication and yet another 
‘Scramble for Africa’, this time in the form of ECD 
interventions. 
North Africa is a region that underwent a major political 
transformation as a result of the Arab Spring (2010–2012). 
The political transformations and unrest in the region 
led to an inﬂux of aid from international donors. The need 
to measure aid effectiveness was a key condition of aid. 
The need for government accountability in the post-Arab 
Spring contexts placed M&E high on the agenda in 
the region. Consequently, the M&E community in North 
Africa has focused on three aspects of M&E:
1. Accountability: measuring the impact of development 
aid and reporting thereon to donors.
2. Inclusiveness: advocating for greater participation of aid 
beneﬁciaries in implementing aid programmes and the 
appraisal thereof.
3. National ownership: advocates for the building of local 
M&E capacities and locals taking a lead in the appraisal 
of aid effectiveness (Jaafar & Amer 2017:158).
These three ECD focus areas on North Africa are appropriate, 
particularly in the context of appraising the Sustainable 
Development Goals (SDGs). A major challenge for the ECD 
community in North Africa is that the region’s political 
culture of authoritarianism means that the demand for 
M&E information in governance and development is 
limited. As a result, ECD interventions in North Africa 
require an added dimension of building a culture of political 
accountability as a precondition for creating systemic 
demand for M&E information.
The Centre for Learning on 
Evaluation and Results – 
Anglophone Africa’s operations 
within the broader evaluation 
capacity development space
For much of its formative years, CLEAR-AA’s work was 
mainly discrete country M&E interventions, for instance, 
capacity strengthening focusing on individual and 
organisational capacity to plan, use, do and manage M&E; 
strengthening legislatures by focusing on how parliaments 
can make better use of evidence and M&E processes; and 
technical assistance, focusing on good M&E practices. 
However, from late 2018, the Centre has changed its modus 
operandi from delivering discrete interventions towards 
achieving systemic and systematic results in individual 
countries and sub-regions through in-depth ECD country 
programmes that are led and owned by the countries 
themselves. The Centre for Learning on Evaluation and 
Results – Anglophone Africa’s principle of ownership is 
paramount and is operationalised through the adopted 
approach where an in-country ministry, department, or 
agency owns and leads the strengthening of the country 
M&E/evaluation system. 
Much of the existing literature around M&E systems is 
based on European, North American and Latin American 
systems (Laguna 2012; Lahey 2012; Mackay 2012; Rubio 
2012), with little written about African M&E systems, with 
the exception of Goldman et al. (2018), who wrote a 
comparison of national evaluation systems (NESs) of Benin 
and Uganda. Monitoring and evaluation systems in Africa 
are at different levels of maturity, and the challenges they 
face vary from country to country. There is a stronger focus 
on monitoring compared to evaluations in Benin, Ghana, 
Kenya, Senegal, South Africa and Uganda (Porter & 
Goldman 2013), while CLEAR-AA’s M&E situation 
assessment reports on the state of M&E systems in Tanzania, 
Namibia, Lesotho, Madagascar and Zambia indicates the 
same phenomenon. Most countries refer to M&E, which 
denotes an equal emphasis on both monitoring and 
evaluation and have established M&E systems. In practice, 
however, the M&E systems are largely focused on 
monitoring (CLEAR-AA 2019; Porter & Goldman 2013). 
Inadequate technical expertise for undertaking evaluations, 
insufﬁcient budget for evaluations, lack of culture for 
supplying and demanding evaluative evidence and 
inadequate follow-ups on M&E recommendations remain 
major challenges (Maimula 2017:25; Masuku 2015:15; 
Mthethwa & Jili 2016:109). 
Despite the challenges facing African M&E systems: 
[T]here are pockets of excellence in evaluation designs and 
methods that have been conducted on the continent, with 
South Africa and Uganda being exemplary, in as much as there 
are other examples where room for improvement is needed. 
(Blaser Mapitsa, Tirivanhu & Pophiwa 2019:6)
<<<PAGE=4>>>
Page 4 of 12 Original Research
http://www.aejonline.org Open Access
Uganda and South Africa are considered exemplary insofar 
as their governments’ adoption of key M&E frameworks 
(M&E policies, evaluation guidelines and evaluation 
plans) which create a favourable environment for the 
institutionalisation of both monitoring and evaluation. 
Evaluation capacity development remains a primary solution 
to the persistent weaknesses and limitations in the demand 
and supply of both monitoring and evaluation capacity on 
the continent (Wao et al. 2017:1).
Value of country monitoring and 
evaluation systems 
The increase in development and strengthening of 
government M&E systems in Africa is a result of the 
demonstration effect provided by the leading countries of 
Chile, Colombia, Mexico and Brazil. This is not to say no 
internal factors are inﬂuencing the development of M&E 
systems in Africa. For example: 
[A]s African countries emerged from civil wars and oppressive 
regimes, they became more stable and citizens’ voices and 
demands became increasingly important. Organised civil society 
has emerged as an important third sector in different countries, 
calling for government and private sector accountability and 
defending human rights. These various developments have 
collectively driven governmental demand for M&E evidence, 
leading to the establishment of monitoring systems largely for 
ﬁnancial accountability. (Chirau, Blaser-Mapitsa & Amisi 2021) 
Cases studies of Chile, Colombia and Australia M&E systems 
provide insights into what is working, what is not working, 
for who and under what circumstances. In 2011, the 
Department of Planning, Monitoring and Evaluation (DPME) 
went on a study tour to Mexico, Colombia, Brazil and the 
United States of America. The purpose of the study tour was 
to develop practical lessons that South Africa could apply on 
how to implement national evaluation systems (DPME 2011). 
The learning from these systems is useful for countries 
wanting to develop their M&E systems, but countries should 
develop their systems according to their circumstances and 
priorities. 
The uniqueness of African M&E systems is that most of them 
are still in their early phases of development. In Africa, a 
whole-of-government approach to country M&E system has 
been adopted, taking lessons from countries like Chile that 
focus on three dimensions of utilisation of M&E information, 
sustainability, and good quality M&E information 
(Mackay 2007). African countries who have developed their 
M&E systems have also modelled their systems along 
these three dimensions. 
Many African countries have adopted the whole-of-
government approach that is centrally driven, as in the case 
of Chile. The approach has proven to be weak as there are 
low levels of ownership especially by ministries, departments 
and agencies (MDAs) (Mackay 2007). There is evidence in 
Africa that the same phenomenon experienced by Chile is 
experienced by central government oversight institutions, 
for example, Ofﬁce of Prime Minister (Uganda), President’s 
Ofﬁce-Public Service Management and Good Governance 
(Tanzania) and Department of Planning Monitoring and 
Evaluation (South Africa) among others. From CLEAR-AA’s 
M&E interventions, the emerging common pattern is that 
central M&E oversight ministries in the respective countries 
experience challenges in coordinating the M&E activities of 
sector ministries and subnational levels of governance. 
Consequently, Anglophone African countries tend to exhibit 
somewhat fragmented M&E systems, with the national 
M&E system being detached from the M&E systems at 
regional and/or local levels of government. Such 
fragmentation may be a by-product of the hybrid nature of 
state bureaucracies, where even in unitary states, there 
may be an experimentation with devolution of governance 
and development planning functions from central to 
subnational levels of government. However, African countries 
are encouraging participatory, iterative and systems 
approach to strengthening the country M&E system 
thereby cultivating a spirit of ownership and utilisation of 
evaluative evidence in both national and subnational 
levels of governance. 
M&E systems are important in aiding government MDAs 
to measure the results (outputs, outcomes and impact) 
achieved by their respective development policies, 
programmes and projects. In January 2010, the Government 
of South Africa committed to the 12 outcomes (later 
augmented to 14 outcomes) as part of the Medium Term 
Strategic Framework (2014–2019). The 14 outcomes are 
essentially the development priorities set by the 
government. Since the adoption of the 14 outcomes, 
quarterly monitoring reports on the outcomes have been 
produced and compared to reports on outputs and sub 
output levels (Goldman et al. 2012). The reports are taken 
to Cabinet and Parliamentary committees for oversight and 
performance appraisal.
In reality, although there is an M&E system at the central 
level, MDAs and local government tend to have their own 
M&E systems that co-exist within a broader centralised M&E 
system (Goldman et al. 2012). Both systems provide 
information on the performance or non-performance of 
government policies, projects and programs at the national, 
sector and local government levels. Importantly, in the 
process of measuring the results at various levels of outputs, 
outcomes and impacts, the M&E system should be able to 
identify what works and what does not and why (Mackay 
2012). Put into context, the Zambia 7th National Development 
Plan (2017–2021) is informed by the evaluation ﬁndings of 
the 6th National Development Plan (2011–2015). By doing so, 
the Government of Zambia identiﬁed what worked and what 
did not work during the implementation of the sixth National 
Development Plan and tried to improve on those 
shortcomings during the course of implementing the seventh 
National Development Plan (Ministry of National 
Development Planning 2017). This is a lesson that other 
countries should learn.
<<<PAGE=5>>>
Page 5 of 12 Original Research
http://www.aejonline.org Open Access
Monitoring and evaluation systems help improve government 
performance and help development programmes to achieve 
their objectives. In so doing, M&E systems provide vital 
evidence to ensure accountability to citizens, legislatures 
and civil society (Mackay 2012). Sound evidence is equally 
critical in improving programme planning, budgeting, policy-
making and decision-making. 
There is evidence that points to the value of developing a 
system (both an M&E system and evaluation system) and an 
M&E policy, although one (an M&E system or evaluation 
system) can come before the other (an M&E policy or 
evaluation policy). Chirau, Waller and Blaser-Mapista (2018) 
argue that there is a direct link between national evaluation 
policies and the development of strong NESs. Effective 
evaluation systems are dependent on evaluation policies for 
framing the purpose of M&E and a delineation of institutional 
M&E responsibilities (Segone, Bamberger & Reddy 2015). To 
demonstrate the importance of both a policy and an evaluation 
system, Goldman et al. (2018) use Table 1 to demonstrate the 
effect of maturing NESs on the number of evaluations done in 
Benin, Uganda and South Africa from 2010 to 2018, following 
the establishment of NESs in these countries. 
Goldman et al. (2018:6) argue that the decline in evaluations 
conducted is attributable to limited individual and 
institutional capacity to conduct evaluations in the three 
countries. This therefore vindicates the rationale for ECD 
interventions in Africa, because strengthening an evaluation 
system goes hand in hand with strengthening individual 
and institutional M&E capacities.
Despite the relative infancy of evaluation in Africa, there is 
empirical evidence suggesting an increase in the number of 
evaluations conducted in both government and non-
governmental institutions (Blaser Mapitsa & Chirau 2019). It 
remains unknown whether the number of evaluations 
conducted indicates a development of an evaluation culture 
in government and non-governmental organisations.
In ensuring the quality of evaluations, evaluation guidelines 
have been established in Uganda, Zambia, Kenya and 
South Africa. The net effect of evaluation guidelines has 
been structuring and systematising how evaluations are 
conducted, particularly in the government sector. For learning 
purposes, repositories are developed, for example, South 
Africa’s DPME has a repository where anyone interested can 
access evaluation guidelines, templates, policy briefs and 
evaluation reports, thereby facilitating learning inside 
and outside government regarding programme or policy 
performance. This epitomises the progress in establishing the 
national evaluation system in South Africa (Amisi 2015).
An adequate supply of trained personnel (including those 
with both monitoring and technical evaluations skills) is 
key for the sustainability of M&E and evaluation systems 
(Lahey 2012). Pieces of trainings are not sufﬁcient and 
should be supplemented by technical assistance, coaching 
and mentoring to ensure knowledge and skills acquired 
through trainings are put to suitable use. This is a holistic 
approach to developing sustainable M&E systems, 
ensuring an equilibrium between the supply and demand 
of M&E information and use thereof across the M&E 
ecosystem of a country (composed of individual and 
institutional M&E capacities, demand for M&E information 
by decision-makers and ultimately, an evaluative culture).
What does an African country 
monitoring and evaluation systems 
look like?
In Africa, M&E systems exist in different MDAs and subnational 
governments, and they work in silos and are seldom 
coordinated (Masuku 2015:15). This is the case in Tanzania, 
Zambia, Uganda, South Africa and Ghana. Despite M&E 
capacity strengthening efforts made by these governments, 
the M&E infrastructure remains biased towards producing 
monitoring data as the main performance management input 
and accountability mechanism. Evaluation remains on the 
periphery. The accountability and over-emphasis on 
monitoring have led to a culture of malicious compliance 
(CLEAR-AA 2012). There is too much attention paid to 
measuring inputs and activities without attention to outcome 
and impact of programmes (CLEAR-AA 2012:19). These 
fragmented African M&E systems are a by-product of the 
fragmented bureaucracies of the colonial and post-colonial 
states in Africa. Muiu (2010:1311) asserts that the colonial 
African state was designed to plunder resources within its 
deﬁned territory with impunity, not accountable to the 
African populations over which they presided. Furthermore, 
the colonial state was an authoritarian, centralised political 
and administrative entity that was not institutionalised 
beyond the capital and cities wherein economic activity was 
concentrated. The post-colonial African state has somewhat 
inherited the colonial state institutions without any signiﬁcant 
improvements. For instance, the colonial and post-colonial 
legislatures in Africa are not designed to play an optimal 
oversight role over the performance of executive institutions. 
This bureaucratic context likewise affects the M&E systems 
that are hosted by these state institutions, meaning that the 
environment for African M&E systems is a challenging one. 
The challenge, therefore, for CLEAR-AA and the broader ECD 
community is how to build harmonised public sector M&E 
systems such that oversight M&E institutions are involved in 
sectoral and subnational M&E systems, which requires a 
degree of work with these different spheres of governance and 
not just one of them.
TABLE 1: Number of evaluations influenced by an evaluation system.
Item Benin Uganda South Africa
Total number of national 
evaluations completed or 
underway as on 31 December 2016
15  
(from 2010)
23  
(from 2008)
56  
(from 2012)
No. of evaluations started in 2016 1 4 8
Completed evaluation reports 14 14 32
Source: Data from government partners adapted from Goldman, I., Byamugisha, A., Gounou, 
A., Smith, L.R., Ntakumba, S., Lubanga, T. et al., 2018, ‘The emergence of government 
evaluation systems in Africa: The case of Benin, Uganda and South Africa’, African Evaluation 
Journal 6(1), a253. https://doi.org/10.4102/aej.v6i1.253
<<<PAGE=6>>>
Page 6 of 12 Original Research
http://www.aejonline.org Open Access
Anglophone African countries have a common practice of 
having a government institution at central level leading, 
advocating for, implementing and using evaluations 
(Goldman et al. 2018). This is the case in South Africa (DPME), 
Uganda (Ofﬁce of the Prime Minister), Ghana (Ministry of 
Monitoring and Evaluation) and Tanzania (Presidents 
Ofﬁce-Public Service Management and Good Governance). 
Genesis Analytics (2016) argues that if the evaluation function 
is not centralised, the evaluation system will be fragmented, 
without standardised systems. Internationally, Mexico 
(National Council for the Evaluation of Social Development 
Policy [CONEVAL]) and Colombia (Department of National 
Planning) have centrally located units to manage the 
evaluation system (Department of Performance Monitoring 
and Evaluation 2011). At the decentralised level, there are 
M&E units coordinating the M&E functions for a sector 
ministry, department, or agency. The M&E units in the sector 
ministries, departments and agencies at times have their own 
M&E systems that co-exist with the central government 
M&E system located in a central M&E institution. This is 
the case in South Africa and Benin. A clear gap exists for 
the ECD community to devise strategies of coordinating 
intergovernmental M&E systems such that the M&E 
evidence from various spheres of governance ﬁnds its way 
to decision-making, development planning, policymaking 
and budgeting cycles. Thus, while central oversight ministries 
are a crucial partner of ECD interventions, it is important 
that the ECD community also pivots towards instituting 
programme and project level ECD interventions where 
the development ‘work’ actually gets done.
Capacity to supply and demand M&E information remains 
a challenge. Countries such as Tanzania, Lesotho, Liberia, 
Madagascar, Namibia, Uganda and Kenya have M&E 
capacity limitations that have been uncovered through M&E 
diagnostic research studies. Findings from South Africa 
indicated that individual M&E capacities and the quality of 
evaluation training are weak (Morkel & Mangwiro 2019). 
Despite the weakness in M&E capacity, Anglophone African 
governments have established M&E units across MDAs; 
however, most are understaffed, which is a major challenge. 
However, Goldman et al. (2018) argues that M&E peer 
learning forums are helpful for sharing of the ‘how to’ and 
‘what works’ as a way of building M&E capacity. Tanzania 
and Kenya are two examples of M&E systems in nascent 
stages for reference in Box 1.
Monitoring and evaluation practice is growing in these 
two countries despite the absence of M&E policies 
guiding M&E in the public sector. Mwaijande (2018) 
cautions that the absence of M&E policies can potentially 
leave programme and policy planning processes up to 
the whims of bureaucrats, thereby compromising the efﬁciency 
and effectiveness of development policies. The absence of 
evaluation policies or systems does not necessarily hinder 
evaluation practice. This has been demonstrated in South 
Africa where evaluations have been conducted by certain 
government departments, some of which had already 
formulated their own M&E policy before the National 
Evaluation Policy Framework (NEPF) had been passed 
(Chirau et al. 2018; Goldman et al. 2018). The National 
Department of Human Settlements is one of the departments 
to  have instituted its own M&E policy before the inception of 
the NEPF. This is also the case in Ghana, where evaluation 
practice is well established in the public sector, despite the 
absence of a prescribed national M&E policy. However, 
the absence of a policy framework creates a public sector 
M&E framework vacuum.
Guiding principles for monitoring 
and evaluation capacity 
strengthening in a country: A centre 
for learning on evaluation and 
results – Anglophone Africa 
perspective
As a further contribution to this growing body of knowledge, 
this section is an overview of what CLEAR-AA considers 
when selecting a country to work with and implementing 
M&E capacity strengthening programmes. The guiding 
principles discussed in this section are general, and they are 
applicable to working with a ministry, department, or agency in 
a country and are highlighted below.
BOX 1: Two examples of African country monitoring and evaluation systems.
United Republic of Tanzania:  The public sector monitoring and evaluation function is managed by the President’s Office – Public Service Management and Good Governance 
(PO-PSMGG). Currently, national M&E is housed within two government agencies, PO-PSMGG and the Planning Commission, the latter being a unit of the Ministry of Finance 
and Planning. Other key stakeholders are M&E Units in MDAs, National Bureau of Statistics (NBS), Parliamentarians and development partners. President’s Office – Public 
Service Management and Good Governance is responsible for the recruitment of M&E specialists and developing capacity for effective M&E units, M&E conscious economists 
and statisticians to ensure high performance of the system and its sustainability. To date, most Ministries, Department and Agencies have M&E units responsible for M&E 
functions at the sector level. The monitoring system is well-developed compared to the evaluation system. The appetite to conduct evaluations are high in government, but 
there are technical capacity skills gaps and budget shortfalls. There are capacity strengthening initiatives which were done in 2019 by CLEAR-AA, commissioned by the 
Independent Development Evaluation (IDEV) at African Development Bank. The United Republic of Tanzania has a history of conducting evaluations; however, majority of 
these are conducted by international donors: United States Agency for International Development (USAID), World Health Organisation (WHO), United Nations Development 
Programme (UNDP) and so forth. At the moment, the Republic is in the process of drafting a policy/strategy for evaluations to systematise and institutionalise the undertaking 
and use of evaluations in the country. 
Kenya: The Monitoring and Evaluation Department (MED) in National Treasury and Planning coordinates all government’s M&E activities, primarily through the National 
Integrated Monitoring and Evaluation System (NIMES). The department also provides technical support to public sector institutions to build technical capacity and inculcate 
M&E practice. Monitoring and Evaluation Department is currently awaiting approval of their National Monitoring and Evaluation Policy by Cabinet. Ministerial M&E Committees 
in each line ministry coordinate ministerial M&E activities, collect information and prepare reports. At the devolved level, the County Integrated Monitoring and Evaluation 
System and the County Monitoring and Evaluation Committees are the key policy advisory bodies. They validate and approve county M&E documents, including plans, progress 
reports, indicator handbooks, and standards and guidelines. Members of Parliament are driven to use evidence as part of their oversight mandate vis-à-vis the Executive. 
Furthermore, the African Parliamentary Network on Development Evaluation (APNODE) has been instrumental in shaping evidence use in Kenya by providing platforms for peer 
learning and sharing. Seven higher education institutions provide formal M&E qualifications. In the main, M&E courses are offered as part of other professional qualifications. 
Some institutions offer M&E certificates and diplomas. The Evaluation Society of Kenya (ESK), the country’s Voluntary Organization for Professional Evaluation (VOPE), is 
spearheading the professionalisation of M&E, in collaboration with the Monitoring and Evaluation Department and universities.
M&E, monitoring and evaluation; CLEAR-AA, Centre for Learning on Evaluation and Results – Anglophone Africa.
<<<PAGE=7>>>
Page 7 of 12 Original Research
http://www.aejonline.org Open Access
The Centre for Learning on Evaluation and Results – 
Anglophone Africa’s ﬁrst selection criteria when selecting 
countries to work in is the presence of internal appetite and/or 
demand for M&E at the administrative and political levels 
(CLEAR-AA 2019:8). Securing political and administrative 
buy-in and will is crucial in making sure that M&E becomes a 
valued practice in governance and development practices. To 
this effect, raising awareness on the value of M&E among 
high-ranking political and administrative leaders, commonly 
referred to as M&E champions, is a crucial activity when 
seeking to institutionalise and entrench M&E into the 
governance apparatus. These M&E champions exert signiﬁcant 
inﬂuence on ministries, departments, agencies and subnational 
government and are therefore strategically positioned to 
promote and advocate for institutionalisation of M&E practice 
in planning, budgeting, policy design, implementation and 
general decision-making. In characterising the M&E and 
evaluation systems, Lazaro (2015) argues that the presence of 
evaluation in political, administrative, and social discourse 
is essential in that it shows that there is a political and 
administrative interest in evaluation. The centralisation of 
oversight and coordination of M&E and evaluation systems in 
South Africa, Uganda and Tanzania epitomise the 
acknowledgement of the value of M&E in the public sector. 
Countries that already have established national M&E/ 
evaluation systems are key to our work and is an additional 
criteria CLEAR-AA considers when selecting a country to 
work with. The Centre for Learning on Evaluation and 
Results – Anglophone Africa works in countries like Uganda, 
Kenya, Tanzania and Zambia among others to strengthen 
M&E systems through a package of interventions that leads 
to system-wide impact. The development of M&E 
infrastructure, for example, M&E frameworks such as the 
M&E policy is an indicator of a given government’s value 
attachment to M&E, viewing M&E practice as a vehicle for 
improving development outcomes. Genesis Analytics (2016) 
indicates that the M&E and evaluation systems are crucial 
in bringing about transparency and accountable governance.
Partnerships with local institutions and individuals that are 
knowledgeable about the country context is a key CLEAR-
AA selection criteria when selecting a country to work with. 
Our approach is unique in that we seek to use a local entity 
in the country to strengthen the country’s M&E system. 
Drawing from the indigenous institutions and individual(s), 
and their kn owledge systems embedded in the speciﬁc 
African country context, has the potential to strengthen 
ways of thinking about M&E, use of evidence emerging from 
M&E and its impact (Chilisa 2015). The local capacity is 
drawn from individuals, higher education institutions, 
consulting ﬁrms and voluntary organisation for professional 
evaluations (VOPEs). Mamdani (2016:79) argues that it is 
critical to position active African participation and African 
voices in the construction of evaluation theory and practice. 
This is key to the indigenisation of knowledge and use 
thereof to inform development processes (i.e. planning, 
implementation and appraisal). This approach increases the 
ownership and buy-in, leading to country-led and owned 
M&E systems. The Centre for Learning on Evaluation and 
Results – Anglophone Africa has done work with Ghana 
Institute of Management and Public Administration (GIMPA) 
and African Centre for Parliamentary Affairs (ACEPA) in 
Accra, Ghana and Zambia Monitoring and Evaluation 
Association among others. In these respective partnerships 
with local institutions, CLEAR-AA has afﬁrmed its 
commitment to local ownership, indigenous knowledge and 
leadership in strengthening local M&E systems and practice.
Steps to consider for capacity 
strengthening in a country
Evaluation capacity development institutions follow various 
steps used when conducting M&E capacity strengthening 
and/or development. These steps tend to be somewhat 
similar, albeit there are nuances (e.g. the ﬁrst common step is 
to conduct a diagnostic study of the state of individual and 
institutional M&E capacities and to survey the broader 
socio-political environment within which M&E takes place). 
Table 2 outlines CLEAR-AA’s three basic steps when 
initiating and implementing ECD interventions in a country. 
Programme inception phase
The Evaluation Systems Programme is one of the six 
programmatic areas that constitute CLEAR-AA as an 
institution. The Evaluation Systems Programme acts as a 
convener of the Centre’s country programmes. It initiates 
communication with a national government institution: this 
may be a department, ministry or agency that has a mandate 
of coordinating and providing oversight of government-
TABLE 2: Three basic steps to initiate monitoring and evaluation capacity strengthening in a country.
Phases Activities
1. Programme inception • CLEAR-AA’s Evaluation Systems programme initiates communication with a relevant institution in the particular country (based on our understanding 
of demand in the country arising from our engagements with key stakeholders); 
• A convening is scheduled in-country to which selected stakeholders are invited by the institution that has a mandate to provide M&E oversight;
• Presentations are made by various stakeholders, and CLEAR-AA presents its ECD offerings. 
2. Programme design 
(What and so what?)
• A situation analysis is undertaken on the incumbent state of M&E (or M&E system) in the country to understand its strengths, as well as define and 
understand problems and their causes; 
• A validation workshop of the situation analysis is conducted in-country;
• A formal agreement (preferably in the form of a contract/memorandum of understanding) is concluded and CLEAR-AA drafts an initial country 
programme proposal with a budget and time frames for interventions;
• An implementation plan and resources necessary for successful implementation are defined; 
• CLEAR-AA, in collaboration with selected local partners, explores the most appropriate resourcing models for the interventions. 
3. Programme planning 
(Now what?)
• A process to deliver change is identified in-country. The process will include different stakeholders with relevant practical and contextual expertise;
• Other CLEAR-AA programmatic areas provide ECD interventions respectively emanating from the empirical results of the situation analysis. 
Source: Centre for Learning on Evaluation and Results – Anglophone Africa (CLEAR-AA), 2019, CLEAR-AA’s regionalisation strategy, University of the Witwatersrand, Johannesburg
CLEAR-AA, The Centre for Learning on Evaluation and Results – Anglophone Africa; ECD, evaluation capacity development; M&E, monitoring and evaluation.
<<<PAGE=8>>>
Page 8 of 12 Original Research
http://www.aejonline.org Open Access
wide M&E system, for instance, the Ofﬁce of the Prime 
Minister in Uganda. Once the country institution agrees to 
an inception meeting, it invites other government institutions 
to attend and participate in the inception meeting. These 
other stakeholders are selected on the basis of playing a role 
in the country’s M&E system and include line ministries, 
departments, agencies or local government and non-state 
institutions such as a VOPE, High Education Institution 
(HEIs), Civil Society Organisation (CSOs) and development 
partners. During the inception meeting, presentations are 
done, in most cases by the institution providing oversight 
over the government-wide M&E system; for instance, in 
Kenya, it will be the Monitoring and Evaluation Department 
housed in National Treasury and Planning. The Centre for 
Learning on Evaluation and Results – Anglophone Africa 
presents its M&E offerings in the Anglophone Africa 
region. The output of that meeting will be an inception 
meeting report. 
Programme design phase
The Centre’s work is informed by a Monitoring and 
Evaluation Situation Analysis (MESA), which is done to 
understand the prevailing M&E landscape of a country. The 
MESA is in the form of a mapping of the strengths, 
weaknesses, opportunities and threats that underpin the 
incumbent M&E system of a particular country. The Centre 
uses the MESA tool that is a qualitative in-house tool for the 
assessment of supply and demand of M&E in a given 
country. The results of the situation analysis are presented in 
a validation workshop with different stakeholders whose 
input will be used to ﬁnalise the ﬁnal M&E situation analysis 
report. The stakeholders may include, but not limited to, 
government, HEIs, CSOs and development partners. 
Naturally, the situation analysis culminates into a country 
M&E Capacity Strengthening Strategy. The strategy 
discusses the results that need to be achieved for the country 
to be able to improve its M&E performance and are listed 
along with the speciﬁc approaches to be followed for 
delivering those results (CLEAR-AA 2019). The strategy is 
accompanied by M&E Capacity strengthening plan that 
provides details on the results proposed in the strategy, 
indicating who will do what, when and what resources will 
be required and where these will come from. 
Programme planning phase
The M&E oversight institution in the country, stakeholders 
and CLEAR-AA formulate and adopt a process to deliver 
change using in-country expertise that has contextual 
knowledge and relevant experience of the country M&E 
system. It is at this point that all other CLEAR-AA’s 
programmatic areas come on board: capacity strengthening, 
strengthening legislatures, technical advisory services, and 
research and learning. It is important to note that the 
aforementioned country programme steps are not as linear 
as they appear, but are rather determined by the country 
interest and windows of opportunity. In simple terms, entry 
levels for each country are different and require different 
interventions depending on the maturity of the M&E system. 
Barriers to negotiating, 
implementing/strengthening 
country monitoring and evaluation 
systems
Countries undergoing austerity measures
African countries have not grown their economies as 
anticipated because of myriad reasons. Recently, the dawn 
of the coronavirus disease 2019 (COVID-19) pandemic has 
worsened macro-economic performance in both developed 
and developing countries. Austerity measures are put in 
place to reduce government spending. Based on our 
experiences, and informal conversations with public sector 
ofﬁcials in English-speaking countries, M&E services suffer 
the most when budgets need to be cut, indicative of the lack 
of acknowledgement of the value of M&E in improving 
government performance, transparency, accountability and 
social change. A possible risk of doing away with M&E 
because of budgetary constraints is that government ofﬁcials 
may not uphold the principles of truth and transparency to 
the citizens of the state, as M&E is an integral element of 
accountable governance (Masuku 2015). A study conducted 
by Mthethwa and Jili (2016) in South Africa reports that a 
lack of effective M&E of public projects in government is a 
major challenge facing government ofﬁcials because they are 
deprived of the opportunity to learn about what works and 
does not work. 
Extreme bureaucracy in government leading to 
a lack of response for country-led programmes
Governments in Africa and elsewhere are known to be 
excessively bureaucratic; this, therefore, makes the initiating 
of ECD country programmes a challenging task, as approval 
needs to go through several senior administrators. 
Low demand/appetite for monitoring and 
evaluation services
Monitoring and evaluation systems are at their nascent 
stages in most Anglophone African countries. As a result, 
the value of M&E is not well recognised (Mthethwa & Jili 
2016). Monitoring and evaluation activities are still seen as 
‘policing’ and ‘witch-hunting’ instead of opportunities 
for learning about what works and does not work, which 
would form the basis for the improvement of programmes 
and projects. Rarely is monitoring viewed as a managerial 
function and evaluation as a strategic function. 
Technological advancements
Changes in how M&E is conducted will inﬂuence how data 
are collected and analysed. Governments in Africa invest less 
in quality and state-of-the-art data management systems that 
provide real-time data that is pertinent to providing early 
warning signs and/or responding to emergency situations.
<<<PAGE=9>>>
Page 9 of 12 Original Research
http://www.aejonline.org Open Access
Data management systems in Africa are still paper-based 
(CLEAR-AA 2019) and not accessible and are rarely utilised 
because of the data quality. 
Donor influence
Donor funding drives M&E. Money, resources and skills 
are being pumped in African countries to conduct effective 
evaluations, to strengthen their M&E frameworks and 
develop departments (public sector units) that will be able to 
conduct evaluations by themselves. Holvoet and Inberg 
(2014) highlight that donor inﬂuence in Uganda’s education 
sector is strong as donors place emphasis on indicators and 
targets based on budget support and the use of performance 
assessment frameworks. This raises questions around 
methods and tools, which should be Africa-centred with the 
ability to recognise context and an African worldview that 
encapsulates African realities. The inﬂuence of donors 
(development partners) is a phenomenon CLEAR-AA is 
aware of, and it is for this reason that CLEAR-AA’s ECD 
strategy and approach seeks to include development 
partners throughout the lifecycle of ECD interventions: 
planning, implementation, monitoring and evaluation. 
This inclusive approach also helps harmonise CLEAR-AA’s 
ECD interventions with those of other ECD institutions 
working in the same countries.
Management changes
Shufﬂing of senior government ofﬁcials and the 
reconﬁguration of state institutions brings about changes in 
the management of M&E departments or units. Mthethwa 
and Jili (2016) argue that new management may lead to 
the abandonment of ECD projects or programmes. 
Without leadership possessing M&E skills, knowledge and 
appreciation, the M&E systems are poorly managed and 
ultimately become obsolete. 
Inadequate institutionalisation of evaluations in 
government
African countries have a history of conducting evaluations. 
Goldman et al. (2018) indicate that, from the year 2010, 
evaluations conducted in Uganda amounted to 14, and in 
South Africa 32 evaluation reports were completed. A 
huge amount of evaluations are commissioned and 
conducted by international development organisations; 
for example, there are 520 evaluations that reference 
Tanzania in the African Evaluation Database (AFRED) 
database, a database jointly maintained and updated by 
CLEAR-AA and the Centre for Research on Evaluation, 
Science and Technology (CREST) at the University of 
Stellenbosch. Situation analyses from ﬁve countries 
conducted in 2018 by CLEAR-AA further indicate that 
evaluations are being done on an ad hoc basis in the public 
sector, and it is not clear how governments (CLEAR-AA 
2019) use the evaluations from both government and 
international development organisations. 
Inadequate evaluation capacity
There is wide acknowledgement on the importance of 
evaluations in the public sector and the broader development 
ecosystem. However, the public sector does not have 
adequate skills to undertake quality evaluations. Inadequate 
evaluation capacity may lead to instruments such as tools, 
techniques for generating data and processing information 
into documents not being put into place (Bouckaert & 
Haligan 2008:28). Bester (2015) highlights that such 
evaluation capacities should be strengthened.
Poor linkages between planning, budgeting and 
monitoring and evaluation systems
Planning, budgeting and the M&E function are not 
integrated in most countries (this is a common ﬁnding in 
M&E diagnostic reports undertaken by CLEAR-AA for ﬁve 
countries [Lesotho, Malawi, Uganda, Tanzania and Liberia]). 
Performance reporting is a prevalent practice in Africa. 
Unfortunately, performance reports and the lack of public 
sector institutionalisation of the evaluation function mean 
that M&E reports are not yet fully integrated into budgeting 
and development planning processes. Increased investment 
in M&E systems and harmonisation can improve these 
linkages. Monitoring and evaluation should be conducted in 
a way that it is linked to governance processes of planning 
and budgeting. Where possible, budget cycles and 
development planning processes should be aligned at 
national and sector levels to ensure integration (DPME 
2014:14). Equally important is for M&E evidence to inform 
the development planning and budgeting processes.
Monitoring data that needs improvements
Monitoring is more pronounced compared to an evaluation 
in Tanzania, Kenya, Zambia, Uganda, Ghana, Botswana and 
Namibia. Despite the prevalence of monitoring, constraints 
are still present in that data generated is of inadequate 
quality, untimely and without or with little veriﬁcation 
processes for validity and reliability. Monitoring data should 
enhance learning to improve the effectiveness and impact of 
government (Masuku 2015). 
Capacity strengthening of 
monitoring and evaluation systems: 
Emerging lessons
The Centre for Learning on Evaluation and Results – 
Anglophone Africa is accumulating substantive experience 
from implementing country M&E capacity strengthening 
interventions, so as to improve country M&E systems. There 
are lessons about what works best and what does not. Key 
lessons are discussed below.
Conducting a situation analysis is a prerequisite
It helps to understand the status quo or prevailing current 
situation of M&E in the country. The Centre for Learning on 
Evaluation and Results – Anglophone Africa’s situation
<<<PAGE=10>>>
Page 10 of 12 Original Research
http://www.aejonline.org Open Access
analysis tool looks at the ‘wider ecosystem of M&E’, that 
means it looks at the government itself, higher education 
institutions, CSOs, parliament and VOPEs. The analysis 
should zoom in on the supply and demand of M&E 
information, examining strengths and weaknesses, as well as 
opportunities and threats. The analysis naturally feeds into an 
M&E Capacity Strengthening Strategy/ Plan. The Strategy/ 
Plan explains the results that need to be achieved for the 
country to be able to improve its individual, institutional and 
systemic M&E capacities, along with the speciﬁc approaches 
to be followed for achieving these capacities. The Strategy 
further indicates who will do what, when, what resources will 
be required and where these will come from.
Identification of a capable and mandated 
institution that oversees the implementation 
and practice of monitoring and evaluation in a 
country
This institution can be a ministry or department; this varies 
from country to country. Having a capable ministry at a 
centralised level, for example, the President’s or Prime 
Minister’s Ofﬁce, demonstrates political and administrative 
will and buy-in for undertaking and utilisation of M&E 
evidence. On the other hand, however, decentralisation 
makes it easier for ministries, sectors and agencies to grow an 
interest in the evaluation work and utilisation of the 
evaluative evidence compared to viewing evaluations as a 
mandated practice enforced by a central oversight institution. 
The Centre for Learning on Evaluation and Results – 
Anglophone Africa’s partnerships with these local, in-
country institutions has given effect to its principle of 
‘country-owned and country-led’ M&E interventions across 
Anglophone Africa.
Capacity strengthening is a long-term effort and 
multi-pronged process that requires devotion, 
determination and dedication
It takes considerable effort and time to gain rapport in a 
country and start capacitation mainly because of how 
governments are structured. Proposals are channelled to 
different people in different ofﬁces until authorisation is 
permitted. It takes an average of 6 months to 1 year of 
negotiation before implementing M&E interventions in a 
country. The process of establishing a good working 
relationship (rapport) with governments requires time and 
patience, and was further complicated by disruptions 
brought about by the COVID-19 pandemic. Furthermore, 
there is also the historical mistrust that African states hold 
vis-a-vis non-state developmental institutions.
Need for powerful champions at political and 
senior administrative level
This can be a Minister, Director and Permanent Secretary 
among others. The role of a champion is that of promoting the 
value of M&E and the evidence that it generates and 
how useful it is in governance and development processes. By 
doing so, it breaks the barrier of underbudgeting of M&E in 
government. In the context of underdevelopment in African 
countries, where communities continue to live without basic 
services such as water, sanitation, health, school and energy, 
M&E can seem like a waste of money, without due recognition 
of how information from M&E can be used to improve service 
delivery and to alleviate these social ills.
Incentives and disincentives are an important 
aspect of both supply and demand
African governments do not offer incentives and 
disincentives for M&E practice. Incentives and disincentives 
offer the possibility of cultivating a culture of conducting 
M&E and utilisation of M&E evidence. The nature of 
incentives for a country will depend on how the country 
envisions using M&E information. It is not automatic or 
natural that M&E will be done, neither is it automatic that 
ﬁndings emerging from M&E will be utilised. Kusek and 
Rist (2004:139) assert that a key incentive that can encourage 
the use of M&E ﬁndings is the involvement and engagement 
of programme civil servants in the actual undertaking 
of M&E activities vis-à-vis a particular development 
intervention. Such incentives are important building blocks 
towards establishing sustainable and country-owned M&E 
systems that organically emerge from ‘below’ (within the 
government) rather than being imposed from ‘above’ (by 
external entities).
Demand for monitoring and evaluation 
information is important within the government
The demand is a prerequisite to assess whether there is a 
serious effort to capacitate and entrench the M&E system. 
This demand should also come from the high ofﬁces, for 
example, Heads of State and/or Government, Ministers, 
Permanent Secretaries and Directors-General. Courses 
aimed at raising awareness of the value of M&E are 
important in raising appetite among high ofﬁce personnel. 
Evaluation capacity development partnerships 
with government and development partners
The Centre for Learning on Evaluation and Results – 
Anglophone Africa is ﬁnding that development partners 
have an established relationship of cooperation with many 
sector ministries across Anglophone Africa. It is important 
for CLEAR-AA to amplify these government-development 
partner cooperative relationships at the sector level so that 
the impact of ECD interventions is transmitted from central 
M&E oversight institutions to the sector Ministries and 
also subnational spheres where actual ‘developmental’ 
work and activities happen. 
Conclusion
This article has provided an overview of ECD interventions 
globally and within the African continent and situates 
CLEAR-AA’s ECD perspective and philosophy within 
the broader ECD environment. The guiding principles 
and phases followed by CLEAR-AA in initiating ECD 
capacity strengthening interventions in a country follow
<<<PAGE=11>>>
Page 11 of 12 Original Research
http://www.aejonline.org Open Access
international best practice documented in existing literature, 
while also sharing nuances CLEAR-AA’s has embarked 
on through experience and observation in Anglophone 
African countries. The article particularly shines the spotlight 
on identiﬁed barriers to negotiating and implementing/
strengthening country M&E systems in Africa, and emerging 
lessons from strengthening and implementing country M&E 
systems in Africa. In each section, we explain and describe 
what we are observing and learning. Although the issues 
raised in this article might seem generic, M&E capacity 
strengthening in countries is largely informed by contexts 
such as the socio-political economy of the country. Experience 
from working with different M&E systems indicates that the 
development of M&E systems is not linear, but rather 
complex and inﬂuenced by a combination of internal and 
external factors. Hence, the systems are at different levels of 
maturity. In strengthening the country M&E systems, the 
primary CLEAR-AA principle is that ECD interventions 
should be country-led, focused and owned to increase the 
likelihood of using the M&E evidence produced by the M&E 
system. The assumption is that in-country ownership should 
breed sustainable M&E systems. The use of local partners 
(both government and non-governmental institutions as 
well as development partners) who have knowledge about 
country M&E systems is a further advantage and privilege 
to be harnessed. Learning is a core element of these systems, 
as the systems are designed to support learning, critical 
reﬂection and curiosity on what works, does not work 
and in what conditions regarding the performance of 
development policies, programmes and projects. In 
designing or strengthening M&E systems in Anglophone 
Africa, CLEAR-AA is driven by the following questions: Are 
we doing the right things? How can we design and 
implement better country ECD interventions? What has 
changed as a result of CLEAR-AA ECD interventions and 
why has it changed? How can we effect meaningful M&E 
change through leveraging partnerships with local partners 
with intimate knowledge of the governance, development 
and M&E landscapes of the particular country? It is clear 
that we need to codify both theoretical and empirical 
research to build a body of African ECD knowledge that is 
shared across institutions providing M&E capacity 
strengthening in Africa and be able to improve strategies 
and interventions in these countries. 
Acknowledgements
The authors acknowledge stakeholders who have written on 
the state of M&E systems in Anglophone Africa.
Competing interests 
The authors declare that they have no ﬁnancial or personal 
relationships that may have inappropriately inﬂuenced them 
in writing this article.
Authors’ contributions
T.C., A.D. and B.M. used empirical ﬁndings of evaluation 
scholars as well as the experience of CLEAR-AA in 
conducting its Evaluation Capacity Development (ECD) 
work on the continent.
Ethical considerations
This article followed all ethical standards for research 
without direct contact with human or animal subjects.
Funding information 
This research received no speciﬁc grant from any funding 
agency in the public, commercial or not-for-proﬁt sectors.
Data availability
Primary data not applicable for this article.
Disclaimer
The views and opinions expressed in this article are those 
of the authors and their interpretation of CLEAR-AA 
principles and other organisational guiding documents.
References
Amisi, M.M., 2015, ‘Improving the use of evaluative evidence through effective 
communication: Lessons from implementing the South African evaluation system’, 
African Evaluation Journal 3(1), 7. https://doi.org/10.4102/aej.v3i1.109
Anderson, G., 2010, Shaping international evaluation: A 30-year journey, Universalia, 
Ottawa.
Bester, A., 2015, Capacity  development:  A  report  prepared  for  the  United  Nations 
department  of  economic  and  social  affairs  for  the  2016  Quadrennial 
Comprehensive  Policy  review, viewed 20 June 2020, from https://www.un.org/
en/ecosoc/qcpr/pdf/sgr2016-deskreview-capdev.pdf.
Blaser Mapitsa, C. & Chirau, T., 2019, ‘Institutionalising the evaluation function: A 
South African study of impartiality, use and cost’, Evaluation  and  Program 
Planning 75, 38–42. https://doi.org/10.1016/j.evalprogplan.2019.04.005
Blaser Mapitsa, C., Tirivanhu, P . & Pophiwa, N., 2019, Evaluation landscape in Africa: 
Context, methods and capacity, African Sun MeDIA, Stellenbosch.
Bouckaert, G. & Halligan, J., 2008, Managing performance. International comparisons, 
Routledge, Abingdon.
Centre for Learning on Evaluation and Results – Anglophone Africa (CLEAR-AA), 2012, 
African monitoring and evaluation systems: Exploratory case studies, viewed 20 
June 2020, from https://www.betterevaluation.org/sites/default/files/
African%20M%26E%20Cases%20-%20FINAL.pdf.
Centre for Learning on Evaluation and Results – Anglophone Africa (CLEAR-AA), 2019, 
CLEAR-AA’s  regionalisation  strategy , University of the Witwatersrand, 
Johannesburg.
Chilisa, B., 2015, A  synthesis  paper  on  the  made  in  Africa  evaluation  concept: 
Commissioned by African Evaluation Association (AfrEA), viewed 8 October 2021, 
from https://afrea.org/wp-content/uploads/2018/06/MAE2-Final-31st-august.
pdf.
Chirau, T.J., Blaser-Mapitsa, C., Amisi, M., Masilela, B. & Dlakavu, A., 2020, ‘A 
stakeholder view of the development of national evaluation systems in Africa’, 
Africa Evaluation Journal 8(1), a504. https://doi.org/10.4102/aej.v8i1.504
Chirau, T., Blaser-Mapitsa, C. & Amisi, M., 2021, ‘Policies for evidence: a comparative 
analysis of Africa’s national evaluation policy landscape’, Evidence & Policy 2(2), 
1–12. https://doi.org/10.1332/174426421X16104826256918
Chirau, T.J., Waller, C. & Blaser-Mapitsa, C., 2018, The  National  Evaluation  Policy 
landscape in Africa: A comparison, Twende Mbele, Johannesburg.
Department of Performance Monitoring and Evaluation (DPME), 2011, Report  on 
study  tour  to  Mexico,  Colombia,  Brazil  and  the  US, 25 June to 12 July 2011, 
Department of Planning, Monitoring and Evaluation, Pretoria.
Department of Planning, Monitoring and Evaluation (DPME), 2014, Performance 
monitoring and evaluation: Principles and approach, Government of the Republic 
of South Africa, Pretoria.
Genesis Analytics, 2016, Evaluation of the national evaluation system in South Africa. 
International  benchmarking  and  literature  review, Draft report, Department of 
Planning, Monitoring and Evaluation, Pretoria.
Goldman, I., Byamugisha, A., Gounou, A., Smith, L.R., Ntakumba, S., Lubanga, T. et al., 
2018, ‘The emergence of government evaluation systems in Africa: The case of 
Benin, Uganda and South Africa’, African Evaluation Journal  6(1), a253. https://
doi.org/10.4102/aej.v6i1.253
<<<PAGE=12>>>
Page 12 of 12 Original Research
http://www.aejonline.org Open Access
Goldman, I., Engela, R., Akhalwaya, I., Gasa, N., Leon, B., Mohamed, H. et al., 2012, 
Establishing a national M&E system in South Africa (English), PREM Notes; no. 21, 
Special series on the Nuts and Bolts of Monitoring and Evaluation (M&E), World 
Bank, Washington, DC.
Holvoet, N. & Inberg, L., 2014, ‘Diagnostic review of the monitoring and evaluation 
system of Uganda´s education sector: Selected findings and discussion’, Journal of 
Education and Training 2(1), 134. https://doi.org/10.5296/jet.v2i1.6720
Jaafar, S.B. & Amer, A., 2017, ‘The role of monitoring and evaluation in the MENA 
region, with a focus on the Arab uprising countries’, in R.D. Van den Berg, I. 
Naidoo, V. Thomas, M. Segone, M.R. Samaranayake & A. Steiner (eds.), Evaluation 
for  agenda  2030:  Providing  evidence  on  progress  and  sustainability, p. 158, 
International Development Evaluation Association, Exeter. 
Kusek, J.Z. & Rist, R.C., 2004, Ten steps to a results-based monitoring and evaluation 
system, World Bank, Washington, DC.
Laguna, M.I.D., 2012, ‘Chile’s M&E system’, in G. Lopez- Acevedo, P . Krause & K. 
Mackey (eds.), Building  better  policies:  The  nuts  and  bolts  of  monitoring  and 
evaluation systems, p. 185, World Bank, Washington, DC. 
Lahey, R., 2012, ‘The Canadian M&E system’, in G. Lopez- Acevedo, P . Krause & K. 
Mackey (eds.), Building  better  policies:  The  nuts  and  bolts  of  monitoring  and 
evaluation systems, p. 211, World Bank, Washington, DC. 
Lazaro, B., 2015, Comparative study on the institutionalisation of evaluation in Europe 
and Latin America, EUROsociAL Programme, Madrid.
Mackay, K., 1999, Evaluation  capacity  development:  A  diagnostic  guide  and  action 
framework, World Bank, Washington, DC.
Mackay, K., 2012, ‘The Australian Government M&E system’, in G. Lopez- Acevedo, P . 
Krause & K. Mackey (eds.), Building  better  policies:  The  nuts  and  bolts  of 
monitoring and evaluation systems, p. 21, World Bank, Washington, DC.
Mackay, K.R., 2007, How to build M&E systems to support better government , World 
Bank, viewed 20 June 2020, from https://commdev.org/pdf/publications/How-to-
Build-Monitoring-Evaluation-Systems-to-Support-Better-Government.pdf.
Maimula, S., 2017, Challenges in practicing monitoring and evaluation: The case of 
local government water projects in Mkuranga, Tanzania , The Open University of 
Tanzania, Dar es Salaam.
Mamdani, M., 2016, ‘Between the public intellectual and the scholar: 
decolonization and some post-independence initiatives in African higher 
education’, Inter-Asia Cultural Studies  17(1), 68–83. https://doi.org/10.1080/
14649373.2016.1140260
Masuku, N.W.K., 2015, ‘A global overview of Monitoring and Evaluation (M&E) and its 
Meaning in the local government context of South Africa’, Africa’s Public Service 
Delivery & Performance Review 3(2), a79. https://doi.org/10.4102/apsdpr.v3i2.79
Ministry of National Development Planning, 2017, 7th  national  development  plan 
2017–2021, Government of Zambia, Lusaka.
Morkel, C. & Mangwiro, N., 2019, ‘Implication of evaluation trends for capacity 
development’, in C. Mapitsa Blaser, P . Tirivanhu & N. Pophiwa (eds.), Evaluation 
landscape in Africa Context, methods and capacity , p. 192, African Sun Media, 
Stellenbosch.
Mthethwa, R.M. & Jili, N.N., 2016, ‘Challenges in implementing monitoring and 
evaluation (M&E): The case of the Mfolozi Municipality’, African Journal of Public 
Affairs 9(4), 109.
Muiu, M., 2010, ‘Colonial and postcolonial state and development in Africa’, Social 
Research 77(4), 1311–1338.
Mwaijande, F., 2018, ‘Why should countries have national evaluation policies?’ 
eVALUation  Matters, First Quarter 2018, Independent Development Evaluation 
(IDEV, African Development Bank), Abidjan.
Porter, S. & Goldman, I., 2013, ‘A growing demand for monitoring and evaluation in 
Africa’, African Evaluation Journal 1(1), a25. https://doi.org/10.4102/aej.v1i1.25
Rubio, G.M., 2012, ‘The Mexican Governments M&E systems’, in G. Lopez- 
Acevedo, P . Krause & K. Mackey (eds.), Building  better  policies:  The  nuts 
and  bolts  of  monitoring  and  evaluation  systems, p. 169, World Bank, 
Washington, DC.
Segone, M., Bamberger, M. & Reddy, S., 2015, National  Evaluation  Policies  for 
sustainable  and  equitable  development:  How  to  integrate  gender  equality  and 
social  equity  in  national  evaluation  policies  and  systems, United Nations, New 
York, NY .
Tarsilla, M., 2014, ‘Evaluation capacity development in Africa: Current landscape of 
international partners’ initiatives, lessons learned and the way forward’, African 
Evaluation Journal 2(1), a89. https://doi.org/10.4102/aej.v2i1.89
United Nations, 2012, National  evaluation  capacity  development:  Practical  tips  on 
how to strengthen National Evaluation Systems , United Nations Children’s Fund, 
New York, NY .
Wao, H., Onyango, R., Kisio, E., Njatha, M. & Onyango, N.O., 2017, ‘Strengthening 
capacity for monitoring and evaluation through short course training in 
Kenya’, African  Evaluation  Journal 5(1), a192. https://doi.org/10.4102/aej.
v5i1.192