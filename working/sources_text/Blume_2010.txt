<<<PAGE=1>>>
Transfer of Training: A Meta-Analytic Review
Brian D. Blume
University of Michigan
J. Kevin Ford
Michigan State University
Timothy T. Baldwin
Indiana University
Jason L. Huang
Michigan State University
Although transfer of learning was among the very first issues addressed by early psychologists, the 
extant literature remains characterized by inconsistent measurement of transfer and significant vari-
ability in findings. This article presents a meta-analysis of 89 empirical studies that explore the 
impact of predictive factors (e.g., trainee characteristics, work environment, training interventions) 
on the transfer of training to different tasks and contexts. We also examine moderator effects of the 
relationships between these predictors and transfer . Results confirmed positive relationships between 
transfer and predictors such as cognitive ability, conscientiousness, motivation, and a supportive 
work environment. Several moderators had significant effects on transfer relationships, including the 
nature of the training objectives. Specifically, most predictor variables examined (e.g., motivation, 
work environment) had stronger relationships to transfer when the focus of training was on open 
(e.g., leadership development) as opposed to closed (e.g., computer software) skills. Other modera-
tors related to the measurement of transfer also influenced transfer relationships, including situations 
in which transfer outcomes were obtained by the same source in the same measurement context—
which consistently inflated transfer relationships. Findings are discussed in terms of their relevance 
for future research and training practice.
Keywords:
 training transfer; 
meta-analysis; trainee characteristics; work environment; train-
ing interventions
1065
Acknowledgments: This study was funded by a grant from the SHRM Foundation. However, the interpretations, 
conclusions, and recommendations are those of the authors and do not necessarily represent the views of the SHRM 
Foundation.
Corresponding author: Brian D. Blume, School of Management, 3119 WSW Bldg., University of Michigan, Flint, 
MI 48502
E-mail: blume@umflint.edu
Journal of Management
V ol. 36 No. 4, July 2010 1065-1105
DOI: 10.1177/0149206309352880
© The Author(s) 2010 
 at UNIV OF MICHIGAN FLINT on June 8, 2010 http://jom.sagepub.comDownloaded from
<<<PAGE=2>>>
1066   Journal of Management / July 2010
Introduction
Today’s most progressive organizations have moved from treating some select human 
resource management practices (e.g., incentive compensation, employee participation, flexible 
work arrangements, training) as obligatory cost factors to regarding them as strategic weapons in 
the battle for competitive advantage. Consistently included in any discussion of such high-
performance human resource practices is employee training (Combs, Liu, Hall, & Ketchen, 
2006; Huselid, 1995; Pfeffer, 1998). Effective training certainly has the potential to increase 
knowledge, skills, and abilities (KSAs) and to enable employees to leverage their KSAs for 
organizational benefit (Becker & Huselid, 1998; Combs et al., 2006).
According to a recent American Society for Training and Development study, U.S. organi-
zations spend more than $125
 bi
llion annually on employee training and development 
(Paradise, 2007). At the same time, organizations continue to question the true yield of their 
training expenditures. Despite the large investments in and potential benefits of training, 
organizational decision makers are often not sure to what extent employees perform differ-
ently once back on the job.
In organizational contexts, original learning in a training experience is rarely enough to render 
that training effective. Rather it is the positive transfer of training—the extent to which the learn-
ing that results from a training experience transfers to the job and leads to meaningful changes in 
work performance—that is the paramount concern of organizational training efforts (Goldstein 
& Ford, 2002). For example, leadership training programs often present a model of leadership 
and include some case studies. While this training may be beloved by participants, the extent to 
which such programs positively affect the leadership behavior of managers while on the job is at 
the crux of the transfer issue. Concerns raised about investing in training often revolve around 
these training transfer issues and the return the organization can expect. This so-called transfer 
problem has led to a body of studies that explore factors that can affect transfer and to a search 
for strategies that enhance the likelihood that acquired knowledge and skills will be applied to 
different tasks and contexts (Ford & Kraiger, 1995).
The purpose of the current study is to provide a comprehensive meta-analysis of predictors of 
transfer of training. Given the clarion call for more evidence-based practice within the manage-
ment discipline (Pfeffer & Sutton, 2006; Rousseau, 2006), we believe such a meta-analytic syn-
thesis is timely and important for several reasons. First, and most generally, there is a need to 
know which predictors actually make a difference in facilitating transfer—not just intuitively or 
anecdotally, but with support from the extant evidence. Second, in the past 20
 ye
ars, there has 
been a burgeoning volume of studies on transfer, and there is significant variability in findings 
across those studies (Cheng & Hampson, 2008). Third, scholars have operationalized transfer in 
various ways, and it is important to quantitatively examine how these different operationaliza-
tions influence predictor–transfer relationships. Therefore, we identify and test a set of theory-
based and methodological moderators of transfer relationships. Before developing our research 
questions below, we first define transfer and its most fundamental dimensions, note limitations 
of the current state of transfer research findings, and highlight the contributions of our meta-
analytic review.
 at UNIV OF MICHIGAN FLINT on June 8, 2010 http://jom.sagepub.comDownloaded from
<<<PAGE=3>>>
Blume et al. / Transfer of Training   1067
The Training Transfer Concept
The transfer of learning has been an enduring problem in psychology and education (Grose & 
Briney, 1963). The history of transfer research goes back more than 100 ye
ars, with researchers 
debating the nature, contexts, and prevalence of transfer (Barnett & Ceci, 2002). What has 
emerged from this research stream is a view of transfer as a complex and dynamic process.
Transfer was originally defined as the extent to which learning of a response in one task or 
situation influences the response in another task or situation (e.g., see Adams, 1987). For exam-
ple, Thorndike and Woodworth (1901) predicted that transfer would occur as long as the aims, 
method, and approaches used for the learning task were similar to the transfer task. They found 
support for the generalization of responses when there was similarity in the stimuli and responses 
in the learning and transfer environments. Research has supported a generalization gradient in 
which transfer is more likely with near transfer tasks, which are highly similar to the learning 
tasks (e.g., working on a small jet engine in training and a larger one in the field), and less likely 
as one moves to far transfer, in which the tasks and situations in the learning situation are quite 
different from the transfer setting (e.g., applying principles of electricity from training to trouble-
shooting complex mechanical problems under extreme time pressures; Royer, 1979). This gen-
eralization process allows people to react appropriately to new situations because of similarities 
with familiar ones (Bass & V aughan, 1966).
Gagne (1965) distinguished between two types of generalization processes—lateral  and 
vertical transfer. Lateral transfer occurs when a skill spreads over a broad set of situations at 
the same level of complexity or difficulty (i.e., applying trained rules and procedures to situ-
ations similar to that trained). In contrast, vertical transfer occurs when an acquired skill 
affects the acquisition of a more complex or superordinate skill (e.g., a pilot gaining knowl-
edge and skills related to flying a plane and then having to learn the appropriate team interrole 
behaviors required for effective flight cockpit performance). Barnett and Ceci (2002) devel-
oped a framework of transfer that categorizes studies based on the training content (what is 
transferred) and the training context (when and where something is transferred). In their 
framework, they noted how the field has expanded the notion of near and far transfer. For 
example, in terms of the physical context, near transfer has been studied in cases in which the 
transfer context is in the same location as the acquisition context. Far transfer has been stud-
ied in cases in which the transfer context is much different in location from the learning 
context, such as when conflict management material learned in a classroom would be applied 
in workplace settings. Near and far transfer can also be discussed in terms of a temporal 
dimension. For example, near transfer can occur and be studied during the same session as 
the learning, and far transfer can be studied months or years later. These frameworks demon-
strate that transfer can be examined in many different ways.
While much of the initial interest in transfer focused on understanding educational issues, 
such as how learning in one domain might affect learning in another (Thorndike, 1933), 
researchers subsequently adapted the study of transfer to improve the application of work-
place training (Goldstein, 1974). For our review, and consistent with historical perspectives, 
we define transfer as consisting of two major dimensions: (a) generalization—the extent to 
which the knowledge and skill acquired in a learning setting are applied to different settings, 
people, and/or situations from those trained, and (b) maintenance—the extent to which 
 at UNIV OF MICHIGAN FLINT on June 8, 2010 http://jom.sagepub.comDownloaded from
<<<PAGE=4>>>
1068   Journal of Management / July 2010
changes that result from a learning experience persist over time. Researchers have studied 
generalization and maintenance issues across a variety of research settings (laboratory, 
simulations, field studies, and field experiments) and time intervals. We examine studies that 
have attempted to better understand the factors that can affect transfer regardless of research 
setting and time interval. In this way we can better understand transfer as a dynamic and 
complex process (Ford & Kraiger, 1995; Royer, 1979).
Transfer Research
As noted by Brown and Sitzmann (in press), the most frequently cited model of training 
transfer is one presented by Baldwin and Ford (1988). They organized their qualitative 
review around a model of training inputs (trainee characteristics, training design, and work 
environment), training outputs (acquisition of knowledge and skills during training), and 
conditions of transfer (generalization of knowledge and skills acquired in training to the job 
and the maintenance of that learning over time on the job). Trainee characteristics consist of 
factors such as ability, skill, motivation, and personality. Training design factors include the 
training objectives and methods and the incorporation of learning principles such as multiple 
training techniques and opportunities for practice. Work environment factors include transfer 
climate, social support from supervisors and peers, and the constraints on or opportunities for 
performing learned behaviors on the job. A good example of these work environment factors 
is provided by Rouillier and Goldstein (1993), who defined transfer climate as consisting of 
two categories: situational cues and consequences. Situational cues consist of things such as 
manager goals, peer support, equipment availability, and opportunity to practice trained 
skills. Consequences consist of punishment, as well as positive and negative feedback from 
both managers and peers when trainees attempt to apply the skills they learned in training.
The goal of Baldwin and Ford (1988) was to “provide a critique of the existing transfer 
research and to suggest directions for future research” (p. 64). They analyzed 63 empirical studies 
spanning the period from 1907 to 1987 and summarized key findings related to the linkage of 
training input factors and transfer. The review also noted key limitations relevant to the way 
transfer had been operationalized. They closed their review by noting, “Conclusions from the 
existing research are problematic, given the relatively short-term, single source, perceptual data-
base that has been created” (p. 100). Since then, the transfer literature has expanded to address a 
number of the issues raised in that review (Ford & Weissbein, 1997). A wider array of individual 
differences and motivational variables have been studied for their impact on transfer. In addition, 
a number of studies have examined the transfer environment for its impact on transfer. Other 
studies have created interventions to facilitate transfer.
A number of authors have recently attempted to qualitatively summarize what we know 
about transfer from this expanding research base (Alvarez, Salas, & Garofano, 2004; 
Baldwin, Ford, & Blume, 2009; Burke & Hutchins, 2007; Cheng & Hampson, 2008; Cheng 
& Ho, 2001; Kopp, 2006; Merriam & Leahy, 2005; Yamnill & McLean, 2001). These 
reviews have typically focused on trainee and work environment characteristics and their 
impact on transfer. They have highlighted several inconsistent and conflicting findings in  
the transfer literature. For example, Cheng and Hampson (2008) concluded, “The studies 
examining the relationships between general dispositions and training transfer have shown 
 at UNIV OF MICHIGAN FLINT on June 8, 2010 http://jom.sagepub.comDownloaded from
<<<PAGE=5>>>
Blume et al. / Transfer of Training   1069
incoherent findings” (p. 334). Similarly, Burke and Hutchins (2007) concluded that there 
was mixed support for conscientiousness and that other Big Five personality variables were 
said to have minimal or no empirical evidence supporting their relationship with transfer.
Cheng and Hampson (2008) further noted that “similar reasoning applies to such variables as 
transfer climate, social support (e.g., supervisors, peers and subordinates) and opportunity to trans-
fer. .
 .  c
ounterintuitive results were reported” (p. 334). Cheng and Ho (2001) also reported con-
flicting findings related to organizational support. They noted that while 10 studies found positive 
relationships between organizational support and transfer outcomes, 2 studies found negative rela-
tionships, and 5 studies found that the link was nonsignificant. Burke and Hutchins further 
described the mixed findings for the impact of trainee interventions on training transfer.
Contributions of Our Quantitative Review
Existing qualitative reviews have provided some evidence of the factors that can affect 
transfer. Nevertheless, a demand for the “best evidence” to drive future research and practice 
requires meta-analytic estimates of transfer relationships. Meta-analytic estimates allow us 
to resolve inconsistent findings in the literature by including confidence intervals, corrected 
estimates, and measures of variability in correlations across studies, permitting more  
accurate inferences of the strength and consistency of relationships. We discuss key meta- 
analyses related to transfer below, highlighting the unique contributions of our meta-analysis.
Of the three training inputs identified by Baldwin and Ford (1988), training design has 
received the most significant research attention to quantify results across studies. Existing 
meta-analytic studies have focused on design characteristics such as overlearning (Driskell, 
Willis, & Copper, 1992), practice (Arthur, Bennett, Stanush, & McNelly, 1998), and training 
delivery methods (Arthur, Bennett, Edens, & Bell, 2003; Sitzmann, Kraiger, Stewart, & 
Wisher, 2006). In addition, there are two quantitative reviews of specific training methods 
of behavioral modeling (Taylor, Russ-Eft, & Chan, 2005) and error management training 
(Keith & Frese, 2008). One element that is missing from current meta-analytic studies on 
training design and transfer is consideration of the training objectives or goals of the training 
program on transfer. Training objectives are the intended outcomes of training, and they 
should dictate the selection of evaluation criteria (Goldstein & Ford, 2002).
As noted by Brown and Sitzmann (in press), research studies need to provide information on 
training objectives so that research can examine the extent to which training is effective when 
certain types of objectives are the focus of training. Baldwin and Ford (1988) stated that one 
objective of a training program can be to teach motor skills where the steps to be learned are 
clearly prescribed. In these training situations, it is desirable for trainees to adopt the modeled 
behaviors in essentially the same form as they are presented in training. For example, there is 
little leeway permitted in the proper way to safely operate a power tool. Consequently, the  
objective is to have the trainee mimic trained behavior as closely as possible. In the case of inter-
personal or leadership training, however, the objective is more to inculcate generalizable rules, 
concepts, and principles. Trainees are to formulate their own plan for how to apply those rules 
and customize the training to fit their needs (Baldwin et al., 2009). Yelon and Ford (1999)  
characterized this important distinction as closed versus open skills. In this meta-analysis, we 
 at UNIV OF MICHIGAN FLINT on June 8, 2010 http://jom.sagepub.comDownloaded from
<<<PAGE=6>>>
1070   Journal of Management / July 2010
distinguish between the goal of training for open versus closed skills and subsequently examine 
the extent to which the type of skills being trained might moderate the relationship between 
trainee and work environment characteristics and training transfer.
Colquitt, Lepine, and Noe (2000) quantitatively reviewed trainee characteristics and work 
environment factors and tangentially considered transfer. The central focus of their review 
was on understanding factors affecting the motivation to learn. In addition, they examined 
impacts on learning and transfer. They found that self-efficacy, valence, anxiety, and climate 
had the largest impact on motivation to learn, and they did not find support for conscien-
tiousness or job involvement. Motivation to learn was found to be significantly related to 
learning measures and transfer measures. Some evidence was found for the impact of con-
scientiousness and climate on transfer. Unfortunately, the number of studies in their review 
that included measures of transfer was quite small (i.e., relationships often were based on 
only two or three studies), and thus it is tenuous to reach conclusions regarding transfer on 
those data alone. On the other hand, our study represents the first full-scale quantitative 
review examining the influence of trainee characteristics and work environment on transfer.
We also examine the relationship between transfer and training interventions (pre- and 
posttraining), learning outcomes (i.e., trainee knowledge or learning, self-efficacy), and 
reactions. Our examination of the learning-transfer and reaction-transfer relationships is an 
update of a meta-analysis by Alliger, Tannenbaum, Bennett, Traver, and Shotland (1997), 
which focused on the relationships between training criteria.
Finally, we consider how transfer has been operationalized and how research design deci-
sions affect reported relationships between training input factors and training transfer. Although 
the distinction has rarely been made explicit, transfer has typically been measured as either the 
use of a trained skill or the effectiveness in performing the trained skill. These two ways of 
measuring transfer are clearly different from one another, and it is unknown to what extent the 
way transfer has been measured could affect the relationships. In addition, training researchers 
have too rarely considered how common method variance and the type of transfer measure (rat-
ings, objective measures) will affect observed relationships between predictor variables of inter-
est and training transfer. Taylor, Russ-Eft, and Taylor’s (2009) meta-analysis found that ratings 
of the impact of behavioral modeling training were related in part to the source (self, supervisor) 
of the transfer measure. Therefore, it is critical that we understand the extent to which transfer 
relationships differ depending on how transfer is measured. We empirically examine these 
issues and others (e.g., lab vs. field studies, time between end of training and the measurement 
of transfer) by looking at moderators of meta-analytic estimates.
Research Questions
A wide variety of empirical studies have emerged since Baldwin and Ford’s (1988) review. 
The result has been a more extensive nomological network for transfer and a considerably greater 
amount of empirical data, but at the cost of convergence and clarity regarding which factors relate 
most significantly with transfer and what can be leveraged to improve transfer. Our review of the 
extant transfer literature prompts several questions that meta-analysis is uniquely suited to 
address. Our seven research questions below concern both direct effects on transfer and modera-
tors of transfer relationships.
 at UNIV OF MICHIGAN FLINT on June 8, 2010 http://jom.sagepub.comDownloaded from
<<<PAGE=7>>>
Blume et al. / Transfer of Training   1071
The first research question concerns the influence of the most frequently identified and 
investigated predictor variables (trainee characteristics, work environment, training inter-
ventions, learning outcomes, and reactions) on transfer. With respect to the variables pro-
posed to influence transfer, a few central questions are of both conceptual and pragmatic 
interest to the transfer community. For example, which of many investigated individual differ-
ences have the strongest or weakest relationship to transfer? How do situational predictors 
vary in the strength of their effects? Are there some interventions that have shown consist-
ently significant relationships with transfer? How do various training outcomes (reactions to 
training, declarative knowledge) relate to transfer? 
Research Question 1a: What is the size of the relationship between transfer and trainee character-
istics (e.g., cognitive ability, experience, personality, motivation), work environment factors 
(i.e., support, climate, constraints/opportunity), training interventions, learning outcomes (i.e., 
knowledge, self-efficacy), and trainee reactions.
Directly related to obtaining these estimates, we found a subset of studies that are likely 
to inflate transfer relationships and, if included in the meta-analytic estimates, would 
provide inaccurate results. These studies are those in which same-source and same-
measurement-context (SS/SMC) effects are present. For example, in some studies 
exploring effects of work environment on transfer outcomes, the measurements of both 
the input factor (i.e., support) and the outcome factor of transfer were gathered from 
self-report measures at the same time (e.g., Chiaburu & Marinova, 2005; Facteau, 
Dobbins, Russell, Ladd, & Kudisch, 1995).
There is a growing body of research examining the extent to which method variance 
influences relationships between measures. Podsakoff, MacKenzie, Lee, and Podsakoff 
(2003) reviewed several meta-analytic studies (e.g., Gerstner & Day, 1997; Podsakoff, 
MacKenzie, Paine, & Bachrach, 2000) that contrasted the strength of the relationship 
between two variables when common method variance was controlled versus when it was 
not. They concluded that, on average, the amount of variance accounted for when common 
method variance was present was approximately 35%, versus approximately 11% when it 
was not present. Given such compelling evidence of the impact of common method variance 
in other research contexts, it is likely that SS/SMC bias is operative in many reported trans-
fer relationships. As one example, Colquitt et al. (2000) reported a mean corrected correla-
tion of .84 between peer support and transfer, so it seems likely that this reported relationship 
is inflated to some extent because of SS/SMC. We think it is important to document the 
extent of such inflation and to seek estimates of predictor–transfer relationships that do not 
reflect this inflation.
Research Question 1b: What are the predictor–transfer relationships after removing SS/SMC bias?
Moderators Directly Related to Transfer Measures
Another set of unaddressed questions concerns how the operationalization of transfer or 
measurement context affects the relationship between predictor variables and transfer. We 
 at UNIV OF MICHIGAN FLINT on June 8, 2010 http://jom.sagepub.comDownloaded from
<<<PAGE=8>>>
1072   Journal of Management / July 2010
contend that three specific distinctions of transfer measurement are particularly important. 
First, transfer measures can be taken immediately after training or after some time lag. We 
would expect that predictor and transfer relationships will be stronger when transfer mea-
sures are taken immediately after training, without a time lag. Barnett and Ceci (2002) refer 
to this as near transfer in both the physical and the temporal context.
Second, the source of transfer ratings (e.g., self vs. other) may also affect transfer correla-
tions. Self-reports may be distorted in the presence of high social desirability (Podsakoff et al., 
2003). In cases in which trainees want to impress a supervisor by affirming that they have 
applied the training they received (i.e., indicating that the training was worthwhile and not a 
waste of time), social desirability could influence trainees’ ratings of transfer. Taylor et al. 
(2009) found that effect size estimates for the transfer of managerial training were largest 
when based on trainees’ self-ratings (compared with supervisor, peer, and subordinate ratings). 
We would therefore expect self-ratings of transfer to yield stronger relationships with predic-
tors than other ratings would.
Third, transfer has been measured as both the use of a trained knowledge or skill and the 
effectiveness of the trainee in applying the knowledge or skill. An example of a use measure of 
transfer is found in Tracey, Tannenbaum, and Kavanagh (1995), who examined the influence of 
the work environment on the transfer of newly trained supervisory skills. Their items reflect a 
broad range of supervisory behaviors, including problem solving and decision making. An exam-
ple item is, “At the present time, the associate to be trained meets regularly with other associates 
to discuss problems and identify ways to solve them.” One example of an effectiveness measure 
of transfer is illustrated in a study by Xiao (1996), who assessed transfer of circuit board produc-
tion workers 9
 mo
nths after training. Two of the six items used were, “Using the new KSA has 
helped me improve my work” and “I have accomplished my job tasks faster than before training.” 
In general, since using the knowledge or skill is necessary, but not sufficient, to effective transfer, 
we would expect stronger predictor–transfer relationships when transfer is measured as use than 
when it is measured as effectiveness. Our second research question is therefore an aggregation of 
the three transfer measurement issues.
Research Question 2. To what extent does the way that transfer is measured, including (a) whether a time 
lag exists between training and the transfer measure, (b) self versus non-self (i.e., peer or objective) 
measures, and (c) use versus effectiveness, influence predictor–transfer relationships?
Open Versus Closed Skills
As discussed above, among the most conspicuous gaps in the transfer literature is a neglect of 
how the open or closed nature of the skills being trained (i.e., training objectives) affects subse-
quent transfer. Training objectives tied to learning specific skills that are to be produced identi-
cally in the transfer environment as in the learning context are labeled closed skills, whereas 
training objectives tied to learning principles are labeled open skills (Yelon & Ford, 1999). Yelon 
and Ford (1999) noted that with closed skills, trainees are to respond in one particular way on the 
job according to a set of rules implemented in a precise fashion. With highly variable open skills, 
there is not a single correct way to act but rather freedom to perform.
 at UNIV OF MICHIGAN FLINT on June 8, 2010 http://jom.sagepub.comDownloaded from
<<<PAGE=9>>>
Blume et al. / Transfer of Training   1073
Salas, Milham, and Bowers (2003) noted the evolution of many military jobs from 
primarily physical roles to roles based more on rapid actions linked to changing situa-
tions. They argued that not only are such open skills more difficult to train, but they 
also require higher-level cognitive components, are subject to greater and more rapid 
decay than are simpler motor skills, and likely demand a more supportive context for 
transfer to occur. That is, with closed skills, a trainee is often given the opportunity to 
apply learned skills immediately on the job, and the rewards and reinforcement for 
transfer are usually self-evident (e.g., the employee can now use a production machine 
he or she previously could not use). The prevalence of opportunities to apply open 
skills, however, is less straightforward and may be a function of the trainee’s seeing the 
potential to use trained principles and guidelines on the job, as well as
 th
e supervisor’s 
taking an active role in offering such opportunities. Therefore, a predictor of transfer, 
such as supervisor support, may differ in its relationship to transfer depending on 
whether the skill being trained is an open or a closed skill.
In the case of open skills, the trainee has more choice regarding whether, how, 
and when to transfer. For example, those more motivated to learn an open skill will 
more likely seek opportunities in the work place to apply the training and perhaps 
also seek out coworker support for applying trained skills (Ford, Quinones, Sego, & 
Sorra, 1992). Therefore, we expect that the relationship of some predictor variables 
(e.g., self-efficacy, motivation to learn) might have a stronger impact on training 
transfer for open rather than for closed skills (Baldwin et al., 2009).
Research Question 3. To what extent are predictor–transfer relationships stronger for open than for 
closed skills?
Additional Moderators
Lab versus field context.  The transfer literature is characterized by a volume of both 
laboratory and field studies. Laboratory studies typically include a student sample, 
whereas field studies have nonstudent samples. Laboratory studies often allow for more 
control over key variables and thus provide the potential for greater in-depth examination 
of transfer processes and outcomes (Evans & Rooney, 2008). At the same time, 
laboratory studies tend to have a shorter time frame between training and the transfer 
measurement. Given these differences, the effect sizes found in a lab setting might not 
be consistent, for the same predictor–transfer relationships, with the effect sizes found 
in field research. We therefore were interested in documenting any systematic differences 
between lab and field studies. 
Research Question 4: To what extent does the laboratory or field context moderate  pr edictor–transfer 
relationships?
Publication source.  The next research question explores the impact on transfer 
relationships of whether the data analyzed were from a published or unpublished source. 
This phenomenon has traditionally been labeled the file drawer effect (Rosenthal, 1979). A 
recent review and evaluation of meta-analytic practices (Geyskens, Krishnan, Steenkamp, & 
 at UNIV OF MICHIGAN FLINT on June 8, 2010 http://jom.sagepub.comDownloaded from
<<<PAGE=10>>>
1074   Journal of Management / July 2010
Cunha, 2009) stressed the importance of examining this phenomenon. Some prior meta-
analyses on training effectiveness have found differences related to whether the source of 
data was published or not (e.g., Arthur et al., 2003). Therefore, our fifth research question is 
designed to explore whether a file drawer effect exists in the transfer literature.
Research Question 5: What is the impact on predictor–transfer relationships related to whether the 
data were from a published or unpublished source?
Time between the end of training and the transfer measure. In addition to issues related to 
the source and type of measurement discussed above, the timing of the measurement is 
important to consider. More specifically, it seems likely that the length of time between the end 
of training and a measure of transfer can affect the relationship between predictor variables and 
transfer. From the standpoint of the temporal context (Barnett & Ceci, 2002), it may be that 
some predictors would have a larger impact on transfer when there is less time between 
training and when the transfer measure is obtained. For example, would the relationship 
between trainee motivation and transfer be stronger if transfer was measured a few weeks after 
training rather than a few months after training? While it may seem logical to predict that 
shorter time frames would lead to stronger predictor–transfer relationships, Taylor et al. (2009) 
made the following point: 
On one hand, longer time lags might be expected to result in smaller effect sizes as a result of 
learning decay, but on the other hand, too little time between training and posttest could result 
in trainees not having had opportunities to use newly learned skills or raters not having had suf-
ficient observational opportunities. (p. 106) 
Therefore, our sixth research question relates to the impact of transfer measurement timing 
on observed relationships.
Research Question 6: To what extent does the length of time between training and the transfer 
measure influence predictor–transfer relationships?
Relationships Between Transfer Measures
Our final research question examines the relationship of multiple measures of transfer for 
a subset of longitudinal studies in which transfer is assessed by multiple sources or at 
multiple times. First, we examined the relationship between trainees’ versus others’ (e.g., 
supervisor or peers) assessment of transfer when these measures are obtained at the same 
time. Although we are not aware of a meta-analysis on transfer that has reported such 
relationships, we might expect correlations to be similar to those found between self–other 
ratings of job performance. For example, Heidemeier and Moser (2009) found an overall 
meta-analytical estimate of the correlation between self- and supervisory ratings of .22  
(r =
 .3
4 when corrected for measurement error). Second, we examined the correlation of 
repeated measures of transfer by the same source at different times. This relates to 
 at UNIV OF MICHIGAN FLINT on June 8, 2010 http://jom.sagepub.comDownloaded from
<<<PAGE=11>>>
Blume et al. / Transfer of Training   1075
maintenance of transfer in that we are examining how transfer changes over time. In other 
words, how consistent are perceptions of transfer over time?
Research Question 7a: What is the correlation between trainees’ versus others’ (e.g., supervisor’s 
or peers’) assessment of transfer when these measures are obtained at the same time?
Research Question 7b: What is the correlation between repeated measures of transfer by the same 
source at different times?
Method
Literature Search
We conducted an extensive search for primary empirical studies reporting a correlation 
between training transfer and at least one of the following variables: age, gender, education, 
experience, cognitive ability, the Big Five personality traits, locus of control, goal orienta-
tion, job involvement, voluntary participation, pretraining self-efficacy, motivation to learn 
or transfer, work environment, learning outcomes of knowledge or self-efficacy, reactions, 
and pre- or posttransfer intervention. We defined a measure as transfer if the skill being trained 
was assessed (a) through different or more complex tasks than the tasks in the training 
session or (b) in an environment different from the training environment. We excluded stud-
ies that looked only at learning outcomes (e.g., declarative or procedural knowledge). We 
limited the search results to articles that were published in English and based on healthy 
adult samples (i.e., we excluded studies of children or of adults with a medical condition).
Studies included in our meta-analysis were identified by a variety of methods. First, we 
conducted a search of the PsycINFO and ERIC databases using the keywords training trans-
fer, transfer of training , training effectiveness, and learning transfer for the years 1988 
through 2008. In addition to the above four keywords, we conducted an expanded search 
using the additional keywords training outcome and training performance from several key 
academic journals
1 to obtain as many published articles as possible that might contain train-
ing transfer measures. We also identified studies published prior to 1988 by examining all 
studies reviewed in Baldwin and Ford (1988). Second, we searched the ProQuest disserta-
tion abstracts database from 1988 through 2008 using the terms training transfer, transfer of 
training, training effectiveness, and learning transfer to identify unpublished dissertations. 
Third, we conducted a search of the Academy of Management (AOM) and the Society for 
Industrial and Organizational Psychology (SIOP) conference programs for 2005 through 
2008 and contacted authors of articles that might report relationships involving training 
transfer. Fourth, we contacted prominent authors in the field to request working papers.
For a study to be included in the meta-analysis, it had to either report or allow the com-
putation of a correlation coefficient between any of the predictor variables and a measure of 
training transfer.
2 On the basis of our literature search, we identified 93 independent samples 
(N = 24
,493), including 60 published articles, 5 unpublished conference papers, 26 disserta-
tions, and 2 unpublished articles.
 at UNIV OF MICHIGAN FLINT on June 8, 2010 http://jom.sagepub.comDownloaded from
<<<PAGE=12>>>
1076   Journal of Management / July 2010
Coding for Meta-Analysis
After developing guidelines for coding, two of the authors coded an initial set of 13 articles. 
Three of the authors then discussed problems encountered and revised the guidelines. The first 
two then coded and discussed five additional articles. Any discrepancies were resolved by 
using a consensus discussion among all of us. One of us subsequently coded the remainder 
of the articles included in the meta-analysis. Another of us also coded 36 of these articles to 
allow for an examination of interrater agreement.
Each of the studies identified was coded as follows: (a) type of transfer (use vs. effective-
ness), (b) time between the predictor variable and transfer measures, (c) time between the 
end of training and the transfer measure, (d) type of skill trained (open vs. closed), (e) source 
of predictor variable measure (objective, self, other), (f) source of transfer measure (objec-
tive, self, other), (g) setting (field vs. lab), (h) sample size (N), (i) measure reliabilities, and 
(j) effect sizes. For coding of effect sizes, we obtained Pearson’s correlation coefficient 
directly from the majority of studies or computed r from existing statistics such as d. The 
level of coding agreement was generally high, with a mean overall agreement of 94.5%  
(SD =
 4.2). Cases 
in which the initial codings of the two raters differed were resolved by 
discussion and recoded as needed.
When coding a transfer measure, we focused on whether transfer was measured as the use 
of a trained skill or the effectiveness of the performance on the trained skill. The majority of 
use measures were from the trainees on the frequency of or extent to which they apply the 
trained skills on the job. The effectiveness measures consisted of approximately equal pro-
portions of objective measures, others’ ratings, and self-report measures that generally 
focused on the outcome of applying the trained skills. For type of skill trained, we coded a 
study as closed skills training if the trainee was taught to respond in a particular way accord-
ing to a set of rules or procedures. A study was coded as open skills training if the trainee 
had considerable latitude in deciding a course of action. Typical closed skills training pro-
grams included various technical training and computer software training, and typical open 
skills training included leadership and interpersonal skills training.
Independence Assumption
When a study reported multiple indicators of a focal construct, we followed the recommen-
dation by Geyskens et al. (2009) and created a single composite variable for that construct in 
order to avoid violating the independence assumption by including multiple correlations from 
the same study. There were three exceptions to the use of linear composites. We chose not to 
create composites when the correlations among the indicators were so low as to indicate that 
they did not measure the same construct. We also decided not to create composites for transfer 
measures across different times, as time was one of the important moderator variables of 
interest, and a composite correlation would obscure the effect of time and prohibit further 
moderator analysis. In some rare cases, we could not create a composite because all necessary 
correlations were not reported. When any of these situations occurred for transfer measures 
within the same study, we selected one of the possible effect sizes based on the following 
 at UNIV OF MICHIGAN FLINT on June 8, 2010 http://jom.sagepub.comDownloaded from
<<<PAGE=13>>>
Blume et al. / Transfer of Training   1077
order of preference: (a) effectiveness over use; (b) others’ report or objective measures over 
self-report; and (c) longer over shorter time lag after training. When these situations did not 
concern transfer measures, we randomly selected one of the possible effect sizes for inclusion 
(Lipsey & Wilson, 2001; Rosenthal & Rubin, 1986).
Outliers
A primary study coefficient may be an outlier in a meta-analytic study because of unique 
features of the study’s design or sample or because of errors in analyses or reporting 
(Huffcutt & Arthur, 1995). With that in mind, we first removed Oakes, Ferris, Martocchio, 
Buckley, and Broach (2001) because of its extremely large sample size of 9,721. To detect 
outliers, we calculated the sample-adjusted meta-analytic deviancy (S
AMD) 
statistic 
(Huffcutt & Arthur, 1995; cf. Beal, Corey, & Dunlap, 2002), which approximates a t distribu-
tion. We used a cutoff of SAMD > 4 (e.g., 
Steel, 2007) to determine outliers for the effect of 
each predictor variable on transfer. This analysis identified 24 effect sizes as outliers out  
of the total of 349 effect sizes between various predictor variables and transfer. A review of 
these effect sizes identified reasons for caution, such as very large sample size (i.e., two 
effect sizes from Dierdorff & Surface, 2008, were based on N
 = 2,105), unlikely 
high effect 
sizes (e.g., Ameel, 1992, with r = .77 between 
posttraining self-efficacy and transfer, 
Mohammed, 1994, with r = .75 between 
social support and transfer), and one-time, self-
report data (e.g., Chiaburu & Marinova, 2005; Velada & Caetano, 2007). The removal of 
outlier effect sizes resulted in a final data set of 325 independent correlations from 89 
sources (N =
 12,496).
Meta-Analytic Procedures
We used Hunter and Schmidt’s (2004) meta-analytic procedure to conduct the overall 
analysis on the relationship between each predictor variable and transfer. We calculated a 
sample-weighted average correlation (r–) and derived the mean of population correlation (r) 
by correcting for unreliability in both the predictor and dependent variables. Consistent with 
the suggestion by Geyskens et al. (2009), we corrected for unreliability at the individual 
level when information was available. When reliability information was reported sporadi-
cally, we corrected for measurement error with artifact distribution (formulas provided in 
Hunter & Schmidt, 2004), which used all reliability coefficients coded for a particular vari-
able for its analysis. We also calculated the percentage of observed variance explained by 
artifacts (i.e., sampling error and unreliability), as well as the standard deviation of the cor-
rected correlation (SD
r).
Moderator Analyses
We used two heterogeneity tests to aid the detection of moderating effects: the 75% rule 
proposed by Hunter and Schmidt (2004) in conjunction with the credibility interval. 
 at UNIV OF MICHIGAN FLINT on June 8, 2010 http://jom.sagepub.comDownloaded from
<<<PAGE=14>>>
1078   Journal of Management / July 2010
Specifically, when variance from sampling and measurement error accounts for less than 
75% of the observed variance, the 75% rule suggests that there is a potential moderator in 
effect. A wide credibility interval also indicates the presence of moderators.
To examine the effect of categorical moderators, we used Hunter and Schmidt’s (2004) 
subgroup analysis. When the subsequent subgroups displayed different mean corrected cor-
relations and had lower average corrected variance than the whole group did, we concluded 
the categorical moderator was in effect. When moderators are not orthogonal to each other, 
hierarchical subgroup analysis can separate effects of different moderators (Geyskens et al., 
2009). We adopted a partial hierarchical approach and examined the effects of categorical 
moderators in the following sequence: (a) SS/SMC bias, (b) transfer operationalization, and 
(c) other moderators not related to the measurement of transfer (i.e., open vs. closed, lab vs. 
field). When examining open skills as a moderator, when possible we divided our analysis 
by interpersonal/leadership versus other skills.
To examine the effect of continuous moderators, we employed weighted least squares 
(WLS) regression with inverse sampling error weighting suggested by Steel and Kammeyer-
Mueller (2002). We conducted WLS regression only when there were more than 10 studies 
for the analysis. Moderator variables with severe positive skewness were first log trans-
formed or power transformed to approximate normal distribution before WLS regression 
analysis.
Results
Study Characteristics
The final 89 studies that contributed at least one effect size to the meta-analyses 
included 58 journal articles, 5 conference papers, 24 dissertations, and 2 unpublished manu-
scripts. The majority of the samples (85%) were from the United States and Canada. The 
trainees included undergraduate students (24 studies, 27%), MBA or graduate students (12 
studies, 13%), managers and supervisors (21 studies, 24%), and other nonmanagerial per-
sonnel (32 studies, 36%).
The sample included 61 field studies and 28 lab experiments. All of the lab studies had 
student samples, whereas 90% of field studies had nonstudent samples. The time between 
training and the transfer measures ranged from immediately after training to 163
 weeks after 
training 
and was shorter for lab studies (i.e., M = 1.6 weeks; median = 1 day) than 
for field 
studies (i.e., M = 15 weeks; median = 7.5 weeks). The 
median length of training was 6 hours.
Th
e field studies contained more open skills training (44 open, 15 closed, and 2 not codable) 
whereas the lab studies had more closed skills training (12 open and 16 closed). The most com-
mon closed skills trained were computer software and those involving simulations, such as flight 
simulator tasks. Of the 56 studies involving open skills, 71% included interpersonal or leadership 
skills (e.g., teamwork, negotiation) and 29% included other open skills (e.g., problem solving, 
substance abuse prevention).
The main effects of the predictor variables on transfer are presented in Table 1. Where 
SS/SMC bias could be expected to influence the relationship between a predictor and trans-
 at UNIV OF MICHIGAN FLINT on June 8, 2010 http://jom.sagepub.comDownloaded from
<<<PAGE=15>>>
Blume et al. / Transfer of Training   1079
fer, we analyzed the effects for two subgroups of studies, one with SS/SMC bias present and 
the other without the influence of SS/SMC. These results are also presented in Table 1. 
Cohen’s (1988) definition of effect sizes (small effect sizes are correlations of .10, moderate 
are .30, and large are .50) guided our interpretation.
Main Effects Considering SS/SMC
Our results indicate that when the predictor variables and transfer were both measured 
by the trainee at the same time, this SS/SMC bias consistently inflated the relationships 
between the constructs examined. For example, in the relationship between environment and 
transfer, the correlation for studies with SS/SMC bias was .54, whereas the correlation for 
studies without SS/SMC bias was .23. When the 13 studies that had SS/SMC bias were 
included in the calculation of the effect size, it increased from .23 to .36. Another example 
is motivation, for which the correlation with transfer was .23 for those studies without SS/
SMC bias versus .41 when SS/SMC bias was present. SS/SMC bias also inflated the results 
of the relationship with transfer for the following constructs: locus of control, goal orienta-
tion, job involvement, posttraining self-efficacy, and utility reactions. To illuminate the 
uninflated or true relationship between constructs, we report on and discuss below only those 
results that exclude SS/SMC bias.
Among the trainee characteristics examined, cognitive ability (.37), conscientiousness 
(.28), and voluntary participation (.34) had moderate relationships with training transfer. It 
should be noted that all but two of the studies that examined the relationship between trans-
fer and cognitive ability were in the lab context, most with no time between the end of train-
ing and the transfer measure. Neuroticism (.19), pretraining self-efficacy (.22), and 
motivation (.23), had small to moderate relationships with transfer. Small correlations were 
found between training transfer and Big Five personality dimensions agreeableness (−.03), 
extraversion (.04), and openness to experience (.08). In addition, small correlations were 
found between training transfer and trainees’ age (.04), education (.07), male gender (.12), 
experience (.09), external locus of control (−.06), and job involvement (.04). Small correla-
tions were also found for learning goal orientation (.14), prove-performance goal orientation 
(.03), and avoid-performance goal orientation (−.12). Most of the studies involving goal 
orientation examined transfer in the lab context with little or no time between training and 
the transfer measure.
In addition to the effect size of .22 discussed above for a general environment construct, 
we were able to perform an analysis on the environment context variable based on how 
environment was measured. We classified these measures into three different categories: 
support (e.g., peer support, supervisor support), transfer climate, and reversed-scored orga-
nizational constraints (e.g., lack of autonomy, situational constraints). Results indicated that 
transfer climate had the highest relationship with transfer (.27), followed by support (.21) 
and constraints (.05; reverse scored), although constraints was based on only two studies. 
Subsequent analysis indicated that supervisor support (.31) may have a stronger relationship 
with transfer than does peer support (.14), although these relationships also are based on 
small sample sizes.
 at UNIV OF MICHIGAN FLINT on June 8, 2010 http://jom.sagepub.comDownloaded from
<<<PAGE=16>>>
Table 1
Relationships Between Predictor Variables and Transfer
Predictor K N r– SDr r SDr % Variance 95% CI 80% CV
Trainee 
characteristics  
         
Age 10 1,049 .04 .13 .04 .02 97 –.04 .12 .01 .07
Gender (male) 5 366 .11 .28 .12 .15 42 –.13 .36 –.12 .37
Educationa 8 1,219 .06 .11 .07 .06 73 –.01 .14 –.02 .16
Experience  16 1,887 .08 .18 .09 .13 38 –.01 .17 –.13 .30
Cognitive ability 10 1,452 .31 .20 .37 .18 23 .19 .43 .08 .66
Conscientiousness 5 433 .23 .12 .28 .07 77 .13 .34 .17 .38
Neuroticism 5 653 –.16 .10 –.19 .04 88 –.25 –.07 –.25 –.13
Agreeableness 3 218 –.02 .07 –.03 .00 100 –.10 .06 –.03 –.03
Extraversion 3 218 .03 .08 .04 .00 100 –.06 .12 .04 .04
Openness 4 303 .06 .19 .08 .16 47 –.12 .25 –.18 .35
Locus of 
control (external) 6 744 –.08 .13 –.12 .08 73 –.19 .02 –.24 .01
  SS/SMC 2 386 –.12 .10 –.17 .00 100 –.26 .01 –.17 –.17
  Not SS/SMC  4 358 –.04 .14 –.06 .09 73 –.18 .10 –.20 .08
Learning goal 
orientation 12 1,718 .13 .14 .16 .10 51 .06 .21 .00 .33
  SS/SMC  1 186 .32 .00 .39 .00  
   
 Not SS/SMC  11 1,532 .11 .13 .14 .07 69 .03 .19 .02 .25
Prove–performance goal 
orientation 13 1,728 .06 .16 .07 .13 39 –.03 .14 –.15 .29
  SS/SMC  1 186 .30 .00 .36 .00     
  Not SS/SMC  12 1,542 .03 .15 .03 .09 57 –.06 .11 –.12 .19
Avoid–performance 
goal orientation 5 904 –.10 .09 –.12 .00 100 –.17 –.02 –.12 –.12
Pretraining self–ef
ficacy 22 1,968 .19 .18 .22 .18 32 .11 .26 –.07 .52
Motivation 29 3,844 .24 .17 .29 .15 29 .18 .30 .03 .54
  SS/SMC  5 1,270 .35 .04 .41 .00 100 .31 .38 .41 .41
  Not SS/SMC  24 2,574 .19 .16 .23 .16 33 .13 .25 –.04 .49
V oluntary 
participationa 5 1,413 .22 .14 .34 .12 34 .10 .34 .14 .54
Job involvementa 4 546 .29 .21 .38 .20 21 .09 .50 .05 .71
  SS/SMC  2 386 .41 .06 .52 .00 100 .33 .48 .52 .52
  Not SS/SMC 2 160 .03 .06 .04 .00 100 –.06 .12 .04 .04
Environmental 
factors  
         
Work 
environmenta 35 5,017 .30 .19 .36 .18 22 .23 .36 .06 .66
  SS/SMC  13 3,623 .43 .20 .54 .12 25 .32 .54 .35 .73
(continued)
1080
 at UNIV OF MICHIGAN FLINT on June 8, 2010 http://jom.sagepub.comDownloaded from
<<<PAGE=17>>>
Table 1 (continued)
Predictor K N r– SDr r SDr % Variance 95% CI 80% CV
  Not SS/SMC 22 2,085 .19 .16 .23 .14 43 .12 .26 .00 .46
Constraints (reverse–scored) 2 140 .05 .07 .05 .00 100 –.05 .14 .05 .05
Support 12 1,075 .18 .14 .21 .07 75 .10 .26 .10 .33
Climate 8 870 .23 .20 .27 .20 26 .09 .36 –.05 .60
Learning outcome 
variables  
         
Posttraining knowledge 34 3,825 .20 .20 .24 .17 30 .13 .26 –.04 .52
Posttraining self–ef
ficacy 17 1,927 .19 .18 .22 .15 35 .10 .27 –.02 .46
  SS/SMC  2 87 .40 .03 .46 .00 100 .36 .44 .46 .46
  Not SS/SMC 15 1,840 .18 .18 .20 .14 35 .09 .27 –.03 .44
Reactions  
         
Utility reactions 9 987 .39 .29 .46 .28 11 .20 .58 .00 .92
  SS/SMC 3 528 .60 .13 .69 .07 47 .45 .75 .58 .80
  Not SS/SMC  6 459 .14 .13 .17 .04 92 .04 .24 .10 .23
Affective 
reactions 8 768 .07 .09 .08 .00 100 .01 .13 .08 .08
Overall reactions 7 897 .07 .18 .08 .12 46 –.06 .20 –.11 .27
Pre– 
or posttraining interventions  
         
Pretraining optimistic 
preview 3 221 .17 .11 .20 .00 100 .05 .30 .20 .20
Posttraining goal–setting  6 378 .07 .23 .08 .15 46 –.11 .26 –.17 .33
Posttraining relapse 
prevention 5 321 –.06 .15 –.06 .00 100 –.19 .08 –.06 –.06
Note. K
 = number of studies included in each analysis; N = total sample size in each analysis; r– = sample size weighted mean correlation; SDr = standard deviation of the 
observed correlations; r = mean population correlation (corrected for unreliability in predictor and criterion); SDr = standard deviation of the corrected correlation; 
% Variance = percentage of variance attributed to sampling error and measurement unreliability; 95% CI = 95% confidence interval around r–; 80% CV  = 80% credibility 
interval 
around r
aAll of the studies were conducted in the field setting.
1081
 at UNIV OF MICHIGAN FLINT on June 8, 2010 http://jom.sagepub.comDownloaded from
<<<PAGE=18>>>
1082   Journal of Management / July 2010
For learning outcomes, posttraining self-efficacy (.20) and posttraining knowledge (.24) 
both had small to moderate effects on transfer. Utility reactions had a corrected correlation 
of .17, while both affective reactions and reactions that included both affective and utility 
dimensions had small relationships (.08) with training transfer.
The effect of training interventions (i.e., optimistic preview, goal-setting, and relapse 
prevention) on transfer were small to moderate (.20, .08, and −.06, respectively), and the 
between-study variation of effect sizes for optimistic preview and relapse prevention was 
fully attributed to artifacts. However, these results should be interpreted with caution as they 
are based on a fairly small number of studies (i.e., 3 to 6). In addition, the 80% credibility 
interval for the correlation between transfer and goal-setting interventions ranged from −.17 
to .33, indicating the presence of moderators on how effective these interventions were on 
improving transfer. An important moderator for goal-setting interventions discussed below is 
the lab-versus-field context.
Moderator Analyses
Given our finding that SS/SMC bias consistently inflates the observed relationships 
between predictors and transfer, the presence of SS/SMC bias could confound any further 
moderator analysis if SS/SMC bias is not orthogonal to the moderator variable. Therefore, 
we used only the studies without SS/SMC bias when further examining effects of other 
moderators.
3 Table 2 includes the moderating effects of transfer operationalization specified 
in Research Question 2.
Time lag versus no time lag between end of training and transfer measure. Pretraining self-
efficacy is influenced by when transfer is measured, that is, r = .3
2 when taken immediately 
after training, versus r = .2
1 when there is a time lag between training and the transfer measure. 
For the four studies in which transfer was measured immediately after training, the correlation 
of posttraining self-efficacy was .38, which was significantly higher than the correlation of .11 
for the 11 studies in which there was at least some time between training and the transfer mea-
sure. As compared with studies that didn’t have a time lag, when there was a time lag between 
training and the transfer measure, our results also indicate a decrease in r for posttraining 
knowledge (i.e., from .48 to .18) and for experience (i.e., from .30 to .03).
Self versus other measure of transfer . The source of the transfer measure influenced the effect 
sizes between transfer and both pretraining self-efficacy and motivation. Pretraining self-efficacy 
had r of .29 for self versus .14 for others/objective. With motivation, when transfer was measured 
by the trainee (self), the r was .33, compared with .11 when transfer was measured objectively 
or by others. Although the difference in effect sizes was not as pronounced as for motivation, the 
correlation between environment and transfer also increased when measured by self versus other 
(i.e., .28 vs. .20).
Use versus effectiveness measure of transfer. We were also able to examine the moderator 
of use versus effectiveness for motivation, environment, and posttraining knowledge. When 
transfer was measured objectively or by others, the relationship between motivation and 
 at UNIV OF MICHIGAN FLINT on June 8, 2010 http://jom.sagepub.comDownloaded from
<<<PAGE=19>>>
Table 2
Moderating Effect of Transfer Operationalization on Predictor–Transfer Relationship
Predictor K N r– SDr r SDr % Variance 95% CI 80% CV
Experience 16 1,887 .08 .18 .09 .13 38 −.01 .17 −.13 .30
  No T
ime Lag 4 423 .28 .09 .30 .00 100 .19 .37 .30 .30
  Time 
Lag  12 1,464 .02 .17 .03 .07 64 −.07 .12 −.10 .15
Pretraining Self–Ef
ficacy 22 1,968 .19 .18 .22 .18 32 .11 .26 −.07 .52
  No T
ime Lag  4 305 .28 .16 .32 .09 64 .12 .43 .17 .47
  Time 
Lag  18 1,663 .17 .18 .21 .19 30 .09 .25 −.10 .52
Other/Objective 10 910 .12 .19 .14 .19 29 .00 .24 −.18 .45
Self  8 753 .23 .17 .29 .15 41 .12 .35 .05 .53
Motivationa  24 2,574 .19 .16 .23 .16 33 .13 .25 −.04 .49
  Other/Objective 13 1,236 .10 .14 .11 .05 85 .02 .17 .03 .19
Effectiveness 11 1,128 .08 .13 .10 .04 89 .01 .16 .03 .16
Use 2 108 .26 .04 .36 .00 100 .20 .31 .36 .36
  Self 10 1,288 .27 .18 .33 .17 27 .16 .38 .05 .61
Effectiveness 4 319 .27 .15 .32 .11 57 .12 .42 .14 .50
Use 6 969 .27 .20 .35 .19 20 .11 .43 .03 .66
Work 
Environmenta  22 2,085 .19 .16 .23 .14 43 .12 .26 .00 .46
  Effectiveness  12 964 .18 .17 .21 .16 42 .08 .27 −.04 .47
  Use 10 1,121 .20 .16 .24 .13 45 .10 .30 .04 .45
  Other/Objective 12 1,292 .17 .20 .20 .18 28 .05 .28 −.10 .50
  Self 8 709 .24 .09 .28 .00 100 .17 .30 .28 .28
Posttraining Knowledge 34 3,825 .20 .20 .24 .17 30 .13 .26 −.04 .52
  No T
ime Lag 7 785 .38 .19 .48 .15 34 .24 .52 .23 .73
  Time 
Lag 27 3,040 .15 .15 .18 .13 45 .09 .21 −.02 .39
Effectiveness 14 1,456 .14 .17 .17 .13 44 .05 .23 −.05 .38
Use 13 1,584 .16 .13 .20 .12 46 .09 .23 .00 .39
Post training 
self–efficacya 15 1,840 .18 .18 .20 .14 35 .09 .27 −.03 .44
  No T
ime Lag 4 659 .32 .08 .38 .00 100 .25 .40 .38 .38
  Time 
Lag 11 1,181 .09 .17 .11 .09 60 −.01 .19 −.04 .26
No
te. K = number of studies included in each analysis; N = to
tal sample size in each analysis; r– = sample size weighted mean correlation; SDr = standard deviation of the observed 
correlations;  r = mean population correlation (corrected for unreliability in predictor and criterion); SDr = standard deviation of the corrected correlation; % V ariance = percentage of 
variance attributed to sampling error and measurement unreliability; 95% CI = 95% confidence interval around r–; 80% CV = 80
% credibility interval around r
aIncluded only studies without SS/SMC bias in the analysis.
1083
 at UNIV OF MICHIGAN FLINT on June 8, 2010 http://jom.sagepub.comDownloaded from
<<<PAGE=20>>>
1084   Journal of Management / July 2010
transfer was higher for the 2 studies in which transfer was measured as use (.36) than in the 
11 studies in which transfer was measured as effectiveness (.10). On the other hand, when 
transfer was measured by self, the relationships between motivation and transfer were 
similar (.35 for use vs. .32 for effectiveness). For environment, use measures have only 
slightly higher relationships than effectiveness measures (.24 vs. .21, respectively). There 
was also a slight increase in the correlation of posttraining knowledge when transfer was 
measured as use (.20) versus effectiveness (.17).
Open versus closed skill. Table 3 presents the results of the moderator analysis for open 
versus closed skills. For the relationship between cognitive ability and transfer, two studies 
examined open skills, and eight studies examined closed skills. Although based on only two 
studies, it is interesting to note that there was a small, negative relationship between cogni-
tive ability and the transfer of open skills (−.14). This contrasts with the moderately strong, 
positive relationship between cognitive ability and the transfer of closed skills (.41).
For all other variables examined, predictor–transfer relationships were stronger for open 
than for closed skills, including trainee experience (.06 and −.02, respectively) and motivation 
(.19 and .11, respectively). For pretraining self-efficacy, the relationship with transfer is 
higher for open than for closed skills (.23 vs. .10). This finding is similar for posttraining self-
efficacy (i.e., .13 for open skills vs. .06 for closed skills). When examining the environment–
transfer relationship, we found a correlation of .26 for open skills and a correlation of .04 for 
closed skills. Finally, in studies that examined the relationship between transfer and posttrain-
ing knowledge with some time lag between the end of training and transfer, the correlation is 
.20 for open skills and .14 for closed skills. When we examined only studies of interpersonal/
leadership skills training (as a subset of open skills), we found that post-training self-efficacy, 
motivation, work environment, post-training knowledge, and pre-training self efficacy all had 
similar correlations with transfer (i.e, .22, .20, .20, .16, and .14, respectively).
Lab versus field context. As seen in Table 4, the effect of posttraining self-efficacy is stronger 
in the field than in the lab context (i.e., .17 vs. .08). Similarly, cognitive ability has a negative 
relationship with transfer in two field studies, whereas it has a positive relationship in lab studies 
(i.e., .41 vs. −.14). On the other hand, other predictors demonstrate stronger relationships in the 
field than in the lab context, such as pretraining self-efficacy (i.e., .24 vs. .11), motivation (i.e., 
.24 vs. .17), and goal setting interventions (i.e., .28 vs. .00). Posttraining knowledge has similar 
relationships with transfer in the field and lab context (i.e., .19 vs. .16).
Publication source. Per Table 5, we found evidence that published studies reported stron-
ger relationships with transfer than unpublished studies did for environment (.26 vs. .18), 
motivation (.28 vs. .15), pretraining self-efficacy (.31 vs. .10), and posttraining self-efficacy 
(.37 vs. .06). The relationship between posttraining knowledge and transfer was contrary to 
this trend, with similar relationships, r =
 .2
3 and .24, for published and unpublished studies, 
respectively.
Time between the end of training and the transfer measure. Table 6 indicates the moderator 
analysis of the length of time between the end of training and the time the transfer measure was 
 at UNIV OF MICHIGAN FLINT on June 8, 2010 http://jom.sagepub.comDownloaded from
<<<PAGE=21>>>
1085
Table 3
Moderating Effect of Type of Skill on Predictor–Transfer Relationship
Predictor K N r– SDr r SDr % Variance 95% CI 80% CV
Cognitive ability 10 1,452 .31 .20 .37 .18 23 .19 .43 .08 .66
  Closed 8 1,338 .34 .12 .41 .10 40 .26 .42 .24 .58
  Open 2 114 –.12 .06 –.14 .00 100 –.21 –.03 –.14 –.14
Experienceb 12 1,464 .02 .17 .03 .07 64 –.07 .12 –.10 .15
  Closed 4 619 –.02 .15 –.02 .04 85 –.17 .13 –.08 .04
  Open 8 845 .06 .16 .06 .08 67 –.05 .16 –.06 .18
Pretraining self–ef
ficacyb 18 1,663 .17 .18 .21 .19 30 .09 .25 –.10 .52
  Closed 3 350 .08 .14 .10 .09 63 –.08 .24 –.05 .25
  Open 15 1,313 .19 .19 .23 .20 29 .10 .29 –.09 .55
Interpersonal/leadership 11 908 .11 .15 .14 .12 56 .03 .20 –.06 .33
Other open 
skills 4 405 .37 .25 .44 .17 28 .13 .62 .17 .72
Motivationa 24 2,574 .19 .16 .23 .16 33 .13 .25 –.04 .49
  Closed 6 589 .09 .13 .11 .00 100 –.01 .19 .11 .11
  Open 17 1,490 .16 .16 .19 .13 47 .08 .24 –.03 .41
Interpersonal/leadership 12 951 .17 .15 .20 .11 58 .08 .26 .02 .39
Other open 
skills 5 539 .14 .21 .17 .17 33 –.05 .32 –.11 .45
Work 
environmenta 22 2,085 .19 .16 .23 .14 43 .12 .26 .00 .46
  Closed 4 337 .03 .11 .04 .00 100 –.07 .13 .04 .04
  Open 18 1,748 .22 .16 .26 .13 46 .15 .29 .05 .48
Interpersonal/leadership 7 545 .17 .14 .20 .00 100 .06 .27 .20 .20
Other open 
skills 5 579 .27 .19 .34 .15 34 .11 .44 .09 .59
(continued)
 at UNIV OF MICHIGAN FLINT on June 8, 2010 http://jom.sagepub.comDownloaded from
<<<PAGE=22>>>
Table 3 (continued)
Predictor K N r– SDr r SDr % Variance 95% CI 80% CV
Posttraining knowledgeb 27 3,040 .15 .15 .18 .13 45 .09 .21 -.02 .39
  Closed 8 959 .13 .14 .14 .09 56 .02 .23 -.01 .29
  Open 19 2,081 .16 .15 .20 .13 42 .09 .23 -.02 .42
Interpersonal/leadership 13 1,217 .13 .17 .16 .12 51 .04 .22 -.04 .36
Other open 
skills 6 864 .21 .11 .25 .13 36 .12 .30 .04 .46
Posttraining self-ef
ficacyb 11 1,181 .09 .17 .11 .09 60 -.01 .19 -.04 .26
  Closed 4 462 .05 .05 .06 .00 100 .00 .11 .06 .06
  Open 7 719 .12 .19 .13 .13 43 -.02 .26 -.08 .34
Interpersonal/leadership 5 494 .19 .16 .22 .09 61 .05 .33 .07 .36
Other open 
skills 2 225 -.04 .04 -.04 .00 100 -.09 .01 -.04 -.04
N
ote. K = number of studies included in each analysis; N = total sample size in each analysis; r– = sample size weighted mean correlation; SDr = standard deviation of the observed 
correlations; r = mean population correlation (corrected for unreliability in predictor and criterion); SDr = standard deviation of the corrected correlation; % V ariance = percentage of 
variance attributed to sampling error and measurement unreliability; 95% CI = 95% confidence interval around r–; 80% CV = 80
% credibility interval around r
aIncluded only studies without SS/SMC bias in the analysis. 
bIncluded only studies that operationalized transfer at least 1  day after training.
1086
 at UNIV OF MICHIGAN FLINT on June 8, 2010 http://jom.sagepub.comDownloaded from
<<<PAGE=23>>>
1087
Table 4
Moderating Effect of Lab versus Field Context on Predictor–Transfer Relationship
Predictor K  N   r– SDr r SDr % Variance 95% CI 80% CV
Cognitive ability 10 1,452 .31 .20 .37 .18 23 .19 .43 .08 .66
 Field 2 114 -.12 .06 -.14 .00 100 -.21 -.03 -.14 -.14
 Lab 8 1,338 .34 .12 .41 .10 40 .26 .42 .24 .58
Pretraining self–ef
ficacyb 18 1,663 .17 .18 .21 .19 30 .09 .25 -.10 .52
 Field 12 1,226 .20 .19 .24 .20 25 .09 .31 -.09 .57
 Lab 6 437 .09 .16 .11 .10 68 -.04 .22 -.05 .26
Motivationa 24 2,574 .19 .16 .23 .16 33 .13 .25 -.04 .49
 Field 18 2,128 .20 .17 .24 .17 27 .12 .28 -.05 .52
 Lab 6 446 .14 .13 .17 .00 100 .04 .25 .17 .17
Posttraining knowledgeb 27 3,040 .15 .15 .18 .13 45 .09 .21 -.02 .39
 Field 19 2,131 .16 .16 .19 .14 37 .09 .23 -.05 .43
 Lab 8 909 .13 .12 .16 .01 99 .04 .21 .14 .18
Posttraining self–ef
ficacy b 11 1,181 .09 .17 .11 .09 60 -.01 .19 -.04 .26
 Field 7 816 .07 .10 .08 .00 100 .00 .15 .08 .08
 Lab 4 365 .15 .22 .17 .16 34 -.07 .37 -.10 .44
Goal–setting intervention 6 378 .07 .23 .08 .15 46 -.1
1 .26 -.17 .33
 Field 3 104 .25 .34 .28 .22 39 -.13 .63 -.09 .64
 Lab 3 274 .00 .09 .00 .00 100 -.10 .10 .00 .00
No
te. K = number of studies included in each analysis; N = to
tal sample size in each analysis; r– = sample size weighted mean correlation; SDr = standard deviation of the observed correla-
tions; r = mean population correlation (corrected for unreliability in predictor and criterion); SDr = standard deviation of the corrected correlation; % V ariance = percentage of variance 
attributed to sampling error and measurement unreliability; 95% CI = 95% confidence interval around r–; 80% CV = 80
% credibility interval around r
aIncluded only studies without SS/SMC bias in the analysis. 
bIncluded only studies that operationalized transfer at least 1 day after training.
 at UNIV OF MICHIGAN FLINT on June 8, 2010 http://jom.sagepub.comDownloaded from
<<<PAGE=24>>>
Table 5
Investigation of Publication Bias on Predictor–Transfer Relationship
Predictor K N r– SDr r SDr % Variance 95% CI 80% CV
Pretraining self–ef
ficacy  
         
  Published data 14 1,109 .26 .18 .31 .16 39 .17 .36 .05 .58
  Unpublished data 8 859 .09 .16 .10 .13 44 -.02 .19 -.1
1 .32
Motivationa            
  Published data 14 1,504 .24 .16 .28 .16 33 .15 .32 .02 .55
  Unpublished data 10 1,070 .13 .17 .15 .12 45 .02 .23 -.06 .35
Work 
environmenta           
  Published data 13 1,244 .22 .19 .26 .17 32 .12 .32 -.02 .54
  Unpublished data 9 841 .15 .13 .18 .00 100 .06 .23 .18 .18
Posttraining knowledge  
         
  Published data 21 2,099 .18 .21 .23 .17 35 .09 .27 -.05 .50
  Unpublished data 13 1,726 .22 .19 .24 .16 25 .11 .32 -.03 .51
Posttraining self–ef
ficacya           
  Published data 7 841 .32 .12 .37 .00 100 .23 .40 .37 .37
  Unpublished data 8 999 .06 .08 .06 .00 100 .00 .11 .06 .06
Note. K
 = number of studies included in each analysis; N = total sample 
size in each analysis; r– = sample size weighted mean correlation; SDr = standard deviation of 
the observed correlations; r = mean population correlation (corrected for unreliability in predictor and criterion); SDr = standard deviation of the corrected correlation; 
% Variance = percentage of variance attributed to sampling error and measurement unreliability; 95% CI = 95% confidence interval around r–; 80% CV = 80% credibility 
interval around 
r
aIncluded only studies without SS/SMC bias in the analysis.
1088
 at UNIV OF MICHIGAN FLINT on June 8, 2010 http://jom.sagepub.comDownloaded from
<<<PAGE=25>>>
Blume et al. / Transfer of Training   1089
taken. The length of time entered in the analysis differed across predictors, with a smaller range 
for both pretraining self-efficacy and posttraining self-efficacy (ranging from immediately after 
training to 19
 we
eks, medians = 4)
 and a larger range for both posttraining knowledge and envi-
ronment (from immediately after training to 163 we
eks, median = 4 
and 9, respectively).
The relationship between transfer and knowledge is moderated by the amount of time 
between training and the transfer measure. The significant, negative beta (β = −.25, p < .05) 
indicates that as the amount of time increased, the strength of the relationship between post-
training 
knowledge and transfer decreased. Our regression results (β = −.64, p < .01) indicate 
that 
the strength of the relationship between posttraining self-efficacy and transfer also 
decreased as the amount of time between training and transfer increased. On the other hand, 
nonsignificant regression results demonstrate that the relationships between transfer and the 
following constructs are not moderated by the amount of time between the end of the train-
ing and transfer: environment, pretraining self-efficacy, and motivation.
Relationships Between Transfer Measures
Table 7 presents the results of those studies in which two different sources (i.e., self and 
other) obtained a similar transfer measure (i.e., both sources rated use, or both sources rated 
effectiveness) at the same time. This analysis demonstrates the association between ratings 
provided by the trainee and either their peers, supervisor, or a trained rater on the trainee’s 
transfer of training. Results indicate that a moderate correlation exists regardless of whether 
the other rater is a supervisor (.28) or peer(s) (.26).
In addition, we found a large relationship (.57) between measures of transfer over time for stud-
ies that obtained similar measures (e.g., both measures of effectiveness or both measures of use) 
by the same source (e.g., both trained raters). Four of the six studies included in this analysis used 
trained raters to measure transfer in a lab context. The Time 1 and Time 2 measures for these four 
studies were separated by 1 to 7
 we
eks. We identified only two field studies (i.e., Axtell et al. 
1997; Martineau, 1995) that obtained multiple measures of transfer over time from the same 
source, and both had strong correlations over time (.58 and .55, respectively).
Discussion
Despite a long research history and several qualitative reviews, the literature on transfer 
of training has remained characterized by mixed findings and the lack of an empirical syn-
thesis. Overall, our study brings some clarity to this literature and demonstrates that the 
transfer of training is influenced by a variety of predictor variables (e.g., motivation of 
trainee, learning outcomes, supportive transfer climate).
A key objective of our meta-analysis was to bring a more precise quantitative lens to a 
literature with a wide variety of studied variables and inconsistent criteria measurement. The 
findings that stand out most are that (a) once SS/SMC is controlled for, there are a surpris-
ingly limited number of strong predictor relationships with transfer; (b) the relationships to 
transfer of several variables are contingent on whether the trained skills were open or closed; 
and (c) reported relationships are significantly affected by the source and timing of transfer 
 at UNIV OF MICHIGAN FLINT on June 8, 2010 http://jom.sagepub.comDownloaded from
<<<PAGE=26>>>
1090   Journal of Management / July 2010
measurement. Below we elaborate on each of these findings and discuss their implications 
for future research and practice.
Discussion of Meta-Analytic Relationships
Our first question concerned the main effects of predictor variables on transfer. An impor-
tant qualifier to our findings is that when predictor variables and transfer measures were both 
self-assessed by the trainee at the same time, there was a consistent inflation of the relation-
ships examined. This effect of SS/SMC ranged from approximately .10 to .50, with correla-
tions typically being inflated by around .20 to .30. For example, our data indicate that 
studies examining the relationship between work environment and transfer have a correla-
tion that is .31 higher when SS/SMC is present (i.e., .54 vs. .23). Based on that finding, we 
suspect that many reported relationships have likely been overstated because of SS/SMC. 
This pattern of findings is consistent with the documented effects of common method vari-
ance in many research areas (Podsakoff et al, 2003). Controlling for SS/SMC effects gives 
us more confidence in the results that we report, as we believe those relationships not char-
acterized by this effect provide the most accurate estimates. The discussion below therefore 
synthesizes results only from studies not subject to SS/SMC.
The search for the “transfer-ready” trainee has been ubiquitous in the literature, and our 
findings indicate that, although there are some significant relationships across studies, there 
are surprisingly few consistently strong individual predictors of transfer. The single largest 
relationship to transfer we found was for cognitive ability. Transfer is not solely dependent 
on trainees’ cognitive ability, however, as other moderately strong relationships were 
observed for other trainee characteristics, such as conscientiousness and voluntary participa-
tion. Neuroticism, pretraining self-efficacy, motivation to learn, and a learning goal orienta-
tion also had moderate relationships with transfer. Most other individual difference variables 
had negligible corrected relationships. We conclude that a select number of trainee charac-
teristics relate positively to transfer, and the relationships found are at roughly the same level 
Table 6
Moderating Effect of the Length of Time Between End of Training  
and Transfer Measure
Predictor K b p
Pretraining self–ef
ficacy 22 –.08a .49
Motivation  22 –.29a .11
Work environment 21 .07b .62
Posttraining knowledge 33 –.25b .01
Posttraining self–efficacy 15 –.64a .00
Note. K = number of effect size included in each analysis; b = beta weight from weighted least square regression. 
aTime lag measured in weeks, power transformed to reduce skewness and influence of extreme time lag; specifically, 
1/3 power transformation was used.
bTime lag measured in weeks, power transformed to reduce skewness and influence of extreme time lag;  
specifically, 1/5 power transformation was used
 at UNIV OF MICHIGAN FLINT on June 8, 2010 http://jom.sagepub.comDownloaded from
<<<PAGE=27>>>
Table 7
Correlations Between Self Versus Other Measures of Transfer at Same Time and Repeated Measures  
of Transfer by Same Rater at Different Times 
Predictor K N r– SDr r SDr % Variance 95% CI 80% CV
Different 
raters at same time 9 938 .23 .22 .28 .12 45 .09 .38 .08 .48
  Self & 
peer 4 644 .23 .16 .26 .10 41 .07 .39 .09 .43
  Self & 
supervisor 4 201 .23 .30 .28 .19 42 −.07 .53 −.04 .60
  Self & 
trained rater 1 93 .30 0 .36 
           
Same raters 
at different time 6 319 .50 .21 .57 .18 32 .33 .67 .27 .87
Note. K
 = number of studies included in each analysis; N = total sample 
size in each analysis; r– = sample size weighted mean correlation; SDr = standard deviation of the 
observed correlations;  r = mean population correlation (corrected for unreliability in predictor and criterion); SDr = standard deviation of the corrected correlation; % Variance 
= percentage of variance attributed to sampling error and measurement unreliability; 95% CI = 95% confidence interval around r–; 80% CV = 80% credibility 
interval around r
1091
 at UNIV OF MICHIGAN FLINT on June 8, 2010 http://jom.sagepub.comDownloaded from
<<<PAGE=28>>>
1092   Journal of Management / July 2010
as the most predictive situational variables. That is, there is no clear superiority of individual 
variables over situational variables, or the reverse. Nevertheless, the results go beyond 
qualitative reviews that report mixed support for the relationship of characteristics with 
transfer (e.g., Burke & Hutchins, 2007) to provide more precise information about these 
predictor–transfer relationships.
In addition, although previous qualitative reviews have indicated mixed support for the 
relationship between work environment and transfer (e.g., Cheng & Hampson, 2008), we 
found meaningful, nonzero correlation between work environment and transfer. Subsequent 
analysis that subdivided the general measure of support into three different categories, (a) 
support (e.g., peer and supervisor support), (b) transfer climate, and (c) organizational con-
straints (e.g., level of autonomy, situational constraints), indicated that transfer climate had 
the highest relative relationship with transfer, followed closely by support. However, the 
confidence and credibility intervals indicate that support has a more consistent relationship 
with transfer than climate does. Constraints had a negligible relationship to transfer—
although that finding is based on few investigations. Further analysis revealed that supervisor 
support had a stronger relationship with transfer than did peer support, although those cor-
relations are also based on small sample sizes.
One appeal of work environment factors is the sense that they are directly subject to influence 
and control in organizational learning environments. That is, there are often logistic and political 
constraints to preselecting a certain group of trainees on the basis of individual characteristics. 
Situational variables, on the other hand, can potentially be actively managed to create environ-
ments most conducive to transfer. Therefore, the finding in support of positive transfer climates 
is encouraging in that it supports a proactive approach to leveraging transfer.
Consistent with prior research comparing different levels of training evaluation (Alliger  
et al., 1997; Colquitt et al., 2000), posttraining self-efficacy and posttraining knowledge both 
had small to moderate mean corrected correlations with transfer. Posttraining utility reac-
tions had a small to moderate correlation with transfer; both affective reactions and overall 
reactions (which included both affective and utility dimensions) had small correlations.
In their 1988 review, Baldwin and Ford noted a paucity of investigations of interventions 
designed to leverage transfer and advocated for an increase in such research. That call has been 
modestly heeded in the succeeding two decades with explorations of transfer interventions that 
include goal setting, relapse prevention, and program framing (i.e., optimistic previews). 
Although some studies reported successful interventions (e.g., Brown, 2005), the overall meta-
analytic effect sizes of existing transfer interventions on transfer were only small to moderate.
Therefore, our data lead to a less optimistic conclusion than a recent summary statement by 
Burke and Hutchins, (2007), “Indeed, using goals (both assigned and participative goal setting) 
to increase training transfer has received much support in the extant literature” (p. 273). In con-
trast, we found a relatively small effect of goal setting on transfer, with very wide confidence and 
credibility intervals. Put simply, the evidence in support of transfer interventions was not as com-
pelling as either our intuition or prior transfer commentaries would suggest. One possible expla-
nation is the small amount of time spent on typical interventions investigated. More specifically, 
the amount of training time spent on interventions ranged from just a half hour to 4
 ho
urs, with 
most interventions lasting just 2 ho
urs or less. It is likely wishful thinking that such minimal 
interventions will significantly enhance an outcome as complex and challenging as transfer.
 at UNIV OF MICHIGAN FLINT on June 8, 2010 http://jom.sagepub.comDownloaded from
<<<PAGE=29>>>
Blume et al. / Transfer of Training   1093
Impact of Open Versus Closed Skills on Transfer Relationships
A general pattern in the present results is that the predictor constructs tended to have 
stronger relationships to transfer with open skills than with closed skills. For example, based 
on our data, pretraining self-efficacy, motivation, and the environmental context become 
more important when training open skills. With open skills, trainees have more choice as to 
what and how to apply trained principles and concepts to the job. Closed skills, in contrast, 
have much more prescribed transfer behaviors, and thus the impact of environmental factors 
may be considerably less.
One intriguing exception to the generally greater influence of predictor variables with 
open skills was cognitive ability, which had a stronger relationship with closed skills. Based 
on eight lab studies, there was a moderately high relationship between cognitive ability and 
transfer of closed skills, but we found only two field studies that examined the transfer of 
open skills and included cognitive ability as a predictor. Both of these field studies indicated 
that there is a small negative relationship between cognitive ability and transfer. While we 
are not suggesting that this is a robust finding, or that having lower cognitive ability will 
improve transfer, it may be that closed skills are more dependent on cognitive ability than 
are open skills. In any case, this is one interesting example of how the open-versus-closed 
distinction alters reported transfer relationships.
Impact of Transfer Measurement and Other Moderators on Transfer Relationships
Another set of our research questions concerned the influence on reported relationships 
of the way in which transfer has been operationalized and measured. One consistent finding 
was that transfer measured immediately following training yielded consistently stronger 
relationships with predictor variables than transfer measured after a time lag. This issue was 
primarily relevant to lab studies. Similar to our findings related to SS/SMC, we believe lab 
studies that include a time lag are of much higher quality than are those that do not. Our 
results also revealed that self-reports had consistently stronger relationships with transfer 
criteria of interest than did data collected from other sources.
Perhaps most interesting, although we were able to examine the effectiveness-versus-use 
moderator for only a few predictor–transfer relationships, use measures of transfer generally 
had slightly stronger relationships than did effectiveness measures. For example, trainee 
motivation has a stronger relationship with transfer measures of use than with measures of 
effectiveness. This is consistent with the reality that trainees with higher levels of motivation 
attempt to utilize trained skills more often. However, how effective the trainee is in transfer-
ring training is affected by additional factors that may not be under the direct control of the 
trainee. In addition, motivation is just one factor that affects trainees’ ability to effectively 
transfer training. These results point to the importance of transfer researchers’ becoming more 
cognizant of distinctions among different types of transfer measurement.
Our remaining research questions dealt with isolating any influence on reported relation-
ships related to whether studies were lab or field based, published or unpublished, and the 
timing and source of transfer measurement. Although the lab-versus-field moderator did 
help explain variance across studies for most predictor variables, the primary observation is 
 at UNIV OF MICHIGAN FLINT on June 8, 2010 http://jom.sagepub.comDownloaded from
<<<PAGE=30>>>
1094   Journal of Management / July 2010
that there was not a consistent effect. In other words, predictor–transfer relationships weren’t 
consistently larger or smaller in lab or field settings. While there is some indication that 
context could make a difference, it is not clear which theoretical mechanisms might explain 
these differences or that they are operating on a consistent basis.
With respect to the file drawer issue (Rosenthal, 1979), we did, in fact, find some limited 
evidence that published studies demonstrate higher correlations than unpublished studies. 
This could be because published studies have more construct-valid measures than unpub-
lished studies do. In any case, a similar result has been found in other meta-analytic studies 
(e.g., Judge & Ilies, 2002; Judge, Thoresen, Bono, & Patton, 2001).
As Baldwin and Ford (1988) noted more than 20
 years ago, 
a critical condition for trans-
fer is maintenance. We found that the relationship between posttraining knowledge and 
transfer did decline when the time between training and transfer was greater. This was also 
the case for posttraining self-efficacy. Therefore, we found some evidence that the effects of 
learning outcomes may decay over time.
Our final question dealt with the relationships between the same measures of transfer taken by 
different raters or taken at different times. We found only modest correlations of others’ reports 
of trainees’ transfer with trainees’ perceptions of their transfer. These correlations are very similar 
in magnitude to research estimates of self and supervisory ratings of job performance (Heidemeier 
& Moser, 2009). In other words, it appears that a trainee’s level of agreement with his or her 
manager is similar when evaluating both training transfer and job performance. This also supports 
the notion that the source of the transfer measure is likely to influence predictor–transfer relation-
ships. When measures of transfer were obtained by the same source at different times, the cor-
relations between these measures were quite high. This is an initial indicator that transfer (or at 
least the perceptions of trainees’ transfer) may be consistent over time.
Implications for Future Research
After carefully considering 89 empirical studies of transfer we have some targeted views 
with respect to the direction of future research. First, our meta-analytic review found that the 
issue of SS/SMC is so pronounced in inflating relationships, and so problematic in interpret-
ing relationships, that we call for a moratorium on such studies. That is, it is impossible to 
draw strong conclusions about transfer relationships from studies that have both SS/SMC 
issues because we cannot disentangle the true relationship from the measurement issues. The 
strongest field studies will not collect both the independent and transfer variables at the same 
time from the trainee (same source). The strongest lab studies will include a time-lag 
between training and the transfer measure.
Beyond recognition of these measurement issues, we would encourage transfer research-
ers to increase precision in their selection and reporting of transfer outcomes. That is, how 
transfer is conceptualized, and how and when it is measured, really does matter. Although 
others are beginning to recognize this reality (Baldwin et al., 2009; Barnett & Ceci, 2002; 
Ford & Weissbein, 1997; Taylor et al., 2009), the present meta-analytic results conclusively 
demonstrate that the way in which transfer is operationalized and measured has significant 
effects on relationships ultimately reported. Indeed, we suspect that several reported and 
conventionally accepted findings might be subject to some reinterpretation if more precise 
delineation of transfer measures was considered.
 at UNIV OF MICHIGAN FLINT on June 8, 2010 http://jom.sagepub.comDownloaded from
<<<PAGE=31>>>
Blume et al. / Transfer of Training   1095
A pressing need for future research, therefore, is an overt focus on the effects of different 
types and forms of transfer measurement (Holton & Baldwin, 2003). For example, we could 
envision studies in which both use and effectiveness measures were obtained from trainees 
and others (e.g., their supervisors or peers). If multiple measures could be obtained over 
time, this type of study would enable researchers to directly examine how the relationship 
between predictors (such as motivation or environment) may differ depending on how trans-
fer is operationalized or when the transfer measure is obtained. Moreover, we believe studies 
that measure the effectiveness of training are better than those that measure use. This is 
because we are ultimately interested in having trainees effectively apply training (which 
ultimately will lead to positive results). While the use of training is necessary and certainly 
a goal of training, if the training is applied ineffectively, then the training ultimately will not 
lead to positive organizational outcomes.
A final understudied area for future research concerns the nature and objectives of the 
training in question. The present finding of significant moderating relationships for open 
versus closed skills is one manifestation of this point. With open skills, trainees have more 
choice as to what and how to apply trained principles and concepts to the job. Training 
research could benefit from examining transfer as a conscious choice that individuals make 
(Baldwin et al., 2009; Yelon, Sheppard, Sleight, & Ford, 2004). One could study why trans-
fer is attempted, how choices are made to personalize or customize the training received, or 
why a choice is made not to attempt to transfer an open skill to the job. For example, 
Anderson (2003) made a convincing case as to why not making a choice is a likely outcome 
in many situations. He cites decision-making research that reveals that, in many situations, 
people prefer no change, nonaction, or choice deferral. Similarly, Steel (2007) argued that 
nonaction often has value, especially when it is uncertain what the outcome will be if a 
choice to act is made. This uncertainty can be heightened in the case when individuals are 
trained in open skills. It is the investigation of theory-driven substantive issues such as these 
that will most advance the field in the years ahead.
Indeed, we find it curious that such limited information about training content and training 
objectives is typically reported in training transfer studies. It is difficult to contemplate a cumula-
tive body of evidence that can provide practical guidance to training professionals without further 
classification and taxonomic work on just what is being trained and what objectives are desired 
(Kraiger, 2002). The present findings, which indicate differences in transfer based on whether the 
training was concerned with open or closed skills, should be a catalyst for this type of orientation. 
Such an orientation would shift the focus of research from the general question, “Can training 
transfer?”—which has already been answered affirmatively—to a more targeted focus on com-
mon training objectives or types of skills trained, such as leadership, sales, and customer service. 
For example, what should be the content and preferred delivery method of a training program for 
leadership skills, and how should it be structured differently across different learner populations 
and organizational contexts? It is the investigation of theory-driven substantive issues such as 
these that will most advance the field. 
Implications for Practice
In addressing the recurring transfer “problem,” some authors have suggested that there has 
been far too much hope and not enough active strategizing and intervention based on the best 
 at UNIV OF MICHIGAN FLINT on June 8, 2010 http://jom.sagepub.comDownloaded from
<<<PAGE=32>>>
1096   Journal of Management / July 2010
scientific evidence available (Holton & Baldwin, 2003). Of course, evidence-based action 
requires a synthesis and accessibility to the evidence that heretofore has not readily existed for 
training professionals. The present findings, although providing no comprehensive blueprint for 
effective transfer, do offer some preliminary guidance for training professionals.
Perhaps most important, the roughly equivalent predictive power of several individual 
and situational predictors reflects the reality that there are no magic bullets for leveraging 
transfer. This means that training professionals should consider multiple transfer strategies 
in combination. Just as personnel selection experts employ multiple selection predictors with 
moderate (but known) relationships to job performance (e.g., work samples, structured inter-
views, aptitude tests), so too should training professionals look to a set of strategies with 
demonstrated relationships to transfer. Based on the present results, the most promising 
avenues seem to be more proactive selection of training cohorts, a focus on increasing the 
motivation of trainees, and finding ways to induce higher levels of supervisor and peer sup-
port in the work environment. Learning outcomes are also related to transfer, suggesting that 
to the extent that the training program can increase posttraining knowledge and self-efficacy, 
the more likely trainees will be to transfer the training.
Another finding of practical importance is the lack of consistent support for any particu-
lar transfer interventions. Interventions may need to be longer and more impactful. Hutchins 
and Burke (2006) note that using a relapse prevention intervention at the end of training may 
not be successful because of trainee fatigue. They suggested that one avenue for increasing 
impact would be to incorporate relapse prevention principles throughout a particular training 
experience, and this is an idea worth testing across different interventions as well. Training 
professionals should be aware of that data and not be misled by false claims.
Despite a lack of strong support for existing interventions, we are not prepared to con-
clude that transfer is resistant to intervention. For example, although based on only three 
studies, optimistic previews (as compared to realistic previews), in which positive state-
ments about the upcoming training are communicated to trainees, had a moderate, positive 
relationship with transfer. This has been a consistent finding even though two of the three 
existing studies predicted the opposite—that realistic previews would be more effective 
(e.g., Hicks & Klimoski, 1987; Ungsrithong, 1991).
The reality is that the bulk of evidence on interventions is still not very action oriented. 
That is, the vast majority of studies have stopped at the point of identifying, describing, or 
measuring factors that may influence transfer without investigating how those factors might 
be effectively managed or changed. So this is an arena that would be ripe for research–prac-
tice partnerships, in which many more of the transfer predictors are tested in the context of 
actual interventions.
We do not believe that achieving higher transfer necessarily involves substantial new pro-
cesses or systems in organizations. Rather, we contend that the most significant gains in trans-
fer will come when learning is more tightly integrated into the process and reward systems  
that already matter in a firm. The challenge is not how to build a bigger and more influential 
transfer support system; it is how to make transfer a more integral part of the existing organi-
zational climate.
 at UNIV OF MICHIGAN FLINT on June 8, 2010 http://jom.sagepub.comDownloaded from
<<<PAGE=33>>>
Blume et al. / Transfer of Training   1097
Study Limitations
Like any comprehensive attempt to aggregate data, this study has several limitations that 
warrant mention. First, the study focused on fairly broad transfer predictors (e.g., work envi-
ronment, motivation). Although in some cases a number of sublevels within those broad 
factors were identified and examined, there is a need for more studies to allow the examina-
tion of other sublevels in future meta-analytic work.
Second, some of our results were based on small cell sizes or few studies and may there-
fore be subject to second-order sampling error (Hunter & Schmidt, 2004). In regard to this 
issue, Schmidt, Hunter, Pearlman, and Hirsh (1985) noted that although meta-analyses based 
on small numbers of studies may increase the variability in the effect sizes, they do not affect 
the mean estimates. Thus, estimates that are distinguishable from zero based on a small 
number of studies will very likely continue to be distinguishable from zero as evidence 
accumulates. Conceptually, even small meta-analyses are superior to the subjectivity and 
imprecision involved in qualitative reviews that attempt to interpret primary study results.
Third, only a few field studies have collected multiple measures of transfer over time 
from the same source, and this made it difficult to truly explore the “maintenance” of trans-
fer over time. More empirical studies are sorely needed if we are to more conclusively 
examine transfer maintenance.
Finally, missing information was encountered in several original studies, leading to the 
exclusion of some data from the present analysis. More careful documentation of the context 
in which training is conducted, as well as basic descriptive statistics (e.g., group means and 
standard deviations; reliabilities of measures), would be helpful in future meta-analyses.
Conclusion
The escalating level of investment made in training and the accompanying expectations 
of that investment enhancing firm performance have combined to create greater urgency in 
the search for evidence and tools to improve the transfer of training. While there is growing 
evidence that investments in training lead to demonstrable results that positively affect indi-
vidual and organizational performance (Arthur et al., 2003; Birdi et al., 2008; Taylor et al., 
2009; Tharenou, Saks, & Moore, 2007), we need to continue to increase our understanding 
of the factors that influence the application and transfer of training. This quantitative review 
synthesizes what we know to date, and our hope is that the findings transfer to more precise 
and impactful transfer investigations, as well as more effective training practice.
Notes
1. These journals included Academy of Management Journal, Human Performance, Human Resource 
Development International, Human Resource Development Quarterly, Human Resource Management, Human 
Resource Management Journal, Human Resource Management Review, International Journal of Human Resource 
Management, International Journal of Training and Development, Journal of Applied Psychology, Journal of 
Business and Psychology, Journal of Management, Journal of Organizational Behavior, Journal of Occupational 
and Organizational Psychology , Organizational Behavior and Human Decision Processes , Performance 
Improvement Quarterly, and Personnel Psychology.
 at UNIV OF MICHIGAN FLINT on June 8, 2010 http://jom.sagepub.comDownloaded from
<<<PAGE=34>>>
1098   Journal of Management / July 2010
2. We eliminated studies that included nontrainees (i.e., control groups that did not receive training) in the 
computation of the correlation coefficients because we were interested only in examining the transfer of those 
participants who received training.
3. When addressing the type of skill and study context (see Tables 3 and 4), to avoid confounding the effect of 
type of skill or study context with transfer operationalization, we tested only the moderating effect of type of skill 
within subsets of studies that used similar operationalizations of transfer. For example, to test the moderating effect 
of type of skill on the relationship between pretraining self-efficacy and transfer, we selected only the studies that 
measured transfer with a time lag after training. Had we included the other four studies that measured transfer with 
no time lag (all of which involved closed skills), the effect of time lag would have confounded the moderating 
effects we were examining.
References
Studies preceded by an asterisk were included in the meta-analysis.
Adams, J. A. 1987. Historical review and appraisal of research on the learning, retention, and transfer of human 
motor skills. Psychological Bulletin, 101: 41-74.
*Al-Ammar, S. A. 1995. The influence of individual and organizational characteristics on training motivation and 
effectiveness. Unpublished doctoral dissertation, State University of New York at Albany.
Alliger, G. M., Tannenbaum, S. I., Bennett, W., Jr., Traver, H., & Shotland, A. 1997. A meta-analysis of the relations 
among training criteria. Personnel Psychology, 50: 341-358.
Alvarez, K., Salas, E., & Garofano, C. M. 2004. An integrated model of training evaluation and effectiveness. 
Human Resource Development Review, 3: 385-416.
*Ameel, L. J. 1992. Transfer of training for a basic sales skills training program. Unpublished doctoral dissertation, 
United States International University, Nairobi, Kenya.
Anderson, C. J. 2003. The psychology of doing nothing. Psychological Bulletin, 129: 139-167.
Arthur, W., Jr., Bennett, W., Jr., Edens, P . S., & Bell, S. T. 2003. Effectiveness of training in organizations: A meta-analysis 
of design and evaluation features. Journal of Applied Psychology, 88: 234-245.
Arthur, W., Jr., Bennett, W., Jr., Stanush, P. L., & McNelly, T. L. 1998. Factors that influence skill decay and reten-
tion: A quantitative review and analysis. Human Performance, 11: 57-101.
*Awoniyi, E. A., Griego, O. V ., & Morgan, G. A. 2002. Person-environment fit and transfer of training. International 
Journal of Training and Development, 6: 25-35.
*Axtell, C. M., Maitlis, S., & Yearta, S. K. 1997. Predicting immediate and longer-term transfer of training. Person-
nel Review, 26(3): 201-213.
*Baldwin, T. T. 1992. Effects of alternative modeling strategies on outcomes of interpersonal-skills training. Journal 
of Applied Psychology, 77: 147-154.
Baldwin, T. T., & Ford, J. K. 1988. Transfer of training: A review and directions for future research. Personnel 
Psychology, 41: 63-105.
Baldwin, T. T., Ford, J. K., & Blume, B. D. 2009. Transfer of training 1988-2008: An updated review and new 
agenda for future research. In G. P. Hodgkinson & J. K. Ford (Eds.), International review of industrial and 
organizational psychology (V ol. 24, pp. 41-70). Chichester, UK: Wiley.
Barnett, S. M., & Ceci, S. J. 2002. When and where do we apply what we learn? A taxonomy for far transfer. Psy-
chological Bulletin, 128: 612-637.
Bass, B. M., & Vaughan, J. A. 1966. Training in industry: The management of learning. Belmont, CA: Wadsworth.
*Bates, R. A., Holton, E. F., III, & Burnett, M. F. 1999. Assessing the impact of influential observations on multiple 
regression analysis on human resource research. Human Resource Development Quarterly, 10: 343-363.
 at UNIV OF MICHIGAN FLINT on June 8, 2010 http://jom.sagepub.comDownloaded from
<<<PAGE=35>>>
Blume et al. / Transfer of Training   1099
Beal, D. J., Corey, D. M., & Dunlap, W. P. 2002. On the bias of Huffcutt and Arthur’s (1995) procedure for iden-
tifying outliers in the meta-analysis of correlations. Journal of Applied Psychology , 87: 583-589.
*Beck, J. W., Kozlowski, S. W. J., & Schmidt, A. M. 2008. Effects of previous experience on transfer of computer 
based training. Paper presented at the annual meeting of the Society of Industrial and Organizational Psychol-
ogy, San Francisco.
Becker, B. E., & Huselid, M. A. 1998. High performance work systems and firm performance: A synthesis of 
research and managerial implications. Research in Personnel and Human Resource Management, 16: 53-101.
*Bell, B. S., & Ford, J. K. 2007. Reactions to skill assessment: The forgotten factor in explaining motivation to 
learn. Human Resource Development Quarterly, 18: 33-62.
*Bell, B. S., & Kozlowski, S. W. J. 2002. Goal orientation and ability: Interactive effects on self-efficacy, perfor-
mance, and knowledge. Journal of Applied Psychology, 87: 497-505.
*Bell, B. S., & Kozlowski, S. W. J. 2008. Active learning: Effects of core training design elements on self-regulatory 
processes, learning, and adaptability. Journal of Applied Psychology, 93: 296-316.
*Bennett, J. B., Lehman, W. E. K., & Forst, J. K. 1999. Change, transfer climate, and customer orientation: A contextual 
model and analysis of change-driven training. Group & Organization Management, 24: 188-216.
Birdi, K., Clegg, C., Patterson, M., Robinson, A., Stride, C. B., Wall, T. D., et al. 2008. The impact of human 
resource and operational management practices on company productivity: A longitudinal study. Personnel 
Psychology, 61: 467-501.
*Borowski, J. L. 2001. The social influence of work organizations on training transfer. Unpublished doctoral dis-
sertation, Wayne State University, Detroit, MI.
*Bourgeois, N. T. 2008. Error training: An examination of metacognition, emotion control, intrinsic motivation, and 
knowledge as mediators of performance effects. Unpublished doctoral dissertation, Louisiana State University, 
Baton Rouge.
*Bowne, A. W. 1999. The field study of a training transfer enhancement process and its effect on transfer of train-
ing. Unpublished doctoral dissertation, Western Michigan University, Kalamazoo.
*Brett, J. F., & VandeWalle, D. 1999. Goal orientation and goal content as predictors of performance in a training 
program. Journal of Applied Psychology, 84: 863-873.
*Brittain, C. R. 2000. The effect of a supportive organizational environment on transfer of training in child welfare 
organizations. Unpublished doctoral dissertation, University of Colorado at Denver.
Brown, K. G., & Sitzmann, T. (in press). Training and development. In S. Zedeck (Ed.), Handbook of industrial and 
organizational psychology (V ol. 2). Washington, DC: American Psychological Association.
*Brown, T. C. 2005. Effectiveness of distal and proximal goals as transfer-of-training interventions: A field 
experiment. Human Resource Development Quarterly, 16: 369-387.
*Brown, T. C., & de Leon, S. 2008. Evaluation of a leadership development program for union and manage-
ment leaders: A comparison of two self-management techniques. Paper presented at the annual meeting of the 
Academy of Management, Anaheim, CA.
*Brown, T. C., & Morrissey, L. 2004. The effectiveness of verbal self-guidance as a transfer of training interven-
tion: Its impact on presentation performance, self efficacy and anxiety. Innovations in Education and Teaching 
International, 41: 255-271.
*Burke, L. A. 1997. Improving positive transfer: A test of relapse prevention training on transfer outcomes. Human 
Resource Development Quarterly, 8: 115-128.
*Burke, L. A., & Baldwin, T. T. 1999. Workforce training transfer: A study of the effect of relapse prevention train-
ing and transfer climate. Human Resource Management, 38: 227-241.
 at UNIV OF MICHIGAN FLINT on June 8, 2010 http://jom.sagepub.comDownloaded from
<<<PAGE=36>>>
1100   Journal of Management / July 2010
Burke, L. A., & Hutchins, H. M. 2007. Training transfer: An integrative literature review. Human Resource Develop-
ment Review, 6: 263-296.
*Casper, B. 2005. The positive transfer of learned skills from training to changed behaviors at the job. Unpublished 
doctoral dissertation, Pepperdine University, Malibu, CA.
*Chen, G., Donahue, L. M., & Klimoski, R. J. 2004. Training undergraduates to work in organizational teams. 
Academy of Management Learning & Education, 3: 27-40.
*Chen, G., Thomas, B., & Wallace, J. C. 2005. A multilevel examination of the relationships among training out-
comes, mediating regulatory processes, and adaptive performance. Journal of Applied Psychology, 90: 827-841.
*Cheng, E. W. L. 2000. Test of the MBA knowledge and skill transfer. International Journal of Human Resource 
Management, 11: 837-852.
*Cheng, E. W. L. 2001. SEM being more effective than multiple regression in parsimonious model testing for man-
agement development research. Journal of Management Development, 20: 650-667.
Cheng, E. W. L., & Hampson, I. 2008. Transfer of training: A review and new insights. International Journal of 
Management Reviews, 10: 327-341.
Cheng, E. W. L., & Ho, D. C. K. 2001. A review of transfer of training studies in the past decade. Personnel Review, 
30: 102-118.
*Chiaburu, D. S., & Marinova, S. V . 2005. What predicts skill transfer? An exploratory study of goal orientation, 
training self-efficacy and organizational supports. International Journal of Training and Development, 9: 110-
123.
*Chiaburu, D. S., Sawyer, K. B., & Thoroughgood, C. N. Working paper under review. Transferring more than 
learned in training: Employees’ and managers’ (over)generalization of skills. 
*Chiaburu, D. S., & Tekleab, A. G. 2005. Individual and contextual influences on multiple dimensions of training 
effectiveness. Journal of European Industrial Training, 29: 604-626.
*Chiaburu, D. S., Van Dam, K., & Hutchins, H. M. In press. Social support in the workplace and training transfer: 
A longitudinal analysis. International Journal of Selection and Assessment.
*Claiborne, S. A. 2003. The relationship between trainee characteristics, situational cues and consequences in the 
work climate and transfer of training. Unpublished doctoral dissertation, Wayne State University, Detroit, MI.
*Clasen, P. S. 1997. Expectancy theory predictions of the transfer of training skills to the job. Unpublished doctoral 
dissertation, California School of Professional Psychology.
Cohen, J. 1988. Statistical power analysis for the behavioral sciences (2nd ed.). Hillsdale, NJ: Lawrence Erlbaum.
Colquitt, J. A., Lepine, J. A., & Noe, R. A. 2000. Toward and integrative of training motivation: A meta-analytic path 
analysis of 20 years of research. Journal of Applied Psychology, 85: 678-707.
Combs, J. G., Liu, Y ., Hall, A. T., & Ketchen, D. J. 2006. How much do high performance work practices matter? A 
meta-analysis of their effects on organizational performance. Personnel Psychology, 59: 501-528.
*Cromwell, S. E., & Kolb, J. A. 2004. An examination of work-environment support factors affecting transfer of 
supervisory skills training to the workplace. Human Resource Development Quarterly, 15: 449-471.
*Cruz, B. J. 1995. An empirical investigation of the validity of self-report assessment versus and instructionally 
aligned assessment to measure training transfer. Unpublished doctoral dissertation, University of San Francisco.
*Dierdorff, E. C., & Surface, E. A. 2008. If you pay for skills, will they learn? Skill change and maintenance under 
a skill-based pay system. Journal of Management, 34: 721-743.
Driskell, J. E., Willis, R. P., & Copper, C. 1992. Effect of overlearning on retention. Journal of Applied Psychology, 
77: 615-622.
*Enos, M. D., Kehrhahn, M. T., & Bell, A. 2003. Informal learning and the transfer of learning: How managers 
develop proficiency. Human Resource Development Quarterly, 14: 369-387.
 at UNIV OF MICHIGAN FLINT on June 8, 2010 http://jom.sagepub.comDownloaded from
<<<PAGE=37>>>
Blume et al. / Transfer of Training   1101
*Essary, V . L. 2001. The influences of self-efficacy on training transfer. Unpublished doctoral dissertation, Califor-
nia School of Professional Psychology.
Evans, A. N., & Rooney, B. F. 2008. Methods in psychological research. Los Angeles: Sage.
*Facteau, J. D., Dobbins, G. H., Russell, J. E. A., Ladd, R. T., & Kudisch, J. D. 1995. The influence of general 
perceptions of the training environment on pretraining motivation and perceived training transfer. Journal of 
Management, 21: 1-25.
*Fagan, E. C. 1998. Effects of self-management training and self-efficacy on assistive device trainees’ transfer of 
training. Unpublished doctoral dissertation, Johns Hopkins University, Baltimore.
*Fisher, S. L., & Ford, J. K. 1998. Differential effects of learner effort and goal orientation on two learning out-
comes. Personnel Psychology, 51: 397-420.
Ford, J. K., & Kraiger, K. 1995. The application of cognitive constructs and principles to the instructional systems 
model of training: Implications for needs assessment, design, and transfer. In C. I. Cooper & I. T. Robertson 
(Eds.), International review of industrial and organizational psychology  (Vol. 10, pp. 1-48). New York: John 
Wiley.
Ford, J. K., Quinones, M. A., Sego, D. J., & Sorra, J. S. 1992. Factors affecting the opportunity to perform trained 
tasks on the job. Personnel Psychology, 45: 511-524.
*Ford, J. K., Smith, E. M., Weissbein, D. A., Gully, S. M., & Salas, E. 1998. Relationships of goal orientation, 
metacognitive activity, and practice strategies with learning outcomes and transfer. Journal of Applied Psychol-
ogy, 83: 218-233.
Ford, J. K., & Weissbein, D. A. 1997. Transfer of training: An updated review and analysis. Performance Improve-
ment Quarterly, 10(2): 22-41.
*Frash, R. E., Jr. 2004. Modeling the context and transfer relationship for blended e-learning instructional design 
and delivery in hospitality. Unpublished doctoral dissertation, Purdue University, West Lafayette, IN.
Gagne, R. M. 1965. The conditions of learning. New York: Holt, Rinehart & Winston.
*Gardner, R. C., Moorcroft, R., & Metford, J. 1989. Second language learning in an immersion programme: Factors 
influencing acquisition and retention. Journal of Language and Social Psychology, 8: 287-305.
*Gaudine, A. P., & Saks, A. M. 2004. A longitudinal quasi-experiment on the effects of posttraining transfer inter-
ventions. Human Resource Development Quarterly, 15: 57-76.
Gerstner, C. R., & Day, D. V . 1997. Meta-analytic review of leader–member exchange theory: Correlates and con-
struct issues. Journal of Applied Psychology, 82: 827-844.
Geyskens, I., Krishnan, R., Steenkamp, J. E. M., & Cunha, P. V . 2009. A review and evaluation of meta-analysis 
practices in management research. Journal of Management, 35, 393-419.
*Gist, M. E., Schwoerer, C., & Rosen, B. 1989. Effects of alternative training methods on self-efficacy and perfor-
mance in computer software training. Journal of Applied Psychology, 74: 884-891.
*Gist, M. E., & Stevens, C. K. 1998. Effects of practice conditions and supplemental training method on cognitive 
learning and interpersonal skill generalization. Organizational Behavior and Human Decision Processes, 75: 
142-169.
*Gist, M. E., Stevens, C. K., & Bavetta, A. G. 1991. Effects of self-efficacy and post-training intervention on the 
acquisition and maintenance of complex interpersonal skills. Personnel Psychology, 44: 837-861.
Goldstein, I. L., 1974. Training: Program development and evaluation. Monterey, CA: Brooks/Cole.
Goldstein, I., & Ford, J. K. 2002. Training in organizations (4th ed.). Belmont, CA: Wadsworth.
Grose, R. F., & Briney, R. C. 1963. Transfer of learning: An enduring problem in psychology. Princeton, NJ: Van 
Nostrand.
*Guardiola, R. J. 2001. A transfer of training evaluation study: Investigating differences between goal setting and 
relapse prevention. Unpublished doctoral dissertation, Colorado State University, Fort Collins.
 at UNIV OF MICHIGAN FLINT on June 8, 2010 http://jom.sagepub.comDownloaded from
<<<PAGE=38>>>
1102   Journal of Management / July 2010
Heidemeier, H., & Moser, K. 2009. Self–other agreement in job performance ratings: A meta-analytic test of a pro-
cess model. Journal of Applied Psychology, 94: 353-370.
*Heimbeck, D., Frese, M., Sonnentag, S., & Keith, N. 2003. Integrating errors into the training process: The func-
tion of error management instructions and the role of goal orientation. Personnel Psychology, 56: 333-361.
*Herold, D. M., Davis, W., Fedor, D. B., & Parsons, C. K. 2002. Dispositional influences on transfer of learning in 
multistage training programs. Personnel Psychology, 55: 851-869.
*Hicks, W. D., & Klimoski, R. J. 1987. Entry into training programs and its effects on training outcomes: A field 
experiment. Academy of Management Journal, 30: 542-552.
*Holladay, C. L., Anderson, D. J., Gilbert, S. M., & Turner, S. L. 2008. Evaluating diversity training effectiveness: 
Self-efficacy as an enabler of transfer. Paper presented at the annual meeting of the Society of Industrial and 
Organizational Psychology, San Francisco.
*Holladay, C. L., & Quiñones, M. A. 2003. Practice variability and transfer of training: The role of self-efficacy 
generality. Journal of Applied Psychology, 88: 1094-1103.
Holton, E. F., III, & Baldwin, T. T. 2003. Making transfer happen: An action perspective on learning transfer sys-
tems. In E. F. Holton III and T. T. Baldwin (Eds.), Improving learning transfer in organizations (pp. 3-15). San 
Francisco: Jossey-Bass.
Huffcutt, A. I., & Arthur, W. 1995. Development of a new outlier statistic for meta-analytic data. Journal of Applied 
Psychology, 80: 327-334.
Hunter, J. E., & Schmidt, F. L. 2004. Methods of meta-analysis: Correcting error and bias in research findings (2nd 
ed.). Thousand Oaks, CA: Sage.
Huselid, M. A. 1995. The impact of human resource management practices on turnover, productivity, and corporate 
financial performance. Academy of Management Journal, 38: 635-672.
*Hutchins, H. M. 2004. Enhancing skill maintenance through relapse prevention strategies: A comparison of two 
models. Unpublished doctoral dissertation, University of North Texas, Denton.
Hutchins, H. M., & Burke, L. A. 2006. Has relapse prevention received a fair shake? A review and implications for 
future transfer research. Human Resource Development Review, 15: 8-24.
Judge, T. A., & Ilies, R. 2002. Relationship of personality and to performance motivation: A meta-analysis. Journal 
of Applied Psychology, 87: 797-807.
Judge, T. A., Thoresen, C. J., Bono, J. E., & Patton, G. K. 2001. The job satisfaction-job performance relationship: 
A qualitative and quantitative review. Psychological Bulletin, 127: 376-407.
*Karl, K. A., & Ungsrithong, D. 1992. Effects of optimistic versus realistic previews of training programs on self-
reported transfer of training. Human Resource Development Quarterly, 3: 373-384.
Keith, N., & Frese, M. 2008. Effectiveness of error management training: A meta-analysis. Journal of Applied 
Psychology, 93: 59-69.
Kopp, D. M. 2006. Trainer self-loathing? Human Resource Development Quarterly, 17: 351-357.
*Kozlowski, S. W. J., Gully, S. M., Brown, K. G., Salas, E., Smith, E. M., & Nason, E. R. 2001. Effects of training 
goals and goal orientation traits on multidimensional training outcomes and performance adaptability. Organi-
zational Behavior and Human Decision Processes, 85: 1-31.
Kraiger, K. (2002). Decision-based evaluation. In K. Kraiger (Ed.), Creating, implementing, and managing effec-
tive training and development systems in organizations: State-of-the-art lessons for practice (pp. 331-375). San 
Francisco: Jossey-Bass.
Lipsey, M. W., & Wilson, D. B. 2001. Practical meta-analysis. Thousand Oaks, CA: Sage.
*Loh, V ., Andrews, S., Griffin, B., & Hesketh, B. 2007. Individual differences in error management training: Not 
everyone learns from their mistakes. Paper presented at the annual meeting of the Society of Industrial and 
Organizational Psychology, New York.
 at UNIV OF MICHIGAN FLINT on June 8, 2010 http://jom.sagepub.comDownloaded from
<<<PAGE=39>>>
Blume et al. / Transfer of Training   1103
*Lorenzet, S. J., Salas, E., & Tannenbaum, S. I. 2005. Benefiting from mistakes: The impact of guided errors on 
learning, performance, and self-efficacy. Human Resource Development Quarterly , 16: 301-322.
*Madera, J. 2006. Effects of training utility perceptions and organizational support on transfer . Paper pre-
sented at the annual meeting of the Society of Industrial and Organizational Psychology, Dallas, TX.
*Martineau, J. W. 1995. A contextual examination of the effectiveness of a supervisory skills training program. 
Unpublished doctoral dissertation, Pennsylvania State University.
*Mathieu, J. E., Tannenbaum, S. I., & Salas, E. 1992. Influences of individual and situational characteristics on 
measures of training effectiveness. Academy of Management Journal, 35: 828-847.
Merriam, S. B., & Leahy, B. 2005. Learning transfer: A review of the research in adult education and training. 
P AACE Journal of Lifelong Learning, 14: 1-24.
*Miles, M. B. 1965. Changes during and following laboratory training: A clinical-experimental study. Journal of 
Applied Behavioral Science, 1: 215-242.
*Mohamed, M. A. K. 1994. An investigation of the contextual factors affecting transfer of training, and the role 
of management values in contextual change: The case of the United Arab Emirates public sector. Unpublished 
doctoral dissertation, University of Southern California, Los Angeles.
*Morin, L., & Latham, G. P. 2000. The effect of mental practice and goal setting as a transfer of training intervention 
on supervisors’ self-efficacy and communication skills: An exploratory study. Applied Psychology: An Interna-
tional Review, 49: 566-578.
*Myers, S. D. 1998. The role of person, outcome, environmental, and learning variables in training effectiveness. 
Unpublished doctoral dissertation, University of Tennessee, Knoxville.
*Naowaruttanavanit, M. 2002. Relationships of collective efficacy, cynicism, and motivation to transfer on transfer 
of training in Thailand. Unpublished doctoral dissertation, University of Minnesota.
*Northcraft, G. B., Neale, M. A., & Earley, P. C. 1994. Joint effects of assigned goals and training on negotiator 
performance. Human Performance, 7: 257-272.
*Oakes, D. W., Ferris, G. R., Martocchio, J. J., Buckley, M. R., & Broach, D. 2001. Cognitive ability and personal-
ity predictors of training program skill acquisition and job performance. Journal of Business and Psychology, 
15: 523-548.
*Ottoson, J. M., & Patterson, I. 2000. Contextual influences on learning application in practice: An extended role 
for process evaluation. Evaluation & the Health Professions, 23: 194-211.
Paradise, A. 2007. State of the Industry: ASTD’ s Annual Review of Trends in Workplace Learning and Performance. 
Alexandria, V A: ASTD.
Pfeffer, J. 1998. Seven practices of successful organizations. California Management Review , 40: 96-124.
Pfeffer, J., & Sutton, R. I. 2006. Hard facts, dangerous half-truths, and total nonsense: Profiting from evidence-
based management. Boston: Harvard Business School Press.
Podsakoff, P. M., MacKenzie, S. M., Lee, J., & Podsakoff, N. P. 2003. Common method variance in behavioral 
research: A critical review of the literature and recommended remedies. Journal of Applied Psychology, 88: 
879-903.
Podsakoff, P. M., MacKenzie, S. B., Paine, J. B., & Bachrach, D. G. 2000. Organizational citizenship behavior: A 
critical review of the theoretical and empirical literature and suggestions for future research. Journal of Manage-
ment, 26: 513-563.
*Poteet, M. L. 1997. The training transfer process: An examination of the role of individual, motivational, and work 
environmental factors. Unpublished doctoral dissertation, University of Tennessee, Knoxville.
*Quiñones, M. A. 1995. Pretraining context effects: Training assignment as feedback. Journal of Applied Psychol-
ogy, 80: 226-238.
 at UNIV OF MICHIGAN FLINT on June 8, 2010 http://jom.sagepub.comDownloaded from
<<<PAGE=40>>>
1104   Journal of Management / July 2010
*Ramirez, A. E. 2000. Individual, attitudinal, and organizational influences on training effectiveness: A test of Noe’ s 
model. Unpublished doctoral dissertation, University of Tulsa, OK.
*Richman-Hirsch, W. L. 2001. Posttraining interventions to enhance transfer: The moderating effects of work envi-
ronments. Human Resource Development Quarterly, 12: 105-119.
Rosenthal R. 1979. The “file drawer problem” and tolerance for null results. Psychological Bulletin, 86: 638-641.
Rosenthal, R., & Rubin, D. B. 1986. Meta-analytic procedures for combining studies with multiple effect sizes. 
Psychological Bulletin, 99: 400-406.
*Rouiller, J. Z., & Goldstein, I. L. 1993. The relationship between organizational transfer climate and positive trans-
fer of training. Human Resource Development Quarterly, 4: 377-390.
Rousseau, D. M. 2006. Is there such a thing as evidence-based management? Academy of Management Review, 31: 
256-269.
Royer, J. M. 1979. Theories of the transfer of learning. Educational Psychologist, 14: 53-69.
Salas, E., Milham, L. M., & Bowers, C. A. 2003. Training evaluation in the military: Misconceptions, opportunities, 
and challenges. Military Psychology, 15: 3-16.
*Scaduto, A., Lindsay, D., & Chiaburu, D. S. 2008. Leader influences on training effectiveness: Motivation and 
outcome expectation processes. International Journal of Training and Development, 12(3): 158-170.
Schmidt, F. L., Hunter, J. E., Pearlman, K., & Hirsh, H. R. 1985. Forty questions about validity generalization and 
meta-analysis. Personnel Psychology, 38: 697-798.
*Short, M. A. 1997. Transfer of training: Examining the relationship of supervisor, peer, and subordinate support on 
the transfer of leadership behaviors to the work place. Unpublished doctoral dissertation, Ohio State University, 
Columbus.
Sitzmann, T., Kraiger, K., Stewart, D., & Wisher, R. 2006. The comparative effectiveness of Web-based and class-
room instruction: A meta-analysis. Personnel Psychology, 59: 623-664.
*Smith, E. M. 1997. The effects of individual differences, discovery learning, and metacognition on learning and 
adaptive transfer. Unpublished doctoral dissertation, Michigan State University, East Lansing.
*Smith-Jentsch, K. A., Salas, E., & Brannick, M. T. 2001. To transfer or not to transfer? Investigating the combined 
effects of trainee characteristics, team leader support, and team climate. Journal of Applied Psychology, 86: 
279-292.
Steel, P. 2007. The nature of procrastination: A meta-analytic and theoretical review of quintessential self-regulatory 
failure. Psychological Bulletin, 133: 65-94.
Steel, P. D., & Kammeyer-Mueller, J. D. 2002. Comparing meta-analytic moderator estimation techniques under 
realistic conditions. Journal of Applied Psychology, 87: 96-111.
*Stevens, C. K., Bavetta, A. G., & Gist, M. E. 1993. Gender differences in the acquisition of salary negotiation 
skills: The role of goals, self-efficacy, and perceived control. Journal of Applied Psychology, 78: 723-735.
*Stevens, C. K., & Gist, M. E. 1997. Effects of self-efficacy and goal-orientation training on negotiation skill main-
tenance: What are the mechanisms? Personnel Psychology, 50: 955-978.
*Switzer, K. C., Nagy, M. S., & Mullins, M. E. 2005. The influence of training reputation, managerial support, and 
self-efficacy on pre-training motivation and perceived training transfer. Applied Human Resource Management 
Research, 10: 21-34.
*Tan, J. A., Hall, R. J., & Boyce, C. 2003. The role of employee reactions in predicting training effectiveness. 
Human Resource Development Quarterly, 14: 397-411.
Taylor, P. J., Russ-Eft, D. F., & Chan, D. W. L. 2005. A meta-analytic review of behavior modeling training. Journal 
of Applied Psychology, 90: 692-709.
 at UNIV OF MICHIGAN FLINT on June 8, 2010 http://jom.sagepub.comDownloaded from
<<<PAGE=41>>>
Blume et al. / Transfer of Training   1105
Taylor, P. J., Russ-Eft, D. F., & Taylor, H. 2009. Transfer of management training from alternative perspectives. 
Journal of Applied Psychology, 94: 104-121.
*Tews, M. J., & Tracey, J. B. 2008. An empirical examination of posttraining on-the-job supplements for enhancing 
the effectiveness of interpersonal skills training. Personnel Psychology, 61: 375-401.
Tharenou, P ., Saks, A. M., & Moore, C. 2007. A review and critique of research on training and organizational-level 
outcomes. Human Resource Management Review, 17: 251-273.
Thorndike, E. L. 1933. A proof of the law of effect. Science, 77: 173-175.
Thorndike, E. L., & Woodworth, R. S. 1901. The influence of improvement in one mental function upon the effi-
ciency of other functions. Psychological Review, 8: 247-261.
*Tracey, J. B., Tannenbaum, S. I., & Kavanagh, M. J. 1995. Applying trained skills on the job: The importance of 
the work environment. Journal of Applied Psychology, 80: 239-252.
*Tziner, A., Fisher, M., Senior, T., & Weisberg, J. 2007. Effects of trainee characteristics on training effectiveness. 
International Journal of Selection and Assessment, 15: 167-174.
*Tziner, A., Haccoun, R. R., & Kadish, A. 1991. Personal and situational characteristics influencing the effective-
ness of transfer of training improvement strategies. Journal of Occupational Psychology, 64: 167-177.
*Ungsrithong, D. 1991. The impact of a realistic training preview on subsequent transfer of training. Unpublished 
doctoral dissertation, Western Michigan University, Kalamazoo.
*Velada, R., & Caetano, A. 2007. Training transfer: The mediating role of perception of learning. Journal of Euro-
pean Industrial Training, 31: 283-296.
*Warr, P., Allan, C., & Birdi, K. 1999. Predicting three levels of training outcome. Journal of Occupational and 
Organizational Psychology, 72: 351-375.
*Weissbein, D. A. 2000. Improving training effectiveness through motivation: Creating a psychological states inter-
vention. Unpublished doctoral dissertation, Michigan State University, East Lansing.
*Werner, J. M., O’Leary-Kelly, A. M., Baldwin, T. T., & Wexley, K. N. 1994. Augmenting behavior-modeling 
training: Testing the effects of pre- and post-training interventions. Human Resource Development Quarterly, 
5: 169-183.
*Wexley, K. N., & Baldwin, T. T. 1986. Posttraining strategies for facilitating positive transfer: An empirical explo-
ration. Academy of Management Journal, 29: 503-520.
Xiao, J. (1996). The relationship between organizational factors and the transfer of training in the electronics indus-
try in Shenzhen, China. Human Resource Development Quarterly, 7: 55-73.
Yamnill, S., & McLean, G. N. 2001. Theories supporting transfer of training. Human Resource Development Quar-
terly, 12: 195-208.
Yelon, S. L., & Ford, J. K. 1999. Pursuing a multidimensional view of transfer. Performance Improvement Quar-
terly, 12: 58-78.
Yelon, S. L., Sheppard, L., Sleight, D., & Ford, J. K. 2004. Intentions to transfer: How autonomous professionals 
become motivated to use trained skills. Performance Improvement Quarterly, 17: 82-103.
*Zayed, M. S. E. 1994. Work environment factors related to the transfer of training to public organizations in Egypt. 
Unpublished doctoral dissertation, Ohio State University, Columbus.
 at UNIV OF MICHIGAN FLINT on June 8, 2010 http://jom.sagepub.comDownloaded from