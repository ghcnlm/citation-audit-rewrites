<<<PAGE=1>>>
Diagnostic Tool for a Monitoring  
and Evaluation Systems Analysis
GUIDANCE NOTE FEB 2022
<<<PAGE=2>>>
GEI  |  MESA Guidance notes  |  FEB 2022
2
Foreword
As the Directors of the World Bank Independent Evaluation Group and the United Nations Development 
Programme Independent Evaluation Office and co-founders of the Global Evaluation Initiative, we are acutely 
aware of countries’ needs for effective monitoring and evaluation systems to track progress on their national 
development strategies, to understand what is working, where and for whom, and where improvements are 
needed. The lack of robust monitoring and evaluation systems leaves many countries at a disadvantage and 
has become an ever more urgent development challenge in the face of the coronavirus pandemic. 
Countries recognize this – even before the pandemic, at an Africa convening event in 2019, participants 
from 24 countries committed to promoting a culture of evaluation and creating the conditions for greater 
use of evaluative evidence to inform public policies. There was also clear demand for support in building 
robust systems of monitoring and evaluation to deliver that evidence. The same year, at the National 
Evaluation Capacities Conference in Egypt, there was consensus amongst participants that evidence, strong 
accountability and learning generated through evaluation will advance the achievement of the Sustainable 
Development Goals. 
The Global Evaluation Initiative, launched in November 2020, is a broad and inclusive partnership, that acts 
as a platform for bringing together the various actors – national governments, civil society, development 
partners, international and regional organizations, and evaluators – who need to work together to close the 
global gap in monitoring and evaluation capacity. For both UNDP and the World Bank, capacity development 
is at the heart of what we do. Capacity development is about transformation that empowers individuals, 
leaders, organizations and societies. And capacity development, including of monitoring and evaluation 
systems, means building on the capacities that already exist. 
Thus, a natural first step to strengthening capacities of a national monitoring and evaluation system is a 
diagnostic, an analysis of current systems and practices, of gaps and opportunities.  
There are existing tools, developed in different contexts, examining different angles, to guide such diagnostics. 
The GEI drew on these tools to develop one that is comprehensive yet flexible, that could be used to guide 
initial reflections with partners as well as to do an in-depth analysis of a national, sectoral or sub-national 
monitoring and evaluation system. 
The GEI Monitoring and Evaluation Systems Analysis – or MESA – is a tool aligned with the GEI conceptual 
framework, which looks at capacities at different levels. These are the enabling environment and the 
institutional and the individual levels. It recognizes that an effective monitoring and evaluation system 
needs to be integrated into public policy making mechanisms, into planning, budgeting, implementing and 
reporting systems. The tool is comprehensive, looking at monitoring and evaluation from multiple angles. It 
is also flexible and can be adapted to local contexts, needs and interests.
<<<PAGE=3>>>
GEI  |  MESA Guidance notes  |  FEB 2022
3
This publication presents the first version of the MESA and will also serve as a primer on national evaluation 
systems that reflects the principles of South-South Cooperation. It has a wide range of examples, illustrating 
each dimension proposed for analysis and providing models for inspiration from developing countries for 
developing countries. 
The MESA is conceived of as a dynamic tool, one that will be regularly updated with new information, new 
examples and new models as the GEI and its partners gain even more experience in strengthening national 
evaluation systems. We invite readers and practitioners to use the tool, and to contribute to its further 
development. 
We look forward to hearing from our partners and everyone who shares our interest in building strong 
monitoring and evaluation systems. 
This Guidance Note is intended to be a dynamic tool that will be regularly updated. For any comments, suggestions, or queries, contact: 
Heather Bryant (heather.bryant@undp.org) and Ketevan Nozadze (knozadze@worldbank.org) 
Alison Evans
Director-General
World Bank Independent 
Evaluation Group
Oscar A. Garcia
Director
UNDP Independent Evaluation Office
<<<PAGE=4>>>
GEI  |  MESA Guidance notes  |  FEB 2022
4
Acknowledgements
This GEI MESA diagnostic tool is the result of collaboration and partnership, and builds on the experience, 
suggestions, and advice of many partners with substantial experience in supporting the development of 
national monitoring and evaluation systems. The GEI wishes to thank all those who contributed to the process 
of developing this tool. The team was led by Ketevan Nozadze and Heather Bryant from the GEI global team, 
with technical support from Gonzalo Hernández-Licona and Ian Goldman, under the overall guidance of the 
GEI Program Manager, Dugan Fraser. With their wide-ranging experience in M&E systems diagnostics, all the 
CLEAR centers shared their valuable experience and lessons learned. In particular, the GEI thanks Candice 
Morkel and Takunda Chirau from CLEAR AA; Lycia Silvia e Lima, Marina Pupo Lafer, and Gabriela Gomez de 
Macedo from CLEAR LAB; Gabriela Pérez, Thania de la Garza, Alonso Miguel de Erice, Karla Pinel and Erick 
Herrera from CLEAR LAC; Edoé Djimitri Agbodjan from CLEAR FA; and Shagun Sabarwal, Sohini Mookherjee, 
and Urbashi Wattal from CLEAR SA. 
The team also benefited from the inputs and perspectives from other GEI partners, such as DEval and the 
World Food Programme. For this, we thank Sven Harten, Juan Sanz, and Michala Assankpon. The team also 
thanks Jozef Leonardus Vaessen, Philip Jespersen, Stephen Francis Pirozzi, and Kamal M. Siblini at the World 
Bank for their comments and suggestions. Many other colleagues from the GEI, the World Bank, and UNDP 
also provided valuable feedback on the various drafts of the guidance.
<<<PAGE=5>>>
GEI  |  MESA Guidance notes  |  FEB 2022
5
Contents
Acronyms and abbreviations         6
About this guide          8
1. Introduction to the GEI’S monitoring and evaluation systems analysis   11
1.2  Why GEI proposes an M&E systems analysis      11
1.3  What is a MESA?         12
1.4  The MESA conceptual framework       12
1.5  The approach to undertaking a MESA       14
2. Contents of a MESA         18
2.1  The MESA diagnostic         18
2.2 The MESA framework         20
3. The MESA process: steps and examples       66
3.1  Making initial contact         66
3.2  Coming to a common understanding on the MESA     68
3.3  Formalizing the understanding       70
3.4  Identifying relevant stakeholders       72
3.5  Establishing structures to increase and embed country ownership   72
3.6  Establishing the team undertaking the MESA      73
3.7  Building capacity to undertake diagnostic work and the MESA   75
3.8  Launching the MESA assessment – ensuring transparency from the outset  76
3.9  Keeping stakeholders informed during the process     77
3.10 Validating the MESA         77
3.11  Overseeing a peer review of the MESA report     80
3.12 Designing a contextually relevant response program     80
4. Summary of the key MESA milestones       83
4.1  Preparing for the MESA        83
4.2  Undertaking the MESA        84
4.3  Writing up the MESA report        84
Bibliography           85
Annexes           92
<<<PAGE=6>>>
GEI  |  MESA Guidance notes  |  FEB 2022
6
Acronyms and abbreviations 
Note that this does not include acronyms and abbreviations that are explained and used only in a single 
example.
BEPPAG Office for the Evaluation of Public Policies and General Actions (Benin)
CARICOM Caribbean Community
CLEAR Center for Learning on Evaluation and Results
CONEVAL Consejo Nacional de Evaluacion de la Politica de Desarrollo Social (Mexico’s agency responsible 
for evaluation of social programs)
CSO Civil society organization
DEVAL German Institute for Development Evaluation
DMEO Development Monitoring and Evaluation Office (India)
DNP Colombia’s Department of National Planning
DPME Department of Planning, Monitoring and Evaluation
ECD Evaluation capacity development
FA Francophone Africa
FCV Fragile states, in conflict or suffering violence 
GDP Gross domestic product
GEI Global Evaluation Initiative
GoJ Government of Jamaica
IDEAS International Development Evaluation Association
INCE National Evaluation Capacities Index
LAB Lusophone Africa and Brazil
LAC Latin America and the Caribbean
M&E Monitoring and evaluation
MESA Monitoring and evaluation systems analysis
Mideplan Ministry of National Planning and Economic Policy, Costa Rica
MIR Matriz de Indicadores para Resultados (logframe in Spanish)
<<<PAGE=7>>>
GEI  |  MESA Guidance notes  |  FEB 2022
7
MoU Memorandum of understanding
NDP National development plan
NDPC National Development Planning Commission (Ghana)
NEC National evaluation capacities
NECD National evaluation capacity development
NES National evaluation system
NGO Nongovernmental organization
NSO National statistical organization
PBM&E Planning, budgeting, and M&E
PMES Performance Monitoring and Evaluation System (of Jamaica)
RBM Results-based management
RREIE Regional Networks of Exchanging Environmental Information (Morocco)
SEDI Strengthening the Use of Evidence for Development Impact Project
T oRs T erms of reference
UNDP United National Development Programme
UNEG United Nations Evaluation Group
UNICEF United Nations Fund for Children
VOPE Voluntary organization for professional evaluation
WFP World Food Programme
<<<PAGE=8>>>
GEI  |  MESA Guidance notes  |  FEB 2022
8
About this guidance
In line with its objective to continue to strengthen monitoring and evaluation systems and practices globally, 
the Global Evaluation Initiative (GEI) has developed a key diagnostic tool. Called the Monitoring and Evaluation 
Systems Analysis (MESA), the tool is a comprehensive and detailed guidance for facilitating the analysis of 
existing national monitoring and evaluation (M&E) systems and capacities. It is hoped, in addition, that the 
MESA will inform national strategies for strengthening country M&E systems and contribute to the enhanced 
use of evidence in policy making. 
Underlying principles of the MESA
GEI believes that effective policy making builds on a culture of evidence-based decision making. This, in turn, 
relies on a country’s M&E systems. In order for countries to strengthen their M&E systems, it is important 
to first understand the current situation of these systems in a country – both de jure and de facto – and the 
prevailing economic, political, and social environment. Before new models for M&E and capacity-development 
strategies are developed, there needs to be a sound understanding of the current formal and informal M&E 
elements and processes. There also needs to be a good understanding of how policy makers view national 
M&E practices with respect to decision making. Gaining a solid understanding of a country’s M&E systems 
is an important first step to understanding needs, priorities, and potential pathways for strengthening those 
systems. 
Conducting a MESA allows governments and civil society and its development partners to build a mutual 
understanding of how the national M&E system functions and to identify opportunities to further strengthen 
capacities. If led by a GEI partner, a MESA can serve as an “ice breaker” for an initial engagement in the 
country. Building trust is essential for a longer-term partnership, as is having a mutual understanding of 
any shortcomings in the M&E system, as well as the opportunities that exist for strengthening the system. 
Drawing on good practices from countries around the world also forms part of the overall exercise. Other 
core principles include country ownership, learning, partnership, flexibility, and the need to be objective and 
credible.
The three broad objectives of a MESA 
The main objective of a MESA as a diagnostic tool is to inform governments’ evaluation capacity-development 
(ECD) strategies and initiatives based on the needs and priorities that have been identified. A MESA is not 
an end in itself, but rather a means to gather, structure, and analyze information to inform and shape 
improvements to a country’s M&E systems. 
 \ The MESA tool is also a guide for the initial engagement by a GEI partner and reflection with a partner 
country’s government. It helps to generate a common and nuanced understanding of the existing 
M&E capacities and to identify opportunities for strengthening these capacities.
 \ The MESA tool is designed to culminate in a report that can serve as a baseline, and against which 
follow-up assessments can meaningfully capture change and measure progress.
<<<PAGE=9>>>
GEI  |  MESA Guidance notes  |  FEB 2022
9
The suggested approach 
While there are many ways to carry out a diagnostic of an M&E system, the GEI MESA adopts a mixed-
method approach, using both quantitative and qualitative methodologies. This includes an exploration of 
the multiple dimensions of national M&E systems, facilitates the analysis of these systems through basic and 
in-depth questions, and provides an understanding of the national M&E capacities. The tool also draws on 
the experience of GEI partners and wide-ranging consultations. 
A detailed framework for the analysis 
The framework for the analysis makes up the bulk of the guidance and is organized around five key parts: 
 \ Background to the country and its current status in relation to M&E. To understand the current M&E 
situation and possibilities for improvement, it is important to have essential background information on 
the country, such as socioeconomic variables, the government structure, and the political and cultural 
environment. It is also important to understand current levels of interest in M&E and motivation for 
strengthening the country’s M&E system. 
 \ Overview of the country’s overall public sector management capacity with focus on planning, 
budgeting and M&E systems. This includes analysis of the legal and policy basis for these systems, the 
roles of key actors, how the planning and budgeting systems function, the key characteristics of the 
country’s M&E system, the status of statistical and administrative data; resources available for M&E, 
how M&E results are communicated, and the extent to which equity, gender, climate change and 
environmental sustainability considerations are integrated into these systems. 
 \ Monitoring and reporting systems. A more in-depth analysis explores monitoring and reporting 
mechanisms at national level, in line ministries and/or sub-national levels, the role played by parliament 
and civil society, the systems and incentives for acting on monitoring information, and how monitoring 
information is used. 
 \ Evaluation systems. This section provides a more in-depth look into the country’s evaluation systems 
and practices at national, line ministry and/or sub-national levels, including government capacity to 
manage, commission and undertake evaluations, capacities to manage and coordinate an evaluation 
system, systems and incentives to use, and actual use of evaluation findings by government, parliament, 
civil society and media. 
 \ Findings, conclusions and recommendations: A MESA concludes with an analysis of what is working 
well, and less well, in the national M&E system, with recommendations for capacity development 
interventions that can trigger wider system change and improve development outcomes.
<<<PAGE=10>>>
GEI  |  MESA Guidance notes  |  FEB 2022
10
The actual process and documenting the analysis
There is also guidance on the actual process, such as setting up parameters for engagement with partners 
and stakeholders, ensuring shared understanding, building trust, and establishing appropriate structures 
for conducting the analysis. Guidance is also given on preparing the final report and agreeing on the way 
forward for responding to the findings and recommendations. 
Structure of the guidance 
 \ Chapter 1: Outlines the principles, objectives, the conceptual framework and suggested approach to 
conducting the MESA. 
 \ Chapter 2: Presents the structure and detailed framework of the MESA analysis. 
 \ Chapter 3: Describes the MESA process and offers some useful tips. 
 \ Chapter 4: Summarizes the key milestones and tasks of a MESA. 
1
<<<PAGE=11>>>
GEI  |  MESA Guidance notes  |  FEB 2022
11
1. Introduction to the GEI’S monitoring 
and evaluation systems analysis
1.1  The Global Evaluation Initiative
The Global Evaluation Initiative (GEI) is a global partnership that is committed to supporting countries to 
develop monitoring and evaluation (M&E) systems and capacities. The underpinning objectives are to 
promote the effective use of evidence in public decision making, enhance accountability, and achieve better 
development results in line with national strategies, and, where relevant, global instruments, such as the 
Sustainable Development Goals (SDGs). To this end, the GEI works with regional and local partner institutions 
and responds to increasing demands from national governments and the international community to 
strengthen national M&E systems3 and enhance the use of evidence in policy making. 
1.2  Why GEI proposes an M&E systems analysis
Countries’ governments and parliaments make public policy decisions on a daily basis, on a range of 
issues such as budgetary matters; the design and execution of programs, projects and strategies; taxation; 
investment; and legislation. Policy makers make decisions based on information acquired from multiple 
sources – both formal and informal. These may include political principles and perceptions; the mass media; 
social media; societal beliefs; anecdotal evidence; lobbying forums; personal and collective experience; and 
scientific evidence arising from research. 
Governments are committed to improving people’s lives. Globally, 91 percent of countries’ national 
development strategies that have been approved since 2015 refer to the 2030 Agenda for Sustainable 
Development and the Sustainable Development Goals. However, according to the Global Partnership for 
Effective Development Co-operation, only 35 percent of countries have reliable data and systems for tracking 
the progress of their policies and programs against these goals. 1 The GEI believes that both gathering and 
using better evidence to formulate more appropriate and targeted policies will help to close this gap. 
Governments understand the need for solid national M&E systems to provide reliable and timely information 
to support decision making, and there is a high demand for resources and expertise to strengthen these 
systems. 
In order to strengthen an M&E system, it is important first to understand the current M&E systems and 
practices – both formal and informal – as well as the decision-making mechanisms, and to identify what 
is working well, what is not working well, and the priority areas for improvement. To develop a national 
evaluation capacity-development strategy or plan that can address all this, an M&E diagnostic tool, or M&E 
systems analysis (MESA) is a logical first step. 
1   Global Partnership for Effective Development Cooperation, Making Development co-operation more effective: Headlines of Parts I and II of the Global Partnership 2019 
Progress Report, 2019. https://www.effectivecooperation.org/system/files/2020-01/GPEDC_2019-Report_Glossy_EN.pdf
<<<PAGE=12>>>
GEI  |  MESA Guidance notes  |  FEB 2022
12
1.3  What is a MESA? 
The MESA is a diagnostic tool. The objective of a well-conducted MESA is to enable countries to assess the 
current capacity of their national M&E systems, identify gaps, and inform potential capacity-development 
strategies to strengthen these systems. Sound evaluative evidence is then used to achieve improved 
performance of government services and programs, ensure better accountability, and to have an incrementally 
positive impact on people’s lives. 
A MESA is not an end in itself, but a tool for gathering, structuring, and analyzing information to inform 
improvements to country M&E systems. The MESA tool is designed for a wide range of users, such as 
governments, M&E practitioners, and policy makers, offering relevant examples of good practices and high-
functioning M&E systems globally. The tool offers a set of guiding questions to understand potential areas 
for strengthening national M&E capacities. 
The tool may be used in different ways: to guide an initial desk review in advance of or during the preliminary 
stages of engagement with a partner government; to conduct an initial assessment; or to undertake a longer-
term more in-depth analysis. The MESA can be used with a view to analyzing entire M&E systems or only 
some elements of a system; it can be customized not only for countries, but also for subnational units or line 
ministries. 
The MESA tool is designed to lead to a report which will not only serve as a guide for preparing a capacity-
development strategy, but which can also be used as a baseline of the country’s M&E situation, against which 
progress can be measured over time. In keeping with World Bank principles, such reports are regarded as a 
public good, and so may be made available in the public domain. 
1.4  The MESA conceptual framework 
The MESA is informed by GEI’s conceptual framework on the National Evaluation Capacity Development 
(NECD) and GEI’s theory of change. As shown in Figure 1, the building of the M&E system takes place 
on three levels: (A) the enabling environment, (B) organizational capacity development, and (C) individual 
capacity development. (Annex 1 shows how the MESA framework and GEI’s National Evaluation Capacity 
Development Framework intersect.) 
Figure 1: GEI’s National Evaluation Capacity Development Framework
<<<PAGE=13>>>
GEI  |  MESA Guidance notes  |  FEB 2022
13
The enabling environment
The enabling environment of a country is the broad social system in which people and organizations function. 
This can include laws, rules, policies, power relations, and the social norms which govern civic engagement. 
The main factors influencing the enabling environment are the political context, culture, incentives, and levels 
of knowledge and understanding of what M&E is. It is not possible to fully understand the current M&E 
system in a country without learning about these factors. For example, the role of the media could benefit 
or inhibit the production and dissemination of evaluations. Electoral cycles may also influence the prevailing 
appetite for evaluation, with governments being more receptive to negative findings when elections are 
further in the future. 
These factors play a role in determining the potential for M&E systems and evaluation capacity development 
(ECD). It is essential to understand this broad context, including both the elements that are deeply engrained 
in society and which capacity-development efforts are unlikely to change, as well as others that can change 
rapidly and which the GEI may seek to positively influence. The MESA framework includes sections and 
questions for exploring different aspects of the enabling environment. 
Organizational capacity development 
The strength and effectiveness of the national evaluation capacities (NEC) of a country are not measured 
by the production of one single evaluation but relate to the management and coordination of a broad 
M&E system. The organizational and institutional capacities of the country are key, especially at the center 
of government. The M&E system is influenced by how the government and its institutions function. The 
existence of a planning body or a strong Ministry of Finance usually favors the development of a relatively 
strong M&E system. However, strong M&E systems may exist in line ministries without there being a national 
M&E system. For example, in Mexico, between 2000 and 2006 there was no national evaluation system, while 
the ministries of social development and health had relatively strong M&E systems. In federal systems it is 
also possible to have good state systems without a strong national system – as is the case in Brazil and India.
For these reasons, it is important that a MESA assess the institutional elements of the central government as 
well as devolved governments (see Figure 1: GEI’s National Evaluation Capacity Development Framework). 
The assessment should include formal and informal arrangements, and the coordination and interaction 
among stakeholders. With parliament as a key policy-making institution, a MESA will also assess its role in 
the overall M&E system. 
Individual capacity development 
Institutions matter, but these are run by individuals. Individual M&E champions are extremely important 
for national evaluation capacities. A robust institutional arrangement can ensure the M&E system has a 
solid structure and a long life. But effective champions and experienced individuals make the M&E systems 
function, and an institution only functions well if it is driven by skilled and motivated individuals.
A case with the experience of a good individual champion for M&E is Chile in the early 2000s. The budget 
director in the Ministry of Finance (MoF) was able to build a significant evaluation unit within the Department 
of Budget of the MoF, while his political skills with other ministries and with the national congress ensured 
that evaluations were accepted by all stakeholders.
<<<PAGE=14>>>
GEI  |  MESA Guidance notes  |  FEB 2022
14
The quality of human capital in the evaluation units and those who will be using and applying the evidence 
from M&E is a crucial aspect of the M&E system. The presence of well-trained specialists in evaluation will 
be one indicator of the maturity and strength of evaluation systems. The MESA should assess the capacity of 
individuals in central government, line ministries, and subnational government in terms of evaluation, as well 
as monitoring. There are particular places in the analysis where this is relevant. 
How the MESA structure links with the GEI National Evaluation Capacity Development 
Framework
Annex 1 is a table showing how the specific sections of the MESA structure map onto the National Evaluation 
Capacity Development Framework. For example, section 2 of the MESA looks at the Country profile (2.1), 
Structure of government (2.2), Political economy and link to M&E (2.3), and Levels of Interest in M&E at the 
beginning of a MESA (2.5). These would all be connected to the Enabling Environment (A) of GEI’s National 
Evaluation Capacity Development Framework, while Organizational culture of government and implications 
for M&E in the MESA structure (2.4), would map onto Organizational Capacity Development (B). In section 
3 of the MESA, which looks at a country’s current M&E environment, M&E capacity-development initiatives 
(3.9) would map onto Individual Capacity Development (3.9) of the GEI framework. (For a comprehensive 
picture of the links between the two frameworks, see annex 1.) 
1.5  The approach to undertaking a MESA
Overall approach to the MESA
There are many ways to carry out diagnostics of countries’ M&E systems, and the GEI network employs three 
different but complementary tools (see box 1). The GEI MESA diagnostic tool has been informed by literature 
review and builds on the experience and work done by GEI partners, including the CLEAR Centers, UNDP , 
UNICEF, Deval, WFP and the World Bank, and others. The tool proposes a standard structure for a MESA, with 
multiple dimensions and subdimensions, and guiding questions, to elicit sound and relevant information 
(see chapter 2). A MESA does not need to cover all dimensions or guiding questions on all occasions. For 
example, if a country has done a previous diagnostic, then many of the questions may be answered through 
reviewing those documents and indicators. 
Box 1: Three GEI tools for national monitoring and evaluation diagnostics
As a global partnership, the GEI supports countries in building sustainable and effective M&E 
frameworks and capacities, by leveraging local, regional, and global knowledge and expertise. The 
GEI places country demand at its core and works toward developing country-owned, sustainable M&E 
frameworks and capacities. At the same time, the GEI seeks to build an understanding of the global 
landscape of national M&E capacities, to build awareness and to promote knowledge generation and 
knowledge sharing
To establish a basis for long-term partner engagement at the national (or sub-national level), the GEI 
network employs two complementary diagnostic tools:
<<<PAGE=15>>>
GEI  |  MESA Guidance notes  |  FEB 2022
15
INCE (Indice de Capacidades Nacionales en Evaluacion): Developed by a broad coalition of partners 
in the Latin American and Caribbean Region, with a facilitation team led by DEval and WFP , the 
INCE has the objective of involving a range of governmental and non-governmental actors in a 
reflection about the state of evaluation in a country. The INCE diagnostics examine five dimensions: 
institutional structure, evaluation offer, quality of evaluations, multi-stakeholder dialogue spaces, and 
use of evaluations. The data collection process encompasses a survey and gathering background 
information through interviews and document review. The results are summarized in a quantitative 
index. 
MESA (Monitoring and Evaluation Systems Analysis): the subject of this guide, the MESA is the 
most comprehensive of the GEI tools for diagnosing national M&E systems. As described in the 
present document, the MESA involves intensive consultation and data collection in collaboration with 
national partners, to develop a clear understanding of planning, budgeting, monitoring, reporting 
and evaluation systems as well as current practices related to use of evidence in policy and decision 
making, with a view to informing potential evaluation capacity development strategies. The MESA is 
designed to flexible and tailored to individual contexts. 
To understand the global landscape of national M&E capacities, the GEI has developed a third tool: 
CAT (Country-level Assessment Tool): A set of standardized core indicators of characteristics 
of national M&E systems, the CAT relies on an efficient and rapid data collection process that is 
conducted systematically and periodically in countries across the globe. It can be used to track 
changes in national M&E systems over time within countries or regions and can facilitate broad-
based cross-country learning.
The relationships between these three tools in terms of their scope are illustrated below:
<<<PAGE=16>>>
GEI  |  MESA Guidance notes  |  FEB 2022
16
The MESA is intended to be flexible as it is applied in different contexts. The MESA could be used with a view 
to improving an entire M&E system or only some elements of it; it could also be applied and customized to 
countries, regions, states, or line ministries. At the heart of each MESA are two overarching questions: 
 \ What does the country’s M&E ecosystem already have in place? 
 \ Based on good practice, as well as a strong understanding of country needs and preferences, what are 
the opportunities to further strengthen the M&E ecosystem? 
To guide decisions about what to cover in the MESA, chapter 2 of this guidance covers each section of the 
MESA with all the dimensions and subdimensions, explaining why they might need to be included. The 
accompanying questions help to guide the process. 
The way the MESA process is carried out is as important as the final product. This is because, aside from 
the technical analysis, a MESA needs to build trust and partnerships for effective learning, successful 
implementation, and the eventual use of high-quality M&E evidence. Thus, the principles underlying the 
MESA are very important, particularly those relating to partnership. This is further addressed in chapter 3 of 
the guidance, which describes in detail possible processes for a MESA.
Methodology and sources of information
To ensure the most accurate and meaningful information is obtained in the MESA, a mixed-method 
methodology, using both quantitative and qualitative research approaches is advised. This means a variety 
of primary and secondary sources would be used, as appropriate. Primary research might involve surveys, 
questionnaires, and interviews. Secondary research would include a range of published resources, such as 
books, journal articles, reports, and official government statistics and documents. While useful sources are 
suggested for the different sections in the MESA framework in chapter 2, it is important that practitioners use 
their initiative and discretion in deciding what the most effective sources are. 
The underlying principles to undertaking the MESA
The MESA needs to be flexible, so it can be adapted to countries’ specific needs and circumstances. 
Nevertheless, it is important that the basic underlying philosophy is observed. For a GEI partner, this 
includes learning from the country, understanding its needs, working together towards improvement, and 
encouraging country ownership. 
Box 2 shows a proposed set of underlying principles.
<<<PAGE=17>>>
GEI  |  MESA Guidance notes  |  FEB 2022
17
Box 2: The principles underpinning the MESA process
GEI and its partners share these principles for all MESA exercises:
 \ Country ownership. GEI and partners should always be clear that sustainable M&E systems are 
about country ownership, where countries are deciding what they want to do to implement M&E 
systems, partnering with external support agencies as needed. Having a strong collaboration 
can inform an effective improvement process. Building effective M&E systems is a long-term 
process and so the partnership may need to be long-term. 
 \ Listening and learning about what happens in the country, informed by local contexts 
and cultural preferences. It is important to meet the country exactly where it is. A GEI MESA 
team will always be genuinely interested in how things are working in the country in terms of 
decision-making processes, maintaining ongoing dialogue with their partners around what is 
working or not, and how systems and practices can be strengthened. The GEI also needs to 
work with local partners who understand the local context.
 \ The MESA needs to be objective and credible. It must be informed by both the local context 
and global good practices, so that government, local, and international external stakeholders 
see the exercise as valid and worthwhile and are prepared to invest in following up on the 
outcomes of the MESA.
 \ The MESA needs to be flexible. Applying the MESA will depend on context, including 
resources and timing. The MESA should be customized to the needs of each country/region 
and GEI partner.
 \ The MESA should be forward-looking. Experience shows that there is greater interest in 
diagnostics when follow-on action is envisaged from the outset.
<<<PAGE=18>>>
GEI  |  MESA Guidance notes  |  FEB 2022
18
2. Contents of a MESA 
2.1  The MESA diagnostic
This chapter provides the analytical framework for the MESA. A map of the overall content of a full MESA is 
shown in table 1. Each subsection is explored in greater detail, explaining why the dimension is important and 
providing examples from different countries, as well as links to further information about the examples or 
the topic. Then, basic questions for answering the analysis are suggested, as well as possible questions for a 
more in-depth analysis. (The links between the sections and GEI’s National Evaluation Capacity Development 
Framework are shown in annex 1.) 
The final product will be a report. In line with the GEI principles of sharing, learning and transparency, this will 
ideally be made accessible in the public domain. 
Once the MESA process is complete, the final report should have a clear executive summary (not more than 
two pages). The summary should capture the essence of the diagnostic and the key findings, and it should 
mention recommendations for ways to strengthen the M&E system in the short and longer term. While the 
analysis is based on the essential principles and some content is mandatory, there is flexibility about much 
of the content, as it needs to be designed according to the needs and priorities of the partner country. It 
is recommended that the maximum length of the publication is 15 pages, with additional information in 
annexes, where appropriate. 
As table 1 shows, the MESA is divided into the following parts: 
1. Introduction to the MESA
2. Country background 
3. Overview of planning, budgeting, and M&E systems (PBM&E) 
4. Monitoring and reporting systems
5. Evaluation systems 
6. Overall findings, conclusions, and recommendations
<<<PAGE=19>>>
GEI  |  MESA Guidance notes  |  FEB 2022
19
Table 1: Structure of the MESA 
Suggested 
introduction to 
MESA and the 
country profile
1 Introduction to the MESA 
1.1  Introduction to the MESA
1.2  Objective of the MESA
1.3  Methodology and process 
1.4  Structure of the MESA report
2 Country background
2.1  Country profile 
2.2  Structure of government 
2.3  Political economy and link to M&E 
2.4  Organizational culture of government and implications for M&E 
2.5  Level of interest in M&E at the beginning of the MESA
Flexible MESA 
analytical 
framework
3. Overview of planning, budgeting, and M&E 
systems (PBM&E)
3.1 Legal and policy basis for the PBM&E systems 
3.2 Roles of key actors in the PBM&E systems 
3.3 Overview of the planning and budgeting systems 
3.4 Overview of the M&E systems
3.5 Role of other stakeholders in relation to M&E 
3.6 Statistical and administrative data
3.7 Resources for M&E
3.8 Communication of M&E evidence
3.9 M&E capacity-development initiatives
3.10 Equity and gender considerations 
in the PBM&E systems
3.11 Climate and environmental sustainability 
considerations in the PBM&E systems
4. Monitoring and reporting systems
4.1 Systems for government monitoring 
and reporting at the national level 
4.2 Systems for government monitoring 
and reporting in line ministries 
and at subnational levels
4.3 Monitoring of government by parliament 
4.4 Capacity in government to 
undertake monitoring and reporting 
4.5 Role of civil society in the 
government monitoring system 
4.6 Systems/incentives for 
acting on monitoring 
4.7 Use of monitoring information 
by government 
5. Evaluation systems
5.1 Evaluation systems at the national level
5.2 Evaluation systems at line ministry and subnational levels
5.3 Government capacity to manage, 
commission, and undertake evaluations
5.4 Government capacity to manage and 
coordinate an evaluation system
5.5 Capacity to undertake evaluations in civil 
society/academia/the private sector
5.6 Systems/incentives for ensuring that evaluation is acted upon 
5.7 Use of evaluations by government 
5.8 Use of evaluations by parliament 
5.9 Use of evaluations by civil society and the media 
5.10 Role of civil society in government evaluation systems 
Overall findings, 
conclusions, and 
recommendations
6. Conclusions
6.1 Overview of the M&E system and how it functions
6.2 Areas that are working well and areas that are working less well 
6.3 Recommendations for interventions that can trigger wider system change and development outcomes 
6.4 Conclusions
<<<PAGE=20>>>
GEI  |  MESA Guidance notes  |  FEB 2022
20
2.2  The MESA framework 
The following tables provide detailed guidance, suggestions, and possible questions for conducting MESA 
diagnostics. It also explains why certain aspects of the M&E systems may be important and provides examples 
of relevant M&E systems and practices internationally. 
1 - Introduction to the MESA 
This section proposes an outline for the introduction to a MESA. This might include why a particular approach 
was taken, the methodology, and the structure of the report.
Subsection Dimensions covered Annexes to the MESA report
1.1 Introduction to the MESA  \ Overall introduction to the MESA
 \ Introduction explaining the parameters of the 
analysis and timeframe
 \ The country and the broad characteristics of 
its current M&E system
 \ The rationale for the MESA
1.2 Objective of the MESA The objective agreed for this specific diagnostic  b A copy of the MESA agreement 
between the country and the GEI 
1.3 Methodology and 
process 
Summary of the methodology, processes 
conducted, and the range of actors involved
 b Annex 2: Program 
 b Annex 3: List of people consulted
 b Annex 4: Key documents consulted
1.4 Structure of the MESA 
report 
Outline of the report structure
<<<PAGE=21>>>
GEI  |  MESA Guidance notes  |  FEB 2022
21
2 - Background to the country and its level of interest in M&E
To understand better the current M&E situation and possibilities for improvement, it is important to have 
essential background information on the country, such as socioeconomic variables, the government structure, 
and the political and cultural environment. It is also important, from the start, to connect these elements with 
the current levels of interest in M&E and motivation for strengthening the country’s M&E system.
2.1 Country profile
Why is this 
important?
This section provides an overview of the economic and social reality to present the context for 
the country, providing some key economic and social indicators. Countries with better economic 
performance may have the resources to build and improve their M&E rapidly, but these situations 
change. If a country is in an economic or social crisis, there may be less focus on improving its 
M&E system than in more stable times; thus, the improvement strategy should be different. At 
the same time, setting the context helps to situate the country in relation to GEI priorities (such as 
income levels and groups; levels of fragility, conflict or violence; vulnerability to climate change; 
and so on.) 
Some examples The case of the COVID-19 pandemic in 2020 is a good example of when countries’ plans for M&E 
improvement changed dramatically. 
Some months after the pandemic struck, India had started improving its M&E systems. However, 
UNICEF and partners suggested taking advantage of this impasse to keep working on some core 
elements of the evaluation system. 
In South Africa, the effects of the pandemic have led to cuts in government budgets, including 
budgets available for evaluations.
For countries in the Caribbean, natural disasters such as hurricanes occur frequently and have a 
significant impact on the distribution of resources. Governments must act quickly and respond 
to these events. This affects planning and budgeting, and activities related to M&E may not be 
priorities.
Useful sources  b A country’s national statistical agency will be a source for much of the data, but there are also 
global databases that can be used. The World Factbook is an excellent source of basic data on 
all countries, including economic, governance and population data, such as those required for in 
sections 2.1 and 2.2 in the diagnostic.2 
 b Other sources include the World Bank’s Development Indicators3 and UNDP's human 
development indicators.4 
 b There are also specific scorecards. For example, for African countries, the Ibrahim Index of 
African Governance (II AG) is a tool that measures and monitors governance performance in 
African countries.5 
2   CIA: The World Factbook – Explore all countries. Accessed February 14, 2022. https://www.cia.gov/the-world-factbook/countries/ 
3   World Bank. “Databank World Development Indicators”. Accessed February 14, 2020. https://databank.worldbank.org/source/world-development-indicators 
4   UNDP: Human Development Reports, accessed February 14, 2022, www.hdr.undp.org/en/data 
5   Mo Ibrahim Foundation. “Ibrahim Index of African Governance”. Accessed February 14, 2022. https://mo.ibrahim.foundation/iiag
<<<PAGE=22>>>
GEI  |  MESA Guidance notes  |  FEB 2022
22
2.1 Country profile
Suggested 
basic questions 
 \ What is the GDP per capita?
 \ What is the current growth rate?
 \ What are the key economic sectors and how are they performing?
 \ What are levels of poverty and inequality? (Use international and comparable data on poverty 
and inequality; but national definitions and alternative measures could be used for a deeper 
dive.) 
 \ Key demographics: median age, life expectancy, gender (for example, the percentage of boys 
and girls at school or the Gender Inequality Index); basic education (for example, the percentage 
of the population that have completed secondary school), health (for example, the rate of 
maternal mortality).
 \ Vulnerability to climate change (for example, incidences of drought, disasters, and weather). 
Possible more 
in-depth 
questions
 \ Peace, conflict, and security issues. (For fragile states or those affected by conflict, this is key 
information).
 \ What are the levels of unemployment?
 \ CO2 emissions in relation to GDP .
 \ Migration: percentage of the population that are migrants – internal and external.
2.2 Structure of government
Why is this 
important?
It is necessary to engage with the government to get a general picture of the way the 
government is structured – including the executive and legislative arms. This informs how M&E 
systems might be structured and run. 
It is also necessary to identify the role of a center-of-government agency or entity that might 
play a key driving role in M&E – such as the presidency or finance ministry. (This is explored in 
more depth in section 3.2.)
It is also important to identify the timing of elections as these are so critical in occupying the 
minds of politicians, and, by extension, government ministries. This will influence the space 
available for considering new options. These cycles also affect the potential turnover of members 
of parliament. For example, would it be worth investing in them if an election is imminent?
Some examples Mexico has a federal government, while Chile and Uganda have unitary governments. This 
difference has important implications for the M&E framework. In Mexico, the power of state 
governors is such that the social law was only able to cover the M&E of the federal government. 
Implementing evaluation in states has to be done through more complex negotiations with 
multiple states. In Chile it is easier to implement a national M&E system. 
Likewise, in a unitary state like Uganda, a national M&E policy is easily enforceable across 
all spheres of government. With parliaments, some countries like Philippines have bicameral 
parliaments, in which case both the senate and congress would need to be considered. In Sri 
Lanka, on the other hand, there is a single parliament.
<<<PAGE=23>>>
GEI  |  MESA Guidance notes  |  FEB 2022
23
2.2 Structure of government
Some examples In some cases, a regional dimension needs to be included. 
For example, in the Caribbean, CARICOM member states have signed a commitment with 
the community for developing and implementing results-based management (RBM) policies. 
Therefore, any progress in this area would consider CARICOM’s elements and would be 
communicated to the Community. CARICOM has a role as a coordinating regional institution that 
is not the case for other regions.6
Useful sources  b The World Factbook is an excellent source of governance data on all countries.7 
 b For more information on governance in African countries, see the African Peer Review 
Mechanism,8 along with the Ibrahim Index of African Governance mentioned in section 2.1.9
Suggested basic 
questions
 \ What is the overall structure of government (for example, a federal or unitary system)?
 \ What is the parliamentary system?
 \ What are the dates/years of the last and next elections?
Possible more  
in-depth 
questions
 \ What are the policy-making mechanisms under multiparty/single party governance? 
 \ How do changes in leadership happen?
(Note that section 3.2 explores the roles of key stakeholders in more depth.)
2.3 Structure of government
Why is this 
important?
The shape and current state of the M&E system can largely be explained by how the incentives 
of political actors have led to certain decisions. The structure of the government helps to explain 
formal relationships. However, it is necessary to go further and explore and learn, when possible, 
about the incentives of other stakeholders in the M&E system. It is important to know whether 
the original M&E idea came from the executive or from congress or any other institution – so the 
political economy of a country is key for determining this
Some examples In the case of Mexico, understanding the political situation of both the executive and congress 
helped to move the M&E system forward. It was not until 1997 that there was a balance of 
power between the executive and congress, at which point congress decided to approve laws 
for transparency and evaluation. So any further improvement of the M&E framework will need to 
consider the Mexican congress. This is not the case in other countries.
In South Africa, presentations to parliamentary portfolio committees are preceded by 
presentations to the ruling party caucus on the committee. This is informal but standard practice. 
This means that any findings or key measures relating to M&E that the central M&E champion or 
line ministries want to make public are presented to party structures first. It is essential therefore to 
understand the party dynamics and not just the formal government arrangements.
India launched an Independent Evaluation Office (IEO) in 2014. The idea was to have a more 
independent institutional mechanism to conduct the evaluation process in central government. 
The IEO did not last long due to the imbalance of power between the Office of the Prime Minister 
and the IEO, together with the fact that in the same year, the government changed. However, the 
new Indian government launched the Development Monitoring and Evaluation Office (DMEO), as 
part of NITI Aayog, a public policy think tank of the Government of India and the body that has 
been responsible for building an important evaluation system in India since 2015.
6   CARICOM. The Strategic Plan for the Caribbean Community 2015 – 2019: Repositioning CARICOM raises the importance of adopting RBM in the region as a mean to improve 
planning and budgeting for achieving the desired results. July 3, 2014. https://caricom.org/documents/strategic-plan-caribbean-community-2015-2019/  
7   CIA: The World Factbook – Explore all countries. Accessed February 14, 2022. https://www.cia.gov/the-world-factbook/countries/ 
8   APRM (African Peer Review Mechanism). Accessed February 14, 2022. https://www.aprm-au.org/page-about/ 
9   Mo Ibrahim Foundation. “Ibrahim Index of African Governance”. Accessed February 14, 2022. https://mo.ibrahim.foundation/iiag
<<<PAGE=24>>>
GEI  |  MESA Guidance notes  |  FEB 2022
24
2.3 Structure of government
Useful sources  b For an example of informal processes in South Africa, see this newspaper article from South 
African online newspaper, Daily Maverick.10  
 b The Strengthening the Use of Evidence for Development Impact (SEDI) project has been 
applying political-economy analysis to case study countries including Pakistan, Ghana, and 
Uganda.11  
Suggested 
basic questions
 \ What are the political forces that have driven the development of M&E or related practices/
systems?
 \ How does accountability work in the government system and in parliament, in theory and in 
practice?
 \ Who will benefit from building an effective M&E system?
 \ Who will not benefit from building the M&E system?
 \ What are the implications of this for strengthening the M&E system?
Possible more  
in-depth 
questions
 \ What are the political forces (policies, laws, regulations, orders, etc.) that have driven the 
development of M&E or related practices/systems? (A deeper dive may be appropriate.) 
 \ Who are the various stakeholders involved in policy making and how do they interact (for 
example, lobbying)? 
 \ What is government’s current political focus (for example, what are the priority outcomes) and 
how has this evolved?
 \ What role do CSOs play in relation to government (in relation to advocacy or service delivery, 
for example)? 
2.4 Organizational culture of government and implications for M&E
Why is this 
important? 
Using M&E for accountability may require a certain mindset shift – that government should be 
accountable for how it performs. Using M&E for learning and improvement may bring in a further 
shift in mindset, and a culture where problems are not avoided but used for improvement. Both 
of these are a challenge in many government systems, where the culture is often of compliance 
and fear to expose failures. It is important to understand the dominant culture, as well as a less 
dominant culture that may be receptive to using M&E, in order to design appropriate responses, 
and find possible champions or government structures that may drive M&E.
Some examples In Malaysia, the Performance Management and Delivery Unit in the Prime Minister’s Office12 
employed a “big fast results” methodology to diagnose key problems with stakeholders in 
a laboratory environment and identify how the problems could be solved. These were then 
monitored on a weekly basis by the relevant government minister, who indicated that “if you 
don’t tell me problems, I assume everything is working perfectly”. This demonstrated an effective 
problem-solving approach, which is central to the country’s delivery unit model.
In South Africa, the Department of Planning, M&E (DPME) was only created in 2010. As a new 
department it was able to create an innovative and problem-solving culture, which meant it was 
able very quickly to establish a wide set of important M&E systems. Over the last four years, 
however, the performance of the system has been more uneven. 
10  Daily Maverick. 2021. https://www.dailymaverick.co.za/article/2021-08-11-ramaphosas-testimony-exposes-the-vast-contours-of-the-ancs-shadow-state/ 
11  Oxford Policy Management. Strengthening Evidence use for Development Impact (SEDI).” Accessed February 14, 2022. 
https://www.opml.co.uk/projects/strengthening-the-use-of-evidence-for-development-impact 
12   Performance Management And Delivery Unit (PEMANDU) in the Prime Minister’s Office, which has now closed.
<<<PAGE=25>>>
GEI  |  MESA Guidance notes  |  FEB 2022
25
2.4 Organizational culture of government and implications for M&E
Useful sources  b For more information on performance culture, read chapter 4 of the book Using Evidence in 
Policy and Practice.13 The chapter covers evidence use by African governments, and explores 
M&E culture in Benin, Uganda, and South Africa.
 b For further information on the DPME model, read this journal article.14 
Suggested basic 
questions 
 \ Is there a demand from managers/technicians/parliamentarians/civil society for performance 
information to inform policy and program planning and budgeting?
 \ How do politicians and senior officials view the usefulness of M&E and results-based 
management? Do they see them as relevant for accountability? What about for learning and 
performance improvement?
 \ What are the dominant incentives in the public service (for example, fear of making a mistake, 
or achieving targets for bonuses)? Does this vary across departments so that some show a more 
transparent, learning, and performance-oriented culture? 
 \ Is there a culture of learning and is there an interest and ability to cultivate this? Does this vary 
across departments? 
 \ How does the government usually respond to negative M&E findings/evidence? 
 \ Overall, what are your conclusions on the organizational culture within the public service?
Possible more in-
depth questions
 \ What kind of decisions are guided by M&E information – in relation to planning, budgeting, and 
other key areas? 
 \ These questions can also be explored in more depth, such as through using survey information 
or literature to deepen the analysis. 
2.5 Level of interest in M&E at the beginning of the MESA
Why is this 
important? 
Governments and people in government change all the time. It is possible that the reasons for 
starting an M&E system sometime in the past may be different from today’s reasons. It is therefore 
essential understand the technical and political reasons for the country’s current levels of interest 
(or lack of it) in M&E. These answers might be different from those in section 2.3, and it would be 
important to know the difference.
Some examples Colombia has had a long experience of evaluation, especially in relation to government 
regulations. Since 2020, the National Department for Planning (DNP) has been motivated 
to improve the use of evaluations and to enhance national capacity. It is keen to approve an 
institutional document for M&E improvement within the National Council of Social and Economic 
Policies (CONPES) to include stakeholders beyond the DNP . If this is done, the improvement and its 
implementation will be sustained long after the current government. 
Worldwide, COVID has increased governments’ motivation to bring evidence to bear on key 
decision making. This creates an opportunity for emphasizing the importance of sound M&E. 
In South Africa, in the Western Cape Province, which has a strong M&E system, the decision was 
taken to undertake some rapid evaluations around key issues related to COVID. This was helpful in 
seeing the value that rapid evaluations could bring.
13   Ian Goldman et al., “Mere compliance or learning – M&E culture in the public service of Benin, Uganda and South Africa”, in Using Evidence in Policy and Practice, eds. Ian 
Goldman and Mine Pabari (Oxfordshire: Taylor & Francis, 2020), 54–74. https://www.taylorfrancis.com/chapters/oa-edit/10.4324/9781003007043-4/mere-compliance-learning-
culture-public-service-benin-uganda-south-africa-ian-goldman-wole-olaleye-stanley-sixolile-ntakumba-mokgoropo-makgaba-cara-waller?context=ubx&refId=c513054a-
4cdb-420d-b196-8ed35908fa53 
14   Sean Phillips et al., “A focus on M&E of results: an example from the Presidency, South Africa”, Journal of Development Effectiveness 6, no. 4, (Dec 2014): 392–406. http://
dx.doi.org/10.1080/19439342.2014.966453
<<<PAGE=26>>>
GEI  |  MESA Guidance notes  |  FEB 2022
26
2.5 Level of interest in M&E at the beginning of the MESA
(cont.) Sri Lanka has been through periods of actively championing M&E: in the 2000s, and then in 
2015–19 – with less interest at other times. This is linked to the roles of individual champions as well 
as changes in government, and political perceptions of the relevance of M&E. It is important to 
understand these possible drivers and to be realistic about the current levels of interest, as well as 
the fact that there is fluidity and always the potential for change. 
In Dominica, there is a dual interest in moving towards an RBM approach and having an M&E 
system. First, as a member state of CARICOM it is has committed to expedite an RBM policy and 
practices.15 Second, having set the goal of becoming the first “climate resilient” country in the 
world, it has created a specific agency, the Climate Resilience Execution Agency for Dominica 
(CREAD), which has a strong alignment with RBM and M&E practices to reach this goal.
Useful sources  b Climate Resilience Execution Agency for Dominica (CREAD)16 
Suggested basic 
questions
 \ How much interest is there in M&E now and from whom?
 \ Why is a MESA diagnostic exercise likely to be of value at this time?
 \ What is motivating the champion(s) or leading government agency or entity to build the M&E 
system?
 \ Are there particular constraints around the development of M&E at this time – such as 
upcoming elections, or crises such as pandemics, or climate change-related disasters or events?
Possible more  
in-depth 
questions
 \ If there is resistance to M&E, what are its origins, and what is the level of interest and capacity to 
change these views? 
15   CARICOM. 2020. Decisions of the fortieth regular meeting of the conference of heads of government of the Caribbean community”, CARICOM Caribbean Community. Fortieth 
Regular Meeting of the Conference of Heads of Government of the Caribbean Community (CARICOM), Gros Islet, Saint Lucia, 3-5 July 2019. 
https://caricom.org/documents/fortieth-regular-meeting-of-the-conference-of-heads-of-government-of-the-caribbean-community-caricom-decisions/ 
16   CREAD (Climate Resilience Execution Agency for Dominica). Accessed February 14, 2022. https://www.creadominica.org/
<<<PAGE=27>>>
GEI  |  MESA Guidance notes  |  FEB 2022
27
3 - Overview of planning, budgeting, and M&E systems 
This section is intended to provide an overview of the planning, budgeting, and M&E (PBM&E) systems, 
which are then explored in detail in section 4 (for monitoring) and section 5 (for evaluation). As evaluation 
in particular needs to inform plans and budgets, an overview of these planning and budgeting systems is 
provided.
3.1 Legal and policy basis for the PBM&E systems
Why is this 
important? 
This section covers the legal and policy basis for the planning, budgeting, and M&E systems. In 
the case of planning and budgeting, these are important in relation to the extent to which they 
influence the use of M&E. There is usually a legal basis for planning and budgeting, but often 
not for M&E. Exceptions might be for line-ministry responsibilities and related legislation. For 
example, a health ministry may be bound by legislation that requires it to undertake monitoring 
in the sector. While evaluations might be developed in countries, having a binding law, regulations 
or policies provides a strong institutional base for the M&E system. It can also provide the M&E 
champion or leading government agency or entity with a stronger basis for requiring sector 
ministries to provide monitoring reports or to undertake evaluations. It also means that the system 
is likely to be more sustainable and less susceptible to political or administrative transitions and 
flux. 
Some examples The system of planning in Costa Rica is grounded in the National Planning Law of 1974 that 
incorporates the mandate to systematically evaluate programs, plans, and policies. However, the 
national evaluation system (NES) was not initiated until 1994, when a law conferred on the Ministry 
of National Planning and Economic Policy (Mideplan) the responsibility to coordinate, monitor, 
and evaluate actions, programs, and development policies. A national evaluation policy was 
only formulated to guide governmental evaluation in 2018 – quite long after the NES had been 
implemented.
Cabo Verde’s foundational law on the planning system (Lei de Base do Sistema de Planeamento) 
is quite detailed. It includes definitions related to the institutional framework, purpose, and 
governing principles, and guidance on M&E practices, data collection, and the respective roles and 
schedules for this. 
In Brazil, the State of Espírito Santo was a pioneer in the development of a public policy M&E 
system (Simapp). According to the law, the state’s governor is responsible for establishing Simapp's 
strategic guidelines. Thereafter, the Strategic Analysis Commission annually approves the state’s 
M&E plan, and indicates which public policies will be monitored and evaluated throughout the 
year. There is always reference to the budget cycle of the current year and the state's multiannual 
plan. For following up, the Nucleus for Monitoring and Evaluation of Public Policies (Numa) 
coordinates the M&A actions that will be implemented by each sector each year.
In Uganda, the National Policy on Public Sector Monitoring and Evaluation provides a clear 
framework for strengthening the coverage, quality, and utility of the assessment (M&E) of public 
policies and investments. Moreover, the policy proposes the allocation of funding for M&E within 
the national budget.
<<<PAGE=28>>>
GEI  |  MESA Guidance notes  |  FEB 2022
28
3.1 Legal and policy basis for the PBM&E systems
Some examples In India, the central government does not have a fully-fledged national evaluation policy or an 
extensive legal mandate for M&E. However, there are specific mandates that provide a legal 
basis for M&E. Since 2005-06, the Ministry of Finance has presented an outcome-based budget, 
with renewed focus on outcomes rather than expenditure. In 2009, the government introduced 
a results-framework document (RFD) under which it was mandatory for all ministries and 
departments to list goals for that financial year and the respective achievement rates against 
the specific indicators. However, at the state level, the Government of Karnataka has set up an 
independent evaluation unit and in 2000, developed an evaluation policy for the state. According 
to this policy, any scheme with a budget above a particular figure should be evaluated.
Useful sources  b National Policy on public sector Monitoring and Evaluation, Government of Uganda17
 b IEG report on government M&E system in India18
Suggested 
basic questions
 \ Where do custodians of the PBM&E systems derive the mandate to provide oversight and 
coordination of PBM&E at varying levels (for example, constitution, laws, regulations, and 
executive powers, including policies)? 
 \ Is there a national monitoring and evaluation policy, or a national monitoring policy, or a 
national evaluation policy? 
 \ Is there national legislation or regulation for monitoring and/or national legislation or regulation 
for evaluations, or a national policy for monitoring and evaluation?
 \ If there is a law, regulation, policy on monitoring and/or evaluation do they include references 
to:
• links between (results) monitoring and planning?
• links between (results) monitoring and the budgetary process?
• links between (results) monitoring and decision making in parliament (legislative)?
• links between (results) monitoring and decision making in higher levels of government 
(executive)?
• links between (results) evaluation and planning?
• links between (results) evaluation and the budgetary process?
• links between (results) evaluation and decision making in parliament (legislative)?
• links between (results) evaluation and decision making in higher levels of government 
(executive)?
 \ the independence of the evaluation unit(s)?
 \ the necessary resources and staff of the evaluation unit(s)?
 \ Is there a regulation/agreement/long-term development agenda that obliges the government 
to communicate program results periodically, whether to the population, donors/agencies, for 
international obligations and/or between ministries?
 \ Is there a legal requirement or regulations requiring the use of evidence in decision making? 
Possible more 
in-depth 
questions
Explore further any legal requirement or regulations requiring the use of evidence in decision 
making – for example, when new programs are approved. 
17   Ministry of Health Knowledge Management, Republic of Uganda. 2011. National Policy on Public Sector Monitoring and Evaluation. 
http://library.health.go.ug/publications/monitoring-and-evaluation/national-policy-public-sector-monitoring-and-evaluation 
18   Santosh Mehrotra. 2013. The Government Monitoring and Evaluation System in India: A Work in Progress. Independent Evaluation Group, The World Bank Group, No.28, 
October 2013. https://ieg.worldbankgroup.org/sites/default/files/Data/reports/ecd_wp28_india_me_0.pdf
<<<PAGE=29>>>
GEI  |  MESA Guidance notes  |  FEB 2022
29
3.2 Roles of key actors in the PBM&E systems
Why is this 
important? 
This section is intended to provide an overview of the roles of key actors in the PBM&E system 
in the executive arm (government) and the legislative arm (parliament). It would also identify the 
key drivers of M&E. It is important to understand the roles of ministries of finance, any planning 
authority, or the government agency or entity driving M&E, as well as any M&E champions. It is 
also important to understand how these structures map onto the line ministries, and in subnational 
governments. 
In terms of questions asked and the competencies required, there are many similarities between 
research and evaluation. So it is worth finding out if there are existing research functions that 
take on the evaluation function. It is important to understand both the formal structure and how 
power plays out in practice. (This is explored more below.) This makes it possible to identify key 
organizations and institutions (rules of the game) and inter-institutional relationships that play an 
important role within the current and future M&E systems.
It is also important to bring out the role of service departments, which often have M&E functions 
and which may have specific roles prescribed by legislation which include monitoring, if not 
evaluation. Often the final use of evaluation recommendations may need to result in changes to 
standard operating procedures of these departments.
Some examples It is important to elicit whether the government agency or entity driving M&E is an overarching 
department like the Office of the Prime Minister in Uganda, or does not have that authority over 
other departments, like the M&E Directorate in the Ministry of Treasury and Planning in Kenya.
In Uganda, the government M&E system has been in existence since 2006 and is integrated 
into ministries, departments, and agencies (MDAs), as well as higher local governments (HLGs). 
Custodianship and oversight of the public sector M&E system is invested in the Office of the 
Prime Minister (OPM). M&E is emphasized in the national, MDA, and district development plans, 
budgeting frameworks, and statistics development plans. The M&E Policy of 2011 defines the 
specific roles and responsibilities of the OPM, ministries, HLGs and other actors in the M&E system.
In Jamaica, the Planning Institute of Jamaica is the country´s leading institution in the formulation 
of economic and social policies, plans, and programs for development. However, in order to 
achieve the desired results of those programs, the government, through the Cabinet Office, has 
implemented a performance monitoring and evaluation system (PMES) within the public sector: 
an improved system for monitoring and evaluating key performance activities, indicators, and 
targets, and reporting on results. The PMES is the responsibility of the Performance Management 
and Evaluation Branch, which works primarily with ministries and their portfolio departments and 
agencies to improve their strategic planning. The PMES is thus a recognized cross-ministerial tool 
within Jamaica.
In India, the Planning Commission was constituted in 1950 and was made responsible for 
developing five-year plans. In 1952, the Programme Evaluation Office (PEO) was established under 
the Planning Commission to evaluate government programs. The evaluation function at the state 
level was introduced at the same time. But from 1970 onwards, the unit’s role and the importance 
attached to it gradually declined. Eventually, in 2009, M&E was given increased importance when 
significant changes were made to the role of the PEO. An independent evaluation office was also 
set up in 2013 and eventually, in 2015, the PEO and the IEO were merged under the Development 
Monitoring and Evaluation Office. The primary mandate of this office is to monitor and evaluate the 
implementation of schemes under the national government.
In South Africa, the Department of Basic Education is responsible for primary and secondary 
education. It has a significant M&E function, including an education management information 
system, and a strong M&E and research function, with significant capacity. It has a legal mandate 
to undertake M&E of the sector.
<<<PAGE=30>>>
GEI  |  MESA Guidance notes  |  FEB 2022
30
3.2 Roles of key actors in the PBM&E systems
Useful sources  b This article discusses the roles of the agencies or entities that are driving M&E in Benin, Uganda, 
and South Africa.19
 b For more information on Jamaica, see the Performance Monitoring and Evaluation System 
(PMES) Framework and the Government Performance Management and Evaluation/PIOJ sites.20
 b India’s Development and Monitoring and Evaluation Office (DMEO), for information on its vision, 
strategy and roles.21
Suggested basic 
questions
 \ Is there a central body responsible for monitoring?
 \ Are there decentralized bodies responsible for monitoring?
 \ Is there a central body responsible for evaluation?
 \ Are there decentralized bodies responsible for evaluation?
 \ What is the legal basis for these entities?
 \ Does the central evaluation unit set standards and provide support for evaluation across 
government?
 \ What are the roles of different stakeholders at national and subnational levels in the planning, 
budgeting, and M&E systems (including communities if relevant)?
 \ Are there individual M&E champions at the political and senior administrative levels in the 
country (for example, directors, permanent secretaries)? 
 \ With respect to parliamentary roles, do laws, regulations, or policies make linkages between 
(results) monitoring and decision making in parliament?
 \ Do laws, regulations, or policies stipulate linkages between evaluation and decision making in 
parliament?
Possible more  
in-depth 
questions
 \ Are there research structures in government departments that could be built on – for example, 
for evaluations?
 \ What is parliament’s role in the planning, budgeting and M&E systems? 
 \ What does a power analysis of the main stakeholders reveal? 
 \ It may be important to further explore the realities of the balance of power between institutions 
and stakeholders. 
19   Ian Goldman et al. 2018. “The emergence of government evaluation systems in Africa: The case of Benin, Uganda and South Africa”, African Evaluation Journal, 6 no. 1, 
(March 2018): 253. https://doi.org/10.4102/aej.v6i1.253 
20   Performance Management and Evaluation Unit, Government of Jamaica. 2010. Performance Monitoring And Evaluation System (PSES) Framework.” 
https://cabinet.gov.jm/resources/performance-monitoring-and-evaluation-system-pmes-framework/ 
Office of the Cabinet, Government of Jamaica. Government Performance Management and Evaluation.” Accessed February 14, 2022. 
https://cabinet.gov.jm/government-performance-and-monitoring/ 
Planning Institute of Jamaica, accessed February 14, 2022. https://www.pioj.gov.jm/ 
21   DMEO (Development Monitoring and Evaluation Office), Government of India. Accessed February 14, 2022. https://dmeo.gov.in
<<<PAGE=31>>>
GEI  |  MESA Guidance notes  |  FEB 2022
31
3.3 Overview of the planning and budgeting systems
Why is this 
important?
This section provides an overview of the development of the planning and budgeting systems, 
which is informed by M&E, as well as the policy cycle, if one is defined. This may be covered at 
national and subnational levels. This probably does not need to be covered in depth but as a key 
use of M&E evidence is to inform planning and budgeting, it is important to have an overview 
of how this system works. While monitoring is looked at in detail in section 4, and evaluation in 
section 5, this guidance does not go into planning and budgeting in detail. More layered iterations 
of this diagnosis could explore program-based budgeting, the policy process, and the degree to 
which planning is participatory. 
Some examples In Cabo Verde, the National Planning Directorate (DNP) is responsible for defining the instruments 
and guidelines for reporting strategic programs to be carried out by all government agencies 
involved – provincial and sectoral. For the purposes of monitoring and evaluating sector plans, the 
DNP currently uses the logical framework models defined in the foundational law on the planning 
system as a "programming instrument represented by a matrix that links the costs of activities with 
the strategic objectives of a program, project or unit, translated into performance indicator targets 
and their respective sources of verification". In Cabo Verde, different sector strategies are now 
planned and monitored in line with logical frameworks and adequate indicator data. 
As a regional example, the Caribbean Community (CARICOM) has institutions that deal with 
planning and budgeting at a regional level. it is important to understand these regional institutions 
in the Caribbean to learn from the evaluation systems within the member countries.
In Mexico, the budget cycle starts in May to prepare the proposed budget for the national 
congress in September. The evaluation strategy for social programs is aligned to the budget cycle 
to provide feedback to relevant budget stakeholders in a timely manner. Program evaluations are 
due in June to feed the proposal from the executive and the discussion in congress.
In Brazil, in the State of Espírito Santo a law made in 2017 links the state's budgeting and 
evaluation cycles. A report on the quality of public spending is developed annually; it discloses 
summaries of the evaluations carried out and ranks these by performance and the need for 
improvement when this is appropriate. The report informs the preparation and review of the state’s 
annual budget.
Useful sources  b Mexican evaluation policy: La Política de Evaluación en México: 10 años del CONEVAL22 
Suggested 
basic questions
 \ How does the planning system work? 
 \ Is there an established process for designing and implementing public policy? What are the 
steps and methodologies? Are there instances of approval where evidence can be applied?
 \ How does the budgeting system work?
 \ Are there processes for performance-based or results-based budgeting and is this culture well 
established?
 \ What evidence does the state use to inform government planning, budgeting, policy, and 
decision making?
22   CONEVAL: La politica de evaluacion en Mexico: 10 anos del CONEVAL. Accessed February 14, 2022.
https://www.coneval.org.mx/InformesPublicaciones/Documents/CONEVAL_politica_de_evaluacion_10_A.pdf
<<<PAGE=32>>>
GEI  |  MESA Guidance notes  |  FEB 2022
32
3.3 Overview of the planning and budgeting systems
(cont.)  \ Do laws, regulations, or policies stipulate the links between (results) monitoring and the 
budgetary process?
 \ Do laws, regulations, or policies stipulate the links between evaluation and national planning?
 \ Do laws, regulations, or policies stipulate the links between Evaluation and the budgetary 
process?
 \ Does the national plan have clear goals, indicators, and targets?
Possible more 
in-depth 
questions
 \ To explore the systems in more depth, there could be a deeper analysis of how these evolved, 
and not just how they are now.
 \ To what extent is the planning process participatory and inclusive (for example, at municipal, 
provincial and national levels)? 
 \ The evidence used could be explored in more depth.
3.4 Overview of the M&E systems
Why is this 
important?
This section provides an overview of the M&E-related systems that are in place. The analysis needs 
to also discuss M&E-like systems. (Note that audit is discussed in section 3.5 below.) This overview 
should include: plans, such as evaluation plans; guidelines; standards; required competencies; 
follow-up systems, such as evaluation management responses or improvement plans; and any 
incentives for adopting M&E. This section may explore M&E policies and guidelines that might 
have already been mentioned in 3.1. (Sections 4 and 5 explore monitoring and evaluation in more 
depth.)
Some examples In Benin, the National Evaluation Policy of 2012 defines the overall framework for planning and 
carrying out evaluations, as well as the use of information drawn from these evaluations. 
The National Evaluation Council is supposed to be the body for guidance and consultation in 
terms of the evaluation of public policies in Benin, and it includes representatives of voluntary 
organizations for professional evaluation (VOPEs). The council is responsible for advising 
the government on evaluation and promoting the development of evaluation at national, 
departmental and municipal levels. However, it has not met since 2015.
There is no evaluation plan, so the policies or programs to be assessed are determined on an ad-
hoc basis, based on requests from line ministries, recommendations from cabinet meetings, or the 
analysis of the national context, as well as the priorities of development partners (DPs). 
Guidelines have been developed, as well as a repository of evaluations. There are now five 
universities offering master’s degrees in M&E or evaluation. 
Useful sources  b This article discusses the evaluation systems in Benin, Uganda, and South Africa.23
23   Ian Goldman et al. 2018. “The emergence of government evaluation systems in Africa: The case of Benin, Uganda and South Africa”, African Evaluation Journal, 6 no. 1, 
(March 2018): 253. https://doi.org/10.4102/aej.v6i1.253
<<<PAGE=33>>>
GEI  |  MESA Guidance notes  |  FEB 2022
33
3.4 Overview of the M&E systems
Suggested 
basic questions
 \ What are the different M&E systems: for example, of departments and projects monitoring 
against the national development plan, monitoring of SDGs, and evaluation systems? 
 \ How have these evolved, briefly?
 \ Is there a national coordination body, such as a national evaluation council?
 \ What components of M&E systems are in place: for example, M&E policy/strategy, M&E 
frameworks, reporting systems, evaluation agenda/plans, standards, competencies, repository of 
evaluations, quality assessments – and how binding are they? 
 \ Are results-monitoring data used to inform the national planning process?
 \ Are results-monitoring data used to inform the budgetary process?
 \ Are results-monitoring data discussed in parliament (or the legislative arm of government)?
 \ Do government documents on policies, programs, and projects contain results frameworks?
 \ Are data on the results of individual policies, programs, and projects collected and reported?
 \ Does the central evaluation unit commission and/or conduct evaluations?
 \ Do decentralized evaluation units commission and/or conduct evaluations?
 \ If there are no specifically designated evaluation units, do other entities commission and/or 
conduct evaluations? 
 \ How many country-led evaluations have been commissioned and implemented by government 
in the past two to three years? 
 \ To what extent are these evaluations perceived to be credible, independent, and impartial? (For 
example, do these evaluations report on challenges or poor results, or do they only highlight 
positive aspects?)
 \ Do evaluations inform the national planning process?
 \ Do evaluations inform the budgeting process?
 \ Are evaluations discussed in parliament (or legislative bodies)?
 \ Is there evidence of changes in programs/strategies/projects due to evaluation findings?
 \ Is there evidence that the evaluations are discussed at higher levels of government (the 
executive arm)?
Possible more 
in-depth 
questions
See optional modules in sections 4 and 5.
<<<PAGE=34>>>
GEI  |  MESA Guidance notes  |  FEB 2022
34
3.5 Role of other 
stakeholders in 
relation to M&E:
Why is this important? There is often a range of other stakeholders who play 
important roles in the M&E ecosystem or are relevant 
for the M&E system. This section explores their roles. 
National statistical 
organization 
(NSO)
This is covered in section 3.6 _
Audit offices Audit often drives behavior. 
It is important to understand 
the audit role and how it 
links to M&E.
 \ What is the role of audit offices? 
 \ Do they undertake performance audits or other functions 
which are close to M&E? 
 \ What is the attitude to audit and how does that affect M&E?
Role of voluntary 
organizations 
for professional 
evaluation 
VOPE(s)
This section provides an 
overview of VOPEs, their 
capacity, and operations. In 
the basic MESA this would 
probably not be detailed, 
but more detail could be 
provided if necessary.
Basic questions:
 \ Is there an evaluation association(s) in the country?
 \ When was the VOPE established, how many members 
does it have, and where do most members come from (for 
example, the public sector, CSOs, academia)?
 \ Is there a selection process for members?
 \ How active is it?
 \ How does the VOPE work with government, civil society, 
and donor organizations in the country to promote 
evaluation and evidence-based policy making?
 \ To what extent does the local VOPE influence M&E activities 
in the country?
In-depth questions:
 \ What are the sources of income for the VOPE?
 \ What are the M&E priorities for the VOPE in the next five 
years?
 \ What are some of the challenges the VOPE is facing and 
how can they be addressed? 
 \ Does the VOPE have an active network of emerging 
evaluators?
Some examples In Uganda, the Uganda Evaluation Association (UEA) is 
registered as a professional association and is guided by a 
formal, documented strategy. The UEA builds capacity of 
evaluators, designs standards to enhance evidence, raises 
awareness of evidence use, and advocates for the use 
of evidence in policy development and implementation. 
However, the UEA’s role is constrained, as the voluntary nature 
of the organization means that contributions are sometimes 
insufficient, thus posing a challenge to its sustainability.24 
24   CLEAR-AA. 2021. “Monitoring and Evaluation Situation Analysis Report for the Republic of Uganda.” Unpublished report. University of the Witwatersrand, Johannesburg, 
2021.
<<<PAGE=35>>>
GEI  |  MESA Guidance notes  |  FEB 2022
35
3.5 Role of other 
stakeholders in 
relation to M&E:
Why is this important? There is often a range of other stakeholders who play 
important roles in the M&E ecosystem or are relevant 
for the M&E system. This section explores their roles. 
Role of NGOs (or 
civil society) in 
the M&E system
This section explores what 
roles NGOs play in the M&E 
system – such as sitting 
on evaluation steering 
committees, or being 
involved in the selection of 
evaluations for evaluation 
plans/agendas. 
Basic questions:
In general terms, what role do other CSOs play (if any) in 
the national M&E system – for example, sitting on steering 
committees, or playing a role in the national coordination 
structure?
In-depth questions:
 \ Do NGOs play an active role in requiring evidence from the 
government about results ex post and about policy choices 
ex ante?
 \ Do CSOs share with government evidence from evaluations 
of programs that have worked, and advocate for scale-ups?
Some examples: In Costa Rica, CSOs sit on the National Evaluation Platform, 
which guides the evaluation system.
In South Africa, CSOs often sit on evaluation steering 
committees on issues in which they have a stake – for 
example, farmers’ associations, or where they can offer 
knowledge or expertise, such as think tanks.
Development 
partners
In many countries, 
development partners 
(multi-lateral, bi-lateral, etc.) 
play an important role in 
M&E systems, funding the 
development of elements of 
the system and/or funding 
evaluations. An enriched 
element would be obtaining 
details of the donor-
funded evaluations being 
undertaken.
Basic questions:
What M&E initiatives are funded by local and international 
development partners in the country – such as training, or the 
development of M&E policies and guidelines? 
Are any development partners funding government-led 
evaluations?
Do any development partners conduct their own evaluations 
using country systems?
In-depth questions:
Over the last three years, what proportion of evaluations have 
been funded by donors? 
What other influence do donors have on M&E activities in the 
country?
Some examples: In Lesotho, UN agencies such as UNICEF, WFP , and the 
UNDP; the European Union (EU); the International Monetary 
Fund (IMF); and the World Bank play key roles in supporting 
development activities and in M&E. The various roles include 
strengthening M&E capacity by providing funds for training 
and, at times, offering training in the sector ministries they 
work with. For instance, the FAO, IFAD, and the World Bank 
finance various programs in the agricultural sector.
<<<PAGE=36>>>
GEI  |  MESA Guidance notes  |  FEB 2022
36
3.5 Role of other 
stakeholders in 
relation to M&E:
Why is this important? There is often a range of other stakeholders who play 
important roles in the M&E ecosystem or are relevant 
for the M&E system. This section explores their roles. 
Development 
partners
(cont.)
They also provide technical assistance, such as the 
development of indicators. In 2019, both UNICEF and UNDP 
provided much-needed financial and technical support in the 
form of consultants to the Government of Lesotho during 
the process for undertaking the Voluntary National Review of 
the United Nations Sustainable Development Goals. UNDP 
supported the Government of Lesotho’s participation at the 
2019 National Evaluation Capacities Conference in Hurghada, 
Egypt.25
Media The media play an 
important role in 
communicating evidence 
through multiple channels. 
They may play a negative 
role, such as in generating 
fake news. Or they could 
play a more positive role 
in reporting accurately on 
evidence emerging from 
M&E, and contributing to 
wider society by holding 
government to account. 
This section also identifies 
any work being undertaken 
to strengthen the capacity 
of the media to use M&E 
evidence. 
Basic questions:
 \ Do the media use M&E evidence?
 \ Are there references in the media to evaluations?
 \ Has any training or support been undertaken to help the 
media use M&E evidence? By whom?
In-depth questions:
 \ How much is the value of scientific evidence recognized 
by the wider public in the country – for example, over 
COVID-19?
 \ How prevalent is “fake news” – for example, covering 
COVID-19?
Some examples: In Mexico, CONEVAL organizes workshops with media 
representatives about the evaluations that are in progress. 
When a special evaluation will be released, there are also 
meetings with journalists, and editorials that explain the results 
and the implications. The media thus make the evaluations 
public and, in general, they are better informed about them.
Political parties In many countries, political 
parties may be very 
dominant, and at times 
dominate government if 
they hold power for long 
periods. In such situations 
it is very important that 
they see the importance 
of M&E evidence. It is thus 
important to understand the 
attitudes to M&E and what 
advocacy work has been 
undertaken in this regard.
Basic questions:
 \ Do political parties lobby for evidence-based policy 
making?
 \ Does the evaluation unit report evaluation findings to 
political parties?
25    “Monitoring and Evaluation Situation Analysis Report for the Kingdom of Lesotho.” Unpublished report. University of the Witwatersrand, Johannesburg, 2021.
<<<PAGE=37>>>
GEI  |  MESA Guidance notes  |  FEB 2022
37
3.6 Statistical and administrative data
Why is this 
important?
Monitoring and evaluation depend on the availability of data. This section explores the availability 
and quality of administrative data from departments’ routine operations, and statistical data – 
such as from the national statistical office (NSO). More layered iterations could explore this in 
more depth: for example, the nature of frontline data collection and how these data are relayed 
upwards. The World Bank reviews the statistical capacity of countries, which involves an exploration 
of the methodology, source data, and periodicity of surveys/reports.26 This can provide much 
of the information required, as well as the websites of the NSOs. However, it does not cover the 
quality of administrative data.
Some examples In Lesotho, the National Strategy for the Development of Statistics 2006–2015 defines the system 
developed for national statistics and the custodian is the Bureau of Statistics (BoS). Key products 
include the 10-yearly census; the intermediate demographic survey; a quarterly continuous 
multipurpose survey (CMS) covering demographics, labor force, consumption and additional 
modules; the household budget survey (HBS), which is being added to the CMS; the labor force 
survey, which used to be every 10 years but which will now be every two years; the agricultural 
census; and the economic census. The BoS defines the poverty line (using the HBS). Reports are 
available to download from the website.27 The BoS is also responsible for the Lesotho Statistical 
Quality Assurance Framework. 
In India, the Ministry of Statistics and Programme Implementation (MOSPI) is the apex institution 
for collecting and disseminating data. In India, MOSPI releases data on the census, sample surveys, 
surveys conducted by state governments, and administrative data. Some of the key surveys it 
releases include the Census of India and the National Sample Survey Organisation’s surveys on 
specific topics. Administrative data collected by state governments are also released by MOSPI.
Useful sources  b The World Bank’s statistical capacity country profiles28 
 b India’s Ministry of Statistics and Programme Implementation (MOSPI)29 
Suggested 
basic questions
 \ Is a population census conducted? How often?
 \ Is there a national statistical system?
 \ Does the government/NSO conduct a demographic census? How often?
 \ Does the government/NSO conduct other household survey (s)?
 \ How accessible are administrative data – are they shared in some way across government?
 \ What is the quality of administrative data (for example, are the data complete, timely, accessible, 
and reliable)? 
 \ Are data disaggregated to track the situation of disadvantaged groups?
Possible more 
in-depth 
questions
 \ Is frontline data collection in electronic or paper format?
 \ If electronic, is this information aggregated and relayed upwards without time lags? 
 \ Do departments/subnational levels conduct any surveys of their own? If so, which?
 \ Explore further the quality of administrative data. For example, are the data complete, timely, 
accessible, and reliable? 
26   World Bank. “Data on Statistical Capacity”. Accessed February 14, 2022. https://datatopics.worldbank.org/statisticalcapacity/ 
27   Bureau of Statistics, Government of Lesotho. Ministry of Development Planning. Accessed February 14, 2022. www.bos.gov.ls 
28   World Bank. “Data on Statistical Capacity”. Accessed February 14, 2022. https://datatopics.worldbank.org/statisticalcapacity/ 
29   Ministry of Statistics and Programme Implementation. Government of India. Accessed February 17, 2022. https://mospi.gov.in/
<<<PAGE=38>>>
GEI  |  MESA Guidance notes  |  FEB 2022
38
3.7 Resources for M&E
Why is this 
important?
This section explores the resources provided for M&E, in terms of budgets for M&E, the size of 
M&E units, and the resources that are specifically allocated for evaluation, or research (research 
and evaluation are often funded from the same source) More in-depth analysis could explore how 
M&E budget needs are determined.
Some examples In South Africa, most national and provincial departments have monitoring and evaluation 
units, although these vary and may be located in different places in the organogram. They have 
corporate roles to play in relation to reporting on annual performance plans, sector reporting, and 
evaluation. For example, in the Department of Basic Education, the unit comprises ten people, four 
of whom have some evaluation specialization. The unit has an annual budget of around $367 000, 
of which $40 000 is for goods and services, including evaluations. Most funding for evaluations 
is from development partners, or the Department of Planning, M&E (DPME).30 The DPME also 
has a specialist evaluation unit, with 15 staff, and a budget of about $1,5 million, of which around 
$800 000 is allocated for eight evaluations per year, to part fund evaluations with national 
departments.
In Mexico, the ministries at the federal level have resources allocated for completing the annual 
evaluation plan determined by CONEVAL and the Ministry of Finance. In addition, these two 
institutions have staff for coordinating, developing, and disseminating evaluations and their 
findings.
Useful sources  b M&E in South Africa31
 b Twende Mbele Ghana scoping report32 
 b Mexican evaluation policy (La Política de Evaluación en México: 10 años del CONEVAL)33 
Suggested 
basic questions
What resources does the government provide for M&E, in terms of budgets for M&E, the size of 
M&E units, and are resources specifically allocated for evaluation, or research?
Possible more 
in-depth 
questions
How are M&E budget needs determined?
3.8 Communication of M&E evidence
Why is this 
important?
If it is to be used, M&E information needs to be communicated. This section explores what 
mechanisms for communication are in place, including the packaging of evidence, and how it 
is shared and made available to the public, to parliament, and to the media. A more in-depth 
analysis could explore knowledge management processes in government.
Some examples In South Africa, the key monitoring reports are made available on departmental websites; these 
include the quarterly reports and the annual reports against the Annual Performance Plan. The 
reports are tabled with parliamentary portfolio committees and are available in parliamentary 
records. Both these documents are used for accountability purposes. Evaluations are available in 
a repository. The communications units in all departments respond to emerging issues and key 
issues highlighted in reports, and they engage the media. The website is very informative and 
notes the publication of any new reports. Government administrative data are not accessible to the 
public.
30   Carol Nuga Deliwe. n.d. Chief Director, Department of Basic Education, Personal communication. 
31   Sean Phillips et al., “A focus on M&E of results: an example from the Presidency, South Africa”, Journal of Development Effectiveness 6, no. 4, (Dec 2014): 392–406. http://
dx.doi.org/10.1080/19439342.2014.966453 
32   Twende Mbele. 2017. Report on a Scoping Visit to Ghana 13-15 June 2017. https://twendembele.org/reports/scoping-visit-to-ghana-13-15-june-2017/ 
33   CONEVAL: La politica de evaluacion en Mexico: 10 anos del CONEVAL. Accessed February 14, 2022. 
https://www.coneval.org.mx/InformesPublicaciones/Documents/CONEVAL_politica_de_evaluacion_10_A.pdf
<<<PAGE=39>>>
GEI  |  MESA Guidance notes  |  FEB 2022
39
3.8 Communication of M&E evidence
(cont.) In Mexico, CONEVAL has a large catalogue of evaluation results and generated evidence. These 
include full reports, two-pager evaluations, databases, infographics, and executive summaries. 
Additionally, a communication strategy has been implemented to reach different users. This 
strategy includes face-to-face meetings, videos, seminars, social media, capacity-building activities 
for media representatives, and courses for congress staff. 
In India, information on M&E activities is publicly available on the websites of state and central 
government ministries/departments. Some departments conduct surveys independently and 
publish the datasets on their websites. For example, the Ministry of Health and Family Welfare 
publishes reports based on the National Family Health Survey conducted every year. In addition to 
this, the Ministry of Statistics and Programme Implementation (MOSPI) releases data from surveys 
and administrative sources at the national and subnational levels.
Useful sources  b Reports and resources on M&E in South Africa34
 b The South African evaluation repository35 
 b About Mexico’s CONEVAL36 
 b About the DMEO in India37 
 b India’s national data archive38
Suggested 
basic questions
 \ Are there formal frameworks for reporting, debating, and discussing monitoring and evaluation 
results at different levels (for example, websites, media workshops)?
 \ To what extent are findings shared with the entire population, and in an easily accessible way (for 
example, policy briefs/accessible reports, practical/implementable solutions)?
 \ What is the percentage of government evaluations that have been made public in the past two 
to three years?
 \ Are there mechanisms to enable ease of access to government data and evidence (for example, 
repositories)?
 \ Does the country report on its contribution to the achievement of the SDGs?
Possible more 
in-depth 
questions
 \ Who is responsible for knowledge management in government departments?
 \ Are there academic journals or other media and forums for evaluation? 
 \ To what extent does M&E information enter public discourse?
 \ Are there mechanisms to enable ease of access to NGO data and evidence (for example, 
repositories)?
34   Department of Basic Education, Republic of South Africa. Annual reports. Accessed February 14, 2022. https://www.education.gov.za/Resources/Reports.aspx 
Department: Basic Education, Republic of South Africa. Accessed February 14, 2022. https://www.education.gov.za/ 
35   DPME (Department of Planning, Monitoring and Evaluation), Republic of South Africa. Evaluations. Accessed February 14. 2022, https://evaluations.dpme.gov.za/evaluations.
aspx 
36   CONEVAL. Accessed February 14, 2022. www.coneval.org.mx 
37   DMEO (Development Monitoring and Evaluation Office), Government of India. DMEO Studies. Accessed February 14, 2022. https://dmeo.gov.in/evaluation/dmeo-evaluation-
studies 
38   Ministry of Statistical and Programme Implementation, Government of India. National Data Bank. Accessed February 14, 2022. https://mospi.gov.in/web/mospi/national-
data-bank-old
<<<PAGE=40>>>
GEI  |  MESA Guidance notes  |  FEB 2022
40
3.9 M&E capacity-development initiatives
Why is this 
important?
It is difficult to develop an M&E system if there is no academic training available in M&E. For 
example, in the Philippines there is no postgraduate course in M&E and this limits the training 
available. This section explores what courses are available, at what level, and what support for 
capacity development is being provided. Enriched questions would explore who is being targeted, 
what M&E components there are in other course (for example, in public administration) and some 
detail on the content of the courses – such as, to what extent evaluation is covered.
Some 
examples
In Costa Rica, there are master's degrees in evaluation in most universities. Among them are 
those offered at the University of Costa Rica, with a demand of around 30 – 40 students per year, 
the Central American Institute of Public Administration, and the Latin American Faculty of Social 
Sciences (FLACSO). Universities have also developed links with other universities in the region, 
most recently with Ecuador, to enhance South-South cooperation in the areas of evaluation.
In Mexico, together with CLEAR LAC, CONEVAL promotes courses around M&E. Additionally, 
CONEVAL has developed an impact evaluation incubator to deliver training and encourage the 
development of impact evaluation among public officers. On each course, around 80 public officers 
attended the incubator.
In Zambia, The University of Zambia (UNZA) offers a one-year postgraduate diploma (PGD) in 
M&E. 
Useful sources  b UNEG Costa Rica case study on NECD39
 b Mexico’s CONEVAL: Incubator of evaluations with impact40 
Suggested 
basic 
questions
 \ Which institutions provide formal degree/postgraduate M&E training and what courses do they 
provide? 
 \ At what level are the trainings pitched (certificate, post-graduate certificate/diploma, master’s, 
doctorate)? 
 \ Which institutions provide short M&E training and what courses do they provide? 
 \ Are there any courses specifically designed for public-sector M&E (for example, an Introduction 
to M&E in the public sector) and by whom? Are they tailored to specific audiences (for example, 
technical staff, mid-level managers, senior managers, politicians)?
 \ Are there M&E capacity-development plans in place? Are processes under way to develop and 
strengthen M&E capacity in government and society more broadly – such as, how to produce, 
manage, and use evidence? 
 \ Has there been any technical assistance, capacity building, or training in M&E currently over 
the past two years for any level of government (national, regional, or local)? Who provided this 
assistance and within what framework or reform process? 
 \ Have M&E competencies been defined for the public sector?
Possible more 
in-depth 
questions
 \ How many people were trained on M&E during this year, and by which institution? 
 \ What is the weighting of courses for both monitoring and evaluation?
 \ Are there M&E modules offered as part of other courses/degrees/qualifications (for example, as 
part of bachelor degrees in sociology or development studies)? 
 \ Are there any other professionalization initiatives?
 \ What difference has the training that has been provided to date made?
39   UNEG. Evaluation Reports. Accessed February 14, 2022. http://www.uneval.org/evaluation/reports 
40   CONEVAL. Incubadora de Evaluaciones de Impacto. Accessed February 14, 2022. https://www.coneval.org.mx/Evaluacion/ESEPS/Paginas/incubadora_impacto.aspx
<<<PAGE=41>>>
GEI  |  MESA Guidance notes  |  FEB 2022
41
3.10 Equity and gender considerations in the PBM&E systems
Why is this 
important?
Poor equity and gender outcomes contribute significantly to poor development outcomes. These 
elements are core SDG goals (SDG 5: Gender Equality, and SDG 10: Reduced Inequalities). This 
section investigates whether the country M&E systems are gender- or equity-informed, and to 
what extent they are specifically included in M&E systems. More in-depth questions would explore 
how far these issues are mainstreamed in M&E systems and how far systems and training are 
taking on board the transformation of M&E to make it fit for purpose in addressing complexity. 
Another element would be if evaluations are specifically targeting these issues.
Some examples An RBM situational analysis for CARICOM revealed that gender was a key issue that required 
attention. As a result, the work plan of phase 1 included the development and application of 
gender-sensitive principles in M&E within the region. A set of gender-equality indicators were 
proposed to monitor them and keep track of what the region does in this area.
In India, NITI Aayog, which is the premier policy think tank of the Government of India, has 
developed an SDG India Index. Through this, it tracks India’s progress towards each of the SDGs. 
To this end, the Development Monitoring and Evaluation Office (DMEO) has published a report 
highlighting where India stood across different SDGs in 2018. It also maintains an SDG India Index 
Dashboard, which collates information and data relevant to specific SDGs and which includes goals 
specifically related to equity, gender, and environmental sustainability. 
Useful sources  b NITI Aayog’s SDG Index41
 b India’s Ministry of Statistics National Data Archive42 
Suggested basic 
questions
 \ Do the legal framework, policy, and/or regulations include specific considerations on gender 
mainstreaming in monitoring and/or evaluation? 
 \ Do the legal framework, policy, and/or regulations include specific considerations with respect to 
mainstreaming equity considerations in monitoring and/or evaluation?
 \ To what extent do monitoring and/or evaluations in government take into account gender and 
inequality issues? Are there formal forums at which these are discussed and taken seriously?
 \ Are there other ways gender, inequality, and equity issues are mainstreamed in M&E systems – 
such as the use of equity criteria in all evaluations?
Possible more in-
depth questions
 \ Is there monitoring by civil society on gender and equity issues? By whom and at what level? 
41   National Portal of India. Accessed February 14, 2022. https://www.niti.gov.in/reports-sdg 
42   Ministry of Statistical and Programme Implementation, Government of India. National Data Bank. Accessed February 14, 2022. https://mospi.gov.in/web/mospi/national-
data-bank-old
<<<PAGE=42>>>
GEI  |  MESA Guidance notes  |  FEB 2022
42
3.11 Climate and environmental sustainability considerations in the PBM&E systems
Why is this 
important?
Climate change is affecting all countries and is a key element of the SDGs, including: SDG 12 
(Responsible Consumption and Production), 13 (Climate Action), 14 (Life below Water), and 15 
(Life on Land). This section investigates whether country M&E systems are accounting for their 
environmental footprint and whether the country has adequate climate change mitigation and 
adaptation M&E frameworks, strategies, and data-collection systems in place. This may include 
whether national and subnational levels are involved and whether data are accumulated across 
sectors, for example. The more in-depth questions will help to explore how far these issues 
are mainstreamed in M&E systems and how far systems and training are taking on board the 
transformation of M&E to be fit for purpose in addressing complexity.
Some examples In Morocco, Regional Networks of Exchanging Environmental Information (RREIEs) were involved 
in the development of the M&E system for each subnational region. Each RREIE is composed 
of representatives from decentralized sectoral services affected by climate change and with 
information that is relevant to M&E of adaptation strategies.
Useful sources  b National biodiversity assessment 2018: the status of South Africa's ecosystems and biodiversity: 
synthesis report43 
 b NITI Aayog’s S-D-G Index44
 b India’s Ministry of Statistics National Data Archive45 
 b GIZ guidebook for developing national adaptation monitoring and evaluation systems46
Suggested basic 
questions
 \ Do the legal framework, regulations, and policies include provisions for mainstreaming climate 
change into M&E? 
 \ Do the legal framework, regulations, and policies include mainstreaming a sustainable 
development perspective in M&E? 
 \ Is there monitoring or evaluation by government on climate change, or issues of environmental 
sustainability (for example, the collapse of species and ecosystems and the depletion of natural 
resources). By whom and at what level? 
 \ Does the country’s PBM&E system track and inform on the environmental footprint? 
 \ What monitoring and what evaluations on climate change and sustainable development are 
happening in government? Are there formal forums at which these are discussed and taken 
seriously? (For example, South Africa has the Presidential Climate Change Commission and the 
Commission for Gender Equality.)
 \ Are there other ways in which these issues are mainstreamed in M&E systems – for example, the 
use of environmental sustainability criteria in all evaluations?
Possible more 
in-depth 
questions
 \ How is climate change-related M&E used and by whom? (For example, Nepal’s Climate Change 
Program Coordination Committee is responsible for coordinating data on climate change M&E 
and it is used to inform new policies and programs.)
 \ Is there monitoring by civil society on climate change, or on issues of environmental 
sustainability, gender, and equity? By whom and at what level? 
43   SANBI. 2019. National Biodiversity Assessment 2018: The status of South Africa’s ecosystems and biodiversity. Synthesis Report. 
https://www.sanbi.org/wp-content/uploads/2019/10/NBA-Report-2019.pdf  
44   National Portal of India. Reports on SDG. accessed February 14, 2022. https://www.niti.gov.in/reports-sdg 
45   Ministry of Statistical and Programme Implementation, Government of India. National Data Bank. Accessed February 14, 2022. https://mospi.gov.in/web/mospi/national-
data-bank-old 
46   Federal Ministry for Economic Cooperation and Development. 2015. Developing national adaptation monitoring and evaluation systems: A guidebook. https://www.
adaptationcommunity.net/download/uploads/giz2015_Developing_national_adaptation_M&E_systems_-_A_guidebook.pdf
<<<PAGE=43>>>
GEI  |  MESA Guidance notes  |  FEB 2022
43
4 - Monitoring and reporting systems
This section explores monitoring and reporting systems in detail, with an emphasis on output- and outcome-
monitoring rather than activity monitoring. Looking at the reporting function is important to understand 
what happens with monitoring data, and the extent to which it is used for decision-making. 
 
4.1 Systems for government monitoring and reporting at the national level
Why is this 
important?
This section explores monitoring and reporting systems at the national level. While this should 
explore formal systems, it should also look at informal systems (for example, how the ruling party 
is engaged), and distinguish systems in theory from what is happening in practice. In some cases, 
the regional dimension may be important, for example in small countries belonging to regional 
economic unions. Where this is the case, this could be included as part of a more in-depth enquiry. 
Some examples In South Africa, there are a number of monitoring systems. Line ministries have their own 
monitoring systems. In terms of central monitoring, each department has to produce a five-yearly 
strategic plan and an annual performance plan (APP). Reports on the APP are produced quarterly, 
and they are sent to the Department of Planning, M&E (DPME) and tabled at portfolio committees 
in parliament. The Auditor General also reviews the reports and comments on them. At the end 
of the year an annual report on the APP is produced. These reports are all for accountability 
purposes and are not learning focused. 
In Jamaica, there are M&E technical groups within each ministry, responsible for gathering, 
validating, and reporting diverse information across the ministry, to incorporate it into their 
planning. Also, all ministries, departments, and agencies (MDAs) produce annual reports to 
document their performance. These are taken into account by the Ministry of Finance for its mid-
term fiscal review on budgeting and planning.
In Cabo Verde, an M&E system platform is currently being implemented, supported by the World 
Bank and the UNDP , which will allow for a better follow-up of programs, projects, and sectoral 
units. The planned periodicity for feeding data is the product (monthly), program (semi-annual), 
and the plan (annual). It is expected that the new system will improve the bases that support the 
M&E process, with a better quality of information produced. 
Useful sources  b M&E in South Africa47
 b Colombia’s national M&E system (SINERGIA)48
 b Jamaican government M&E website49
47   Sean Phillips et al. 2014. “A focus on M&E of results: an example from the Presidency, South Africa”, Journal of Development Effectiveness 6, no. 4, (Dec 2014): 392–406. 
http://dx.doi.org/10.1080/19439342.2014.966453 
48   DNP (Department of National Planning). Synergia. Government of Colombia. Accessed February 16, 2022. https://sinergia.dnp.gov.co/Paginas/Internas/Seguimiento/Que-
es-seguimiento.aspx
49   Office of the Cabinet, Government of Jamaica. Government Performance Management and Evaluation. Accessed February 14, 2022. 
https://cabinet.gov.jm/government-performance-and-monitoring/
<<<PAGE=44>>>
GEI  |  MESA Guidance notes  |  FEB 2022
44
4.1 Systems for government monitoring and reporting at the national level
Suggested 
basic questions
 \ What are the main monitoring systems at the national level and who are the custodians of 
these? 
 \ Is there monitoring and reporting of the national development plan, and other formalized plans? 
 \ What monitoring and reporting systems are in place for outputs, for outcomes, and for budget/
expenditure?
 \ What roles do line ministries play in monitoring?
 \ Are there incentives or sanctions in place to ensure that sectoral ministries and/or subnational 
governments adopt M&E practices in their daily work and report as required?
Possible more 
in-depth 
questions
 \ Are there other systems that are not called PM&E but that in fact are PM&E systems? 
 \ How is information collected on expenditure/inputs/outputs/, intermediate outcomes, and long-
term outcomes and impacts? 
 \ The evolution of these systems could be explored in more depth, as well as the implications for 
where they are headed.
 \ What mechanisms are there for government to share monitoring evidence and engage 
stakeholders (for example, CSOs) on policy and performance matters (such as through platforms 
like workshops or public hearings)? 
 \ What are the main monitoring systems at the regional level and who are the custodians of 
these? 
4.2 Systems for government monitoring and reporting in line ministries and at subnational levels
Why is this 
important?
This section explores monitoring and reporting of subnational levels, as well as deconcentrated 
levels of national government. This is particularly important in federal/semi-federal systems like 
India, Nigeria, and Mexico, where the states have their own governments and their own reporting 
systems. Within devolved units there are often lower levels of devolved local government. 
Some examples In Ghana, there are two main levels of government – national and district. There are also 10 
regions with regional coordinating councils (RCCs) as the regional coordination structures. They 
are administrative levels of government and not governments in their own right. They provide 
guidance to districts in the development of their M&E plans and collate district data, which they 
pass on to the National Development Planning Commission (NDPC) and other stakeholders. 
They review and collate district annual performance reviews (APRs) to produce the regional APR 
and facilitate the evaluation of the district plans and make recommendations for a policy review. 
Decentralized sector departments have offices at the regional level, which provide guidance 
to decentralized departments at the district level, including on how to implement their sector 
M&E plans, collating district data. District assemblies are the local governments. Decentralized 
departments at the district level collect data on sector-specific indicators and report to the district 
planning coordination units (DPCUs) and heads of departments at the regional level. They also 
support the DPCUs in conducting evaluations and participatory M&E exercises. 
Useful sources  b Twende Mbele Ghana scoping report50 
50   Twende Mbele. 2017. Report on a Scoping Visit to Ghana 13-15 June 2017. https://twendembele.org/reports/scoping-visit-to-ghana-13-15-june-2017/
<<<PAGE=45>>>
GEI  |  MESA Guidance notes  |  FEB 2022
45
4.2 Systems for government monitoring and reporting in line ministries and at subnational levels
Suggested 
basic questions
 \ What are the main monitoring systems coordinated by line ministries? 
 \ What are the main monitoring systems at subnational levels and who are the custodians of 
these? 
 \ What monitoring and reporting systems are in place for outcomes and for outputs at these 
levels?
 \ What lower-level monitoring and reporting do line ministries do?
 \ How does this link with local government or state governments?
Possible more 
in-depth 
questions
 \ Is there formalized monitoring and reporting of a subnational development plan and other 
plans? At state or other local government level? 
4.3 Monitoring of government by parliament
Why is this 
important? 
This section explores how the legislative arm carries out oversight of the executive. This may be 
through using the products of government’s monitoring systems, but also their own tools to 
monitor government. For example, some parliaments have research departments, with library 
sections that sometimes generate evidence or collate existing evidence.
Some 
examples
Sri Lanka has a unicameral parliament. It has select committees, sectoral oversight committees, 
ministerial consultative committees, legislative standing committees, and committees for special 
purposes. The select committees are ad-hoc committees appointed from time to time as needed. 
The sectoral oversight committees do all or any of the following: 
• review and study the application, administration, execution, and effectiveness of legislative 
projects and programs addressing subjects within its jurisdiction;
• review and study the organization and operation of departments and Institutions having 
responsibilities for the administration and execution of legislative projects and programs 
addressing subjects within its jurisdiction;
• engage in future research and forecasting on subjects within its jurisdiction.
The Secretary General and their staff function as secretary to all committees established by 
parliament. Staff with functions relevant to M&E include the library, with nine staff and a research 
unit with five staff. Most of what research staff provide is data relating to the operations of 
departments, which is made available to individual MPs or committees. They do not access 
evaluations. A proposal has been developed to bring an evaluation function into the research unit.
In Uganda, parliament has three units – an M&E unit, a research unit, and a budget office. The 
research unit has 36 staff, of whom 30 are allocated to committees. There are 16 sector committees 
and 14 select committees. The M&E unit handles the internal M&E of parliament. There is an M&E 
framework that is used to monitor parliament. There are not evaluators per se but the researchers 
are members of the evaluation association and the International Development Evaluation 
Association (IDEAS). They undertake the analysis of legislation and post-legislative scrutiny, and 
impact assessments related to bills. The team carries out data collection and analysis itself. It 
sometimes uses evaluations produced in government.
<<<PAGE=46>>>
GEI  |  MESA Guidance notes  |  FEB 2022
46
4.3 Monitoring of government by parliament
Useful sources  b African Parliamentary Network on Development Evaluation (APNODE)51
 b Book on African parliaments and evaluation52
 b Report on the use of evidence in African parliaments (VakaYiko, DFID)53 
Suggested 
basic 
questions
 \ How does parliament monitor government performance? 
 \ How is government monitoring information used in parliament? 
Possible more 
in-depth 
questions
 \ How effective is this monitoring?
 \ Do committees feel they can get an in-depth understanding of what the departments are doing 
and how effective it is?
4.4 Capacity in government to undertake monitoring and reporting
Why is this 
important?
This section explores the institutional and individual capacity for monitoring and reporting, and 
any capacity-development plans at different levels of government. At the institutional level, it 
is important to understand what capacity for monitoring there is, including numbers of staff, 
capability of staff, and what systems are in place to support monitoring. At the individual level 
it is important to understand what training people have had, and how familiar they are with 
monitoring approaches like RBM. An enriched module would involve getting more detailed 
information on individual capacity, possibly derived from a survey.
Some 
examples
The following extract from a past diagnostic illustrates a mix of strengths and weaknesses in a 
country: 
M&E arrangements and practice at all levels – national, line ministry, provincial, and district 
– were found to be poor. Sector ministries, provinces, and districts did not have permanent 
M&E units and dedicated M&E staff, except for the central planning ministry, and a few sector 
ministries, such as health and education. The country-level M&E system was not providing 
stakeholders with adequate information for informing critical development processes, such 
as policy making, decision making, planning, budgeting, resource allocation, and advocacy. 
Capacities for M&E were acknowledged as lacking across the system. However, a structure 
responsible for coordinating M&E across government and automating data management 
and information flows was being set up. The government was making other positive changes, 
including the adoption of a national planning and budgeting policy five years prior to the 
diagnostic, and the development of a national performance framework, an M&E plan, an 
M&E management information system, and had recently adopted a national monitoring 
and evaluation policy. There was however no M&E capacity building program in place. 
Development partners were providing support that was considered key to the strengthening 
and institutionalization of M&E practice in the country. 
In the case of Mexico, the Ministry of Finance, together with CONEVAL in Mexico, decided that 
all social programs should have a results framework (Matriz de Indicadores para Resultados) 
(MIR) and they should update it every year. As this was new for programs, a large training process 
started in 2007 and has continued every year since then. CONEVAL received assistance with 
this from Chile through the Latin American and Caribbean Institute for Economic and Social 
Planning (ILPES-ECLAC ). The monitoring capacity increased dramatically in a few years. Today in 
Mexico, talking about MIRs in ministries and states is common.
51   African Development Bank. Independent Development Evaluation (IDEV). African Parliamentarians’ Network on Development Evaluation (APNODE). Accessed February 14, 
2022. https://idev.afdb.org/en/page/related-page/african-parliamentarians-network-development-evaluation-apnode 
52    Linda  Kumalo  et  al.,  eds.  2021.  African  Parliaments  Volume  1:  Evidence  Systems  for  Governance  and  Development.  Stellenbosch:  African  Sun  Media. 
DOI:10.52779/9781991201454
53   African Centre for Parliamentary Affairs. 2018. Evidence in African parliaments. https://www.inasp.info/sites/default/files/2018-04/Evidence%20in%20parliaments.pdf
<<<PAGE=47>>>
GEI  |  MESA Guidance notes  |  FEB 2022
47
4.4 Capacity in government to undertake monitoring and reporting
Useful sources  b World Bank article on institutionalizing monitoring and evaluation systems for improvement54
 b World Bank-sponsored note on devising an appropriate strategy for capacity building of a 
national monitoring and evaluation system, based on selected: African countries55
Suggested 
basic 
questions
 \ Are there skilled personnel in government with the technical capacity for performance 
monitoring (for example, gathering, analyzing, and reporting on the performance of 
government policies and programs)? 
 \ What training have they had?
 \ Overall, is there institutional capacity to undertake meaningful monitoring that feeds back into 
management? At what levels?
 \ Is there a capacity-strengthening plan for monitoring skills in government (for example, training, 
coaching, mentoring, technical assistance/support)?
Possible more 
in-depth 
questions
 \ A special MESA-related module, such as a survey, could collect more detailed information on 
individual capacity. 
4.5 Role of civil society in the government monitoring system
Why is this 
important? 
It is important to understand any specific roles that CSOs play in government monitoring systems 
– for example, in community-based monitoring, or sitting on monitoring structures, such as district 
health committees. These can help to ensure the relevance of the information collected, and 
challenge government when systems are not working appropriately. 
Some examples In South Africa, the Framework for Strengthening Citizen-Government Partnerships for 
Monitoring Frontline Service Delivery, done through the Department of Planning, Monitoring 
and Evaluation (DPME), was approved by the cabinet in August 2013 and a community-based 
monitoring system has been used to get citizen feedback on particular issues or in particular 
areas. There are some specialist think tanks, like the Health Systems Trust, which have played an 
important role in sectoral monitoring.
In Ghana, an NGO, CDD Ghana, was involved in undertaking knowledge-brokering, using 
government monitoring data at local government level, and drawing up a district league table, 
which showcased which district assemblies were performing well or poorly in a range of services. 
This case highlights the effects of strengthened evidence use in assessing sanitation performance 
at the local level: citizens putting pressure on district assemblies for improving performance in 
sanitation; more effective channels for citizen-level engagement with a source of pressure being 
created at district level; civil society using the evidence for their own project planning; and district 
assemblies being motivated to improve performance.
54   Keith Mackay. Institutionalization of monitoring and evaluation systems to improve public sector management (English). Evaluation Capacity Development Working Paper 
series, no. ECD 15 Washington, D.C.: World Bank Group. 
http://documents.worldbank.org/curated/en/715431468325271413/Institutionalization-of-monitoring-and-evaluation-systems-to-improve-public-sector-management 
55   Robert Lahey. 2015. Devising an Appropriate Strategy for Capacity Building of a National Monitoring and Evaluation System: Lessons from Selected African Countries. 2015. 
Note sponsored by the Poverty Global Practice of the World Bank Group. Washington, D.C.: World Bank Group. 
https://openknowledge.worldbank.org/bitstream/handle/10986/22079/Devising0an0ap0ed0African0countries.pdf?sequence=1&isAllowed=y
<<<PAGE=48>>>
GEI  |  MESA Guidance notes  |  FEB 2022
48
4.5 Role of civil society in the government monitoring system
Useful sources  b Citizen-based monitoring56 
 b Uganda Evaluation Association57 
 b Use of monitoring evidence in Ghana’s district league table58 
Suggested 
basic questions
Are there any specific roles that CSOs play in government monitoring systems – such as sitting on 
monitoring structures, or being involved in community-based monitoring? 
Possible more 
in-depth 
questions
What CSOs involved in social accountability and audit mechanisms exist to monitor government? 
4.6 Systems/ incentives for acting on monitoring
Why is this 
important?
Ultimately, the prevailing incentives and sanctions, whether formal or informal, tend to influence 
what actually happens in government. This can be in the form of rewards, such as recognition 
and promotion, or sanctions on the lack of follow-up or strong messaging from leaders about the 
importance of follow-up. 
This section explores whether there is a system for institutionalizing and incentivizing the use 
of monitoring evidence, such as performance dialogues on quarterly reports, or sections in 
performance agreements which explicitly refer to follow-up on problems identified). It also looks 
into whether the systems may provide negative incentives, with negative effects.
Some examples In South Africa, the quarterly reporting by government departments is followed up in some 
cases by performance dialogues. In these dialogues, the Department of Planning, M&E (DPME), 
the National Treasury, and the relevant departments come together to reflect on performance 
monitoring information, budget information, and evaluations, and how performance is going 
and what changes are needed. This provides incentives to follow up on the reports. Similarly, as 
these reports are tabled at parliamentary committees, they come under some scrutiny. This also 
sometimes results in parliamentary questions being asked. 
Useful sources  b For more information on performance culture, read chapter 4 of the book Using Evidence in 
Policy and Practice.59 The chapter covers evidence use by African governments, and explores 
M&E culture in Benin, Uganda, and South Africa. 
Suggested 
basic questions
Is there a system for institutionalizing and incentivizing the use of monitoring evidence (such as 
rewards, sanctions, and messaging from leadership)?
Possible more  
in-depth 
questions
Explore the above in more depth and how this relates to culture.
56   DPME (Department of Planning, Monitoring and Evaluation). Republic of South Africa. Citizen-based Monitoring. Accessed February 14, 2022. https://www.dpme.gov.za/
keyfocusareas/cbmSite/Pages/default.aspx 
57   Uganda Evaluation Association. Accessed February 14, 2022. https://ugandaevaluationassociation.org/web/ugandaevaluationassociation/default.aspx 
58   Ian Goldman et al. 2020. “Mere compliance or learning – M&E culture in the public service of Benin, Uganda and South Africa”, in Using Evidence in Policy and Practice, 
eds. Ian Goldman and Mine Pabari, 54–74. Oxfordshire: Taylor & Francis. https://www.taylorfrancis.com/chapters/oa-edit/10.4324/9781003007043-4/mere-compliance-
learning-culture-public-service-benin-uganda-south-africa-ian-goldman-wole-olaleye-stanley-sixolile-ntakumba-mokgoropo-makgaba-cara-waller?context=ubx&refId=c5130
54a-4cdb-420d-b196-8ed35908fa53 
59   Ibid.
<<<PAGE=49>>>
GEI  |  MESA Guidance notes  |  FEB 2022
49
4.7 Use of monitoring information by government
Why is this 
important?
This section explores whether and how monitoring information is used to inform management 
decision making and any lessons that may emerge. 
Some 
examples
In the Ghana case outlined before, an NGO, CDD Ghana, was involved in undertaking knowledge 
brokering using government monitoring data at local government level and drawing up a district 
league table (DLT) which showcased which district assemblies were performing well or poorly 
in a range of services. The DLT has been successful in contributing to strengthening evidence 
use, particularly at the district level. The capacity strengthening of civil society groups, coupled 
with access to DLT data, strengthened the confidence and capabilities of citizens to engage in 
evidence-based advocacy. This created pressure points on government actors to improve service 
delivery, particularly at the subnational level. 
The ranking of districts using the DLT has created a sense of competition among district officials. 
District assemblies that perform poorly on the DLT are flagged at the national level and peer 
pressure from other districts together with the evidence informed advocacy from civil society act 
as incentives to improve service delivery.
Useful sources  b District league table case: CLEAR-AA policy brief on evidence use for improving sanitation in 
Ghana60
Suggested 
basic 
questions
 \ How does monitoring information within government inform decision making: planning, project 
or program management, budgeting, and performance reporting?
 \ What examples are there of the use of monitoring information in national plans, strategies, and 
government programs? 
 \ How does the government usually respond to negative M&E findings/evidence?
Possible more 
in-depth 
questions
 \ What is the role of each department within the state in making these decisions based on M&E?
60   Dede Bedu-Addo and Mohammed Awal. 2020. All hands in the community bowl: Evidence use for improved sanitation in Ghana. CLEAR-AA Policy Brief. https://wiredspace.
wits.ac.za/bitstream/handle/10539/29177/Evidence%20Use%20for%20Improved%20Sanitation%20in%20Uganda.pdf?sequence=5&isAllowed=y
<<<PAGE=50>>>
GEI  |  MESA Guidance notes  |  FEB 2022
50
5 - Evaluation systems 
This section goes into the country’s evaluation systems in detail. Here, the MESA focuses not only on the 
production and use of single evaluations, but on the status of the evaluation system as a whole.
5.1 Evaluation systems at the national level
Why is this 
important?
Mirroring section 4.1 on monitoring, this section explores evaluation systems and practices at 
the national level. Building on the overview in section 3, this is one of the most important parts 
of the MESA, as it explores the center of the evaluation system and its main components. It will 
be important to look into both formal and informal systems, as well as distinguish systems in 
theory from what is happening in practice. This section focuses on the identification of the main 
stakeholders of the evaluation system within government, their roles and how they interact with each 
other. In some cases, where there are strong regional links, it may be important to highlight practices 
at the regional level, such as CARICOM in the Caribbean. 
Some 
examples
Most of the literature and many evaluation diagnostics provide information on this (CLEAR LAC and 
Deval INCE for Latin America, for example). They identify how governments have built evaluation 
systems. There is a range of useful examples: 
Chile originally developed its evaluation system around the Department of the Budget, within the 
Ministry of Finance. For many years this was the only evaluation unit in the country. However, in 
2011, the Ministry of Social Planning (later the Ministry of Social Development and now the Ministry 
of Social Development and Family) also started evaluation for the social sector. Doing a MESA for 
Chile today involves assessing the evaluation processes in both ministries and their strategies for 
coordinating with each other.
In South Africa, the driving agency in government is the Department of Planning, M&E (DPME), 
housed in the Presidency. A national evaluation policy was adopted by the cabinet in 2011 (and 
revised in 2019). This promotes a utilization-focused approach, with evaluations conducted at 
national, provincial, and ministry/department levels. Since 2012, a national evaluation plan has 
been produced annually, with evaluations conducted as a partnership between the DPME and the 
respective sector department. DPME part-funds the evaluations, and the reports go to the cabinet 
along with a management response and an improvement plan. These are large evaluations, a mix 
of diagnostic, implementation, and impact evaluations. Seventy-three evaluations have begun, 
covering projects and programs to the value of around US$10 billion of government expenditure. 
By 2021, 50 evaluations had been completed and closed61. Twenty-seven guidelines/templates have 
been produced, which are available publicly, along with a repository of evaluations, standards, and 
required competencies.
This section can also identify changes in evaluation tools and the reasons for those changes. 
In the USA, during the G. W. Bush administration, a useful evaluation tool called the Program 
Assessment Rating Tool (PART) assessed public programs based on direct answers covering the life 
cycle of programs. This tool was terminated during the Obama administration. Exploring the reasons 
for this change could shed light on the M&E systems, goals, and challenges.
In Mexico, the M&E guidelines launched by CONEVAL and the Ministry of Finance in 2007 have 
been shaping the M&E system ever since. These guidelines specify the way several elements should 
be addressed: the annual evaluation plan, types of evaluations, the need to make all evaluations 
public, programs’ log frameworks, the periodicity to assess results indicators, and the mechanism to 
follow up on evaluations’ recommendations. 
61   DPME (Department of Planning, Monitoring and Evaluation). Republic of south Africa. Evaluation Update. https://www.dpme.gov.za/publications/Reports%20and%20Other%20
Information%20Products/EVALUATION_UPDATE_April-Sept%202021_Latest.pdf
<<<PAGE=51>>>
GEI  |  MESA Guidance notes  |  FEB 2022
51
5.1 Evaluation systems at the national level
In Uganda, the National Integrated Monitoring and Evaluation Strategy (NIMES, 2006) has been 
managed through sector working groups: the National Monitoring and Oversight (NM&O) Working 
Group and the Evaluation Sub-Committee (ESC). It is through the NIMES and the sector working 
groups that Uganda established its national evaluation system.
In Uganda, in its work on developing evaluation agendas, the Office of the Prime Minister partnered 
with Twende Mbele62 in 2020 and 2021, working through CLEAR-AA, and collaborated with health-
sector CSOs to develop the Health Sector Evaluation Agenda, which is aligned to the National 
Development Plan III (2021/21–2024/25).
Useful 
sources
 b CLEAR LAC and Deval’s INCE are important readings to show assessment of different evaluation 
systems in Latin America.63 This guidance suggests using questions from the Deval/WFP INCE to 
assess section 5 of THE MESA.
 b Progress in the South African system64 
 b The DPME website65 
 b The M&E Guidelines for Mexico, issued in 200766 
Suggested 
basic 
questions
 \ Who are the custodians of the evaluation system at regional/national level?
 \ What is the extent of the coverage of the evaluation custodian or evaluation unit across 
government?
 \ Is evaluation of the national development plan, ministries’ plans and other plans formalized/
institutionalized?
 \ How are line ministries involved in evaluation?
 \ What roles do they play regarding evaluation?
 \ How effective are public entities in managing evaluations?
 \ Is there a demand from line ministries for external evaluations? 
 \ Which type of interventions/programs/sectors are evaluated by the system?
 \ How are evaluations funded? 
 \ What type of evaluations are typically conducted (for example, design, implementation, outcome, 
and impact)?
 \ How are the credibility, independence, and impartiality of evaluations fostered?? 
 \ Are there mechanisms in place to ensure quality?
 \ What is the quality and technical rigor of the evaluations performed?
 \ Do countries have methodologies/guidance to define recommendations? 
 \ What mechanisms are there for government to share evaluation evidence and engage 
stakeholders on policy and performance matters (such as through platforms like workshops or 
public hearings)? 
62   Twende Mbele. A knowledge sharing platform to improve M&E in Africa. Accessed February 14, 2022. https://twendembele.org 
63   Gabriela Perez-Yarahuan and Glaudia Maldonado, eds. National Monitoring and Evaluation Systems. Experiences from Latin America. CLEAR-LAC, 2020. 
https://clear-lac.org/3d-flip-book/national-monitoring-and-evaluation-systems/ 
64   Ian Goldman et al., “The emergence of government evaluation systems in Africa: The case of Benin, Uganda and South Africa”, African Evaluation Journal, 6 no. 1, (March 
2018): 253. https://doi.org/10.4102/aej.v6i1.253 
65   DPME (Department of Planning, Monitoring and Evaluation), Republic of South Africa. Evaluations. Accessed February 14, 2022.
https://www.dpme.gov.za/keyfocusareas/evaluationsSite/Pages/default.aspx 
66   CONEVAL. Evaluación De La Política Social. Accessed February 14, 2022. https://www.coneval.org.mx/Evaluacion/NME/Paginas/LineamientosGenerales.aspx
<<<PAGE=52>>>
GEI  |  MESA Guidance notes  |  FEB 2022
52
5.1 Evaluation systems at the national level
Possible more 
in-depth 
questions
 \ Is there a willingness to overcome current negative perceptions about evaluation in the public and 
nongovernmental sectors?
 \ Does a classification of program performance exist?
 \ What is the quality of the ToR for conducting evaluations?
 \ What is the degree of impartiality in evaluation processes?
 \ If so desired, the systems at regional level (for example, CARICOM) can be explored. The questions 
for the national level can be used here. 
 \ How many country-led evaluations commissioned or implemented by government started in the 
past two to three years? 
5.2 Evaluation systems at line ministry and subnational levels
Why is this 
important?
In this section, it is important to assess the main elements of evaluation systems in states, 
municipalities, and the subnational level, if they exist. To learn fully about the evaluation system 
in a country, it is important to understand the existence and status of the evaluation systems at 
the levels of line ministries and subnational levels, which could include subnational governments. 
This is crucial If countries have a federal system. Ideally, similar questions to those asked at the 
national level should be asked. An additional element is to assess the level of coordination around 
evaluation between the central and local levels.
Some 
examples
It is not possible to understand the evaluation system in India or in Mexico without learning what 
type of evaluation systems have been set up at the state level. 
In India, Karnataka and Odisha are two states with well-established evaluation systems. 
In Mexico, Mexico City, the State of Mexico, and Oaxaca have well-structured evaluation systems, 
while the systems in other states are not yet as well developed. 
In South Africa, eight of the nine provinces have had provincial evaluation plans and have 
implemented some evaluations. Limpopo and Western Cape are examples of provinces that 
have taken evaluation seriously. Western Cape has implemented a very structured process and 
conducted over 50 provincial evaluations. These evaluations are outsourced and conducted 
by consultants or universities. Both Limpopo and Western Cape have tested models of rapid 
evaluations, conducted by government staff, as mechanisms to reduce both the costs and time 
involved in completing evaluations.
In Brazil, state governments rely on public research institutes that conduct evaluations and which 
are staffed by civil servants, such as the João Pinheiro Foundation in Minas Gerais. These institutes 
establish relationships with local universities to support the development of evaluations.
Useful sources  b The State Evaluation Assessment undertaken by CONEVAL in Mexico assesses evaluation 
practices and norms at the state level67 
 b This article reviews the provincial evaluation system in the Western Cape, South Africa68
67   CONEVAL. Diagnóstico Del Avance En Monitoreo Y Evaluación De Las Entidades Federativas. Accessed February 14, 2022. https://www.coneval.org.mx/coordinacion/entidades/
Paginas/Indice_diagnosticos_temp.aspx 
68   Zeenat Ishmail and Victoria L. Tully, “An overview of the provincial evaluation system of the Western Cape Government of South Africa as a response to the evaluation of the 
National Evaluation System”, African Evaluation Journal 8, no. 1, (April 2020): 425. https://doi.org/10.4102/aej.v8i1.425
<<<PAGE=53>>>
GEI  |  MESA Guidance notes  |  FEB 2022
53
5.2 Evaluation systems at line ministry and subnational levels
Suggested 
basic 
questions
 \ In this section, it will be important to include similar questions as the ones asked for the national 
level, including additional questions about the coordination between the central government 
and local government:
 \ Who are the custodians of the evaluation system within line ministries?
 \ Who are the custodians of the evaluation system at the state/district/municipality level?
 \ What is the extent of the coverage of the subnational evaluation custodian or evaluation unit in 
the state/local government?
 \ Are the evaluation of the state/district/municipality development plans, or of ministry/sectoral 
plans, and/or other plans formalized or institutionalized?
 \ How are subnational line ministries involved in evaluation?
 \ How effective are subnational entities in managing evaluations?
 \ What type of interventions/programs/sectors are evaluated at subnational level?
 \ How are evaluations funded? 
 \ What type of evaluations are mainly conducted at the subnational level?
 \ How are credibility, independence, and impartiality encouraged in conducting evaluations? 
 \ What is the quality and technical rigor of the evaluations performed?
 \ Are there mechanisms to ensure quality?
 \ Does the subnational level have methodologies/guidance to define recommendations? 
 \ What mechanisms are there for the subnational government to share evaluation evidence 
and engage stakeholders on policy and performance matters (such as through platforms like 
workshops or public hearings)?
 \ Are there formal and informal mechanisms for coordinating the subnational evaluation system 
with the central government system?
 \ Does subnational government produce evaluations together with the central government?
Possible more 
in-depth 
questions
 \ Does a classification of program performance exist?
 \ What is the quality of the ToR for conducting evaluations?
 \ What is the degree of impartiality in evaluation processes?
5.3 Government capacity to manage, commission, and undertake evaluations
Why is this 
important?
This section focuses on the government’s capacity to directly manage evaluations, commission 
them, and potentially also conduct evaluations using internal staff. (Section 5.4 looks at the 
capacity to manage a running evaluation system.) It is very important to determine if the 
government is an efficient enabler of evaluations in the country at the technical level, and to 
identify its main partners. The capacities can be both institutional and individual. Often a limitation 
is the lack of technical skills in government to both produce and manage evaluations. Developing 
capacity around these elements will be an important part of a capacity development plan for the 
evaluation system as a whole.
<<<PAGE=54>>>
GEI  |  MESA Guidance notes  |  FEB 2022
54
5.3 Government capacity to manage, commission, and undertake evaluations
Some examples When Costa Rica started to implement its evaluation system in a significant way, it started with 
only 15 evaluations, in the period 2015–18. Its current plan is to conduct 60 evaluations. Some 
of these evaluations are to be undertaken externally, particularly in 2020-21, with government 
budgets under strain due to the COVID pandemic.
In Mexico, at the subnational level, when the state government of Oaxaca started to demonstrate 
interest in evaluation, CONEVAL’s assessment was that evaluation skills were relatively weak. 
Through capacity-building strategies, where both the Ministry of Finance and CONEVAL partnered 
with the state, it was able to improve its evaluation capacities within five years. The same 
happened with the State of Yucatán.
Useful sources  b Mexico states’ M&E Index, CONEVAL69 
 b For evaluation capacity and systems in Benin, Uganda, and South Africa70 
Suggested 
basic questions
 \ Are there skilled personnel71 in government with the technical capacity for undertaking or 
managing evaluations? 
 \ What is government's capacity to commission evaluations (for example, managing and 
sponsoring one or more evaluations)?
 \ What is government's capacity to conduct evaluations itself, either centrally or in ministries? 
 \ Is there a capacity strengthening plan for evaluation skills in government (for example, training, 
coaching, mentoring, technical assistance/support)? 
5.4 Government capacity to manage and coordinate an evaluation system
Why is this 
important? 
It is possible that governments are able to produce single evaluations. However, being able to 
coordinate an entire evaluation system requires not only technical abilities but institutional and 
political abilities and systems too. Because running an evaluation system involves systems and not 
just individual evaluations, learning about this is crucial for each country, whether at the national 
or subnational level. This section is linked to sections 3.1–3.4 for monitoring, where regulations and 
formal institutional arrangements are explored. In this section, the focus is on the realities of the 
institutional settings for running an NES in greater depth.
Some examples South Africa has developed significant capacity in the Department of Planning, M&E (DPME) to 
oversee the evaluation system. This has enabled many elements of the evaluation system to be 
developed: around eight significant national evaluations conducted per year, and the development 
of capacity across the whole of government. These evaluations were co-funded by DPME and the 
relevant sector department. 
National departments have M&E units, and in some cases, these have significant evaluation 
capacity, while in some departments there are no people with evaluation expertise. Central offices 
in each province also have some capacity, with some having dedicated evaluation capacity, 
such as Western Cape, with four staff members. The tightening of the fiscal situation since the 
mid-2010s and especially the prevailing context of COVID-19, have put considerable strain on 
evaluation budgets, which has actually stimulated an interest in the use of rapid evaluations that 
are conducted internally.
69    CONEVAL.  Publicaciones  Sobre  La  Colaboración  Con  Entidades  Federativas.  Accessed  February  14,  2022.  https://www.coneval.org.mx/InformesPublicaciones/
InformesPublicaciones/Paginas/Colaboracion-con-Entidades-Federativas.aspx 
70   Ian Goldman et al., “The emergence of government evaluation systems in Africa: The case of Benin, Uganda and South Africa”, African Evaluation Journal, 6 no. 1, (March 
2018): 253. https://doi.org/10.4102/aej.v6i1.253 
71   Define “skilled” before asking, for example, post-graduate qualification in M&E, experience of undertaking evaluations, and so on.
<<<PAGE=55>>>
GEI  |  MESA Guidance notes  |  FEB 2022
55
5.4 Government capacity to manage and coordinate an evaluation system
Useful sources  b For capacity and systems in Benin, Uganda, and South Africa72
Suggested 
basic questions
 \ How able is government to manage and run an evaluation system (in relation to knowledge, 
skills, human and financial resources)? 
 \ How many evaluations have been conducted and with what coverage?
 \ What capacity is invested in the entity running evaluations and in developing the systems, such 
as plans, frameworks, standards and training?
 \ How effective is coordination among stakeholders in building an ecosystem across government, 
including with nongovernmental stakeholders? 
 \ Is government able to plan and implement a national evaluation agenda/plan?
 \ What is the involvement of a range of government institutions and non-governmental 
stakeholders to agree on and monitor the evaluation agenda?
 \ What is the involvement of a range of government institutions and non-governmental 
stakeholders in dialogue around the system?
5.5 Capacity to undertake evaluations in civil society/academia/ the private sector
Why is this 
important?
In most cases, government does not undertake evaluations itself – it commissions third parties. 
To do this there needs to be sufficiently capacity in civil society, academia, and the private 
sector to undertake high-quality evaluations. These skills could have been built because these 
organizations are undertaking evaluations for development partners, for CSOs, or from experience 
in undertaking evaluations for government. In addition, the country is better off in terms of M&E if 
civil society produces evaluations even if the evaluations are not commissioned by government. It 
is important to understand the capacity that exists, so that if evaluation systems scale up there is 
the capacity to undertake the expansion in demand.
Some 
examples
The Twende Mbele Project73 has funded studies to look at the supply of evaluators and demand 
for evaluations in Benin, South Africa, and Uganda. 
In South Africa, many professional service providers do not employ permanent evaluation staff – 
rather, they form evaluation-specific associations with individuals with the required qualifications, 
expertise, and experience. There is therefore a pool of people, some evaluation specialists and 
some sector specialists, that can be drawn on by evaluation consultancies. Many of them work 
for a range of different evaluation consultancies. Their interest in carrying out evaluations often 
depends on factors such as who the client is, the track record of the client in terms of the way 
in which it manages evaluations, the quality of the ToR, and whether the budget is realistic. 
Nevertheless, it is possible to conclude that to date, supply has generally been adequate to meet 
demand, apart for some exceptions for highly specialized evaluations. A lag and increase in 
demand and in supply should be expected, due to the time required for capacity building. 
A study on impact evaluation skills in Sub-Saharan Africa found that some countries (notably 
South Africa, Kenya, and Uganda) have a strong supply of impact evaluation specialists, although 
this is concentrated in a few sectors, mostly health. 
72   Ian Goldman et al., “The emergence of government evaluation systems in Africa: The case of Benin, Uganda and South Africa”, African Evaluation Journal, 6 no. 1, (March 
2018): 253. https://doi.org/10.4102/aej.v6i1.253 
73   Twende Mbele. A catalyst for Knowledge Sharing. Accessed February 14, 2022. https://twendembele.org
<<<PAGE=56>>>
GEI  |  MESA Guidance notes  |  FEB 2022
56
5.5 Capacity to undertake evaluations in civil society/academia/ the private sector
(cont.) In Mexico, various CSOs have started doing evaluations themselves. This contributes to 
intensifying accountability and pressure on government to perform. Furthermore, there have been 
seminars and workshops where evaluations commissioned by CONEVAL coincide with evaluations 
done by CSOs.
In the north-east region of Brazil, there are several universities that have been conducting 
evaluations of public policies: Federal Universities of Ceará (UFC), Bahia (UFBA), Pernambuco 
(UFPE) and Paraíba (UFPB). Within these academic institutions, research centers and labs have also 
been created to conduct evaluations: 
• M&E Study Lab (LEMA), at UFPB
• Public and Economic Policy Evaluation Group (GAPPE), at UFPE
• Results-based Management Center (CGPR), at UFC
In addition, UFC has recently created and is offering the Professional Master’s Program in Public 
Policy Evaluation (MAPP).
Useful sources  b CLEAR-AA study on the state of monitoring and evaluation in Anglophone Africa74 
 b Comparative study on the institutionalization of evaluation in Europe and Latin America75
 b Scoping the impact evaluation capacity in sub-Saharan Africa76 
 b Examples of CSOs in Mexico doing evaluations77 
Suggested 
basic 
questions
 \ Who are the local providers of evaluation services (for example, consulting firms, auditors, 
independent consultants, academia)? 
 \ To what extent are evaluations commissioned by government, donors, and CSOs conducted by 
local evaluators? 
 \ Is there a sufficient supply of quality local evaluators? 
 \ Are the country's universities producing evaluations on a systematic basis? 
Possible more 
in-depth 
questions
 \ How many evaluations have been produced by non-governmental institutions every year?
 \ What types of evaluations are done by non-governmental institutions?
5.6 Systems/ incentives for ensuring that evaluation is acted upon
Why is this 
important?
The prevailing incentives (explicit or tacit) are key elements of the country’s evaluation system. 
It is important to understand how evaluation findings are used, and whether this is systematic. 
This will guide some of these elements needed in follow-up work to strengthen the system. Even 
where evaluations are completed, there may be a limited capacity to make use of the findings 
of the evaluation. According to Goldman and Pabari (2020), the use of evidence is particularly 
encouraged when policy makers have the motivation, capability, and the opportunity to use 
it. Evidence use may be encouraged by the existence of specific internal systems, for example, 
improvement plans, which require government to plan for improvements as a result of the 
evaluation. The improvement plan is an example of providing opportunities to use the evidence, 
and possibly motivation, if there are consequences for not following up. It is also possible that the 
system is not mature enough to overcome negative incentives arising from the challenges found 
during the evaluation process. 
74   Dugan I. Fraser and Candice Morkel. 2020. “State of monitoring and evaluation in Anglophone Africa: Centre for Learning on Evaluation and Results in Anglophone Africa’s 
reflections”, African Evaluation Journal 8, no. 1, (Nov 2020): 505. https://aejonline.org/index.php/aej/article/view/505/936 
75   Blanca Lázaro. 2015. “Comparative study on the institutionalisation of evaluation in Europe and Latin America”, Study n. 15 Series: State of the Art Area: Public Finance, 
EUROsociAL Programme (July 2015). http://sia.eurosocial-ii.eu/files/docs/1456851768-E_15_ENfin.pdf 
76   Ibid. 
77   Mexico Evalua. Accessed February 14, 2022. https://www.mexicoevalua.org/ 
Animal Politico. Accessed February 14, 2022, https://www.animalpolitico.com/ 
Mexicanos Contra la Corrupcion y la Impunidad. Accessed February 14, 2022. https://contralacorrupcion.mx/
<<<PAGE=57>>>
GEI  |  MESA Guidance notes  |  FEB 2022
57
5.6 Systems/ incentives for ensuring that evaluation is acted upon
Some 
examples
Both in South Africa and in Mexico, there are annual evaluation awards, where the central 
evaluation units hold a public event to award government officials in various M&E categories. 
One is about the proper use of evaluation findings. In this way, the M&E systems seek to include 
positive incentives to use the evaluation findings, trying to offset the potential negative ones. 
Similarly, countries have systems of improvement plans to institutionalize the application of the 
findings.
In Brazil, the newly launched Evidence-based Policy-making Award (Prêmio Evidência) is a 
joint initiative between FGV EESP CLEAR LAB, the National School of Public Administration, and 
the Institute of Social Mobility. The award generates significant visibility of public policies that 
showcase the use of evidence at different stages of implementation.
The award will feature municipal-, state-, and national-level public programs that have 
demonstrated, through the use of evidence, the promotion of social mobility and the reduction of 
inequality in Brazil. This initiative intends to recognize and showcase public policies that make use 
of evidence in its multiple stages, as well as to foster collaboration between scientific research and 
public policy management. 
Useful sources  b The impact of impact evaluation78
Suggested 
basic 
questions
 \ Are there mechanisms for institutionalizing and incentivizing the use of evaluation evidence 
(for example, evaluation steering committees to institutionalize ownership of evaluations, or 
improvement plans or management responses following evaluation)?
 \ Is there a management response/improvement plan-type process to respond to evaluation 
findings and recommendations? 
 \ How is the implementation of such an improvement plan monitored?
 \ Describe how the government usually responds to negative M&E findings/evidence?
 \ When there is poor performance in an area or in a program/policy, what is the process to ensure 
adjustments and improvements happen? 
 \ What is the link between evaluation results and program/policy budget allocations?
Possible more 
in-depth 
questions
 \ What is the greatest fear that program managers have around the implementation challenges 
arising from evaluations?
 \ Do program managers participate in the generation of recommendations as part of the 
evaluation process? 
78   Richard Manning, Ian Goldman, and Gonzalo Hernández Licona, “The impact of impact evaluation: Are impact evaluation and impact evaluation synthesis contributing to 
evidence generation and use in low- and middle- income countries?”, WIDER Working Paper 2020/20, (March 2020). https://www.wider.unu.edu/sites/default/files/Publications/
Working-paper/PDF/wp2020-20.pdf
<<<PAGE=58>>>
GEI  |  MESA Guidance notes  |  FEB 2022
58
5.7 Use of evaluations by government
Why is this 
important?
In this section, the MESA should find concrete examples of how evaluation findings have 
been used in public policy by government. Together with section 5.6, this is one of the most 
important sections of the MESA. If the information coming from the evaluation systems is used 
by government to learn about how to improve public policy, then the evaluation system makes 
sense. This important phase of the evaluation cycle has never been easy. While section 5.6 shows 
the potential problems, this section aims to find concrete examples of the use of evaluations by 
government. Sometimes the government uses the findings of one evaluation, and sometimes 
there are systems that make stakeholders use the evaluation findings every year. Finding positive 
examples is important in building the case for an evaluation system, and the cost benefits of the 
system. In many countries, the use of evaluation evidence requires the changes to be embedded 
not just in changes of policies but in the standard operating procedures of programs and services.
Some examples Fortunately, there are many examples of evaluations being used by governments in different 
countries. 
The Philippine government was able to use the findings of at least three impact evaluations: the 
Pantawid Pamilyang Pilipino Conditional Cash transfer, the Kalahi-CIDSS79, and the Special Program 
for the Employment of Students. The government was able to make changes in the three programs 
due to the evaluation findings.
In Benin, the evaluation of agricultural policy in 2010 contributed to significant changes in 
agricultural policy, including to the significant expansion of cotton production in the country.80
In Mexico, part of the evaluation process is a mechanism for tracking evaluation findings 
(Mecanismo de seguimiento de aspectos susceptibles de mejora). After the evaluation is finished, 
the program/ministry agrees to address certain findings and they write down their commitment in 
an Improvement plan, which is made public. CONEVAL tracks these improvements. In this way, it is 
possible to measure improvements made in public policy based on the evaluation findings.
Useful sources  b Book on using evidence in policy and practice, with lessons from Africa.81 This includes a series of 
case studies of using evaluation evidence, including the Benin example above.
 b The impact of impact evaluation82
 b Mexico’s mechanism for tracking evaluation findings83 
Suggested 
basic questions
 \ What examples are there of evidence from government evaluations informing government 
decision making: planning (including of national development plan), policies, project or program 
management, budgeting and performance reporting?
 \ Does government draw on M&E evidence from stakeholders (for example, NGOs, think tanks, 
development partners) to inform government planning, policy, and decision making, and if so, 
how?
79   Known as the Kapit-Bisig Laban sa Kahirapan-Comprehensive and Integrated Delivery of Social Services. 
80   Bonaventure Kouakanou et al., “The potential and the challenges of evaluations to positively influence reforms: Working with producers in the Benin agricultural sector”, 
Using Evidence in Policy and Practice, eds. Ian Goldman, Mine Pabari (Oxfordshire: Taylor & Francis, 2020), 152–168. 
https://www.taylorfrancis.com/chapters/oa-edit/10.4324/9781003007043-9/potential-challenges-evaluations-positively-influence-reforms-bonaventure-kouakanou-dossa-
aguemon-marius-aina-abdoulaye-gounou-emmanuel-david-gnahoui?context=ubx&refId=da33ea01-bb97-4414-90a7-d399b6d3e23a 
81   Using Evidence in Policy and Practice, eds. Ian Goldman and Mine Pabari (Oxfordshire: Taylor & Francis, 2020). 
https://www.taylorfrancis.com/books/oa-edit/10.4324/9781003007043/using-evidence-policy-practice-ian-goldman-mine-pabari 
82   Richard Manning, Ian Goldman, and Gonzalo Hernández Licona, “The impact of impact evaluation: Are impact evaluation and impact evaluation synthesis contributing to 
evidence generation and use in low- and middle- income countries?”, WIDER Working Paper 2020/20, (March 2020). https://www.wider.unu.edu/sites/default/files/Publications/
Working-paper/PDF/wp2020-20.pdf 
83   CONEVAL. Informe De Seguimiento A Los Aspectos Susceptibles De Mejora De Los Programas Y Acciones Federales De Desarrollo Social 2020-2021. Accessed February 
14, 2022. https://www.coneval.org.mx/Evaluacion/CMPE/Paginas/Informe-de-seguimiento-asm-2020-2021.aspx
<<<PAGE=59>>>
GEI  |  MESA Guidance notes  |  FEB 2022
59
5.7 Use of evaluations by government
Possible more 
in-depth 
questions
 \ What lessons are there from why evaluation evidence was used in these cases?
 \ Does the use of evaluation findings change according to the government cycle?
 \ Is there any evidence of evaluation findings being used in voluntary national reviews and in the 
follow-up to the national SDG agenda?
5.8 Use of evaluations by parliament
Why is this 
important? 
Ideally, evaluation findings should be used by many stakeholders. An important potential user is 
parliament. Parliaments are part of the center of government, making important decisions, such 
as on issues like the budget and legislation. If the M&E system works properly, parliaments should 
use evaluations produced by governments. At the same time, parliamentary research staff can 
produce their own evaluative studies, or draw from performance audits. In a number countries, 
evaluation findings are sent to the legislative arm of government, such as parliament or the 
congress. It is not clear, however, that these findings are actually used by them for key decisions. 
In this section, the MESA should find concrete examples of how the evaluation findings have been 
used by parliament, and how parliamentary committees could use evaluative evidence.
Some 
examples
In South Africa, government evaluations are tabled in parliament once they have been to cabinet. 
In one case, parliament specifically requested an evaluation to be undertaken, which was done. 
Thus, evaluations are considered, although it is not clear to what extent they influence decision-
making. 
In several countries, parliaments are very interested in accessing evaluations and so are tabling 
bills to apply the evaluation system in legislation. These include Philippines, Sri Lanka, and Benin.
Useful 
sources? 
 b Book on African parliaments and evaluations, first volume84 
(Forthcoming, second volume on institutions and practice)
Suggested 
basic 
questions
 \ Do parliamentary portfolio committees consider government or non-governmental evaluations 
in their oversight and legislative work?
 \ Do parliamentary portfolio committees commission evaluative studies from their parliamentary 
researchers?
 \ Does parliament draw on evidence from non-governmental stakeholders (for example, NGOs, 
think tanks, development partners) to inform their work?
 \ What are the key challenges affecting the use of evaluative evidence in parliament?
Possible more 
in-depth 
questions
 \ Are there sufficient capacities within parliament (for example, parliament M&E/research units and 
portfolio committees) to draw on and utilize M&E evidence?
 \ Are there sufficient capacities within parliament (for example, parliament M&E/research units) to 
undertake evaluative studies, including synthesizing from existing evaluations?
84    Linda  Kumalo  et  al.,  eds.  2021.  African  Parliaments  Volume  1:  Evidence  Systems  for  Governance  and  Development.  Stellenbosch:  African  Sun  Media. 
DOI:10.52779/9781991201454
<<<PAGE=60>>>
GEI  |  MESA Guidance notes  |  FEB 2022
60
5.9 Use of evaluations by civil society and the media
Why is this 
important?
If evaluations are part of the democratic process of countries, then the role of civil society is 
important – not only to use the evaluations produced by government, but also to promote, 
commission, and produce evaluations. Civil society and the media are important stakeholders for 
demanding the production and use of evaluations for public policy and accountability purposes. 
An active civil society is part of the enabling environment that promotes and demands the 
production and use of evaluations. 
In this section, the MESA should determine the extent to which civil society (such as CSOs, 
schools and universities) and the media access and use the evaluations produced by various 
stakeholders, especially the government. They may also use their own evaluations for advocacy 
with government, and thus exert significant influence on the government. 
Some 
examples
When evaluations can be accessed in public repositories or on websites they can be used by the 
wider public as part of their advocacy work. 
In Bangladesh, a large nutrition program was being planned with World Bank support, based on 
an apparently successful program which had resulted in greatly lowered levels of malnutrition. 
However, this being attributed to the World Bank-funded program was challenged by an 
evaluation conducted by Oxfam. Instead, it was found that the lowered malnutrition levels were 
common to areas outside the program, and in fact the main factor was the drop in the price of 
rice.85 
In Mexico, the media have been an important part of the enabling environment for the M&E 
system, especially since 2000. Evaluation findings are clearly of potential interest to the media. In 
an open democracy (the case in Mexico since 1997) the media use evaluations to show potential 
challenges in the government’s public policy. A recognition of the importance of the media by 
high-ranked officials has contributed to shaping the Mexican M&E system. For example, before 
evaluations are launched, CONEVAL runs workshops with the media, explaining the contents of the 
evaluations. The media have also helped to highlight challenges in programs and thus have helped 
to improve them on some occasions. Using the power of the media to enhance the M&E system is 
always important in democratic countries.
Suggested 
basic 
questions
 \ Is there evidence from civil society demanding evaluations of government programs (pressuring 
government to do evaluations, or to be able to access evaluations)?
 \ Are there examples of NGOs using government evaluations to put pressure on government 
about results ex post and about policy choices ex ante?
 \ How often does the media shows information coming from the evaluation system?
 \ Are results of government evaluations commonly used in public discourse and in the media?
Possible more 
in-depth 
questions
 \ Is there evidence of CSOs sharing with government evidence from their evaluations of programs, 
and advocating for changes/scale-ups?
85   Howard White and Edoardo Masset. "Assessing interventions to improve child nutrition: a theory-based impact evaluation of the Bangladesh Integrated Nutrition 
Project," Journal of International Development, 19, no. 5, (2007): 627–652, DOI:10.1002/jid.1344
<<<PAGE=61>>>
GEI  |  MESA Guidance notes  |  FEB 2022
61
5.10 Role of civil society in government evaluation systems
Why is this 
important?
Government can be very inward looking, sometimes suspicious of civil society and seeing it as 
potentially undermining the state. Civil society has the potential to represent beneficiaries of 
government policies and programs, as implementors of some services. It also includes advocacy 
organizations that work on human rights and the environment, for example, often representing 
disadvantaged groups and communities. These organizations can thus present important 
perspectives on whether programs and policies are working or not. They can also present 
important perspectives if they participate in aspects of the evaluation system. It is important 
to understand whether and how civil society participates in the evaluation system and has the 
potential to influence it, including government and parliament. This role may in fact help to 
strengthen the sustainability and impact of the system.
Some 
examples
In Costa Rica, civil society is one of the stakeholders represented in the national evaluation 
platform, which has around 30 participants per meeting and includes representatives from the 
legislative assembly, the auditor general, and civil society. 
Similarly, in Uganda, to ensure wider participation, an evaluation subcommittee was established 
with the mandate to provide management and oversight support in the implementation of the 
evaluation system. The committee includes a range of key state actors, non-state actors from 
academia, civil society development partners and government-financed research institutions. This 
collaboration was shown to have contributed to the effectiveness of the system. 
In South Africa, the VOPE plays an active role. Civil society often participates in evaluation steering 
committees, where it frequently make significant contributions.
Useful sources  b Use of evidence in a complex social program: Case of an evaluation of the state’s response to 
violence against women and children in South Africa86
Suggested 
basic 
questions
 \ Do civil society organizations or representatives play specific roles in structures and systems 
related to government evaluations (for example, steering committees, a national evaluation 
council)?
 \ What is the role of VOPEs in the national and subnational M&E systems? 
 \ How involved are citizens, civil society organizations, or other actors in specific government 
evaluations?
Possible more 
in-depth 
questions
 \ What is the degree of maturity of VOPEs?
 \ See also questions on VOPEs in section 3. 
86   Amisi Matodzi., Thabani Buthelezi, and Siza Magangoe, “Use of evidence in a complex social programme: Case of an evaluation of the state’s response to violence against 
women and children in South Africa”, Using Evidence in Policy and Practice, eds. Ian Goldman, Mine Pabari (Oxfordshire: Taylor & Francis, 2020), 92–114. 
https://www.taylorfrancis.com/chapters/oa-edit/10.4324/9781003007043-6/use-evidence-complex-social-programme-matodzi-amisi-thabani-buthelezi-siza-agangoe?contex
t=ubx&refId=967c993d-21eb-4bed-8514-9963534bc702Ann
<<<PAGE=62>>>
GEI  |  MESA Guidance notes  |  FEB 2022
62
6 - Overall findings, conclusions, and recommendations
The MESA should result in objective and credible findings. As in evaluations, these findings should provide a solid analysis 
and be the basis for developing a collaborative capacity development plan with the country. They should also enable the 
country to proceed with acting on some of these issues immediately. This section covers these elements.
6.1 Overview of the M&E ecosystem and how it functions
Why is this 
important?
This section provides a brief overview of what is already in place, based on the preceding analysis. 
Some examples The monitoring system in some assessed countries includes the monitoring of government 
departments, the monitoring of projects, and the monitoring of priority outcomes. However, there 
is not always much evidence that this monitoring is used to influence decision making. In terms 
of evaluation, some key systems are in place, including a national evaluation policy. However, 
governments are not undertaking evaluations systematically and those that are being carried 
out are initiated and funded by donors. The respective parliaments are not using evaluations 
at present and are focusing on using government statistics as well as tracking government 
performance using departmental administrative data. Master’s level training in M&E is available 
in these countries and there is a reasonable supply of local evaluators that can be used for 
evaluations.
Suggested 
basic questions
What is the overall picture of the current M&E ecosystem? (In three to four paragraphs this can 
provide a baseline to compare against in future.) 
6.2 Areas that are working well and areas that are working less well
Why is this 
important?
This section summarizes the most important advances as well as the challenges of the system. 
Some examples In 2020, CLEAR-AA undertook a MESA exercise in Zambia. CLEAR-AA was able to assess Zambia’s 
M&E system with the objective of having a partnership with the government to improve the 
system. It produced a full report that was made public. 
In 2017, Twende Mbele conducted a scoping visit to Ghana to assess its M&E system. The table 
below is drawn from that report. 
What works well What works less well
  There are well-established monitoring 
systems nationally and in sectors and strong 
links between district/regional/national 
levels.
  There is a disconnect between data-
collection systems and current plans and 
data needs.
  Some monitoring systems involve direct 
data input at the district level and so are 
immediately available (for example, in the 
health sector). 
  M&E systems are weaker in agencies, such is 
in the health sector.
<<<PAGE=63>>>
GEI  |  MESA Guidance notes  |  FEB 2022
63
6.2 Areas that are working well and areas that are working less well
What works well What works less well
  There is some M&E and data-collecting 
capacity with units in all ministries, 
departments, agencies and district 
assemblies, with planning/M&E and 
statistics/research divisions. 
  There are delays in the monitoring systems. 
Many are not real-time, and so are seen by 
the Ministry of Monitoring & Evaluation as 
historical. Data-collection tools can be in 
short supply.
  There is a well-established institutional 
driver of M&E, the Ghana Statistical Services 
(GSS). 
  Units are small, and capacity is limited, 
particularly in evaluation. Staff are usually 
not trained in M&E, except for in one or two 
short courses. 
  Evaluations are taking place in Ghana with 
an established link to project/program 
cycles. There is oversight from a range 
of stakeholders and donor funding for 
evaluations is available. 
  There are challenges with data quality and 
it is less focused on administrative data and 
more on surveys. 
  There are well-established Ghanaian 
evaluation consultants. 
  Evaluations are donor driven with no overall 
policy framework to guide them; there is 
no evaluation system; the evaluations are 
not freely available; and there is no central 
repository. 
  Short reviews are carried out internally.   There are no established M&E competencies. 
The indicated outputs from the Ministry of 
Health are not always of good quality. 
  There is capacity for M&E in the country and 
some M&E courses were scheduled to start 
in September 2022. 
  Capacity for evaluation is limited – for 
example, for compiling good, comprehensive 
TORs.
Useful sources  b Monitoring and evaluation situation analysis report for Zambia87 
 b Scoping report on visit to Ghana88
Suggested 
basic questions
 \ What are the strengths of the system (areas that work well)?
 \ What are the weaknesses (areas that work less well)?
Possible more 
in-depth 
questions 
The questions above could be addressed separately and in more detail for monitoring systems 
and evaluation systems, and perhaps also for the use of M&E evidence.
87   CLEAR-AA. “Monitoring and Evaluation Situation Analysis Report for the Republic of Zambia.” Unpublished report. University of the Witwatersrand, Johannesburg, 2021.
88   Twende Mbele. 2017. Report on a Scoping Visit to Ghana 13-15 June 2017. https://twendembele.org/reports/scoping-visit-to-ghana-13-15-june-2017/
<<<PAGE=64>>>
GEI  |  MESA Guidance notes  |  FEB 2022
64
6.3 Recommendations for interventions that can trigger wider system change and development 
outcomes
Why is this 
important?
The previous section identifies strengths and weaknesses in M&E systems. For making any 
improvements in an M&E system It is important to note that there are many possible entry points. 
These can be slow, incremental changes, or bigger, more dramatic changes. This section identifies 
areas where M&E capacity can be strengthened, and where partnerships may contribute to this.
Some 
examples
In 2017, Twende Mbele representatives conducted a scoping visit to Ghana to assess its M&E 
system. They produced a report of the visit, which included next steps and recommendations. 
The key change in the Ghanaian system is the introduction of the new ministries of planning and 
M&E in the Presidency. There is a strategic opportunity to assist the ministry and help it to play a 
strong role, drawing from others’ experience.
Both the roles of the BEPPAAG89 in Benin and DPME in South Africa have similar elements to 
the new ministry in Ghana and there can be constructive sharing between them, to help build a 
strategic M&E function within the Presidency in Ghana. 
While there is experience in monitoring in Ghana, the NDP is very keen to take forward the 
evaluation system, including the National Evaluation Policy, which has links with the system and 
capacity development components. The key question is around funding for evaluations, as donor 
funding has declined due to the country being upgraded to lower middle income country status. It 
is not clear whether government has funding for evaluations, but it is likely over the next few years 
that donor funding can be coordinated and used in a more effective way – like Uganda does with 
its basket funding through the Government Evaluation Facility. Even simple tasks such as creating 
a repository of existing evaluations would be valuable, as well as supporting Ghana to develop its 
National Evaluation Policy. This would have to cut through what seem to be strong sectoral silos 
such, as health or agriculture.
In Cabo Verde, after conducting an M&E diagnostic (based on MESA), CLEAR LAB, in partnership 
with the government, was able to identify opportunities and, together, they developed a capacity-
building strategy for the country. The tailor-made strategy encompassed advisory in building 
a national M&E system. Workshops were held with high-level government officials, resulting in 
a draft design of the national M&E system. Along with this strategy there were other capacity-
building activities, such as trainings, mentorships for pilots of rapid evaluations, as well as the 
collaborative production of guidelines with context-appropriate M&E content.
Useful sources  b Scoping report on visit to Ghana90
Suggested 
basic 
questions
 \ What are the opportunities for M&E capacity development that would appear to have the most 
significant effect, be easiest to implement, and have in-country support?
 \ Is there an obvious order of priority, bearing in mind the interests of government?
89   Twende Mbele. Accessed February 16, 2022. https://twendembele.org/countries/benin/ 
90   Twende Mbele. 2017. Report on a Scoping Visit to Ghana 13-15 June 2017. https://twendembele.org/reports/scoping-visit-to-ghana-13-15-june-2017/
<<<PAGE=65>>>
GEI  |  MESA Guidance notes  |  FEB 2022
65
6.4 Conclusions
Why is this 
important? 
National stakeholders (government, academics, civil society) may be well positioned to begin 
implementing changes to the national M&E system, but there may also be scope for GEI partners 
to further support the county to develop a concrete evaluation capacity development strategy. 
This concluding section can provide an overall comment on what has been found and the 
opportunities which arise and make a bridge to a possible next phase of support which could be 
designing the capacity development plan with all the potential stakeholders.
Some examples The example of the previous sections was about Ghana. For next steps it was possible to 
differentiate between what the country could do and what partners (in this case Twende Mbele) 
could do to help them improve the system.
Useful sources Scoping report on visit to Ghana91
Suggested 
basic questions
What are your overall conclusions on the state of the PBM&E systems?
What are your recommendations for action in key areas?
91   Ibid. https://twendembele.org/reports/scoping-visit-to-ghana-13-15-june-2017/
<<<PAGE=66>>>
GEI  |  MESA Guidance notes  |  FEB 2022
66
3. The MESA process: steps  
and examples
This chapter summarizes approaches and good practices in the processes involved in preparing for a MESA, 
and in writing up and using the results of the MESA. Drawing extensively on the CLEAR centers’ experiences in 
conducting M&E diagnostics, this section is largely oriented towards a MESA that is conducted by an external 
team. For a MESA that is conducted by practitioners from within the country’s own M&E system, the approach 
would obviously be slightly different. Nevertheless, there are useful resources and suggestions for all forms of 
diagnostic, and practitioners would need to use their discretion in deciding what is useful. 
There are 12 key steps in the process:
1. Making initial contact 
2. Coming to a common understanding on the MESA 
3. Formalizing the understanding
4. Identifying relevant stakeholders and formulating agreements 
5. Establishing structures to increase and embed country ownership
6. Establishing the team for undertaking the MESA
7. Building capacity to undertake diagnostic work and the MESA 
8. Launching the MESA assessment – ensuring transparency
9. Keeping stakeholders informed during the process 
10. Validating the MESA
11. Overseeing a peer review of the report
12. Designing a contextually relevant response program
3.1  Making initial contact 
Different entry points
Typically, for an externally led MESA, a government entity approaches GEI or a partner for support on national 
evaluation capacity development (NECD). The request for support could be for the whole M&E ecosystem or 
only for some of its elements. The request may come from national and subnational governments, as well as 
a line ministry. Another possibility is that the initial contact comes from a regional organization, as was the 
case of collaboration between CLEAR LAC and CARICOM (see box 3).
<<<PAGE=67>>>
GEI  |  MESA Guidance notes  |  FEB 2022
67
Box 3: CLEAR LAC and CARICOM
CARICOM, the Caribbean Community organization, includes 15 member states and 5 associate 
members from the region. In 2019, CARICOM approached CLEAR Latin America and the Caribbean 
(CLEAR LAC) for support in developing and strengthening results-based management (RBM) in the 
region. There was an early agreement between CARICOM and CLEAR LAC about the initial needs 
of CARICOM. The agreement included a preliminary diagnostic analysis (preparedness diagnostic), 
which started in 2020. At the beginning of the engagement, the idea was to start the diagnostic 
exercise as a pilot in three countries and three regional institutions. The finding of the diagnostic 
would be part of the new agreements on the future plan for strengthening RBM. 
The concrete demand from CARICOM thus defined the specific elements of the diagnostic for the 
region. This is the type of process that is at the core of the MESA.
It is possible that the first communication between a country (or a state, or a region, or a line ministry) and 
GEI and/or other partners may not be on M&E, but on general development support for the country – for 
example, the improvement of the health system. In this case, during the initial agreements GEI and partners 
(such as the World Bank) could suggest that strengthening the M&E in the country (or in a specific sector) 
could enhance the results of the initial development support – for example, the improvement of the national 
health system. While investing in M&E may require fewer resources than those required for upgrading the 
health system, those resources could have an ultimately greater impact because of the impact on improving 
the overall system’s performance, especially if evaluation becomes a significant part of the system. Thus, 
while the initial request may not be for M&E support, interest in it and demand for support may emerge, at 
which point a MESA may become appropriate. 
Initial steps: scoping meetings, desk reviews, and discussions
A first step is likely to be initial scoping meetings to explore what the country is looking to do with its M&E 
system and what kind of support it is seeking. This may change later, depending on what emerges from the 
MESA. Box 4 shows how initial discussions in African Lusophone countries led to a decision to undertake a 
MESA.
Box 4: CLEAR LAB’s MESA for Lusophone African countries
The CLEAR Center on Lusophone Africa and Brazil (CLEAR LAB) developed diagnostic tools that were 
tailored according to the needs of different Lusophone countries. The discussions with countries 
started after an international M&E convening event in Ghana in 2019 focused on strengthening 
M&E capacities on the continent. An action plan was developed in which participants agreed to 
prioritize the conducting of an M&E diagnostic in each country and the provision of M&E training. 
The conference participants became the focal points for conducting M&E diagnostics in their home 
countries and MESAs have been tailored to their country needs.
<<<PAGE=68>>>
GEI  |  MESA Guidance notes  |  FEB 2022
68
A subsequent early step for a MESA team is likely to be a desk review to assemble existing diagnostic 
information as well as holding discussions with a few stakeholders who know the country’s M&E ecosystem, 
and to anticipate areas where collaboration may be fruitful. The guiding questions in section 2 can help with 
the desk review. 
3.2  Coming to a common understanding on the MESA
Once there is an initial agreement on the importance of conducting a MESA, it is important that all stakeholders 
develop a common understanding of what that particular MESA will involve. 
Initial contacts and agreement on the mutual understanding are important for building a strong relationship 
of trust with the country partner. This time is also important for identifying what GEI and partners can do 
to start working together. An initial scoping mission is ideal, if the MESA team is not in-country, and if 
circumstances (such as COVID-related constraints) allow. 
1. Clarifying the purpose of the MESA
The first step is for all stakeholders to consider the main reasons for conducting a MESA exercise. This 
typically involves: 
	\ Generating a common understanding on the status of:
 • M&E stakeholders and practices in a country – both formal and informal;
 • Individual and institutional capacities for monitoring and evaluation and the use of evidence 
from M&E;
 • Opportunities and options for strengthening those capacities. 
	\ Building initial partnerships in the country by starting a dialogue with national players and facilitating 
a collaborative approach to undertaking the diagnostic which can build a platform for a partnership 
at the implementation stage. 
	\ Providing a baseline against which follow-up assessments can capture meaningful changes emerging 
from the collaborative program. 
During the initial dialogues it is important that stakeholders are clear that the MESA tool will be adapted 
according to country needs and mutual agreements among stakeholders. Both the final MESA tool and the 
improvement plan to strengthen national evaluation capacities should actually reflect the country’s needs, 
while being objective, credible, and practicable.
<<<PAGE=69>>>
GEI  |  MESA Guidance notes  |  FEB 2022
69
2. Determining the scope of the MESA
Developing a common understanding of the scope of the MESA is important (see resource 1):
Resource 1: Steps for developing a common understanding on the specific 
MESA tool
 \ Determine the specific demand coming from the country. Identify GEI and its partners’ 
interests in supporting a MESA exercise. 
 \ Find out how much time and what resources stakeholders have at their disposal to participate 
in the MESA process.
 \ Find out whether prior M&E diagnosis work has been done that can be built on in the current 
MESA.
 \ Determine the parameters of the MESA and the levels at which it will be conducted: regional, 
national, subnational, line ministries.
 \ Have a common understanding about concepts such as monitoring and evaluation and 
related planning terminology. Countries may name M&E and planning activities in a variety 
of ways.
Previous M&E diagnosis work in the country could have been done by other national or international 
institutions, or by the government itself. The MESA exercise should build on these, as past diagnoses can 
be used to summarize many of the MESA guiding questions, and then the MESA team can concentrate on 
areas of particular interest. For a MESA led by a GEI partner, this will be done in a spirit of partnership – a key 
element of GEI’s approach.
For example, when CLEAR-FA worked in Gabon, the Ministry of Good Governance requested CLEAR-FA to 
conduct a MESA as a complementary analysis to existing assessments that UNICEF had already conducted in 
the country. To ensure a common understanding of M&E concepts and terminology, partners could generate 
agreements based on experience, suggestions, and a common reference.
<<<PAGE=70>>>
GEI  |  MESA Guidance notes  |  FEB 2022
70
Resource 2: Key contents of the MESA roadmap – based on an exercise in 
Burundi
CLEAR FA designed a roadmap for its MESA exercise with Burundi in 2021.
The broad headings of this roadmap could be useful for all roadmap design. 
1. Context
2. Objectives
3. Introduction to the approach to the diagnostic 
4. Methodology 
 • Preparation
 • Document review
 • Data collection (questionnaires, interviews)
 • Analytical framework
 • Approach to drafting and validating the report
5. Implementation mechanisms, roles and responsibilities
6. Implementation schedule
3.3  Formalizing the understanding 
It is recommended that the agreements about the MESA be formalized and documented. The format this 
takes will depend on partner-specific requirements. 
Agreeing the plan or terms of reference for what needs to be done 
The MESA roadmap could be complemented by a specific plan or terms of reference (TORs) for the GEI/
country team that prescribes the responsibilities and activities for undertaking the MESA. The plan/TOR 
should be a clear, accessible, and practical guide that outlines the concrete steps in the MESA. This will also 
constitute the formal agreement on the process to be undertaken and the timeline.
This is an example from the ToR used for a diagnostic tool applied in Lesotho (see resource 3).
3. Developing a roadmap for the MESA
Once there is an in-principle agreement, it is important to have a roadmap for the MESA. This will be used 
by all stakeholders during and after the MESA process, and can be refined as and when it is appropriate (see 
resource 2).
<<<PAGE=71>>>
GEI  |  MESA Guidance notes  |  FEB 2022
71
Resource 3: MESA terms of reference – based on an exercise in Lesotho
This was a collaborative exercise between the South African and Lesotho governments based on an 
agreement to conduct a joint assessment of Lesotho’s M&E system. These are the main elements of 
the ToR:
1. Background
2. Intended outcome
3. Scope
4. Proposed activities and program. (The program included all the activities for every day of the 
assessment.)
5. Preparatory activities
6. Composition of the teams
Other kinds of formalized agreements 
The MESA roadmap and TORs are examples of written documents showing the initial agreements between 
GEI and partners and the country partner. There are others. 
For example, CLEAR LAB has used the following:
 • Concept note: includes history of relationship and description of product/service, with no direct 
agreement between parts (usually for trainings); 
 • Technical proposal for Angola: includes tentative scope to be agreed between parts, cost and 
timeline; 
 • Technical proposal and contract (through CLEAR-AA) for Mozambique; 
 • Cooperation Term (since there is data sharing) and following work plan for Cabo Verde (draft 
minutes, to be approved by the government). 
CLEAR FA for Madagascar developed a roadmap and then an inception report (at the completion of the 
scoping phase). In Burundi, only a roadmap was required.
<<<PAGE=72>>>
GEI  |  MESA Guidance notes  |  FEB 2022
72
3.4  Identifying relevant stakeholders 
An important step in the MESA is deciding which stakeholders need to be involved in the process. There are 
different categories of stakeholders, who may have separate or overlapping roles in the MESA process. Here 
are some useful questions to ask for determining this (see resource 4). 
Resource 4: Analysis of the MESA stakeholders
 \ Which stakeholders are the official clients of the MESA? 
 \ Which stakeholders have the power to facilitate or block the process? 
 \ Which stakeholders are most actively involved in the MESA process? 
 \ Which stakeholders will be the end-users of the diagnosis? 
 \ Who are M&E champions? 
 \ What structures and institutions do the stakeholders represent? (For example: government, 
line ministries and subnational government; M&E staff within the government; regional 
agencies, such as CARICOM; development partners supporting M&E, such as CLEAR; VOPEs, 
parliament; consultants; and CSOs.) 
If a more in-depth study is desired, other exercises can be carried out, such as: looking at the impact and 
influence of each stakeholder, a power analysis, or a political economy analysis. (Section 2.3 of the MESA 
suggests some of these). 
A well-informed M&E champion would be able to help identify the key stakeholders, as would support 
agencies working in the sector such as CLEAR centers, VOPEs, or development partners working in the 
sector. Other key informants may be able to help when working with subnational agencies (for example, a 
ministry of local government).
3.5  Establishing structures to increase  
and embed country ownership  
For a MESA led by a GEI partner, local ownership of the exercise is crucial. Following the principle of partnership 
and trust, it is recommended that local oversight structure(s) be established to oversee the MESA process.
The type of structure set up in a country will depend on the country and the agreements among stakeholders. 
One possibility is to use existing structures to be part of the process. For example, if there are existing 
planning committees whose mandate includes M&E elements, these could provide oversight of the process 
and make decisions along the way. In this case, the committee(s) should be part of the initial discussions and 
agreements on MESA. An example is that given in box 5, which describes the shadow team that CLEAR LAC 
established in the Caribbean.
<<<PAGE=73>>>
GEI  |  MESA Guidance notes  |  FEB 2022
73
Box 5: Shadow team in CARICOM
In 2021, CLEAR LAC and the Secretariat of CARICOM agreed to have a “shadow team” work in parallel 
with the CLEAR LAC team in the diagnostic process. The CLEAR LAC team developed the diagnostic 
for three countries and one regional institution. At the same time CLEAR LAC supported the shadow 
team to learn about the diagnostic methodology and implementation processes, and then the 
shadow team conducted diagnostics of two additional regional institutions, accompanied by CLEAR 
LAC. In the future, the members of this shadow team can contribute to future diagnostics or follow-
up actions, further enhancing local capacity development and awareness. 
Another possibility is to have short-term structures, such as a MESA steering committee or MESA 
technical committee. These committees would be part of the MESA process and they should also 
be involved in the plan/ToR and roadmap agreements and development. These structures ensure 
that the partner country, state, or line ministry have a sense of ownership of the MESA process and 
product (see resource 5). 
Resource 5: Support structures for MESA
 \ GEI and partners should suggest having one or more local structures to support the MESA 
process.
 \ The country should select an already existing committee or set up a new one.
 \ It is advisable to have two type of structures: a technical one and an institutional/political one.
 \ Ideally, members from the Ministry of Finance, Planning, key line ministries and the Presidency 
should be part of these committees. In some cases, a member of parliament could be invited.
 \ In all cases, there must be agreement on the objectives and functions of the structures.
 \ Where an existing local structure is selected, it is important to invite them to the initial 
discussions and agreements on MESA.
3.6  Establishing the team undertaking the MESA
As mentioned in the Introduction to this guidance, the underlying principle for the MESA is partnership 
between the government and the GEI implementing partner (such as a CLEAR center). There needs to be 
agreement on the work they will collaborate on, and a commitment to ensuring an objective and credible 
diagnostic. 
The constitution of the team carrying out the MESA may take many forms. Ideally, there should be a 
high-level government champion leading or overseeing and facilitating the implementation of the MESA
<<<PAGE=74>>>
GEI  |  MESA Guidance notes  |  FEB 2022
74
(see resource 6). In CLEAR LAC’s work in CARICOM, an executive coordinator was designated in the CARICOM 
Secretariat to oversee the whole collaboration, and then each country or regional institution engaged in the 
process also designated an executive coordinator. To further facilitate coordination and communication, a 
focal point person was also designated in each relevant ministry, department, or agency. 
Strong country ownership is likely if a joint team undertakes the assessment, for example with three to four 
members from government and two to three members from the GEI partner, as was the case in Lesotho in 
2016. This would make it a co-production exercise. There could also be a local consultant in the team, acting 
on behalf of government or as part of the GEI partner’s team. In this way the assignment can be a genuinely 
joint project, owned by both parties. It is then likely to reflect both the understanding of the national team 
members of the national context and their sensitivity to national priorities, with the expertise of the external 
team. 
Other options may involve less direct involvement by government, where a GEI implementing partner 
undertakes the diagnostic, but with strong steering from the country through an oversight body. The relevant 
body would agree on the plan and methodology, and review and validate the findings and the report. (In 
section 3.12, the possibility of an oversight body that the team can report to, such as a steering committee 
is explored.)
Resource 6: Terms of reference for a government team leader
Possible terms of reference for an internal team leader could be:
Purpose: To manage the internal team and the effective 
participation from the side of government
Tasks:
 \ Participate in the conceptualization of the study and development of the approach and terms 
of reference for the diagnostic.
 \ Lead the preparation work, including sourcing background documents, identifying key 
respondents, and setting up interviews, focus groups, and workshops.
 \ Participate in the research phase of the assignment, undertaking interviews, writing up notes, 
and participate effectively in team meetings.
 \ Contribute to the diagnostic report. 
 \ Ensure government team members play their assigned roles in relation to preparation, 
research, and writing.
 \ Keep the principals (for example, in the CLEAR LAC-CARICOM case, the executive coordinator 
at the Secretariat) informed on progress of the diagnostic, feeding back to the joint team.
<<<PAGE=75>>>
GEI  |  MESA Guidance notes  |  FEB 2022
75
The team could be divided into pairs where appropriate, for example, for undertaking interviews, with 
one external member and government staff member. This means work can be undertaken in parallel, thus 
maximizing what can be undertaken in a short space of time.
Time needs to be allocated for the team to meet and get to know each other, before the intensive work 
begins. Government team members may also need to receive training if they are unfamiliar with research 
processes. (See, for example, the “shadow team” with CLEAR LAC in box 5).
3.7  Building capacity to undertake diagnostic work  
and the MESA 
It may be useful to complement the conduct of the MESA with training. For example, key policy champions 
may benefit from a course on results-based M&E. This may help them gain an understanding of why evidence 
is important for decision making and the valuable role that M&E can play in providing such evidence, while 
also further strengthening the understanding of the importance of doing a MESA. 
Including government staff in MESA teams is an excellent way to strengthen ownership and capacities. MESA 
team members need sound research skills. These include how to conduct document reviews, interviews, and 
focus groups, and how to analyze the data. It is also important that team members understand the structure 
of the MESA and can participate effectively in meetings to refine the structure of the report to be prepared, 
and to understand how the research tools will be used to answer the underlying questions of the report. 
It may be very helpful for the team to undertake a two- day course in research methodology, to build a 
common understanding and strengthen skills, which they can then practically apply in the research phase. 
CLEAR LAC trained government staff along the way, including training of coordinators and the shadow team. 
Box 6 shows the trainings that CLEAR-FA provided in three countries. 
Box 6: Training provided by CLEAR FA for Francophone African countries 
implementing a MESA
Gabon: a training of key stakeholders was conducted to make sure that they were able to differentiate 
“evaluation” from “performance review”, “audit”, “inspection”, and other concepts. Seventy 
professionals have been trained in total. They come from ministries, the National Assembly, the 
auditor general, universities, civil society, VOPE, and consulting firms. The theme of the training was 
Creating a National Evaluation System: actors, principles and methods. As part of the training, the 
participants were asked to conduct their own assessment of their NES using the MESA framework. 
This helped in discussing the strategy to build the national evaluation system.
Burundi: Training workshops were important because CLEAR-FA implemented an assessment 
remotely with the support of a local consultant. They wanted to make sure that the respondents 
understood the approach and that they did not simply consider the guide as a questionnaire they 
would quickly complete. Two training workshops were held during the implementation of the MESA, 
which helped to clarify the rationale behind the MESA framework, its requirements, as well as to 
answer questions. 
Madagascar and Burundi: CLEAR could not travel to the country because of COVID-19 and national 
consultants were selected to conduct the interviews. The national consultant was also trained on the 
approach and the understanding of the questions.
<<<PAGE=76>>>
GEI  |  MESA Guidance notes  |  FEB 2022
76
3.8  Launching the MESA assessment – ensuring transparency 
from the outset
The MESA is conducted when there is an agreement and demand for the M&E diagnostic to inform the 
strengthening of national M&E systems. Stakeholders, including national or subnational governments or 
line ministries, need to be familiar with the M&E capacity-development process, particularly as they will be 
overseeing its implementation. An open MESA process has the following benefits: 
 • It makes sure that all stakeholders are informed about the process.
 • It avoids making the process seem as though it is the initiative of a single institution.
 • It avoids bypassing an important player who could be important in the future, or who may 
become an obstacle for the implementation of the recommendations in the future.
Depending on the context, it may be appropriate to have a launch event. The lead government agency may 
want to inform the entire administration and stakeholders of the launch of the MESA and to encourage them 
to be available for interviews and data collection. For example, when CLEAR-FA engaged in a diagnostic with 
Madagascar, there was a launch event with the Steering Committee, chaired by the General Secretary of the 
Government. CLEAR-LAC had launch events in every country and every regional institution with whom it was 
doing diagnostics (see boxes 7 and 8).
Box 7: The experience of CLEAR LAC 
CLEAR LAC starts by asking for a set of documents. In the case of CARICOM, the appointed champion 
(the executive coordinator) fills in a set of basic questions, sends some information and specific 
documents, and is asked to suggest respondents to be surveyed and to be interviewed. The semi-
structured interviews (SSIs) are adapted for each respondent. LAC starts by interviewing the key 
informants identified with the executive coordinator (including, for example, permanent secretaries) 
who may provide further key respondents to interview. They conduct around eight interviews 
per country, with customized questions. This information is used to develop customized online 
questionnaires. A national questionnaire is filled out by different key informants identified together 
with the executive coordinator, and a ministry-level questionnaire is completed by different thematic 
experts in each ministry, who, in turn, are coordinated by the focal person for each ministry. 
Box 8: The experience of CLEAR LAB
The first phase is the completion an off-line Word questionnaire, possibly by a member of the central 
M&E department, at this stage probably without consulting other line ministries/stakeholders. To fill 
in the gaps, CLEAR LAB asks the focal-point person in each country (M&E authority representative), 
for the referral of key actors to be interviewed. These are mainly M&E technical staff in line ministries 
(about six staff) who have a more developed M&E practice, plus one member of VOPE, plus one 
member of a university. This method of choosing interviewees gives a strategic overview, but care 
must be taken that this does not result in biased responses.
<<<PAGE=77>>>
GEI  |  MESA Guidance notes  |  FEB 2022
77
3.9  Keeping stakeholders informed during the process 
Keeping stakeholders informed during the MESA process is absolutely critical. A communication strategy 
should be developed for this. In this way, the process itself helps stakeholders to reflect on their strengths and 
weaknesses and engage for future actions. The communication strategy also helps to remind stakeholders 
about the main principles of the MESA. Resource 7 suggests some elements of a communication plan.
Resource 7: A communication plan for stakeholders
The MESA could take between one and six months, depending on the nature of the process agreed. 
In all cases it is important to keep stakeholders informed. Some good practices include:
1. Taking good minutes in every meeting, especially about decisions, which are shared with all those 
participating in the meeting.
2. Keeping track of the planned timeline, checking progress and any corrections needed.
3. Summarizing the emerging M&E diagnostic findings at least every fortnight, and giving feedback, 
for example through the steering committee.
4. Keeping track of challenges in undertaking the MESA and potential solutions.
5. Having regular meetings with main stakeholders – every fortnight – to inform on all the above. 
For example, CLEAR-LAC had weekly meetings with the Secretariat of CARICOM and periodic meetings 
with the network of executive coordinators. Additionally, CLEAR-LAC is in constant contact with the 
executive coordinators via email or WhatsApp.
3.10 Validating the MESA
It is very important to validate the findings from the MESA research process, and to receive feedback from 
stakeholders. This will help to test the findings, and to make sure that recommendations are relevant, 
implementable, and action oriented. The validation process in itself also has a conceptual value, in helping 
stakeholders to enrich their picture of the M&E ecosystem, with the benefit of an external perspective. 
Giving stakeholders an opportunity to express their views also increases trust among them and increases the 
credibility of the exercise, strengthens ownership over the results, and lays a strong foundation for the way 
forward. 
Typically, the findings and recommendations are tested in a workshop with stakeholders. This can either be 
before the MESA report is written and the conceptual testing of the findings and recommendations, or it 
can be based on the draft report, where the text can be critiqued by stakeholders. If there is a concept to 
be tested, it may well be worth testing it in a presentation at an early stage rather than waiting for the draft 
report (see box 9). If there are not significant conceptual changes to be made, and the emphasis of the 
consultation is on the detail, then testing the draft report in a workshop may be more appropriate.
<<<PAGE=78>>>
GEI  |  MESA Guidance notes  |  FEB 2022
78
Box 9: CLEAR LAB in Mozambique
CLEAR LAB met with the central M&E department representatives and key support agencies, presenting 
the key findings in the dimensions they were assessing. Each dimension was split into “Description” 
(such as background information), “Analysis” (framing the challenge) and “Opportunities” (possible 
solutions and how to move forward). 
A sample workshop program is shown in resource 8. 
Resource 8: Sample MESA validation workshop program
Objectives: By the end of the workshop participants will have validated and added to the findings 
and recommendations of the MESA diagnosis.
PROGRAM
Time Item Responsible
08.00 Registration
08.30 Objectives and flow of the day Chair
Introductions
08.45 Overview of the national M&E system M&E Champion
09.00 Introduction to the MESA
Overview of the MESA diagnosis – background, TORs and 
process
External/internal team leaders
09.20 Discussion Chair
09.30 MESA findings and recommendations
Presentation of findings and recommendations External/internal team leaders
10.15 Discussion Chair
10.30 Coffee
10.50 Group work on findings and recommendations 
Introduction to the group task MESA team member
11.00 Groups work on different sections of the findings and 
recommendations
All
12.30 Lunch
13.30 Report back Chair
Groups report back on the main issues emerging and 
cross-cutting issues
14.45 Quick tea break
15.00 Discussion on cross-cutting issues External/internal team leaders
15.30 Way forward and closing Chair
<<<PAGE=79>>>
GEI  |  MESA Guidance notes  |  FEB 2022
79
GROUP TASK
Background: detailed work on the findings
The group session is where the detailed work to validate and enrich the findings gets done. Groups 
are allocated different elements of the report to look at:
1 - Section A
2 - Section B, etc. 
You will have been allocated one of these topics.
Objective
The group has validated and enriched the findings and recommendations for one or two sections of 
the report.
Process
1. Someone will have been allocated the role of facilitator, and someone to take detailed notes.
2. Select someone to do the report back.
3. Each group will be given some sections of the report.
4. A resource person presents the findings and recommendations of these sections (15 minutes). 
5. Have a general discussion about the picture that is emerging (15 minutes). 
6. Go through the findings and recommendations one by one, asking:
 • Does the finding make sense?
 • Is the recommendation appropriate to the finding? Is 
it realistic and will it make a difference? 
 • The rapporteur should capture major issues and the 
secretariat should make detailed changes. 
7. Draw out what seem to be the major comments to report back on:
 • Overall, do you agree with the thrust of this part of the report? 
 • What are major changes to the findings/recommendations you would like to see (if any)? 
 • Are there any cross-cutting issues which need to be discussed in plenary?
<<<PAGE=80>>>
GEI  |  MESA Guidance notes  |  FEB 2022
80
3.11  Overseeing a peer review of the MESA report 
It is good practice for quality assurance to have peer reviewers who know the country to check the quality 
of the report – both in terms of content and the soundness of the methodology used. The peer reviewers 
could be from another CLEAR center, the GEI global team, another country which has done a MESA, another 
international organization, or local academic institutions. The peer reviewers could assist with the tasks 
suggested in resource 9.
Resource 9: Possible roles for a peer reviewer
Deliverable Role of peer reviewer Time allocation 
(days)
Plan/TORs If the peer review is commissioned in time it would 
be beneficial to get comments on the TORs
0.5
Data-collection methods, 
instruments and other tools
Comment on the tools and methods, including the 
proposed sampling methodology and instruments
0.5
Draft MESA for review Comment on report 1
Possibly a workshop with 
stakeholders to discuss 
the draft report; 
Possibly participate 1
The final report Comment on the first and final draft of final report. 
Also write up short report summarizing main 
issues from the peer review, and the learnings.
1
Participate in developing 
the improvement plan
Possibly participate 1
Potential total time allocation for the MESA and follow-up 5 days
3.12 Designing a contextually relevant response program 
Following on from the agreed findings and recommendations which stakeholders have endorsed, a plan 
needs to be developed for a suitable response program. There are several ways this can be developed. 
One way would be within the joint team which would define a set of possible improvement outcomes (for 
example, short-term outcomes for changes in systems and capacities), and then to widen it to a workshop 
with stakeholders to define a set of improvement outcomes, identifying the outputs and activities to achieve 
these. 
Box 10 shows how CLEAR LAB sent preliminary ideas for subsequent work.
<<<PAGE=81>>>
GEI  |  MESA Guidance notes  |  FEB 2022
81
Box 10: The experience of CLEAR LAB
Along with the Diagnostic Report, CLEAR-LAB also produced a “Preliminary Ideas for a Development 
Plan Report”. These were sent and presented during a meeting to the authorities covering M&E, 
planning, and budgeting. The “Preliminary Ideas” were derived from the diagnostic and showcase 
potential projects to tackle the challenges identified, whether they would be addressed through 
CLEAR or not. 
Countries were advised, after the presentation, to come up with a set of priorities from the preliminary 
ideas. Then, jointly with CLEAR, they would assess which plans could be supported by the center, to 
then formalize the partnership around these plans. 
Resource 10 (next page) shows a possible format for a plan, building on the improvement plan in the South 
African evaluation system.
<<<PAGE=82>>>
GEI  |  MESA Guidance notes  |  FEB 2022
82
Resource 10: Possible format for an M&E strengthening plan92
Improvement outcomes 1 xxx, 2 xxx, 3 xxx, ...
Outcome 1
Outputs to achieve 
the objective
Priority L/M/H Activity to 
achieve output
Person/institution 
responsible
By when? 
(Deadline)
Target Embedded 
where93 
Budget 
available
Current situation/ 
Progress report94 
92  Based on the improvement plan system used in the South African national evaluation system.
93  Which system, plan or document is this embedded in – such as a departmental plan or program plan?
94  This is to report on what the current situation is, and would be used in progress reports to update the situation.
<<<PAGE=83>>>
GEI  |  MESA Guidance notes  |  FEB 2022
83
4. Summary of the key MESA 
milestones
This chapter summarizes the key MESA milestones and tasks involved in the process of undertaking the 
MESA.
1. Preparing for the MESA 
2. Undertaking the MESA 
3. Writing up the MESA report
4. Developing the response program
4.1  Preparing for the MESA 
The preparation stage builds on the understanding of what the specific country needs are and what the 
MESA should cover (sections 2.1–2.7) In terms of carrying out the MESA, GEI recommends the following 
steps:
1.  Identifying potential team members and having those officially appointed (see section 3.6 in the 
MESA). This often requires the support of a national consultant or focal-point person for a successful 
engagement with stakeholders. The direct human interaction in the field is still key to recruiting respondents 
and collect documents. If a consultant is used, it is critical to get the right profile (a person with a strong 
network and good social capital can be very useful). 
2.  Collecting basic background documents based on desk research to get an overview of the system;
3.  Deciding on the MESA report structure (see annex 2) and which sections will be included;
4.  Deciding on the research design and identifying the detailed questions to be asked and how these 
questions will be answered; (the table in annex 2 can be adapted.)
5.  Developing the detailed methodology, tools and instruments95 including:
 • A survey instrument to implement with the main M&E champion; if it is a federal/semi-
federal system then it will be the decentralized units; and potentially with line ministries. 
 • Drafting a letter to accompany requests for the completion of the survey, as well as the interviews;
 • Checklists for semi-structured interviews (which can be drawn from 
the methodology matrix), are adapted for different categories of 
respondents, and identifying the main people to be interviewed;
 • Planning for any workshops, including selecting dates;
6.  Doing a detailed activity-based plan and budget for the MESA process;
7.  Confirming the steering committee for the exercise, if appropriate, and getting the plan approved (see 
3.6);
95   This has to take into account whether the work will be done remotely, or in person.
<<<PAGE=84>>>
GEI  |  MESA Guidance notes  |  FEB 2022
84
8.  Organizing initial interviews with key respondents, notably with the key M&E stakeholders.
9.  Developing and implementing an offline survey (using the interviews) to get key data before the 
intensive research phase.
10. Identifying remaining respondents to interview , including key planning and budget staff, key M&E 
staff in government (central institutions and line ministries), parliament, VOPEs, and development partners 
supporting M&E.
If the exercise is to be conducted virtually, there is more flexibility over timing. However, if it is to be a physical 
visit then it is likely to be an intensive phase of two to three weeks of fieldwork.
4.2  Undertaking the MESA 
The main stages of the MESA are likely to include:
1.  Desk research: Review existing literature and relevant country information to inform the specific country 
MESA approach and design. 
2.  Interviews: These may well be in pairs of external support agency and a government staff member.
3.  Focus groups: Possibly with several staff members – for example, from the M&E champion.
4.  Regular meetings: of the team every two to three days to reflect on the emerging picture and do detailed 
planning.
5.  Initial findings: These would need to be identified, agreed, and articulated in writing. 
6.  Validation workshop: On the initial findings and recommendations. 
If the intensive phase is physical, all of these steps would be undertaken probably within a two–three-week 
visit. If it is done remotely, it could be longer. (Preparation time could be much longer, possibly several 
months.)
4.3  Writing up the MESA report
Writing up the MESA report entails analyzing qualitative and quantitative information received about the 
country M&E systems and processes. Once the MESA diagnostic content has been agreed in the preparatory 
phase, appropriate people should be assigned to write specific sections for the report in line with the interviews 
they conducted. Ideally, government members should contribute to this MESA process in the data-collection 
process and in writing up examples, as well as being involved in their national M&E processes, as this also 
helps to promote and embed ownership. The analysis and findings need to be drafted by an independent 
MESA team. 
4.4 Developing the response program
It is likely that the main MESA report would identify the key areas of work proposed, but the development of a 
response plan would be a subsequent step following the MESA. This may be best undertaken in a workshop, 
where the overall objectives/outcomes and outputs can be defined and groups could work on the detailed 
planning of the components. This constitutes the next phase, and does not form part of this guidance.
<<<PAGE=85>>>
GEI  |  MESA Guidance notes  |  FEB 2022
85
Bibliography
Adaptation Community. 2015. Developing national adaptation monitoring and evaluation 
systems: A guidebook. https://www.adaptationcommunity.net/download/uploads/
giz2015_Developing_national_adaptation_M&E_systems_-_A_guidebook.pdf 
African Centre for Parliamentary Affairs. 2018. Evidence in African parliaments. 
https://www.inasp.info/sites/default/files/2018-04/Evidence%20in%20parliaments.pdf 
African Development Bank. Independent Development Evaluation (IDEV). African Parliamentarians’ 
Network on Development Evaluation (APNODE). Accessed February 14, 2022. https://idev.afdb.
org/en/page/related-page/african-parliamentarians-network-development-evaluation-apnode  
African Peer Review Mechanism. APRM. “About ARPM”. Accessed February 
14, 2022. https://www.aprm-au.org/page-about/ 
Amisi M. Matodzi, Thabani Buthelezi, and Siza Magangoe. 2020. “Use of evidence in a complex social 
programme: Case of an evaluation of the state’s response to violence against women and children in 
South Africa.” In Using Evidence in Policy and Practice, edited by Ian Goldman and Mine Pabari, 92–114. 
Oxfordshire: Taylor & Francis. https://www.taylorfrancis.com/chapters/oa-edit/10.4324/9781003007043-6/
use-evidence-complex-social-programme-matodzi-amisi-thabani-buthelezi-siza-magangoe 
Amisi, Matodzi M., Thabani Buthelezi, and Siza Magangoe. 2020. “Use of evidence in a 
complex social programme: Case of an evaluation of the state’s response to violence 
against women and children in South Africa.” In Using Evidence in Policy and Practice, 
eds. Ian Goldman, Mine Pabari, 92–114. Oxfordshire: Taylor & Francis. 
https://www.taylorfrancis.com/chapters/oa-edit/10.4324/9781003007043-6/use-
evidence-complex-social-programme-matodzi-amisi-thabani-buthelezi-siza-maga
ngoe?context=ubx&refId=967c993d-21eb-4bed-8514-9963534bc702Ann 
Bourgeois, Isabelle, Eleanor Toews, Jane Whynot, and Mary Kay Lamarche. 2013. “Measuring Organizational 
Evaluation Capacity in the Canadian Federal Government.” Canadian Journal of Program Evaluation, 
28, no. 2 (2013): 1–19. https://journalhosting.ucalgary.ca/index.php/cjpe/article/view/30828 
Boyle, R. and D. Lemaire. 1999. Building Effective Evaluation Capacity: Lessons from Practice. 
New Brunswick, New Jersey: Transaction Publishers. https://www.routledge.com 
Bedu-Addo, Dede and Mohammed Awal. 2020. All hands in the community bowl: Evidence use for improved 
sanitation in Ghana. CLEAR-AA Policy Brief. https://wiredspace.wits.ac.za/bitstream/handle/10539/29177/
Evidence%20Use%20for%20Improved%20Sanitation%20in%20Uganda.pdf?sequence=5&isAllowed=y 
Bureau of Statistics. Ministry of Development Planning. Government of 
Lesotho. Accessed February 14, 2022. www.bos.gov.ls 
CARICOM (Caribbean Community). 2019. Decisions of the fortieth regular meeting of the conference of heads 
of government of the Caribbean community. Fortieth Regular Meeting of the Conference of Heads 
of Government of the Caribbean Community (CARICOM), Gros Islet, Saint Lucia, 3-5 July 2019. 
https://caricom.org/documents/fortieth-regular-meeting-of-the-conference-of-
heads-of-government-of-the-caribbean-community-caricom-decisions/
<<<PAGE=86>>>
GEI  |  MESA Guidance notes  |  FEB 2022
86
CARICOM (Caribbean Community). 2019. The Strategic Plan for the Caribbean Community 2015 – 2019: 
Repositioning CARICOM raises the importance of adopting RBM in the region as a mean to improve 
planning and budgeting for achieving the desired results.  
https://caricom.org/documents/strategic-plan-caribbean-community-2015-2019/ 
CIA (Central Intelligence Agency). World Factbook. Accessed February 14, 
2022. https://www.cia.gov/the-world-factbook/countries/ 
CLEAR (Centers for Learning on Evaluation and Results). 2013. An Assessment of Demand 
for Monitoring, Evaluation and Performance Management Information and Services. 
Washington, D.C.: World Bank. http://www.theclearinitiative.org/clear_pubs.html 
CLEAR-AA. “Monitoring and Evaluation Situation Analysis Report for the Republic of Uganda.” 
Unpublished report.  University of the Witwatersrand, Johannesburg, 2021.
CLEAR-AA. (n.d). “Monitoring and Evaluation Situation Analysis Report for the Republic of 
Zambia.” Unpublished report.  University of the Witwatersrand, Johannesburg.     
CLEAR-AA. 2018. Tracking monitoring and evaluation developments in Anglophone 
Africa 2018. https://wiredspace.wits.ac.za/bitstream/handle/10539/28488/
CLEAR-AA%20Compass.pdf?sequence=1&isAllowed=y 
CLEAR-AA. 2021. “Monitoring and Evaluation Situation Analysis Report for the Kingdom of 
Lesotho.” Unpublished report. University of the Witwatersrand, Johannesburg. 
CLEAR-AA. 2021. “Monitoring and Evaluation Situation Analysis Report for the Republic of 
Uganda.” Unpublished report. University of the Witwatersrand, Johannesburg.
CLEAR FGV-EESP (n.d) Diagnóstico de Necessidades e Capacidades em Seguimento e Avaliaçã. 
REPÚBLICA DE CABO VERDE. Accessed February 14, 2022. http://fgvclear.org/pt/curso-fgv-
eesp-clear-propicia-introducao-monitoria-e-avaliacao-para-paises-da-africa-lusofona/ 
CLEAR-LAC. https://clear-lac.org/3d-flip-book/national-monitoring-and-evaluation-
systems/ (Note that the DEVAL weblink is not yet operational.)
CONEVAL (Consejo Nacional de Evaluacion de la Politica de Desarrollo Social). 2014. La 
politica de evaluacion en Mexico: 10 anos del CONEVAL. https://www.coneval.org.mx/
InformesPublicaciones/Documents/CONEVAL_politica_de_evaluacion_10_A.pdf 
CONEVAL (Consejo Nacional de Evaluacion de la Politica de Desarrollo Social). 
Accessed February 14, 2022. www.coneval.org.mx 
CONEVAL (Consejo Nacional de Evaluacion de la Politica de Desarrollo Social). Incubadora de Evaluaciones de 
Impacto. Accessed February 14, 2022.  
https://www.coneval.org.mx/Evaluacion/ESEPS/Paginas/incubadora_impacto.aspx 
CONEVAL (Consejo Nacional de Evaluacion de la Politica de Desarrollo Social). 
Evaluación de La Política Social. Accessed February 14, 2022. https://www.
coneval.org.mx/Evaluacion/NME/Paginas/LineamientosGenerales.aspx 
CONEVAL (Consejo Nacional de Evaluacion de la Politica de Desarrollo Social). Diagnóstico Del Avance En 
Monitoreo Y Evaluación De Las Entidades Federativas. Accessed February 14, 2022.  
https://www.coneval.org.mx/coordinacion/entidades/Paginas/Indice_diagnosticos_temp.aspx
<<<PAGE=87>>>
GEI  |  MESA Guidance notes  |  FEB 2022
87
CONEVAL (Consejo Nacional de Evaluacion de la Politica de Desarrollo Social). Publicaciones Sobre La 
Colaboración Con Entidades Federativas . Accessed February 14, 2022. https://www.coneval.org.mx/
InformesPublicaciones/InformesPublicaciones/Paginas/Colaboracion-con-Entidades-Federativas.aspx 
CONEVAL (Consejo Nacional de Evaluacion de la Politica de Desarrollo Social). Informe De 
Seguimiento A Los Aspectos Susceptibles De Mejora De Los Programas Y Acciones 
Federales De Desarrollo Social 2020-2021. Accessed February 14, 2022. https://www.coneval.
org.mx/Evaluacion/CMPE/Paginas/Informe-de-seguimiento-asm-2020-2021.aspx 
CREAD (Climate Resilience Execution Agency for Dominica). Accessed 
February 14, 2022. https://www.creadominica.org/ 
Daily Maverick. 2021. https://www.dailymaverick.co.za/article/2021-08-11-ramaphosas-
testimony-exposes-the-vast-contours-of-the-ancs-shadow-state/  
Department of Basic Education. Republic of South Africa. Accessed 
February 14, 2022. https://www.education.gov.za/  
Department of Basic Education. Republic of South Africa. Annual reports. Accessed 
February 14, 2022. https://www.education.gov.za/Resources/Reports.aspx  
DNP (Department of National Planning). Synergia. Government of Colombia. Accessed February 16, 
2022. https://sinergia.dnp.gov.co/Paginas/Internas/Seguimiento/Que-es-seguimiento.aspx
DPME (Department of Planning, Monitoring and Evaluation). Republic of South Africa. Citizen-based Monitoring. 
Accessed February 14, 2022. https://www.dpme.gov.za/keyfocusareas/cbmSite/Pages/default.aspx  
DPME (Department of Planning, Monitoring and Evaluation). Republic of South Africa. Evaluations. 
Accessed February 14, 2022. https://evaluations.dpme.gov.za/evaluations.aspx 
DPME (Department of Planning, Monitoring and Evaluation). Republic of South Africa. Evaluations. Accessed 
February 14, 2022. https://www.dpme.gov.za/keyfocusareas/evaluationsSite/Pages/default.aspx 
Federal Ministry for Economic Cooperation and Development. 2015. Developing national 
adaptation monitoring and evaluation systems: A guidebook. Berlin: Deutsche Gesellschaft 
fur Internationale Zusammenarbeit (GIZ) https://www.adaptationcommunity.net/download/
uploads/giz2015_Developing_national_adaptation_M&E_systems_-_A_guidebook.pdf 
Finol-Romero, Lorayne. “Institutionalization of the Monitoring and evaluation systems for public 
policies in Venezuela: Making Progress or Deteriorating?” In National Monitoring and 
Evaluation Systems: Experiences from Latin America. Center for Learning on Evaluation 
and Results, Latin America and the Caribbean (CLEAR-LAC) and Centro de Investigación y 
Docencia Económicas (CIDE), 354–379. https://www.researchgate.net/publication/341576849_
Libro_CIDE_2020_National_Monitoring_and_Evaluation_Systems-2th_edition 
Foa, R. and J. Tanner. 2012. Methodology of the Indices of Social Development.  
http://www.indsocdev.org/resources/Methodology%20of%20the%20
Social%20Development%20Indices_%20jan11.pdf 
Fraser, Dugan I. and Candice Morkel. 2020. “State of monitoring and evaluation in Anglophone Africa: 
Center for Learning on Evaluation and Results in Anglophone Africa’s reflections.” African Evaluation 
Journal 8, no. 1, (Nov 2020): 505. https://aejonline.org/index.php/aej/article/view/505/936
<<<PAGE=88>>>
GEI  |  MESA Guidance notes  |  FEB 2022
88
Furubo, J-E. and R. Sandahl. 2002. “A Diffusion Perspective on Global Developments in 
Evaluation.” In International Atlas of Evaluation, edited by J–E. Furubo, R. C. Rist, 
and R. Sandahl, 1–23. Piscataway, New Jersey: Transaction Publishers. 
GESOC (Gestion Social y Cooperacion). 2019. Índice Estatal de Capacidades para 
el Desarrollo Social. México. https://ides2019.gesoc.org.mx/ 
Global Partnership for Effective Development Cooperation. 2019. Making Development co-operation 
more effective: Headlines of Parts I and II of the Global Partnership 2019 Progress Report. https://
www.effectivecooperation.org/system/files/2020-01/GPEDC_2019-Report_Glossy_EN.pdf 
Goldman, Ian, Albert Byamugisha, Abdoulaye Gounou, Laila R. Smith, Stanley Ntakumba, 
Timothy Lubanga, Damase Sossou, and Karen Rot-Munstermann. 2018. “The emergence 
of government evaluation systems in Africa: The case of Benin, Uganda and South Africa.” 
African Evaluation Journal 6 no. 1, (March 2018): 253. https://doi.org/10.4102/aej.v6i1.253 
Goldman, Ian and Mine Pabari, eds. 2020. Using Evidence in Policy and Practice. Oxfordshire: 
Taylor & Francis. https://www.taylorfrancis.com/books/oa-edit/10.4324/9781003007043/
using-evidence-policy-practice-ian-goldman-mine-pabari 
Goldman, Ian, Wole Olaleye, Stanley Sixolile Ntakumba, Mokgoropo Makgaba, and Cara Waller. 
2020. “Mere Compliance Or Learning – M&E Culture in the Public Service of Benin, Uganda 
and South Africa.” In Using Evidence in Policy and Practice, edited by Ian Goldman and 
Mine Pabari, 54–74. Oxfordshire: Taylor & Francis. https://www.taylorfrancis.com/chapters/
oa-edit/10.4324/9781003007043-4/mere-compliance-learning-culture-public-service-benin-
uganda-south-africa-ian-goldman-wole-olaleye-stanley-sixolile-ntakumba-mokgoropo-
makgaba-cara-waller?context=ubx&refId=c513054a-4cdb-420d-b196-8ed35908fa53 
Government of India. “The Development Monitoring and Evaluation Office 
(DMEO)”. Accessed February 14, 2022. https://dmeo.gov.in 
Government of India. DMEO Studies. Accessed February 14, 2022. https://
dmeo.gov.in/evaluation/dmeo-evaluation-studies  
Heider, Caroline. 2010. “Conceptual Framework for Developing Evaluation Capacities. Building on Good 
Practice in Evaluation and Capacity Development.” In Conceptual Framework for Developing Evaluation 
Capacities Building on Good Practice in Evaluation and Capacity Development. Washington DC: 
World Bank. https://web.worldbank.org/archive/website01404/WEB/IMAGES/PAPER_-3.PDF 
Holvoet, Natalie and Heidy Rombouts. 2008. “The Denial of Politics in PRSP’s Monitoring 
and Evaluation Experiences From Rwanda.” Discussion Paper/2008.02. Antwerp: 
Institute of Development Policy. https://repository.uantwerpen.be  
Ishmail, Zeenat and Victoria L. Tully. 2020. “An overview of the provincial evaluation system of the Western 
Cape Government of South Africa as a response to the evaluation of the National Evaluation 
System.” African Evaluation Journal 8, no. 1, (April 2020): 425. https://doi.org/10.4102/aej.v8i1.425 
Kouakanou, Bonaventure, Dossa Aguemon, Marius S. Aina, Abdoulaye Gounou, and Emmanuel M. David-
Gnahoui. 2020. “The potential and the challenges of evaluations to positively influence reforms: 
Working with producers in the Benin agricultural sector.” In Using Evidence in Policy and Practice, 
edited by Ian Goldman and Mine Pabari, 152–168. Oxfordshire: Taylor & Francis. https://www.
taylorfrancis.com/chapters/oa-edit/10.4324/9781003007043-9/potential-challenges-evaluations-
positively-influence-reforms-bonaventure-kouakanou-dossa-aguemon-marius-aina-abdoulaye-
gounou-emmanuel-david-gnahoui?context=ubx&refId=da33ea01-bb97-4414-90a7-d399b6d3e23a
<<<PAGE=89>>>
GEI  |  MESA Guidance notes  |  FEB 2022
89
Kumalo, Linda, Candice Morkel, Caitlin Blaser Mapitsa, Hermine Engel, and Aisha Jore Ali, 
eds. 2021. African Parliaments Volume 1: Evidence Systems for Governance and 
Development. Stellenbosch: African Sun Media. DOI:10.52779/9781991201454
https://idev.afdb.org/en/page/related-page/african-parliamentarians-
network-development-evaluation-apnode 
Lahey, Robert. 2016. “Why developing monitoring and evaluation capacity is critical to understanding and 
addressing issues of poverty and inequality.” In Poverty, Inequality, and Evaluation: Changing Perspectives, 
edited by Ray C. Rist, Frederic Martin, and Ana Maria Fernandez. 209–236. Washington, DC: World Bank. 
https://openknowledge.worldbank.org/bitstream/
handle/10986/22769/9781464807039.pdf?sequence=1&isAllowed=y 
Lahey, Robert. 2018. “Devising an Appropriate Strategy for Capacity Building of an NMES: Lessons 
from Selected African Countries.” Evaluation Matters (Second Quarter 2018).
https://openknowledge.worldbank.org/bitstream/handle/10986/22079/
Devising0an0ap0ed0African0countries.pdf?sequence=1&isAllowed=y 
Lázaro, Blanca. 2015. Comparative Study on the institutionalisation of evaluation in Europe 
and Latin America, Study n. 15 Series: State of the Art Area: Public Finance. EUROsociAL 
Programme. http://sia.eurosocial-ii.eu/files/docs/1456851768-E_15_ENfin.pdf 
Mackay, Keith. 1999. Evaluation Capacity Development: A Diagnostic Guide and Action Framework. World 
Bank. Evaluation Capacity Development. Working Paper Series No. 6. Washington, D.C.: World Bank. 
https://documents1.worldbank.org/curated/en/807321468765312873/
016824232_200309275053013/additional/multi-page.pdf 
Mackay, Keith. 2008. Institutionalization of Monitoring and Evaluation Systems to improve Public 
Sector Management. Evaluation Capacity Development Working Paper series, no. ECD 15. 
Washington, D.C.: World Bank. http://documents.worldbank.org/curated/en/715431468325271413/
Institutionalization-of-monitoring-and-evaluation-systems-to-improve-public-sector-management 
Manning, Richard, Ian Goldman, and Gonzalo Hernández Licona. 2020. The impact of impact 
evaluation: Are impact evaluation and impact evaluation synthesis contributing to 
evidence generation and use in low- and middle- income countries? WIDER Working 
Paper 2020/20. https://www.wider.unu.edu/publication/impact-impact-evaluation 
Mehrotra Santosh. 2013. The Government Monitoring and Evaluation System in India: A Work in 
Progress. No.28, October 2013. Independent Evaluation Group, The World Bank Group, 
Washington, D.C.: World Bank. https://ieg.worldbankgroup.org/sites/
default/files/Data/reports/ecd_wp28_india_me_0.pdf 
Mexico Evalua. Accessed February 14, 2022. https://www.mexicoevalua.org/  
Animal Politico. Accessed February 14, 2022. https://www.animalpolitico.com/ 
Mexicanos Contra la Corrupcion y la Impunidad. Accessed 
February 14, 2022. https://contralacorrupcion.mx
Ministry of Health Knowledge Management, Republic of Uganda. 2011. National Policy on Public 
Sector Monitoring and Evaluation. http://library.health.go.ug/publications/monitoring-
and-evaluation/national-policy-public-sector-monitoring-and-evaluation
<<<PAGE=90>>>
GEI  |  MESA Guidance notes  |  FEB 2022
90
Ministry of Statistics and Programme Implementation. Government of India. 
Accessed February 17, 2022. https://mospi.gov.in/ 
Ministry of Statistics and Programme Implementation. Government of India. “National Data 
Archive”. Accessed February 14, 2022. http://microdata.gov.in/nada43/index.php/home 
Ministry of Statistics and Programme Implementation. Government of India. “National Data Bank”. 
Accessed February 14, 2022. https://mospi.gov.in/web/mospi/national-data-bank 
Mo Ibrahim Foundation. Accessed February 14, 2022. https://mo.ibrahim.foundation/iiag 
Mo Ibrahim Foundation. “Ibrahim Index of African Governance.” Accessed 
February 14, 2022. https://mo.ibrahim.foundation/iiag 
National Portal of India. Reports on SDG. Accessed February 14, 2022. https://www.niti.gov.in/reports-sdg 
Office of the Cabinet, Government of Jamaica. Government Performance Management and Evaluation”. 
Accessed February 14, 2022. https://cabinet.gov.jm/government-performance-and-monitoring/ 
Oxford Policy Management. 2018. Strengthening Evidence use for Development 
Impact (SEDI). Accessed February 14, 2022. https://www.opml.co.uk/projects/
strengthening-the-use-of-evidence-for-development-impact 
Patton, M. 2008. Utilization-focused Evaluation, 4th edition. Thousand Oaks, California: Sage. 
Perez-Yarahuan, Gabriela and Glaudia Maldonado (eds). 2020. National Monitoring and 
Evaluation Systems. Experiences from Latin America. CLEAR-LAC. https://clear-
lac.org/3d-flip-book/national-monitoring-and-evaluation-systems/ 
Performance Management and Evaluation Unit. Government of Jamaica. 2010. Performance 
Monitoring And Evaluation System (PSES) Framework. November 8, 2010. https://cabinet.
gov.jm/resources/performance-monitoring-and-evaluation-system-pmes-framework/ 
Phillips, Sean. 2014. “A Focus on M&E of Results: An Example from the Presidency, South Africa.” Journal of 
Development Effectiveness 6, no. 4 (2014): 392–406. http://dx.doi.org/10.1080/19439342.2014.966453 
Planning Institute of Jamaica. Accessed February 14, 2022. https://www.pioj.gov.jm/ 
Preskill, H. and S. Boyle. 2008. “A Multidisciplinary Model of Evaluation Capacity Building.” American 
Journal of Evaluation 29, no. 4 (2008): 443–459. http://www.unm.edu/~marivera/522%20
readings%203/Multidisciplinary%20model%20of%20evaluation%20capacity%20building.pdf 
Rist, Ray C., Marie-Helene Boily, and Frederic Martin. (2011). “Evaluation Capacity Building: A 
Conceptual Framework.” In Influencing Change. Building Evaluation Capacity to Strengthen 
Governance, 1-11. Washington, D.C.: World Bank. http://documents1.worldbank.org/
curated/en/806231468327365321/pdf/608080PUB0Infl10Box358332B01PUBLIC1.pdf 
Segone, M. (2010). “Moving from Policies to Results by Developing National Capacities 
for Country-Led Monitoring and Evaluation Systems.” In From Policies to Results: 
Developing Capacities for Country Monitoring and Evaluation Systems, edited by 
UNICEF. Geneva: UNICEF. https://digitallibrary.un.org/record/690429?ln=en 
Stufflebeam, Daniel 2002. Institutionalizing evaluation checklists. https://wmich.edu/evaluation/checklists
<<<PAGE=91>>>
GEI  |  MESA Guidance notes  |  FEB 2022
91
Tobing-David, V. E. 2017. Review of National Evaluation Systems and Capacities for Evaluating 
Progress Towards the Sustainable Development Goals. Geneva: UNICEF.
https://gpffe.org/wp-content/uploads/2019/07/UNDP-UNICEF-Indonesia-
NES-Review-and-Readiness-Assessment-FInal-Report.pdf 
South African National Biodiversity Institute (SANBI). 2018. National Biodiversity Assessment 2018: The 
status of South Africa’s ecosystems and biodiversity. Synthesis Report. South African National 
Biodiversity Institute, an entity of the Department of Environment, Forestry and Fisheries, 
Pretoria. https://www.sanbi.org/wp-content/uploads/2019/10/NBA-Report-2019.pdf  
Twende Mbele. A Catalyst for Knowledge Sharing. Accessed February 14, 2022. https://twendembele.org 
Twende Mbele. A knowledge sharing platform to improve M&E in Africa. 
Accessed February 14, 2022. https://twendembele.org 
Twende Mbele. 2017. Report on a Scoping Visit to Ghana 13-15 June 2017. https://
twendembele.org/reports/scoping-visit-to-ghana-13-15-june-2017/ 
Uganda Evaluation Association. Accessed February 14, 2022. https://ugandaevaluationassociation.
org/web/ugandaevaluationassociation/default.aspx 
UNDP (United Nations Development Programme). Human Development Reports. 
Accessed February 14, 2022. www.hdr.undp.org/en/data 
UNEG (United Nations Evaluation Group). Evaluation Reports. Accessed February 
14, 2022. http://www.uneval.org/evaluation/reports 
Varone, Frederic. and Llleven de Winter. 2005. “Polity, Politics and Policy Evaluation in 
Belgium.” Evaluation 11, no. 3 (2005): 253–273. DOI:10.1177/1356389005058475 
White, Howard and Edoardo Masset. 2007. "Assessing interventions to improve child nutrition: a 
theory-based impact evaluation of the Bangladesh Integrated Nutrition Project." Journal 
of International Development, 19, no. 5, (2007): 627–652. DOI:10.1002/jid.1344
World Bank. “Data on Statistical Capacity”. Washington, D.C.: World Bank. Accessed 
February 14, 2022. https://datatopics.worldbank.org/statisticalcapacity/ 
World Bank. “Databank World Development Indicators.” Washington, D.C.: World Bank. Accessed 
February 14, 2022. https://databank.worldbank.org/source/world-development-indicators
<<<PAGE=92>>>
GEI  |  MESA Guidance notes  |  FEB 2022
92
Annexes
<<<PAGE=93>>>
GEI  |  MESA Guidance notes  |  FEB 2022
93
Annex 1: The GEI’s National Evaluation Capacity Development Framework and relevant sections 
of the MESA
Enabling environment Organizational capacity development Individual capacity 
development
2.1 Country profile
2.2 Structure of government
2.3 Political economy and link to M&E
2.5 Level of interest in M&E at the 
beginning of the MESA 
2.4 Organizational culture of government and implications for M&E
3.8 Communication of M&E evidence 
3.10 Equity and gender considerations 
in the PBM&E systems
3.11 Climate and environmental 
sustainability considerations in the 
PBM&E systems
3.1 Legal and policy basis for the PBM&E systems 
3.2 Roles of key actors in the PBM&E systems
3.3 Overview of the planning and budgeting systems
3.4 Overview of the M&E and related systems
3.5 Role of other stakeholders in relation to M&E
3.6 Statistical and administrative data
3.7 Resources for M&E
3.9 M&E capacity-development 
initiatives
4.5 Role of civil society role in the 
government monitoring system
4.6 Systems/incentives for acting on 
monitoring
4.1 Systems for government monitoring and reporting at national level
4.2 Systems for government monitoring and reporting in line ministries and at 
subnational levels 
4.3 Monitoring of government by parliament
4.4 Capacity in government to undertake monitoring and reporting
4.7 Use of monitoring information by government 
4.4 Capacity in government to 
undertake useful monitoring and 
reporting. 
5.7 Use of evaluations by government
5.8 Use of evaluations by parliament
5.9 Use of evaluations by civil society 
and the media
5.10 Role of civil society in government 
evaluation systems
5.1 Evaluation systems at the national level
5.2 Evaluation systems at line ministry and subnational levels
5.3 Government capacity to manage, commission, and undertake evaluations
5.4 Government capacity to manage and coordinate an evaluation system 
5.6 Systems/incentives for ensuring that evaluation is acted upon
5.7 Use of evaluations by government
5.8 Use of evaluations by parliament
5.9 Use of evaluations by civil society and the media
5.10 Role of civil society in government evaluation systems
5.2 Government capacity 
to manage, commission or 
undertake evaluations
5.4 Government capacity to 
manage and coordinate an 
evaluation system
5.5 Capacity to undertake 
evaluations in civil society/
academia/ private sector
<<<PAGE=94>>>
GEI  |  MESA Guidance notes  |  FEB 2022
94
Annex 2: Structure of the MESA with linked questions
This table consolidates all the questions from the MESA in chapter 2. The table starts as section 2, as there are no questions for section 1.
2. Background to the country and its level of interest in M&E
Subsection Suggested basic questions Possible more in-depth questions
2.1 Country profile  \ What is the GDP per capita?
 \ What is the current growth rate?
 \ What are the key economic sectors and how are they performing?
 \ What are levels of poverty and inequality? (Use international and comparable data on 
poverty and inequality; but national definitions and alternative measures could be used for a 
deeper dive.) 
 \ Key demographics: median age, life expectancy, gender (for example, the percentage of 
boys and girls at school or the Gender Inequality Index); basic education (for example, the 
percentage of the population that have completed secondary school), health (for example, 
the rate of maternal mortality).
 \ Vulnerability to climate change (for example, incidences of drought, disasters and weather). 
 \ Peace, conflict, and security issues. (For fragile states 
or those affected by conflict, this is key information).
 \ What are the levels of unemployment?
 \ CO2 emissions in relation to GDP .
 \ Migration: percentage of the population that are 
migrants – internal and external.
2.2 Structure of government  \ What is the overall structure of government (for example, a federal or unitary system)?
 \ What is the parliamentary system?
 \ What are the dates/years of the last and next elections?
 \ What are the policy-making mechanisms under 
multiparty/single party governance? 
 \ How do changes in leadership happen?
 \ (Note that section 3.2 explores the roles of key 
stakeholders in more depth.)
<<<PAGE=95>>>
GEI  |  MESA Guidance notes  |  FEB 2022
95
Subsection Suggested basic questions Possible more in-depth questions
2.3 Political economy and the 
link to M&E
 \ What are the political forces that have driven the development of M&E or related practices/
systems?
 \ How does accountability work in the government system and in parliament, in theory and in 
practice?
 \ Who will benefit from building an effective M&E system?
 \ Who will not benefit from building the M&E system?
 \ What are the implications of this for strengthening the M&E system?
 \ What are the political forces (policies, laws, 
regulations, orders, etc.) that have driven the 
development of M&E or related practices/systems? 
(A deeper dive may be appropriate.) 
 \ Who are the various stakeholders involved in policy 
making and how do they interact (for example, 
lobbying)? 
 \ What is government’s current political focus (for 
example, what are the priority outcomes) and how 
has this evolved?
 \ What role do CSOs play in relation to government 
(in relation to advocacy, for example)? 
2.4 Organizational culture of 
government and implications 
for M&E
 \ Is there a demand from managers/technicians/parliamentarians/ civil society for performance 
information to inform policy and program planning and budgeting?
 \ How do politicians and senior officials view the usefulness of M&E and results-based 
management? Do they see them as relevant for accountability? What about for learning and 
performance improvement?
 \ What are the dominant incentives in the public service (for example, fear of making a 
mistake, or achieving targets for bonuses)? Does this vary across departments so that some 
show a more transparent, learning, and performance-oriented culture? 
 \ Is there a culture of learning and is there an interest and ability to cultivate this? Does this 
vary across departments? 
 \ How does the government usually respond to negative M&E findings/evidence? 
 \ Overall, what are your conclusions on the organizational culture within the public service?
 \ What kind of decisions are guided by M&E 
information – in relation to planning, budgeting, 
and other key areas? 
 \ These questions can also be explored in more 
depth, such as through using survey information or 
literature to deepen the analysis.
2.5 Level of interest in M&E at 
the beginning of the MESA
 \ How much interest is there in M&E now and from whom?
 \ Why is a MESA diagnostic exercise likely to be of value at this time?
 \ What is motivating the champion(s) or leading government agency or entity to build the 
M&E system?
 \ Are there particular constraints around the development of M&E at this time – such as 
upcoming elections, or crises such as pandemics, or climate change-related disasters or 
events?
 \ If there is resistance to M&E, what are its origins, 
and what is the level of interest and capacity to 
change these views?
<<<PAGE=96>>>
GEI  |  MESA Guidance notes  |  FEB 2022
96
3. Overview of planning, budgeting, and M&E systems
This section is intended to provide an overview of the planning, budgeting, and M&E (PBM&E) systems, which are then explored in detail in section 4 (for monitoring) 
and section 5 (for evaluation). As evaluation in particular needs to inform plans and budgets, an overview of these planning and budgeting systems is provided.
Subsection Suggested basic questions Possible more in-depth questions
3.1 Legal and policy basis 
for the PBM&E systems
 \ Where do custodians of the PBM&E systems derive the mandate to provide oversight and coordination 
of PBM&E at varying levels (for example, constitution, laws, regulations, and executive powers, including 
policies)? 
 \ Is there a national monitoring and evaluation policy, or a national monitoring policy, or a national 
evaluation policy? 
 \ Is there national legislation or regulation for monitoring and/or national legislation or regulation for 
evaluations, or a national policy for monitoring and evaluation?
 \ If there is a law, regulation, policy on monitoring and/or evaluation do they include references to:
• links between (results) monitoring and planning?
• links between (results) monitoring and the budgetary process?
• links between (results) monitoring and decision making in parliament (legislative)?
• links between (results) monitoring and decision making in higher levels of government 
(executive)?
• links between (results) evaluation and planning?
• links between (results) evaluation and the budgetary process?
• links between (results) evaluation and decision making in parliament (legislative)?
• links between (results) evaluation and decision making in higher levels of government (executive)?
• the independence of the evaluation unit(s)?
• the necessary resources and staff of the evaluation unit(s)?
 \ Is there a regulation/agreement/long-term development agenda that obliges the government 
to communicate program results periodically, whether to the population, donors/agencies, for 
international obligations and/or between ministries?
 \ Is there a legal requirement or regulations requiring the use of evidence in decision making? 
 \ Explore further any legal requirement or 
regulations requiring the use of evidence 
in decision making – for example, when 
new programs are approved.
<<<PAGE=97>>>
GEI  |  MESA Guidance notes  |  FEB 2022
97
Subsection Suggested basic questions Possible more in-depth questions
3.2 Roles of key actors in the 
PBM&E systems
 \ Is there a central body responsible for monitoring?
 \ Are there decentralized bodies responsible for monitoring?
 \ Is there a central body responsible for evaluation?
 \ Are there decentralized bodies responsible for evaluation?
 \ What is the legal basis for these entities?
 \ Does the central evaluation unit set standards and provide support for evaluation across 
government?
 \ What are the roles of different stakeholders at national and subnational levels in the planning, 
budgeting, and M&E systems (including communities if relevant)?
 \ Are there individual M&E champions at the political and senior administrative levels in the country 
(for example, directors, permanent secretaries)? 
 \ With respect to parliamentary roles, do laws, regulations, or policies make linkages between (results) 
monitoring and decision making in parliament?
 \ Do laws, regulations, or policies stipulate linkages between evaluation and decision making in 
parliament?
 \ Are there research structures in 
government departments that could be 
built on – for example, for evaluations?
 \ What is parliament’s role in the 
planning, budgeting, and M&E systems? 
 \ What does a power analysis of the main 
stakeholders reveal? 
 \ It may be important to further explore 
the realities of the balance of power 
between institutions and stakeholders. 
3.3 Overview of the planning 
and budgeting systems
 \ How does the planning system work? 
 \ Is there an established process for designing and implementing public policy? What are the steps 
and methodologies? Are there instances of approval where evidence can be applied?
 \ How does the budgeting system work?
 \ Are there processes for performance-based or results-based budgeting and is this culture well 
established?
 \ What evidence does the state use to inform government planning, budgeting, policy, and decision 
making?
 \ Do laws, regulations, or policies stipulate the links between (results) monitoring and national 
planning?
 \ Do laws, regulations, or policies stipulate the links between (results) monitoring and the budgetary 
process?
 \ Do laws, regulations, or policies stipulate the links between evaluation and national planning?
 \ Do laws, regulations, or policies stipulate the links between Evaluation and the budgetary process?
 \ Does the national plan have clear goals, indicators, and targets?
 \ To explore the systems in more depth, 
there could be a deeper analysis of how 
these evolved, and not just how they are 
now.
 \ To what extent is the planning process 
participatory and inclusive (for example, 
at municipal, provincial and national 
levels)? 
 \ The evidence used could be explored in 
more depth.
<<<PAGE=98>>>
GEI  |  MESA Guidance notes  |  FEB 2022
98
Subsection Suggested basic questions Possible more in-depth questions
3.4 Overview of the M&E 
systems
 \ What are the different M&E systems: for example, of departments and projects monitoring 
against the national development plan, monitoring of SDGs, and evaluation systems? 
 \ How have these evolved, briefly?
 \ Is there a national coordination body, such as a national evaluation council?
 \ What components of M&E systems are in place: for example, M&E policy/strategy, M&E 
frameworks, reporting systems, evaluation agenda/plans, standards, competencies, 
repository of evaluations, quality assessments – and how binding are they? 
 \ Are results-monitoring data used to inform the national planning process?
 \ Are results-monitoring data used to inform the budgetary process?
 \ Are results-monitoring data discussed in parliament (or the legislative arm of government)?
 \ Do government documents on policies, programs, and projects contain results frameworks?
 \ Are data on the results of individual policies, programs, and projects collected and reported?
 \ Does the central evaluation unit commission and/or conduct evaluations?
 \ Do decentralized evaluation units commission and/or conduct evaluations?
 \ If there are no specifically designated evaluation units, do other entities commission and/or 
conduct evaluations? 
 \ How many country-led evaluations have been commissioned and implemented by 
government in the past two to three years? 
 \ To what extent are these evaluations perceived to be credible, independent, and impartial? 
(For example, do these evaluations report on challenges or poor results, or do they only 
highlight positive aspects?)
 \ Do evaluations inform the national planning process?
 \ Do evaluations inform the budgeting process?
 \ Are evaluations discussed in parliament (or legislative bodies)?
 \ Is there evidence of changes in programs/strategies/projects due to evaluation 
findings?
 \ Is there evidence that the evaluations are discussed at higher levels of government 
(the executive arm)?
 \ See optional modules in sections 4 and 5.
<<<PAGE=99>>>
GEI  |  MESA Guidance notes  |  FEB 2022
99
3.5 Role of other stakeholders in relation to M&E
National statistical 
organization (NSO)
This is covered in section 3.6
Audit offices Audit often drives behavior. 
It is important to understand 
the audit role and how it 
links to M&E.
 \ What is the role of audit offices? 
 \ Do they undertake performance audits or other functions which are close to M&E? 
 \ What is the attitude to audit and how does that affect M&E?
Role of voluntary 
organizations for 
professional evaluation 
VOPE(s)
This section provides an 
overview of VOPEs, their 
capacity, and operations. In 
the basic MESA this would 
probably not be detailed, 
but more detail could be 
provided if necessary.
Basic questions:
 \ Is there an evaluation association(s) in the country?
 \ When was the VOPE established, how many members does it have, and where do most members come from (for example, 
the public sector, CSOs, academia)?
 \ Is there a selection process for members?
 \ How active is it?
 \ How does the VOPE work with government, civil society, and donor organizations in the country to promote evaluation and 
evidence-based policy making?
 \ To what extent does the local VOPE influence M&E activities in the country?
In-depth questions:
 \ What are the sources of income for the VOPE?
 \ What are the M&E priorities for the VOPE in the next five years?
 \ What are some of the challenges the VOPE is facing and how can they be addressed? 
 \ Does the VOPE have an active network of emerging evaluators?
Role of NGOs (or civil 
society) in the M&E 
system
This section explores what 
roles NGOs play in the M&E 
system – such as sitting 
on evaluation steering 
committees, or being 
involved in the selection of 
evaluations for evaluation 
plans/agendas. 
Basic questions:
 \ In general terms, what role do other CSOs play (if any) in the national M&E system – for example, sitting on steering 
committees, or playing a role in the national coordination structure?
 \ In-depth questions:
 \ Do NGOs play an active role in requiring evidence from the government about results ex post and about policy choices ex 
ante?
 \ Do CSOs share with government evidence from evaluations of programs that have worked, and advocate for scale-ups?
<<<PAGE=100>>>
GEI  |  MESA Guidance notes  |  FEB 2022
100
Development partners In many countries, development partners (multi-lateral, 
bi-lateral, etc.) play an important role in M&E systems, 
funding the development of elements of the system 
and/or funding evaluations. An enriched element would 
be obtaining details of the donor-funded evaluations 
being undertaken.
Basic questions:
 \ What M&E initiatives are funded by local and international development partners in the country – 
such as training, or the development of M&E policies and guidelines? 
 \ Are any development partners funding government-led evaluations?
 \ Do any development partners conduct their own evaluations using country systems?
In-depth questions:
 \ Over the last three years, what proportion of evaluations have been funded by development 
partners? 
 \ What other influence do donors have on M&E activities in the country?
Media The media play an important role in communicating 
evidence through multiple channels. They may play a 
negative role, such as in generating fake news. Or they 
could play a more positive role in reporting accurately 
on evidence emerging from M&E, and contributing 
to wider society by holding government to account. 
This section also identifies any work being undertaken 
to strengthen the capacity of the media to use M&E 
evidence.
Basic questions:
 \ Do the media use M&E evidence?
 \ Are there references in the media to evaluations?
 \ Has any training or support been undertaken to help the media use M&E evidence? By whom?
In-depth questions:
 \ How much is the value of scientific evidence recognized by the wider public in the country – for 
example, over COVID-19?
 \ How prevalent is “fake news” – for example, covering COVID-19?
Political parties In many countries political parties may be very 
dominant, and at times dominate government if 
they hold power for long periods. In such situations 
it is very important that they see the importance of 
M&E evidence. It is thus important to understand the 
attitudes to M&E and what advocacy work has been 
undertaken in this regard.
Basic questions:
 \ Do political parties lobby for evidence-based policy making?
 \ Does the evaluation unit report evaluation findings to political parties?
In-depth questions:
 \ Has any effort been made to brief political parties on M&E evidence?
 \ How important has this briefing been in influencing decision making in the country?
3.5 Role of other stakeholders in relation to M&E
<<<PAGE=101>>>
GEI  |  MESA Guidance notes  |  FEB 2022
101
Subsection Suggested basic questions Possible more in-depth questions
3.6 Statistical and 
administrative data
 \ Is a population census conducted? How often?
 \ Is there a national statistical system?
 \ Does the government/NSO conduct a demographic census? How often?
 \ Does the government/NSO conduct other household survey (s)?
 \ How accessible are administrative data – are they shared in some way 
across government?
 \ What is the quality of administrative data (for example, are the data 
complete, timely, accessible, and reliable)? 
 \ Are data disaggregated to track the situation of disadvantaged groups?
 \ Is frontline data collection in electronic or paper format?
 \ If electronic, is this information aggregated and relayed upwards without 
time lags? 
 \ Do departments/subnational levels conduct any surveys of their own? If 
so, which?
 \ Explore further the quality of administrative data. For example, are the 
data complete, timely, accessible, and reliable?
3.7 Resources for M&E  \ What resources does the government provide for M&E, in terms of 
budgets for M&E, the size of M&E units, and are resources specifically 
allocated for evaluation, or research?
 \ How are M&E budget needs determined?
3.8 Communication of M&E 
evidence
 \ Are there formal frameworks for reporting, debating, and discussing 
monitoring and evaluation results at different levels (for example, 
websites, media workshops)?
 \ To what extent are findings shared with the entire population, and in 
an easily accessible way (for example, policy briefs/ accessible reports, 
practical/implementable solutions)?
 \ What is the percentage of government evaluations that have been made 
public in the past two to three years?
 \ Are there mechanisms to enable ease of access to government data and 
evidence (for example, repositories)?
 \ Does the country report on its contribution to the achievement of the 
SDGs?
 \ Who is responsible for knowledge management in government 
departments?
 \ Are there academic journals or other media and forums for evaluation? 
 \ To what extent does M&E information enter public discourse?
 \ Are there mechanisms to enable ease of access to NGO data and 
evidence (for example, repositories)?
<<<PAGE=102>>>
GEI  |  MESA Guidance notes  |  FEB 2022
102
Subsection Suggested basic questions Possible more in-depth questions
3.9 M&E capacity-
development initiatives
 \ Which institutions provide formal degree/postgraduate M&E training and what courses 
do they provide? 
 \ At what level are the trainings pitched (certificate, post-graduate certificate/diploma, 
master’s, doctorate)? 
 \ Which institutions provide short M&E training and what courses do they provide? 
 \ Are there any courses specifically designed for public-sector M&E (for example, 
an Introduction to M&E in the public sector) and by whom? Are they tailored to 
specific audiences (for example, technical staff, mid-level managers, senior managers, 
politicians)?
 \ Are there M&E capacity-development plans in place? Are processes under way to 
develop and strengthen M&E capacity in government and society more broadly – such 
as, how to produce, manage, and use evidence? 
 \ Has there been any technical assistance, capacity building, or training in M&E currently 
over the past two years for any level of government (national, regional, or local)? Who 
provided this assistance and within what framework or reform process? 
 \ Have M&E competencies been defined for the public sector?
 \ How many people were trained on M&E during this 
year, and by which institution? 
 \ What is the weighting of courses for both 
monitoring and evaluation?
 \ Are there M&E modules offered as part of other 
courses/degrees/qualifications (for example, as part 
of bachelor degrees in sociology or development 
studies)? 
 \ Are there any other professionalization initiatives?
 \ What difference has the training that has been 
provided to date made?
3.10 Equity and gender 
considerations in the PBM&E 
systems
 \ Do the legal framework, policy, and/or regulations include specific 
considerations on gender mainstreaming in monitoring and/or evaluation? 
 \ Do the legal framework, policy, and/or regulations include specific 
considerations with respect to mainstreaming equity considerations in 
monitoring and/or evaluation?
 \ To what extent do monitoring and/or evaluations in government take into 
account gender and inequality issues? Are there formal forums at which these 
are discussed and taken seriously?
 \ Are there other ways gender, inequality, and equity issues are mainstreamed 
in M&E systems – such as the use of equity criteria in all evaluations?
 \ Is there monitoring by civil society on gender and 
equity issues? By whom and at what level?
<<<PAGE=103>>>
GEI  |  MESA Guidance notes  |  FEB 2022
103
Subsection Suggested basic questions Possible more in-depth questions
3.11 Climate and 
environmental sustainability 
considerations in the PBM&E 
systems
 \ Do the legal framework, regulations, and policies include provisions for 
mainstreaming climate change into M&E? 
 \ Do the legal framework, regulations, and policies include mainstreaming 
a sustainable development perspective in M&E? 
 \ Is there monitoring or evaluation by government on climate change, 
or issues of environmental sustainability (for example, the collapse of 
species and ecosystems and the depletion of natural resources). By 
whom and at what level? 
 \ Does the country’s PBM&E system track and inform on the 
environmental footprint? 
 \ What monitoring and what evaluations on climate change and 
sustainable development are happening in government? Are there 
formal forums at which these are discussed and taken seriously? (For 
example, South Africa has the Presidential Climate Change Commission 
and the Commission for Gender Equality.)
 \ Are there other ways in which these issues are mainstreamed in M&E 
systems – for example, the use of environmental sustainability criteria in 
all evaluations?
 \ How is climate change-related M&E used and by whom? (For example, 
Nepal’s Climate Change Program Coordination Committee is responsible 
for coordinating data on climate change M&E and it is used to inform 
new policies and programs.)
 \ Is there monitoring by civil society on climate change, or on 
issues of environmental sustainability, gender, and equity? By 
whom and at what level?
<<<PAGE=104>>>
GEI  |  MESA Guidance notes  |  FEB 2022
104
4. Monitoring and reporting systems
This section explores monitoring and reporting systems in detail, with an emphasis on output- and outcome-monitoring rather than activity monitoring. Looking at 
the reporting function is important to understand what happens with monitoring data, and the extent to which it is used for decision-making. 
Subsection Suggested basic questions Possible more in-depth questions
4.1 Systems for 
government monitoring 
and reporting at the 
national level
 \ What are the main monitoring systems at the national level and who are 
the custodians of these? 
 \ Is there monitoring and reporting of the national development plan, and 
other formalized plans? 
 \ What monitoring and reporting systems are in place for outputs, for 
outcomes, and for budget/expenditure?
 \ What roles do line ministries play in monitoring?
 \ Are there incentives or sanctions in place to ensure that sectoral ministries 
and/or subnational governments adopt M&E practices in their daily work 
and report as required?
 \ Are there other systems that are not called PM&E but that in fact are 
PM&E systems? 
 \ How is information collected on expenditure/inputs/outputs/, intermediate 
outcomes, and long-term outcomes and impacts? 
 \ The evolution of these systems could be explored in more depth, as well 
as the implications for where they are headed.
 \ What mechanisms are there for government to share monitoring evidence 
and engage stakeholders (for example, CSOs) on policy and performance 
matters (such as through platforms like workshops or public hearings)? 
 \ What are the main monitoring systems at the regional level and who are 
the custodians of these? 
4.2 Systems for government 
monitoring and reporting 
in line ministries and at 
subnational levels
 \ What are the main monitoring systems coordinated by line 
ministries? 
 \ What are the main monitoring systems at subnational levels and 
who are the custodians of these? 
 \ What monitoring and reporting systems are in place for 
outcomes and for outputs at these levels?
 \ What lower-level monitoring and reporting do line ministries do?
 \ How does this link with local government or state governments?
 \ Is there formalized monitoring and reporting of a subnational 
development plan and other plans? At state or other local 
government level?
4.3 Monitoring of government 
by parliament
 \ How does parliament monitor government performance? 
 \ How is government monitoring information used in parliament?
 \ How effective is this monitoring?
 \ Do committees feel they can get an in-depth understanding of 
what the departments are doing and how effective it is?
<<<PAGE=105>>>
GEI  |  MESA Guidance notes  |  FEB 2022
105
Subsection Suggested basic questions Possible more in-depth questions
4.4 Capacity in government 
to undertake monitoring and 
reporting
 \ Are there skilled personnel in government with the technical 
capacity for performance monitoring (for example, gathering, 
analyzing, and reporting on the performance of government 
policies and programs)? 
 \ What training have they had?
 \ Overall, is there institutional capacity to undertake meaningful 
monitoring that feeds back into management? At what levels?
 \ Is there a capacity-strengthening plan for monitoring skills 
in government (for example, training, coaching, mentoring, 
technical assistance/support)?
 \ A special MESA-related module, such as a survey, could collect 
more detailed information on individual capacity.
4.5 Role of civil society in 
the government monitoring 
system
 \ Are there any specific roles that CSOs play in government 
monitoring systems – such as sitting on monitoring structures, or 
being involved in community-based monitoring?
 \ What CSOs involved in social accountability and audit 
mechanisms exist to monitor government?
4.6 Systems/incentives for 
acting on monitoring
 \ Is there a system for institutionalizing and incentivizing the use of 
monitoring evidence (such as rewards, sanctions, and messaging 
from leadership)?
 \ Explore the above in more depth and how this relates to culture.
4.7 Use of monitoring 
information by government
 \ How does monitoring information within government inform 
decision making: planning, project or program management, 
budgeting, and performance reporting?
 \ What examples are there of the use of monitoring information in 
national plans, strategies, and government programs? 
 \ How does the government usually respond to negative M&E 
findings/evidence?
 \ What is the role of each department within the state in making 
these decisions based on M&E?
<<<PAGE=106>>>
GEI  |  MESA Guidance notes  |  FEB 2022
106
5. Evaluation systems
This section goes into the country’s evaluation systems in detail. Here, the MESA focuses not only on the production and use of single evaluations, but on the status 
of the evaluation system as a whole.
Subsection Suggested basic questions Possible more in-depth questions
5.1 Evaluation systems at the 
national level
 \ Who are the custodians of the evaluation system at regional/national level?
 \ What is the extent of the coverage of the evaluation custodian or evaluation unit across 
government?
 \ Is evaluation of the national development plan, ministries’ plans and other plans formalized/
institutionalized?
 \ How are line ministries involved in evaluation?
 \ What roles do they play regarding evaluation?
 \ How effective are public entities in managing evaluations?
 \ Is there a demand from line ministries for external evaluations? 
 \ Which type of interventions/programs/sectors are evaluated by the system?
 \ How are evaluations funded? 
 \ What type of evaluations are typically conducted (for example, design, implementation, 
outcome, and impact)?
 \ How are the credibility, independence, and impartiality of evaluations fostered?? 
 \ Are there mechanisms in place to ensure quality?
 \ What is the quality and technical rigor of the evaluations performed?
 \ Do countries have methodologies/guidance to define recommendations? 
 \ What mechanisms are there for government to share evaluation evidence and engage 
stakeholders on policy and performance matters (such as through platforms like workshops or 
public hearings)? 
 \ Is there a willingness to overcome current negative 
perceptions about evaluation in the public and 
nongovernmental sectors?
 \ Does a classification of program performance exist?
 \ What is the quality of the ToR for conducting 
evaluations?
 \ What is the degree of impartiality in evaluation 
processes?
 \ If so desired, the systems at regional level (for 
example, CARICOM) can be explored. The questions 
for the national level can be used here. 
 \ How many country-led evaluations commissioned 
or implemented by government started in the past 
two to three years?
<<<PAGE=107>>>
GEI  |  MESA Guidance notes  |  FEB 2022
107
Subsection Suggested basic questions Possible more in-depth questions
5.2 Evaluation systems at 
line ministry and subnational 
levels
In this section, it will be important to include similar questions as the ones asked for the national level, 
including additional questions about the coordination between the central government and local 
government: 
 \ Who are the custodians of the evaluation system within line ministries?
 \ Who are the custodians of the evaluation system at the state/district/municipality level?
 \ What is the extent of the coverage of the subnational evaluation custodian or evaluation unit in the 
state/local government?
 \ Are the evaluation of the state/district/municipality development plans, or of ministry/sectoral plans, 
and/or other plans formalized or institutionalized?
 \ How are subnational line ministries involved in evaluation?
 \ How effective are subnational entities in managing evaluations?
 \ What type of interventions/programs/sectors are evaluated at subnational level?
 \ How are evaluations funded? 
 \ What type of evaluations are mainly conducted at the subnational level?
 \ How are credibility, independence, and impartiality encouraged in conducting evaluations? 
 \ What is the quality and technical rigor of the evaluations performed?
 \ Are there mechanisms to ensure quality?
 \ Does the subnational level have methodologies/guidance to define recommendations? 
 \ What mechanisms are there for the subnational government to share evaluation evidence and 
engage stakeholders on policy and performance matters (such as through platforms like workshops 
or public hearings)?
 \ Are there formal and informal mechanisms for coordinating the subnational evaluation system with 
the central government system?
 \ Does subnational government produce evaluations together with the central government?
 \ Does a classification of program performance 
exist?
 \ What is the quality of the ToR for conducting 
evaluations?
 \ What is the degree of impartiality in 
evaluation processes?
<<<PAGE=108>>>
GEI  |  MESA Guidance notes  |  FEB 2022
108
Subsection Suggested basic questions
5.3 Government capacity to 
manage, commission, and 
undertake evaluations
 \ Are there skilled personnel1 in government with the technical capacity for undertaking or managing evaluations? 
 \ What is government's capacity to commission evaluations (for example, managing and sponsoring one or more evaluations)?
 \ What is government's capacity to conduct evaluations itself, either centrally or in ministries? 
 \ Is there a capacity strengthening plan for evaluation skills in government (for example, training, coaching, mentoring, technical assistance/support)?
5.4 Government capacity to 
manage and coordinate an 
evaluation system
 \ How able is government to manage and run an evaluation system (in relation to knowledge, skills, human and financial resources)? 
 \ How many evaluations have been conducted and with what coverage?
 \ What capacity is invested in the entity running evaluations and in developing the systems, such as plans, frameworks, standards and training?
 \ How effective is coordination among stakeholders in building an ecosystem across government, including with nongovernmental stakeholders? 
 \ Is government able to plan and implement a national evaluation agenda/plan?
 \ What is the involvement of a range of government institutions and non governmental stakeholders to agree on and monitor the evaluation agenda?
 \ What is the involvement of a range of government institutions and non governmental stakeholders in dialogue around the system?
Subsection Suggested basic questions Possible more in-depth questions
5.5 Capacity to undertake 
evaluations in civil society/ 
academia/the private sector
 \ Who are the local providers of evaluation services (for example, 
consulting firms, auditors, independent consultants, academia)? 
 \ To what extent are evaluations commissioned by government, donors, 
and CSOs conducted by local evaluators? 
 \ Is there a sufficient supply of quality local evaluators? 
 \ Are the country's universities producing evaluations on a systematic 
basis? 
 \ How many evaluations have been produced by non governmental 
institutions every year?
 \ What types of evaluations are done by non governmental institutions?
1  Define “skilled” before asking, for example, post-graduate qualification in M&E, experience of undertaking evaluations, and so on.
<<<PAGE=109>>>
GEI  |  MESA Guidance notes  |  FEB 2022
109
Subsection Suggested basic questions Possible more in-depth questions
5.6 Systems/incentives for 
ensuring that evaluation is 
acted upon
 \ Are there mechanisms for institutionalizing and incentivizing the use of evaluation 
evidence (for example, evaluation steering committees to institutionalize ownership of 
evaluations, or improvement plans or management responses following evaluation)?
 \ Is there a management response/improvement plan-type process to respond to 
evaluation findings and recommendations? 
 \ How is the implementation of such an improvement plan monitored?
 \ Describe how the government usually responds to negative M&E findings/evidence?
 \ When there is poor performance in an area or in a program/policy, what is the process 
to ensure adjustments and improvements happen? 
 \ What is the link between evaluation results and program/policy budget allocations?
 \ What is the greatest fear that program managers have 
around the implementation challenges arising from 
evaluations?
 \ Do program managers participate in the generation of 
recommendations as part of the evaluation process?
5.7 Use of evaluations by 
government
 \ What examples are there of evidence from government evaluations informing 
government decision making: planning (including of national development plan), 
policies, project or program management, budgeting and performance reporting?
 \ Does government draw on M&E evidence from stakeholders (for example, NGOs, think 
tanks, development partners) to inform government planning, policy, and decision 
making, and if so, how?
 \ What lessons are there from why evaluation evidence 
was used in these cases?
 \ Does the use of evaluation findings change according to 
the government cycle?
 \ Is there any evidence of evaluation findings being used 
in voluntary national reviews and in the follow-up to the 
national SDG agenda?
<<<PAGE=110>>>
GEI  |  MESA Guidance notes  |  FEB 2022
110
Subsection Suggested basic questions Possible more in-depth questions
5.8 Use of evaluations by 
parliament
 \ Do parliamentary portfolio committees consider government or non 
governmental evaluations in their oversight and legislative work?
 \ Do parliamentary portfolio committees commission evaluative studies 
from their parliamentary researchers?
 \ Does parliament draw on evidence from non governmental stakeholders 
(for example, NGOs, think tanks, development partners) to inform their 
work?
 \ What are the key challenges affecting the use of evaluative evidence in 
parliament?
 \ Are there sufficient capacities within parliament (for example, parliament 
M&E/research units and portfolio committees) to draw on and utilize 
M&E evidence?
 \ Are there sufficient capacities within parliament (for example, parliament 
M&E/research units) to undertake evaluative studies, including 
synthesizing from existing evaluations?
5.9 Use of evaluations by civil 
society and the media
 \ Is there evidence from civil society demanding evaluations 
of government programs (pressuring government to do 
evaluations, or to be able to access evaluations)?
 \ Are there examples of NGOs using government evaluations to 
put pressure on government about results ex post and about 
policy choices ex ante?
 \ How often does the media shows information coming from the 
evaluation system?
 \ Are results of government evaluations commonly used in public 
discourse and in the media?
 \ Is there evidence of CSOs sharing with government evidence 
from their evaluations of programs, and advocating for changes/
scale-ups?
5.10 Role of civil society 
in government evaluation 
systems
 \ Do civil society organizations or representatives play specific roles in 
structures and systems related to government evaluations (for example, 
steering committees, a national evaluation council)?
 \ What is the role of VOPEs in the national and subnational M&E systems? 
 \ How involved are citizens, civil society organizations, or other actors in 
specific government evaluations?
 \ What is the degree of maturity of VOPEs?
 \ See also questions on VOPEs in section 3.
<<<PAGE=111>>>
GEI  |  MESA Guidance notes  |  FEB 2022
111
6. Overall findings, conclusions, and recommendations
The MESA should result in objective and credible findings. As in evaluations, these findings should provide a solid analysis and be the basis for developing a 
collaborative improvement plan with the country. They should also enable the country to proceed with acting on some of these issues immediately. This section 
covers these elements.
Subsection Suggested basic questions Possible more in-depth questions
6.1 Overview of the M&E 
ecosystem and how it 
functions
 \ What is the overall picture of the current M&E ecosystem? (In three 
to four paragraphs this can provide a baseline to compare against in 
future.) 
6.2 Areas that are working 
well and areas that are 
working less well
 \ What are the strengths of the system (areas that work well)?
 \ What are the weaknesses (areas that work less well)?
 \ These questions could be addressed separately and in more detail for 
monitoring systems and evaluation systems, and perhaps also for the 
use of M&E evidence.
6.3 Recommendations for 
interventions that can trigger 
wider system change and 
development outcomes
 \ What are the opportunities for M&E capacity development that would 
appear to have the most significant effect, be easiest to implement, and 
have in-country support?
 \ Is there an obvious order of priority, bearing in mind the interests of 
government?
6.4 Conclusions  \ What are your overall conclusions on the state of the PBM&E systems?
 \ What are your recommendations for action in key areas?
<<<PAGE=112>>>
www.globalevaluationinitiative.org