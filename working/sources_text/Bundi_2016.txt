<<<PAGE=1>>>
Article
What Do We Know About
the Demand for Evaluation?
Insights From the
Parliamentary Arena
Pirmin Bundi1
Abstract
Research on evaluation has mainly focused on the use of evaluation and has given little attention to
the origins of evaluation demand. In this article, I consider the question of why parliamentarians
demand evaluations with parliamentary requests. Building on the literature of delegation, I use a
principal-agent framework to explain the origins of evaluation demand. In doing so, I argue that the
parliamentarians mainly demand evaluations in order to hold the government accountable. The
quantitative analysis shows that Swiss parliamentarians demand more evaluations if they have the
impression that the administration does not implement the policies within their meaning. This
finding suggests that parliamentarians demand evaluations in order to fulfill their oversight function
towards the government. This conclusion could be relevant in order to understand the role of
evaluations within the parliamentary arena.
Keywords
evaluation theory, evaluation practice, politics, surveys
Introduction
In the last 20 years, the importance of evaluations has increased worldwide, which can be observed
due to their rising institutionalization (Barbier & Hawkins, 2012; Fouquet & Me´asson, 2009; Jacob,
Speer, & Furubo, 2015). In times of recession and austerity, evaluations are an important informa-
tion source for policy makers in order to estimate the effectiveness and efficiency of public expenses
(Frey & Widmer, 2011; Leeuw, 2009).1 Considered as an academic service, evaluations assess
government actions systematically and transparently and contribute to the successful operation of
the state in various ways (Widmer & DeRocchi, 2012, p. 14, 27). Unsurprisingly, Dahler-Larsen
(2012) argues that we live in the age of evaluation.
1 Department of Political Science, University of Zurich, Switzerland
Corresponding Author:
Pirmin Bundi, Department of Political Science, University of Zurich, Affolternstr. 56, 8050 Zurich, Switzerland.
Email: bundi@ipz.uzh.ch
American Journal of Evaluation
2016, Vol. 37(4) 522-541
ª The Author(s) 2016
Reprints and permission:
sagepub.com/journalsPermissions.nav
DOI: 10.1177/1098214015621788
aje.sagepub.com
<<<PAGE=2>>>
Even though governments spend a considerable amount of financial resources for evaluations every
year, the question about the origin of evaluations has rarely been investigated so far, since research on
evaluation has mainly focused on the use of evaluation (Alkin & Taut, 2002; Askim, 2008, 2009;
Balthasar, 2007; Cousins & Leithwood, 1986; Frey & Widmer, 2011; Henry & Mark, 2003; Johnson
et al., 2009; Kirkhart, 2000; Weiss, 1987, 1989, 1998; Whiteman, 1985). Within the political system, the
parliament is an important demander of evaluations, as evaluations are particularly useful for members
of parliament. On the one hand, evaluations provide information for the legislation in order to make a
decision (Christie, 2003, p. 9; Weiss, 1989). The evaluation reports contain information either about
what consequence policies have or what policies work.2 On the other hand, evaluations help parliaments
to fulfill their oversight function toward the government (Ba¨ttig & Schwab, 2015; Lees, 1977; Pelizzo &
Stapenhurst, 2012). Consequently, recent studies have observed an increasing importance of evaluations
in the parliaments (Jacob et al., 2015; Speer, Pattyn, & DePeuter, 2015).
Although some authors have discussed the demand for evaluation (Pattyn, 2014a, 2014b;
Toulemonde, 1999; Widmer, 2008; Zollinger, 2009), literature has so far mainly neglected the
origins of evaluation. Moreover, scholars have completely left the parliament as a demander of
evaluations out of the discussion, although parliamentarians are an important stakeholder of evalua-
tions (Vedung, 2010, p. 268). The knowledge about the parliamentarians’ motivation to demand
evaluations may lead to evaluations where parliamentarians have stronger interests to be involved.
Moreover, parliaments often ignore evaluation results (Weiss, 1999, p. 474). In order to increase the
evaluation utility for parliamentarians, one has to understand what parliamentarians are seeking in
evaluations, so that evaluators can improve the evaluation practice (Rog, 2015, p. 226). Hence, this
article aims to contribute to research on evaluation by explaining the demand for evaluations
specifically within the parliamentary arena.
In this article, I consider the question of why members of parliament demand evaluations with parlia-
mentary requests. Building on the delegation literature (Braun & Gilardi, 2006; Kiewiet & McCubbins,
1991; Strøm, Mu¨ller, & Bergman, 2006), I argue that the chain of delegation has two consequences for the
parliament in order to fulfill its oversight function. On the one hand, a parliamentarian cannot be sure
whether an agency will implement a policy in the parliament’s sense (bureaucratic drift). On the other
hand, the parliament often lacks in information in order to access the implementation by an agency
(asymmetric information). Hence, I argue that parliamentarians demand evaluations in order to hold the
government and its agencies accountable. In doing so,the article examines the hypotheses that a parlia-
mentarian’s perception of the extent of bureaucraticdrift and asymmetric information influence a parlia-
mentarian’s likelihood to demand an evaluation with parliamentary requests.
I analyze these arguments empirically with a parliamentary survey that was conducted among
Swiss parliamentarians at the national and subnational level in order to obtain information about
their relationship to evaluations. Switzerland is of particular interest, as it is characterized by an
advanced evaluation culture (Balthasar, 2007; Horber-Papazian, 2015; Horber-Papazian & Jacot-
Descombes, 2012; Jacob, 2002; Jacob & Varone, 2004; Mader, 2009). According to Jacob, Speer,
and Furubo (2015, p. 145), the Swiss parliament is characterized by a high institutionalization of
evaluation compared to other parliaments from Organisation for Economic Co-operation and Devel-
opment (OECD) member states. Moreover, a general evaluation clause was introduced in the course
of the new federal constitution in 1999, urging the Federal Assembly to ensure that federal measures
are evaluated with regard to their effectiveness (Widmer, 2007, p. 76).
This article is structured as follows: First, the second section illustrates how parliaments can
demand evaluations in Switzerland. The third section describes the concept chain of delegation and
how delegation affects the evaluation demand by the parliament. Then the fourth section presents
another group of variables, which might influence the demand for evaluations. The fifth section
introduces data and methods, together with the operationalization. Then the sixth section presents
the results of a multilevel analysis, which shows that parliamentarians are more likely to demand
Bundi 523
<<<PAGE=3>>>
evaluations with parliamentary requests if they think that the administration does not implement the
policies in their sense. Finally, the seventh section discusses the results, while the eighth section
concludes them and discusses their relevance for research on evaluation.
How Parliaments Demand Evaluations in Switzerland
Switzerland has not only developed a high degree of evaluation institutionalization, but also an
active evaluation practice, even if the administration activity is not evaluated in a comprehensive
and frequent way (Mader, 2009, p. 60). According to Jacob et al. (2015), Switzerland has the second
highest evaluation culture after Finland. In doing so, the country has the most developed institutio-
nalization of evaluation within the parliaments of all OECD member states.
Swiss parliamentarians have different possibilities in order to demand evaluations.3 In general,
one can distinguish between two different ways: On the one hand, parliamentary committees can
demand evaluations directly by commissioning specialized units with an evaluation. Although this
procedure has a legal basis, committees hesitate to go by this way in Switzerland, with the exception
of the Parliamentary Control of the Administration.4 On the other hand, individual members of
parliament can indirectly demand evaluations. In doing so, parliamentarians do not commission
evaluations directly but urge the government to evaluate a policy. Parliamentarians can either
include an evaluation clause5 into the law that obliges the agencies to conduct an evaluation and
to report about its results (Bussmann, 2005) or to submit a parliamentary request to the government.
According to Janett (2004, p. 145), Swiss parliamentarians prefer to demand evaluations with
parliamentary requests.
Parliamentarians ask for all sorts of evaluations. Bundi, Varone, Gava, and Widmer (2015)
analyzed the parliamentary requests of parliamentarians at the federal level between 2010 and
2014. In total, the members of parliament submitted 188 parliamentary requests that demanded
an evaluation, which all had different characteristics (Table 1). In doing so, the study distinguished
between the evaluation purpose, perspective, and object6. According to the analysis, the parliamen-
tarians most often demand evaluations in order to prospectively assess the effectiveness of a strat-
egy. These findings confirm the results of Balthasar (2009, p. 497), who argues that parliamentarians
are rather interested in prospective than retrospective evaluations.
In the next section, I will present the theoretical framework of with whom I plan on answering my
research questions. The relationship between the parliament and the government is characterized by
Table 1. Parliamentary Evaluations in Switzerland 2010–2014.
Evaluation Characteristic Attribute Percentage
Purpose Effectiveness 40.0
Efficiency 13.0
Benefit 17.4
Cost 29.6
Perspective Ongoing 16.3
Retrospective 32.6
Prospective 51.1
Object Single measure 25.5
Project 21.8
Program 19.2
Strategy 33.5
Policy field 0.0
Note. n ¼ 188.
524 American Journal of Evaluation 37(4)
<<<PAGE=4>>>
a principal–agent relationship, since the parliament delegates the implementation of policies to the
government (Lupia, 2003).7 Hereafter, I will argue that the delegation of policy implementation
leads to a principal–agent situation, in which evaluations help parliamentarians to oversee the
executive’s actions.
Delegation and Evaluation
A central concept in the policy cycle process is thechain of delegation, in which those authorized to
make political decisions mandate others to make such decisions on their behalf (Braun & Gilardi,
2006; Strøm, 2000; Strøm et al., 2006). In contemporary democracies, the chain of delegation starts
with an election where citizens delegate their policy preferences to politicians (Mu¨ller, Bergman, &
Strøm, 2006, pp. 19–21). The elected politicians—the parliamentarians—are responsible for trans-
forming the policy preferences into the legislation. Since they only have limited resources and lack
in specific policy knowledge, parliamentarians are not suitable for the implementation of the leg-
islation. Hence, they delegate the implementation of the policies to the government, which usually
distributes the tasks among the heads of the different government departments. The chain of delega-
tion closes when the responsible heads of the government departments delegate the implementation
of the specific policies to their public servants.
The concept of the chain of delegation was developed in the context of parliamentary democracies.
Although Strøm (2000, p. 264) argues that Switzerland is not a parliamentary system, as the govern-
ment is not dependent on the parliament’s confidence,8 the concept is also suitable for the Swiss
context. Concerning the policy process, two additional steps in the chain of delegation appear. First,
Swiss voters can not only delegate their policy preferences to their representatives through the process
of elections but also influence the policy process directly via direct democratic instruments (Linder,
Bolliger, & Rielle, 2010; Vatter, 2014). They can change the constitutions if a majority of voters and
cantons accept the proposal in a ballot. In doing so, they delegate their policy preference to the
government, which leads us to the second additional step of the Swiss chain of delegation. In general,
the government prepares the policy proposals and delegates them to the parliament—about 75%of the
bills are developed by the executives (Lu¨thi, 2014; Vatter, 2014). Although the government prepares
the policies, the parliament has a strong influence on the legislative proposals. Studies on the rate of
the amendments assume that more than 40% of the government proposals are modified within the
parliament (Jegher & Lanfranchini, 1996; Schwarz, Ba¨chtiger, & Lutz, 2011). After the parliament
has formulated the policy, the remaining process is equivalent to other parliamentary democracies. As
soon as the parliament has formulated a policy and submitted it to the government, the policy is
assigned to a particular department, which delegates the implementation to an agency (Figure 1).
In literature, it is often argued that the chain of delegation can be modeled as a principal–agent
relationship (Huber, 2000; Kiewiet & McCubbins, 1991; Mu¨ller et al., 2006). The principal–agent theory
describes the basic problems between a principala n da na g e n t( G r o s s m a n&H a r t ,1 9 8 3 ;P r a t t&Z e c -
khauser, 1991; Williamson, 1975). According to Gilardi and Braun (2002, pp. 147–148), the principal
Figure 1. The chain of delegation in Switzerland.
Bundi 525
<<<PAGE=5>>>
commissions the agent to render a service in his advantage in exchange for a certain reward. The theory is
based on the assumptions of a methodological individualism: From this point of view, the agent is
interested in reducing its effort as much as possible—as long as the principal barely can be satisfied. The
principals’ interests are insufficiently taken into account, as the agent does not inform the principal about
opportunities for action. Hence, the principal cannot control whetherthe agent accomplishes a task that
should be done while he is dependent on him. As a consequence of this dependency, the principal has to
deal with an uncertainty, if the agent proceeds in a certain way in order to achieve his goals.
According to Kiewiet and McCubbins (1991), two problems appear in the delegation process
between the parliament and the agencies, which implement the delegated tasks by the government.
First, the parliament may not approve an implementation of a certain policy by the agency. This
situation is often calledbureaucratic driftin literature, since the public servants drift away in their
interpretation of the policy from the goals of the parliament (McCubbins, Noll, & Weingast, 1989, pp.
435–440). Second, the parliament may lack in information in order to assess the policy implementa-
tion by the agency. Since the public servants know much more about the implementation of a policy
than the parliament, there is anasymmetric information between them (Banks & Weingast, 1992;
Saalfeld, 2000). As a consequence, there is uncertainty as to what extent the agency will implement a
policy in a way, which the parliament would approve. In order to reduce this uncertainty, the chain of
delegation is mirrored by a corresponding chain of accountability that runs in the opposite direction
(Mu¨ller et al., 2006, p. 19). According to Lupia (2003, pp. 44–51), the problem of bureaucratic drift
and asymmetric information gives the parliament an incentive to seek information about the govern-
ment. He argues that such information can be generated in institutions and can distinguish between ex
ante and ex post mechanisms. On the one hand, ex ante mechanisms help parliaments to learn about
their agencies before and to anticipate asymmetric information problems. On the other hand, ex post
mechanisms can be used in order to learn about the agencies’ actions after the task and to deal with
bureaucratic drift. Members of parliament have different possibilities in overseeing the administration
units in order to control them and ensure accountability. According to McCubbins and Schwartz
(1984), parliaments have a strong preference to fire alarm oversight where the parliament only
intervenes in the case of indications from the media or the civil society. In doing so, they can organize
hearings, inspections, or commission evaluations in order to fulfill their oversight function.
In Switzerland, the parliament’s oversight function is not only weakened by the direct democratic
instruments but also by the strong position of the government. Thus, the control capacity of the Swiss
parliaments is rather limited compared to other countries (Schnapp & Harfst, 2005). In order to
fulfill their oversight function, the control committees are the most important institutions for Swiss
parliaments. The committees continuously control the administration with inspections by establish-
ing subgroups, which focus on a special issue and write a report with recommendations for the
attention of the government. Though, the government is not always responsive to the recommen-
dations. Although it comments on the reports and often agrees with the findings, they put forward
good reasons why no changes are needed in the present practices. Furthermore, the control com-
mittees also have problems in dealing with the high amount of information, which is why other
instruments are taken into account (Mastronardi, 1990, pp. 139–144).
As a consequence, the Swiss parliaments cannot control the complete policy implementation
process. While hearings and inspections are difficult and costly to establish with nonpublic actors,
and the resources of the control committees are limited, members of parliaments focus on parlia-
mentary instruments (Proksch & Slapin, 2011; Wiberg, 1995). Evaluations in particular seem to be
an instrument to oversee the activities of agencies and thus to provide accountability (Jacob et al.,
2015, p. 40; Pollitt, 2006). During evaluations, agencies have to report about their activities and
provide information for parliaments. Not only do the parliamentarians gather information about a
certain policy, but also do they find out how the administration has implemented it. Moreover,
evaluations allow parliamentarians to selectively oversee the policy implementation, which they
526 American Journal of Evaluation 37(4)
<<<PAGE=6>>>
tend to prefer than monitoring all activities. Hence, parliamentarians mainly demand evaluations in
order to hold the government accountable (Speer et al., 2015; Widmer & DeRocchi, 2012). Thus,
following hypotheses are investigated:
Hypothesis 1:The bigger a parliamentarian’s perceived bureaucratic drift, the more likely a
parliamentarian will demand an evaluation with parliamentary requests.
Hypothesis 2:The stronger a parliamentarian’s perceived asymmetric information between
the parliament and the agencies, the more likely a parliamentarian will demand an evalua-
tion with parliamentary requests.
Since research on evaluation has not investigated the motivation for the parliamentary demand
for evaluations, only little is known about this topic. Hence, it seems appropriate to focus on further
explanatory factors. Building on literature about evaluations and parliaments, several aspects have to
be considered in order to answer the research question. I call this variable group the(un)usual
suspects, since some of them are known to be important for the evaluation activity in the literature,
while others are less well discussed. In the next chapter, I will explain their relevance for the
parliamentary demand for evaluations.
The (Un)Usual Suspects
In research on evaluation, the attitude toward evaluations has widely been used as an explaining
factor in several studies. According to Johnson et al. (2009, p. 384), several studies analyze the
influence of attitude on the utilization of evaluations but unfortunately find no clear evidence in the
investigated articles.9 On the other hand, the literature on evaluation capacity building (ECB) uses
the attitude toward evaluations as a requirement in order to build evaluation capacity (Labin, Duffy,
Meyers, Wandersman, & Lesesne, 2012). In both research areas, a more positive attitude toward
evaluations leads to a higher use of evaluations or ECB. There is a good reason to believe that the
individual attitude of parliamentarians toward evaluation not only varies among them but also has an
influence on the motivation to demand an evaluation (Christie, 2007; Mark & Henry, 2004). Par-
liamentarians with a more positive attitude toward evaluations are more likely to demand evalua-
tions because they are more familiar with them and they see a profit.
Hypothesis 3:The more positive a parliamentarian’s attitude toward evaluations, the more
likely a parliamentarian will demand an evaluation with parliamentary requests.
The most important characteristic of parliamentarians is their ideology. The political parties have
a different attitude toward the state or the society, which effects their behavior in the parliament.
According to Balthasar and Rieder (2009, p. 416), a parliament will rather check the administration’s
performance in cantons with a high percentage of liberals and conservatives, but the authors have not
found a significant influence. However, Frey (2012, p. 279) argues that politicians from the political
center allow themselves to be convinced by evaluations, as the political ideology moderates the
openness toward evaluations. Since they are more open for evaluative information, it does not seem
unlikely that political center parliamentarians demand evaluations with parliamentary requests more
often than a parliamentarians of a left- or a right-wing party.10
Hypothesis 4: A parliamentarian of a center party will more likely demand an evaluation
with parliamentary requests than a parliamentarian of a left- or right-wing party.
Parliaments are usually subdivided into committees, which can be distinguished between two dif-
ferent types. According to Heierli (2000, p. 18), both the federal and cantonal level know committees,
Bundi 527
<<<PAGE=7>>>
which differ in their time frame (standing and ad hoc) and their function (legislative and oversight). The
oversight committees both deal with questions about the government and administration’s actions.
While the finance committees oversee the budget, the control committees supervise the government,
the administration, and the courts. In doing so, both come across evaluations more frequently than other
parliamentarians. Since the oversight committee members are more exposed to evaluations, it is more
likely that they will more often demand evaluations than other members of parliament.
Hypothesis 5: A parliamentarian of an oversight committee will more likely demand an
evaluation with parliamentary requests than a parliamentarian, which is not a member of an
oversight committee.
As mentioned in the introduction, Switzerland has a general evaluation clause, which shall encour-
age the parliament to let the public policies be evaluated on their effectiveness. While the federal level
has known this type of evaluation clause since 1999, some cantons included a general clause in their
constitution afterwards or had it even before (Horber-Papazian, 2007, p. 137). A general evaluation
clause is an article in the constitution that suggests that public measures should be evaluated. Although
a general evaluation clause is mostly of symbolic use and does not have a binding effect, there is a
probability that this factor influences the parliamentarians’ motivation to demand an evaluation with
parliamentary requests. A general evaluation clause provides a legal foundation in order to conduct an
evaluation and foster the parliamentarians’ motivation to demand an evaluation.
Hypothesis 6:A parliamentarian in a parliament, whose constitution has a general evalua-
tion clause, will more likely demand an evaluation with parliamentary requests than a
parliamentarian in a parliament, whose constitution has no general evaluation clause.
The institutional position of a parliament toward the executive can also influence the parliamen-
tary demand for evaluations. A study from Kaiss (2010) illustrates the cantonal variation of the
parliament’s power in an index.11 While Geneva and Berne have strongly developed legislative
competences, Glarus and both Appenzell Outer Rhodes and Inner Rhodes have rather weaker
positions. I argue that the stronger the parliamentary rights are, the more the parliament will demand
evaluations because it feels at eye level with the government.
Hypothesis 7:The stronger the institutional position of the parliament toward the executive,
the more likely a parliamentarian will demand an evaluation with parliamentary requests.
In the next section, I will discuss the data and the methods that I use to examine the hypotheses. In
doing so, I discuss the parliamentary survey and the operationalization of the variables that are
included in the model.
Data and Method
The basis of this study is an online survey among the cantonal and federal members of parliament,
which was conducted during May and June 2014. The parliamentarians were asked about their
relationship to evaluations.12 In total, 1,570 parliamentarians have participated in the survey, which
comes up to a response rate of 55.3%.13 Compared to similar surveys among Swiss parliaments, this
percentage is relatively high. Brun and Siegel (2006) achieved a response rate of 21.3% in a survey
about performance reports in the context of new public management. Focusing only on the federal
level, Bu¨tikofer (2014) was even able to collect 65% in the lower and 70% in the upper house.
In order to measure the dependent variable—the demand of an evaluation with parliamentary
requests—the parliamentarians were asked if they ever submitted a request in the last 4 years in
528 American Journal of Evaluation 37(4)
<<<PAGE=8>>>
order to investigate a public policy regarding its effectiveness or efficiency. The independent
variables were also mostly collected through the online-survey. The delegation variables were
obtained by asking the parliamentarians if they agreed that the administration implements the
legislation in their meaning, or that they had enough information in order to judge the administra-
tion’s implementation. In contrast, the parliamentarian’s attitude toward evaluations is measured on
a multidimensional scale. According to Rosenberg and Hovland (1965), attitude is based on a three-
dimensional structure, which contains cognitive, affective, and behavioral components. First, the
cognitive dimension illustrates the (potential) knowledge about evaluations. Second, the affective
component indicates the parliamentarian’s benefit of an evaluation. Finally, the last dimension
indicates the behavioral intention of a parliamentarian whether the person will use an evaluation.
Hence, the parliamentarians were asked whether they read evaluation summaries, whether they think
that evaluations are useful for them, and whether they usually use evaluations in order to make
decisions. The 3 items are gathered together in a single index.14 In addition, I create a dummy
variable for parliamentarians of center parties15 and a dummy variable for the membership in an
oversight committee. Similarly, a dummy variable indicates if there is a general evaluation clause in
the cantonal or federal constitution, while the institutional position is measured by an index accord-
ing to Kaiss (2010). Moreover, I also include several control variables: age, sex, urbanity, education,
professionalization, parliament experience, board membership,16 the size of the administration, and
the expenses on the cantonal and federal level. The operationalization is summarized in Table A1 in
the Appendix, and the distribution of the variables is described in Table A2 in the Appendix.
Two aspects have to be considered when choosing a suitable method to examine the hypotheses.
First, the outcome of the dependent variable is binary, which is why I will use a logistic regression
model. Second, the data are grouped into a higher level (parliaments). Thus, the parliamentarian’s
behavior might be dependent on the parliament in which the parliamentarian is part of. Hence, a
multilevel approach is pursued, as it involves data, which is arrayed hierarchically and has several
advantages (Steenbergen & Jones, 2002). In doing so, I can integrate variables on the parliament
level in my model, which I expect to have a theoretical impact on the parliamentarian’s probability
to demand a parliamentary request. However, in this way, I also can reduce the standard errors,
which would be underestimated if the parliament variables had not been integrated in the model. In
doing so, I cluster the data with regard to the parliaments.
Through statistical analysis, I will test the two theories against each other in order to find out if the
delegation variables can explain the parliamentary demand for evaluations or if the (un)ususal
suspects play the leading part in this story. Hence, I will test different models, which distinguish
between their included variables. However, in the literature on evaluation, hardly anything is known
about the parliamentary demand for evaluations. As a consequence, I will first illustrate the distri-
bution of the dependent variable.
Results
In the survey, the parliamentarians were asked if they proposed a parliamentary request in order to
examine a state measure in the last 4 years (Figure 2). Almost 50% of the parliamentarians, which
participated in the survey, replied with no. On the other hand, nearly the same percentage (49%)
demanded an evaluation with a parliamentary request during the last 4 years. Within this group,
there is about the same share of parliamentarians that proposed only once (24%), respectively,
several times (25%). At a first glance, this percentage seems quite high. However, one has to
consider that parliamentary requests can not only be proposed by a single parliamentarian but also
by several members of parliament, especially when a committee is the initiator of the request.
Moreover, by far not all parliamentary requests successfully pass the parliamentary arena.
Bundi 529
<<<PAGE=9>>>
If the parliamentarians responded with no, they had to declare their most important reason for not
demanding an evaluation with a parliamentary request (Figure 3). According to more than 42%,n o
suitable opportunity ever arose. Twenty-six percent of the asked parliamentarians indicated that the
administration already provides enough evaluation reports. Moreover, 7% of the members of par-
liament argued that they have only been in the parliament for a short time and have not much
experience. Only few parliamentarians chose the response option that there is no need for such
studies and that evaluations should be resigned for financial reasons (each 7%). Hence, only 13%
mention rather negative reasons why they do not demand evaluations, albeit one can assume that
parliamentarians with no suitable opportunity may simply not be interested in the evaluations. This
corresponds to the responses to the question about the parliamentarian’s utilization of evaluation.17
As a next step, I will check the determinants fort h ep r o b a b i l i t yt od e m a n da ne v a l u a t i o nw i t ha
parliamentary request. In doing so, I executed six different models (Table 2). First, an ‘‘empty model’’
is tested in order to ascertain if there is any variance on the parliament level. In doing so, Model 0 has no
0%
10%
20%
30%
40%
50%
no yes, one time yes, several don't know
Figure 2. Percent of parliamentarians demanding an evaluation (n ¼ 1,499). ‘‘Did you propose a parlia-
mentary request in order to examine a state measure regarding its implementation and effects?’’
0%
10%
20%
30%
40%
no
need
administration
provides
enough
financial
reasons
no
suitable
opportunity
not
much
experience
other
reason
don't
know
Figure 3. Parliamentarians’ reason for no parliamentary requests (n ¼ 724). ‘‘Why did you not propose a
parliamentary request in order to examine a state measure regarding its implementation and effects?’’
530 American Journal of Evaluation 37(4)
<<<PAGE=10>>>
indicators on the individual- and parliament levels, suggesting some autocorrelation in the variance of
parliamentary requests on the parliament level. The likelihood ratio testshows that the error terms correlate
on the parliament level, since the variance between them does not equal to zero.18 Hence, it seems
reasonable to use a multilevel approach, which should explain thevariation at the parliament level.
Model 1 tests the explanatory strength of the delegation variables, controlling the parliamen-
tarians’ predispositions and political dispositions. As we can see, the variable bureaucratic drift
has a significant effect, which means that if a parliamentarian thinks the administration imple-
ments the legislation in the meaning of the parliament, the parliament’s probability to propose a
parliamentary request decreases. On the other hand, it seems that it has no effect if a member of
parliament thinks he has enough information to judge the implementation. However, also the
professionalization, the experience in a parliament and the membership in the parliament board
have a highly significant influence in whether an evaluation will be demanded. When the vari-
ables on the parliament level are also included, the outcome does not change remarkably (Model
2). Not only does the effect of the political dispositions stay highly significant but also the effect
of the variable bureaucratic drift. On the contrary, the size of the administration and the public
expenses do not seem to have an effect.
Table 2. Individual and Parliament Random Effects Models.
Dependent Variable: Parliamentary Request
Model 0 Model 1 Model 2 Model 3 Model 4 Model 5
Individual level
Predispositions
Age 0.679 0.687 0.600 0.661 0.840
Sex 0.134 0.129 0.200 0.208* 0.176
Urbanity 0.070 0.055 0.023 0.040 0.054
Education 0.127 0.136 0.058 0.068 0.094
Political dispositions
Professionalization 0.705** 1.015** 0.159 /C0 0.031 0.002
Parliament experience 0.026*** 0.026*** 0.029*** 0.029*** 0.028***
Board member 0.395** 0.379** 0.366** 0.384** 0.397**
Delegation
Bureaucratic drift /C0 0.338* /C0 0.350* /C0 0.523**
Asymmetric information /C0 0.006 /C0 0.006 0.039
(Un)usual suspects I
Attitude 0.704*** 0.697*** 0.728***
Center party /C0 0.053 /C0 0.077 /C0 0.151
Oversight committee 0.205* 0.206* 0.276**
Parliament level
Parliamentary disposition
Size of administration /C0 0.000 /C0 0.000 /C0 0.000*
Public expenses /C0 0.000 /C0 0.000 /C0 0.000
(Un)usual suspects II
Evaluation base 0.205* 0.229*
Institutional position 1.037 1.026
Residual variance
Between c 0.031 0.131 0.097 0.085 0.000 0.000
Parliamentarians 1,474 1,372 1,372 1,384 1,384 1,337
Log likelihood /C0 1,020.519 /C0 928.145 /C0 926.804 /C0 908.097 /C0 903.459 /C0 866.227
Note. n ¼ 28 Parliaments.
*p< .1. **p< .05. ***p< .01.
Bundi 531
<<<PAGE=11>>>
After testing the effect of the delegation variables, Model 3 checks if the variables of the group
(un)usual suspects I have an influence on the dependent variable. The parliamentarians’ attitude toward
an evaluation and the membership in an oversight committee are indeed significantly positive, while the
party ideology does not seem to be of relevance.19 In contrast, the professionalization of a parliamentar-
ian is no longer significant. This finding indicates that the effect of professionalization in Models 2 and 3
is probably not robust. A possible explanation could be an interfering effect of the (un)usual suspects I
variables. In Model 4, the variables on the higher level are added as well as the parliamentary disposition
and the (un)usual suspects II. Compared to Model 3, the coefficients stay stable. While the evaluation
base in the cantonal and federal constitution only has a weakly significant effect on the parliamentarian’s
likelihood to demand an evaluation, the institutional position has no influence at all.
In Model 5, I combine the delegation variables and the (un)usual suspects. The full model
confirms the prior results and provides evidence for Hypotheses 1, 3, and 5 and tends to reject
Hypotheses 2, 4, 6, and 7. First, the perceived bureaucratic drift seems to influence a parliamentar-
ian’s likelihood to demand an evaluation, while the asymmetric information has no influence.
Second, the parliamentarians’ predispositions do not seem to be important, but their political dis-
positions indeed play a crucial role. Third, the un(us)al aspects have no influence on the parliamen-
tarian’s motivation to demand an evaluation, apart from the attitude toward evaluations and the
Attitude
Predicted Probability
0.2
0.3
0.4
0.5
0.6
0.7
Board Member
Predicted Probability
0.45
0.50
0.55
0.60
0.65
Bureaucratic Drift
Predicted Probability
0.45
0.50
0.55
0.60
0.65
0.70
Evaluation Base
Predicted Probability
0.42
0.44
0.46
0.48
0.50
0.52
0.54
0.56
1.0 1.5 2.0 2.5 3.0 3.5 4.0
0.0 0.2 0.4 0.6 0.8 1.0
0.0 0.2 0.4 0.6 0.8 1.0
0.0 0.2 0.4 0.6 0.8 1.0
Figure 4. Individual probability to demand an evaluation with parliamentary requests.
532 American Journal of Evaluation 37(4)
<<<PAGE=12>>>
membership in an oversight committee. The effects of the variables can also be observed in the
predicted probability to demand an evaluation (Figure 4).
The figure illustrates the individual propensity to demand an evaluation for the effect of the
variable’s bureaucratic drift, attitude, board member, and evaluation base.20 As the graphs show, the
strongest effect can be observed between a parliamentarian with a negative attitude and a parlia-
mentarian with a high one. The other variables have a less strong effect, but also the 95% confidence
interval is broader.
Discussion
In the end, who demands evaluations in the parliament? The statistical analysis provides some evi-
dence that those parliamentarians demand evaluations who want to hold the government accountable.
Since they have the impression that the agencies might not implement the policies in their sense,
parliamentarians seem to take evaluations as an instrument in order to fulfill their oversight function.
Hence, it is not surprising that parliamentarians in an oversight committee tend to demand more
evaluations than their colleagues who are not. In addition, a parliamentarian needs to have a positive
attitude toward the instrument evaluation in order to request it. The analysis also shows that more
experienced members and members in a leading position (parliament board members) demand more
evaluations, which suggests that they are more sensible to accountability than their colleagues. As a
consequence, the evidence from the analysis suggests that the parliamentarians see themselves as
principals who want to control the agent, in form of the bureaucratic agencies. Moreover, these
findings confirm other studies that suggest that parliamentary requests are an important instrument
in order to perform oversight (Martin & Vanberg, 2008; Proksch & Slapin, 2011). As Wiberg (1995)
argues that parliaments rather control the government by threatening it with a vote of confidence than
by parliamentary requests, the latter receives an even more important role, since the Swiss parliament
cannot dissolve the government. However, since the exertion of such instruments are time consuming,
members of parliament demand evaluations sparingly.
These conclusions could be very relevant for the literature on evaluation use and the evaluation
practice. In the last 15 years, several scholars have argued that research on evaluation should shift
from evaluation useto evaluation influencein order to capture advanced impacts and consequences
of evaluations (Kirkhart, 2000; Mark & Henry, 2004). However, Herbert (2014, p. 412) argues that
present studies on evaluation influence have several limitations. On the one hand, the studies rely
mostly on the information from the evaluator, whose perspective could be biased. On the other hand,
several studies focus on self-reports by organizational stakeholders that have an interest to be
perceived as an evidence-based organization. Hence, the findings of this study provide important
new insights from the parliamentary arena, an important stakeholder of policy evaluations (Vedung,
2010). The findings mostly coincide with those of Speer, Pattyn, and DePeuter (2015), who have
investigated the evaluation demand in the Flemish and in the German parliament. Compared to these
parliaments, the Swiss case can be classified between them. While Swiss members of parliaments
rather ask for evaluations for reasons of accountability than to use the evaluation information as in
Germany, parliamentarians from opposition and government parties do not differ from each other in
their evaluation demand as in Flanders. This is not surprising, since Switzerland is considered as a
consensus democracy, which involves a substantial share of parties in the government (Lijphart,
2012; Sciarini, Fischer, & Traber, 2015). The results imply an important message: If an evaluation
wants to be relevant and influential for a parliament, it should rather focus on accountability than
on learning. Evaluators can enhance the utility of evaluations when they pay attention to the
parliamentarians’ needs. This conclusion corresponds with the findings of Borra´s and Højlund
(2015, p. 114) that the main learners of evaluations are program units and not external stakeholders
(e.g., parliaments).
Bundi 533
<<<PAGE=13>>>
Conclusion
In the last 20 years, evaluations have established themselves as an important instrument to assess
public policies. In research on evaluation, the motivation for the production of evaluations has rarely
been investigated empirically so far. Moreover, the role of the parliament has completely been
neglected in this discussion, although an evaluation is an important tool for the members of parlia-
ment. In this article, I have developed the argument that parliamentarians demand evaluations in
order to hold the government accountable. The statistical analysis of the parliamentary requests
demanding an evaluation indicates that Swiss parliamentarians ask more likely for evaluations, if
they think that the administration does not implement the policies in their sense.
This study has also some limitations. When conducting a survey, different sources of measurement
errors can additionally occur that may question the analytical power of the sample, even if the number
of participants is sufficient. Generally, there are two main problems: On the one hand, the representa-
tiveness of the sample can be biased by the members of parliament who did not participate, since the
nonresponses might differ significantly from the responses of the participants (self-selection). On the
other hand, the responses are reported directly by the parliaments themselves. Since the members of
parliament have to remember their past actions on evaluations, they are likely to under- or over-
estimate their activities (misreporting). In addition, the findings are limited due to the fact that only
one country was investigated, although Switzerland is very appropriate for these research questions,
since it is characterized by a high evaluation institutionalization. However, more studies from other
countries would help explain the demand for evaluations. Moreover, it would also help to understand
whether the strong evaluation culture affects the evaluation demand by the parliament. The analysis
suggests that the individual factors are more important than the context, even if the evaluation culture
might influence all parliamentarians. This finding alludes that the analysis provides information on the
parliamentary evaluation demand that goes beyond the case of Switzerland.
This article offers strong empirical evidence for the explanation of the motivation behind the
parliamentary demand for evaluations due to a new database which was gathered by conducting a
survey. Until now, only selective aspects have been researched in the relationship between parlia-
ments and evaluations. Although plausible arguments were discussed in this article, it is clear that
more research has to be done in order to understand the role of evaluations in parliaments. In my
opinion, this article is a useful starting point for such research.
Appendix
Table A1. Operationalization of The Variables.
Variable Operationalization Source ER HYP
Dependent variable
Parliamentary request In the last 4 years, did you propose a
parliamentary request in order to examine a
state measure with regard to implementation
and impact? Dummy: 0 forno, 1 foryes
Parliament survey
Individual level
Predispositions
Age Age of a parliamentarian in years rescaled on a
scale of 0–1
Parliament survey
Sex Dummy: 0 for male, 1 forfemale Parliament survey
Urbanity Place of residence—Urbanity Parliament survey
Dummy: 0 forrural, 1 forurban
(continued)
534 American Journal of Evaluation 37(4)
<<<PAGE=14>>>
Table A1.(continued)
Variable Operationalization Source ER HYP
Education What is your highest degree of education?
Dummy: 0 forunder pedagogical university, 1 for
pedagogical university and upper
Parliament survey
Political disposition
Professionalization Over the last year, what is the amount of time
spent for your parliament mandate, in
percentage of a full-time job?
Parliament survey
Scale of 0–100
Parliament experience How many years of experience do you have in a
communal, cantonal, and/or national
parliament?
Parliament survey
Total years
Individual level
Political disposition
Board member Membership in the parliament office Parliament survey
Dummy: 0 forno, 1 foryes
Delegation
Bureaucratic drift Generally, the administration implements the
legislation within the meaning of the parliament
Parliament survey — C
Dummy: 0 foragree, 1 fordisagree
Asymmetric information The parliament has enough information to judge
the administration’s implementation of the
legislation
Parliament survey — F
Dummy: 0 foragree, 1 fordisagree
(Un)usual suspects I
Attitude Index of three dimensions: Parliament survey þ C
During the last 4 years, how many times did you
read an evaluation summary?
Evaluation is a useful instrument for me as a
member of parliament
Whenever possible, my political decisions are
supported by evaluation or other studies
Scale between 1¼ never/strongly disagree and
4 ¼ very frequently/strongly agree
Center party Membership in a center party Parliament survey þ F
Dummy: 0 forno, 1 foryes
Oversight committee Membership in an oversight committee Parliament survey þ C
Dummy: 0 forno, 1 foryes
Parliament level
Political disposition
Size of administration Size of administration Badac (2008)
Number of employees of the public
administration
EPA (2014)
Public expenses Public expenses per inhabitant in Swiss francs
(CHF)
Badac (2010)
(Un)usual suspects II
Evaluation base General evaluation clause in the cantonal/federal
constitution
Horber-Papazian
(2007, supp.)
þ C
Dummy: 0 forno, 1 foryes
Institutional position Institutional position of the parliament toward
the government
Kaiss (2010, supp.)þ F
Note.E R¼ Expected relationship; HYP¼ Hypothesis corroborated (C) or proven false (F); supp¼ Data supplemented.
Bundi 535
<<<PAGE=15>>>
Acknowledgment
Previous versions of this article were presented at the SynEval Workshop 2014 (Lausanne, Switzerland) and the
11th EES Biennial Conference 2014 (Dublin, Ireland). I thank all the participants for their feedback. In
addition, I would like to thank Daniela Eberli, Kathrin Frey, Augusta Prorok, Fre´de´ric Varone, and Thomas
Widmer for their helpful comments. Special thanks go to Vanessa Di Giorgi, Gwenyfar Gubler, Mika¨el Re´din
and Benjamin Schlegel for their excellent research assistance.
Declaration of Conflicting Interests
The author(s) declared no potential conflicts of interest with respect to the research, authorship, and/or
publication of this article.
Funding
The author(s) received the following financial support for the research, authorship, and/or publication of this
article: This work was supported by the Swiss National Science Foundation (grant number 141893).
Notes
1. In the literature, it is widely discussed, which role evaluations played during the financial crisis. While
some authors see an increasing amount of evaluations due to the austerity, others argue that evaluations do
not seem to have helped policy makers to solve the dilemma of spending (Curristine & Flynn, 2013, p. 126;
Marra, 2013).
2. Retrospective evaluations are well discussed in the context of evidence-based policy making (EBPM).
According to EBPM, evidence should take the center stage in the decision-making process in order to make
more effective policies (Davis, Nutley, & Smith, 2000). In contrast, prospective evaluations as Regulatory
Impact Assessments appraise policies ex ante in order to inform decision makers. As such, evaluations
predict and evaluate the consequences of an intended public policy under specific conditions, they can help
parliamentarians to make better regulations (Rissi & Sager, 2013, p. 348).
3. In this article, an evaluation is defined as a report or document that systematically and transparently
assesses the effectiveness, efficiency, benefit, and/or costs of a policy.
Table A2. Descriptive Statistic of All Variables.
Variable Observations Mean SD Min Max
Parliamentary request 1,474 0.493 0.500 0 1
Age 1,570 0.517 0.102 0.21 0.83
Sex 1,570 0.301 0.459 0 1
Urbanity 1,570 0.643 0.479 0 1
Education 1,481 0.511 0.500 0 1
Professionalization 1,483 0.239 0.161 0 1
Parliament experience 1,486 10.576 8.330 0 56
Board member 1,570 0.147 0.348 0 1
Bureaucratic drift 1,486 0.915 0.278 0 1
Asymmetric information 1,448 0.711 0.454 0 1
Attitude 1,508 2.719 0.628 1 4
Center party 1,570 0.452 0.498 0 1
Oversight committee 1,492 0.396 0.489 0 1
Size of administration 1,570 17,810.630 17,108.07 344 57,747
Public expenses 1,570 13,291.960 3,527.737 7,530 23,662
Evaluation base 1,570 0.571 0.495 0 1
Institutional position 1,570 0.608 0.108 0.28 0.76
536 American Journal of Evaluation 37(4)
<<<PAGE=16>>>
4. The Parliamentary Control of the Administration is the competence center of the Federal Assembly in
matters of evaluations and conducts evaluations on behalf of the control committee. The unit only exists on
the federal level, yet its function is partly fulfilled by the cantonal audit offices (Gru¨ter, 2013, p. 650). Since
1993, they have conducted 62 evaluations: http://www.parlament.ch/pvk (Last update: 9/2/2015).
5. Bussmann (2005, pp. 97–99) distinguishes between four different types of evaluation clauses: General, insti-
tutionally focused and area-field-focused evaluation clauses, and evaluation clauses for para-state institutions.
6. Policy evaluations can target different levels of policies. Widmer and DeRocchi (2012, p. 26) differ
between five levels. Single measure, project (several measures and temporary), program (several measures,
perpetual), strategy (several projects or programs), and policy field.
7. The principal–agent theory is rarely ever used in research on evaluation. Although Vedung (2008) used the
framework prominently in order to distinguish between political actors in an evaluation context, there are
only few other examples (Clements, Chianca, & Sasaki, 2008; Van Thiel & Leeuw, 2002).
8. The Federal Council—the Swiss government—is elected inthe beginning of the legislature by the parliament for 4
years. However, the parliament is not able to dissolve the government. Unless the members of the Federal Council
resign, they stay in their position for the complete legislature (Klo¨ti, Papadopoulos, & Sager, 2014, p. 195).
9. The latest investigation suggests rather no effect on the evaluation utilization. According to Bogenschnei-
der, Little, and Johnson (2013, p. 266), parliamentarians from New York and Wisconsin do not often use
evaluations, although they have quite a positive attitude toward them.
10. In addition, Speer et al. (2015, p. 45) argue that DIE LINKE in Germany has the highest interest in EBPM,
but it remains unclear whether this result is due to ideological preferences or to their opposition role.
11. The index measures the parliament’s power toward the government and is based on the three main
functions of the parliament: election, legislation, and oversight. In total, 17 indicators are used for the
measurement (e.g., possibility to elect the head of the government, right to initiative legislation, power of
the committees, etc.). For more information, see Kaiss (2010).
12. As parliamentarians have a broad understanding of an evaluation, the survey gave a definition in the introduction:
‘‘In this survey, evaluations are interpreted as studies, reports or other documents, which assess a state’s measure
in a systematic and transparent way with respect to their effectiveness, efficiency, or fitness for purpose.’’
13. N ¼ 2,841. Note that some seats were vacant due to parliamentarians’ withdrawals.
14. Cronbach’sa of the 3 items is .69; they correlate significantly on the 99% level.
15. Following parties are considered as a center party: Free Democratic Party, The Liberals, Christian Dem-
ocratic People’s Party, Green Liberal Party, Conservative Democratic Party, Evangelical People’s Party,
and Christian Social Party.
16. The parliament board is responsible for the organization and for the procedures of the parliament and thus
has a leading function.
17. The parliamentarians were asked if they use evaluations for legislation (11% never), oversight (13%), and
budget-making decisions (12%).
18. c is significant at the 10% level.
19. Concerning the party ideology, I also tested the effects for every single party as well as for the two party
groups ‘‘left parties’’ and ‘‘right parties.’’ There were no significant effects for these variables.
20. All other individual and contextual determinants are at the median.
References
Alkin, M. C., & Taut, S. M. (2002). Unbundling evaluation use.Studies in Educational Evaluation, 29, 1–12.
Askim, J. (2008). Determinants of performance information utilization in political decision making. In W. V.
Dooren & S. V. de Walle (Eds.),Performance information in the public sector(pp. 125–139). New York,
NY: Palgrave Macmillan.
Askim, J. (2009). The demand side of performance measurement: Explaining councilors’ utilization of per-
formance information in policymaking.International Public Management Journal, 12, 24–47.
Bundi 537
<<<PAGE=17>>>
Badac. (2008). Personal der O¨ffentlichen Zentralverwaltungen nach Rechtsform (NOGA 2008) (VZS). Lau-
sanne, Switzerland: IDHEAP.
Badac. (2010).Gesamtausgaben pro Einwohner (Kanton, Gemeinden). Lausanne, Switzerland: IDHEAP.
Balthasar, A. (2007).Institutionelle Verankerung und Verwendung von Evaluationen.Z u¨rich/Chur, Switzer-
land: Ru¨egger Verlag.
Balthasar, A. (2009). Evaluationen in der Schweiz: Verbreitung und Verwendung. In T. Widmer, W. Beywl, &
C. Fabian (Eds.), Evaluation. Ein systematisches Handbuch (pp. 486–497). Wiesbaden, Germany: VS
Verlag fu¨r Sozialwissenschaften.
Balthasar, A., & Rieder, S. (2009). Wo ist evidenzbasierte Politik mo¨glich? Die Verbreitung von Evaluationen
auf kantonaler Ebene. In A. Vatter, F. Varone, & F. Sager (Eds.),Demokratie als Leidenschaft. Planung,
Entscheidung und Vollzug in der schweizerischen Demokratie(pp. 115–129). Zu¨rich/Chur, Switzerland:
Ru¨egger Verlag.
Banks, J. S., & Weingast, B. R. (1992). The political control of bureaucracies under asymmetric information.
American Journal of Political Science, 36, 509–524.
Barbier, J.-C., & Hawkins, P. (2012).Evaluation cultures. Sense-making in complex times. New Brunswick, NJ:
Transaction Press.
Ba¨ttig, C., & Schwab, P. (2015). La place de l’e´valuation dans le cadre du controˆle parlementaire. In K. Horber-
Papazian (Ed.), Regards croise´s sur l’e´valuation en Suisse (pp. 1–23). Lausanne, Switzerland: Presses
Polytechniques et Universitaires Romandes.
Bogenschneider, K., Little, O. M., & Johnson, K. (2013). Policymakers’ use of social science research: Looking
within and across policy actors.Journal of Marriage and Family, 75, 263–275.
Borra´s, S., & Højlund, S. (2015). Evaluation and policy learning: The learners’ perspective.European Journal
of Political Research, 54, 99–120.
Braun, D., & Gilardi, F. (2006).Delegation in contemporary democracies. New York, NY: Routledge.
Brun, M. E., & Siegel, J. P. (2006). What does appropriate performance reporting for political decision makers
require? Empirical evidence from Switzerland.International Journal of Productivity and Performance
Management, 55, 480–497.
Bundi, P., Varone, F., Gava, R., & Widmer, T. (2015).Self-selection and misreporting in legislative surveys
(Unpublished Working Paper). Zurich, Switzerland: University of Zurich and University of Geneva.
Bussmann, W. (2005). Typen und Terminologie von Evaluationsklauseln.LeGes - Gesetzgebung und Evalua-
tion, 16, 97–102.
Bu¨tikofer, S. (2014).Das Schweizer Parlament: Eine Institution auf dem Pfad der Moderne. Baden-Baden,
Germany: Nomos.
Christie, C. A. (2003). What guides evaluation? A study of how evaluation practice maps onto evaluation
theory. New Directions for Evaluation, 2003, 7–36.
Christie, C. A. (2007). Reported influence of evaluation data on decision makers’ actions. An empirical
examination. American Journal of Evaluation, 28, 8–25.
Clements, P., Chianca, T., & Sasaki, R. (2008). Reducing world poverty by improving evaluation of develop-
ment aid.American Journal of Evaluation, 29, 195–214.
Cousins, J. B., & Leithwood, K. A. (1986). Current empirical research on evaluation utilization.Review of
Educational Research, 56, 331–364.
Curristine, T., & Flynn, S. (2013).In search of results: Strengthening public sector performance. Washington,
DC: International Monetary Fund.
Dahler-Larsen, P. (2012).The evaluation society. Stanford, CA: Stanford University Press.
Davis, H. T., Nutley, S. M., & Smith, P. C. (2000).What works? evidence-based policy and practice in public
services. Bristol, England: The Policy Press.
Eidgeno¨ssisches Personalamt (EPA). (2014).Stellenbestand der Bundesverwaltung. Bern, Switzerland: Author.
Fouquet, A., & Me´asson, L. (2009).L’e´valuation des politiques publiques en Europe: Culture et futurs. Paris,
France: Editions L’Harmattan.
538 American Journal of Evaluation 37(4)
<<<PAGE=18>>>
Frey, K. (2012).Evidenzbasierte Politikformulierung in der Schweiz. Gesetzesrevisionen im Vergleich. Baden-
Baden, Germany: Nomos.
Frey, K., & Widmer, T. (2011). Revising Swiss policies: The influence of efficiency analyses.American
Journal of Evaluation, 32, 494–517.
Gilardi, F., & Braun, D. (2002). Delegation aus der Sicht der Prinzipal-Agent-Theorie.Politische Vierteljah-
resschrift, 43, 147–161.
Grossman, S. J., & Hart, O. D. (1983). An analysis of the principal-agent problem.Econometrica: Journal of the
Econometric Society, 51, 7–45.
Gru¨ter, K. (2013). Finanzkontrolle. In A. Ladner, et al. (Eds.),Handbuch der o¨ffentlichen Verwaltung in der
Schweiz.Z u¨rich, Switzerland: Verlag Neue Zu¨rcher Zeitung.
Heierli, C. (2000).Die Sta¨rke der Kommissionen in den 26 Kantonalen Parlamenten: Arbeits oder Redeparla-
mente? Bern, Switzerland: Lizentiatsarbeit an der Universita¨t Bern.
Henry, G. T., & Mark, M. M. (2003). Beyond use: Understanding evaluation’s influence on attitudes and
actions. American Journal of Evaluation, 24, 293–314.
Herbert, J. L. (2014). Researching evaluation influence. A review of the literature.Evaluation Review, 38,
388–419.
Horber-Papazian, K. (2007). La place de l’e´valuation des politiques publiques en suisse. In J.-L. Chappelet
(Ed.), Contributions a` l’action publique - Beitra¨ge zum o¨ffentlichen Handeln (pp. 131–144). Bern,
Switzerland: Haupt.
Horber-Papazian, K. (2015).Regards croise´s sur l’e´valuation en Suisse. Lausanne, Switzerland: Presses Poly-
techniques et Universitaires Romandes.
Horber-Papazian, K., & Jacot-Descombes, C. (2012). Is evaluation culture shaped by the Swiss political system
and multiculturalism? In J.-C. Barbier & P. Hawkins (Eds.),Evaluation cultures. Sense-making in complex
times (pp. 89–104). New Brunswick, NJ: Transaction Press.
Huber, J. D. (2000). Delegation to civil servants in parliamentary democracies.European Journal of Political
Research, 37, 397–413.
Jacob, S. (2002).L’institutionnalisation de l’e´valuation des politiques publiques en Suisse. Louvain-la-Neuve,
Belgium: Universite´ Catholique.
Jacob, S., Speer, S., & Furubo, J.-E. (2015). The institutionalization of evaluation matters: Updating the
international atlas of evaluation 10 years later.Evaluation, 21, 6–31.
Jacob, S., & Varone, F. (2004). Cheminement institutionnel de l’e´valuation des politiques publiques en France,
en Suisse et aux Pays-Bas (1970–2003).Politiques et Management Public, 22, 135–152.
Janett, D. (2004). Die Evaluationsbilanz des Bundesparlamentes - eine Zwischenbilanz.LeGes - Gesetzgebung
und Evaluation, 15, 137–150.
Jegher, A., & Lanfranchini, P. (1996).Der Einfluss von National- und Sta¨nderat auf den Gesetzgebungspro-
zess: Eine Analyse quantitativer und qualitativer Aspekte der parlamentarischen Gesetzgebungsta¨tigkeit in
der 44. Legislaturperiode (1991–1995). Bern, Switzerland: Institut fu¨r Politikwissenschaft der Universita¨t
Bern und Parlamentsdienste.
Johnson, K., Greenseid, L. O., Toal, S. A., King, J. A., Lawrenz, F., & Volkov, B. (2009). Research on evaluation
use. A review of the empirical literature from 1986 to 2005.American Journal of Evaluation, 30, 377–410.
Kaiss, S. (2010).Das Verha¨ltnis zwischen Exekutive und Legislative in den Schweizer Kantonen: Das Ausmass
der Exekutivdominanz auf kantonaler Ebene.Z u¨rich, Switzerland: Lizentiatsarbeit an der Universita¨t Zu¨rich.
Kiewiet, R. D., & McCubbins, M. D. (1991).The logic of delegation. Chicago, IL: University of Chicago Press.
Kirkhart, K. E. (2000). Reconceptualizing evaluation use: An integrated theory of influence.New Directions for
Evaluation, 2000, 5–23.
Klo¨ti, U., Papadopoulos, Y., & Sager, F. (2014). Regierung. In P. Knoepfel, Y. Papadopoulos, P. Sciarini, A. Vatter,
&S .H a¨usermann (Eds.),Handbuch der Schweizer Politik(pp. 193–218). Zu¨rich, Switzerland: NZZ Libro.
Labin, S. N., Duffy, J. L., Meyers, D. C., Wandersman, A., & Lesesne, C. A. (2012). A research synthesis of the
evaluation capacity building literature.American Journal of Evaluation, 33, 307–338.
Bundi 539
<<<PAGE=19>>>
Lees, J. D. (1977). Legislatures and oversight: A review article on a neglected area of research.Legislative
Studies Quarterly, 2, 193–208.
Leeuw, F. (2009). Evaluation policy in the Netherlands.New Directions for Evaluation, 2009, 87–102.
Lijphart, A. (2012).Patterns of democracy: Government forms and performance in thirty-six countries. New
Haven, CT: Yale University Press.
Linder, W., Bolliger, C., & Rielle, Y. (2010).Handbuch der eidgeno¨ssischen Volksabstimmungen 1848-2007.
Bern, Switzerland: Haupt.
Lupia, A. (2003). Delegation and its perils. In K. Strøm, W. C. Mu¨ller, & T. Bergman (Eds.),Delegation and
accountability in parliamentary democracies(pp. 33–54). Oxford, England: Oxford University Press.
Lu¨thi, R. (2014). Parlament. In P. Knoepfel, Y. Papadopoulos, P. Sciarini, A. Vatter, & S. Ha¨usermann (Eds.),
Handbuch der Schweizer Politik(pp. 169–192). Zu¨rich, Switzerland: NZZ Libro.
Mader, L. (2009). Die institutionelle Einbettung der Evaluationsfunktion in der Schweiz. In T. Widmer, W.
Beywl, & C. Fabian (Eds.),Evaluation. Ein systematisches Handbuch(pp. 52–63). Wiesbaden, Germany:
VS Verlag fu¨r Sozialwissenschaften.
Mark, M. M., & Henry, G. T. (2004). The mechanisms and outcomes of evaluation influence.Evaluation, 10,
35–57.
Marra, M. (2013). Shifting economic paradigms: Can evaluation help solve the European dilemma of public
spending? In J.-E. Furubo, R. C. Rist, & S. Speer (Eds.),Evaluation and turbulent times: Reflections on a
discipline in disarray(pp. 109–130). New Brunswick, NJ: Transaction Publishers.
Martin, L. W., & Vanberg, G. (2008). Coalition government and political communication.Political Research
Quarterly, 61, 502–516.
Mastronardi, P. (1990). Parlamentarische Verwaltungskontrolle: Aufgaben und Entwicklungsmo¨glichkeiten
in der Schweiz. In P. Stadlin (Ed.),Die Parlamente der schweizerischen Kantone(pp. 137–149). Zug,
Switzerland: Verlag Kalt-Zehnder.
McCubbins, M. D., Noll, R. G., & Weingast, B. R. (1989). Structure and process, politics and policy:
Administrative arrangements and the political control of agencies. Virginia Law Review , 75,
431–482.
McCubbins, M. D., & Schwartz, T. (1984). Congressional oversight overlooked: Police patrols versus fire
alarms. American Journal of Political Science, 28, 165–179.
Mu¨ller, W. C., Bergman, T., & Strøm, K. (2006). Parliamentary democracy: Promise and problems. In K.
Strøm, W. C. Mu¨ller, & T. Bergman (Eds.),Delegation and accountability in parliamentary democracies
(pp. 3–32). Oxford, England: Oxford University Press.
Pattyn, V. (2014a).Policy evaluation (in)activity unraveled. Leuven, Belgium: KU Leuven.
Pattyn, V. (2014b). Why organisations (do not) evaluate? Explaining evaluation activity through the lens of
configurational comparative methods.Evaluation, 20, 348–367.
Pelizzo, R., & Stapenhurst, R. (2012).Parliamentary oversight tools: An comparative analysis. New York, NY:
Routlegde.
Pollitt, C. (2006). Performance information for democracy. The missing link?Evaluation, 12, 38–55.
Pratt, J. W., & Zeckhauser, R. (1991).Principals and agents. Boston, MA: Harvard Business School Press.
Proksch, S.-O., & Slapin, J. B. (2011). Parliamentary questions and oversight in the European Union.European
Journal of Political Research, 50, 53–79.
Rissi, C., & Sager, F. (2013). Types of knowledge utilization of regulatory impact assessments: Evidence from
Swiss policymaking.Regulation & Governance, 7, 348–364.
Rog, D. J. (2015). Infusing theory into practice, practice into theory small wins and big gains for evaluation.
American Journal of Evaluation, 36, 223–238.
Rosenberg, M. J., & Hovland, C. I. (1965).Cognitive, affective, and behavioural components. New Haven, CT:
Yale University Press.
Saalfeld, T. (2000). Members of parliament and governments in Western Europe: Agency relations and
problems of oversight.European Journal of Political Research, 37, 353–376.
540 American Journal of Evaluation 37(4)
<<<PAGE=20>>>
Schnapp, K.-U., & Harfst, P. (2005). Parlamentarische Informations- und Kontrollressourcen in 22 westlichen
Demokratien. Zeitschrift fu¨r Parlamentsfragen, 36, 348–370.
Schwarz, D., Ba¨chtiger, A., & Lutz, G. (2011). Switzerland: Agenda-setting power of the government in a
seperation-of-powers framework. In J. E. Rasch & G. Tsebelis (Eds.),The role of governments in legislative
agenda setting(pp. 127–143). London, England: Routledge.
Sciarini, P., Fischer, M., & Traber, D. (2015).Political decision-making in Switzerland: The consensus model
under pressure. Basingstoke, England: Palgrave Macmillan.
Speer, S., Pattyn, V., & DePeuter, B. (2015). The growing role of evaluation in parliaments: Holding govern-
ments accountable.International Review of Administrative Sciences, 81, 37–57.
Steenbergen, M. R., & Jones, B. S. (2002). Modeling multilevel data structures.American Journal of Political
Science, 46, 218–237.
Strøm, K. (2000). Delegation and accountability in parliamentary democracies.European Journal of Political
Research, 37, 261–290.
Strøm, K., Mu¨ller, W. C., & Bergman, T. (2006).Delegation and accountability in parliamentary democracies.
Oxford, England: Oxford University Press.
Toulemonde, J. (1999). Incentives, constraints and culture-building as instruments for the development of
evaluation demand. In R. Boyle & D. Lemaire (Eds.),Building effective evaluation capacity. Lessons from
practice (pp. 153–176). New Brunswick, NJ: Transaction Press.
Van Thiel, S., & Leeuw, F. L. (2002). The performance paradox in the public sector.Public Performance &
Management Review, 25, 267–281.
Vatter, A. (2014).Das politische System der Schweiz. Baden-Baden, Germany: Nomos.
Vedung, E. (2008).Public policy and program evaluation. New Brunswick, NJ: Transaction Press.
Vedung, E. (2010). Four waves of evaluation diffusion.Evaluation, 16, 263–277.
Weiss, C. H. (1987). Congressional committee staffs (do, do not) use analysis. In M. Bulmer (Ed.),Social
science research and government: Comparative essays on Britain and the United States(pp. 94–111). New
York, NY: Cambridge University Press.
Weiss, C. H. (1989). Congressional committees as users of analysis.Journal of Policy Analysis and Manage-
ment, 8, 411–431.
Weiss, C. H. (1998). Have we learned anything new about the use of evaluation?American Journal of
Evaluation, 19, 21–33.
Weiss, C. H. (1999). The interface between evaluation and public policy.Evaluation, 5, 468–486.
Whiteman, D. (1985). The fate of policy analysis in congressional decision making: Three types of use.
Political Research Quarterly, 38, 294–311.
Wiberg, M. (1995). Parliamentary questioning: Control by communication? In H. Do ¨ring (Ed.),
Parliaments and majority rule in Western Europe (pp. 179–222). New York, NY: St. Martin’s
Press.
Widmer, T. (2007). Rahmenbedingungen und Praxis der Evaluation im schweizerischen Bundesstaat.O¨HW -
Das o¨ffentliche Haushaltswesen in O¨sterreich, 48, 69–93.
Widmer, T. (2008). Evaluationen in der Aussenpolitik. Gru¨nde fu¨r eine Evaluationslu¨cke. Zeitschrift fu¨r
Internationale Beziehungen, 15, 125–137.
Widmer, T., & De Rocchi, T. (2012).Evaluation. Grundlagen, Ansa¨tze und Anwendungen.Z u¨rich/Chur,
Switzerland: Ru¨egger Verlag.
Williamson, O. E. (1975).Markets and hierarchies. Analysis and antitrust implications. New York, NY: The
Free Press.
Zollinger, C. (2009). Gru¨nde fu¨r die Produktion staatlicher Perfomanceinformationen. Eine vergleichende
Analyse staatlicher Massnahmen der Verkehrs- und Migrationspolitik der Schweiz.Z u¨rich, Switzerland:
Lizentiatsarbeit an der Universita¨t Zu¨rich.
Bundi 541