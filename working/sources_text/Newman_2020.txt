<<<PAGE=1>>>
82
8. Politics, public administration, and 
evidence-based policy
Joshua Newman
INTRODUCTION
The catchphrase “evidence-based policy” has been the subject of much debate since at least the 
1990s. Appeals to evidence-based policy, or similar terminology, have been used copiously 
by politicians, especially Tony Blair, Al Gore, Tony Abbott, George W. Bush, Barack Obama, 
Helen Clark, and many others. Vigorous – and sometimes vitriolic – dialogues have been 
pursued in academic circles for many years, emerging mainly after the year 2000 and continu-
ously expanding since then. Most recently, dedicated academic journals, advocacy groups, and 
think tanks have appeared in support of evidence-based policy, while at the same time voices 
of criticism and skepticism continue to grow louder and more confident.
At the surface level, it is difficult to see what might be so controversial. If public policy were 
not based on evidence, what else could it be based on? Religious dogma, racial prejudice, and 
partisan strategy, among other options, are all obviously less desirable information sources 
for important public decisions than evidence. Understandably, “evidence-based policy” is 
therefore a highly effective political slogan.
Critics, however, point out that what constitutes evidence is not always agreed upon by 
all affected or interested parties. Claims to evidence can actually be a means of suppressing 
minority voices, entrenching bias, locking out particular forms of knowledge, and, ironically, 
justification for political decisions already reached.
Unfortunately, after many years of public and academic discourse, this debate has ossified. 
While the overall output, in terms of academic publications, think tank and consultant reports, 
and new political campaigns, continues to grow, the messages themselves are no longer devel-
oping. In fact, there are really only four main arguments in favor of evidence-based policy, and 
four against. These arguments repeat themselves, sometimes illustrated by novel case studies, 
but not much gets added to their force or substance at each new iteration.
Fortunately, scholarship on evidence-based policy can be made more productive if the 
various arguments can be made to work together. But first, as I will elaborate below, scholars 
will have to address the relationship between administrative and political actors in the policy 
decision making process, and they will have to recognize the importance of the principle of 
accumulation of knowledge. Without these two elements, the entire enterprise is at risk of 
stagnation.
ARGUMENTS IN FAVOR OF EVIDENCE-BASED POLICY
Academic scholarship in support of evidence-based policy can generally be organized into 
four arguments. This is not to say that there are only four possible arguments – indeed, many 
Joshua Newman - 9781839109447
Downloaded from https://www.elgaronline.com/ at 03/17/2025 11:11:03PM
via The World Bank Group
<<<PAGE=2>>>
Politics, public administration, and evidence-based policy 83
more arguments are possible. However, these are the four most commonly employed, and they 
are so common that other points of view barely attract any attention at all. All four arguments 
take the position that evidence-based policy is desirable, achievable, superior to alternative 
methods of policy decision making, and also superior to the status quo, in which policy 
decisions are seen to be insufficiently derived from adequate evidence. All four arguments 
contend that evidence-based policy decisions will produce more effective, more efficient, 
more sustainable, and more equitable social outcomes, but they provide different views on 
how evidence is to be used, who should use it, and to what purpose.
The Research-to-Policy Pipeline
Arguments from this perspective claim that more research evidence (quantity) or more con-
clusive research evidence (quality) should be produced so as to provide decision makers with 
a more solid evidence base on which to support policy decision making. Alternatively, some 
arguments in this vein claim that good quality research already exists in adequate quantity, 
but the problem is getting that research into the hands of decision makers. In either case, the 
problem is seen as an inadequate direct supply of high-quality research to decision makers.
Often, these arguments are made in reference to a specific policy problem or issue area. 
For example, Just and Byrne (2020) discuss various ways that research on consumer food 
behavior, such as how people choose between options at the grocery store, might better inform 
policies to address obesity, child nutrition, and food sustainability. Other arguments are 
more general and cut across policy areas. Some authors refer to entire jurisdictions: Andrews 
(2017), for instance, details the evidence-to-policy process in Wales, and argues that research 
evidence provided by experts is a critical input for effective government decision making in 
that jurisdiction. Others discuss methodologies for producing evidence. One popular, ongoing 
debate involves the importance of randomized controlled trials, in which a particular policy 
intervention is applied to a group over a set period of time, and the results are then compared 
with a similar group whose members did not receive the intervention. While there are probably 
as many voices urging the expansion of randomized controlled trials for informing policy deci-
sions (e.g. Doleac 2019) as there are voices who caution against a blind faith in randomization 
(e.g. Deaton and Cartwright 2018), all of these arguments adopt the perspective that improving 
the supply of evidence will enable superior policy decision making and better policy outcomes.
 Many of these arguments place the responsibility for improving research, or for communi-
cating research evidence to policy makers, with researchers, who are mainly university-based 
academics (e.g. Poot et al. 2018; Richards 2017). But authors adopting this position rarely 
acknowledge that academic researchers lack the training, aptitude, or experience for creat -
ing policy advice and are insufficiently rewarded by their institutions for their outreach to 
governments. Researchers also have no professional responsibility for governance – that is 
the purview of duly elected political officers and appointed administrative staff in the public 
service.
A growing number of authors avoid this problem by supposing that the communication 
of research to policy makers – often called knowledge translation (Grimshaw et al. 2012) 
or knowledge brokering (Smits et al. 2018) – is best achieved by independent actors in spe-
cialized roles, whose job is to gather research evidence from the people who create it and 
communicate it to the people who need it for purposes of making public policy. Many of these 
analyses model this activity with the “two communities” approach, which sees researchers and 
Joshua Newman - 9781839109447
Downloaded from https://www.elgaronline.com/ at 03/17/2025 11:11:03PM
via The World Bank Group
<<<PAGE=3>>>
84 Handbook on the politics of public administration
policy makers separated by different languages, pressures, rewards and incentives, schedules, 
and core motivation for action (Caplan 1979). These arguments claim that the highest prior-
ity in improving evidence-based policy is overcoming barriers in communication between 
researchers and policy makers (Poot et al. 2018; Richards 2017). However, the two communi-
ties model generally presupposes a homogeneous policy community, which empirical studies 
have suggested is unrealistic (e.g. Newman 2014).
Policy Capacity
A second argument supportive of evidence-based policy is one that pertains to improving 
the capacity of public agencies to process information for purposes of policy making. 
The argument is that most public sector organizations are dangerously understaffed and 
under-resourced when it comes to collecting policy-relevant information, processing that 
information into a format that makes it useful for policy decision making, and communicating 
the resulting advice to superior (often, political) decision makers. Many authors conclude that 
organizational change, including cultural change (Cherney et al. 2015), improved education 
and training (Newman et al. 2017), and expansion of personnel (Hahn 2019: 535) are the keys 
to better use of research evidence in policy decision making.
Policy capacity arguments are similar to research-to-policy pipeline arguments, in that 
both arguments understand the problem to be one of inadequate use of information. However, 
whereas pipeline arguments call for more information, better information, and better commu-
nication of information, capacity arguments call for better infrastructure at the point where 
information is being used. This is a major point of difference, because from this perspective, 
the onus is on the government to improve policy decision making, not on outside actors like 
academic researchers.
Policy capacity arguments generally focus on only one aspect of the policy process: the 
processing of information. This makes it difficult for these arguments to explain how the 
system came to be deficient in the first place. If policy outcomes could be improved by simply 
boosting the capacity of advice-creating agencies to process information, why does this con-
tinue to be a problem? A focus on advice creation ignores the political dynamics – like the 
influence of conservative parties espousing a contraction in public service personnel as an 
austerity measure to curtail public spending – that have shaped the structure of public agencies 
in many jurisdictions.
A Focus on Implementation
A third school of thought argues that it is more important that evidence be used to support 
decisions on how policies should be implemented, and less important for helping decide which 
policies to choose in the first place (Breunig 2018: 73; Khosrowi 2019: 53). For instance, 
when the Canadian government decided to legalize the recreational use of marijuana, it made 
a political decision held up by democratic support through the election of Justin Trudeau’s 
Liberal party to government in 2015. However, the details of how this policy would be imple-
mented, including where legal marijuana would be sold, where it could be legally used, how 
it would be kept out of the hands of children, and so on, were not provided during the election 
campaign in which this policy was promoted. The technicalities of implementation were left to 
administrative staff to work out (see Engel 2017), and this is where research evidence would, 
Joshua Newman - 9781839109447
Downloaded from https://www.elgaronline.com/ at 03/17/2025 11:11:03PM
via The World Bank Group
<<<PAGE=4>>>
Politics, public administration, and evidence-based policy 85
according to this perspective, be most useful (for a more in-depth discussion on these points, 
see Newman 2017). More specifically, the kind of evidence used in these instances would 
arise from the evaluation of previous or existing programs in the same or similar jurisdictions 
(Weiss 1999).
The advantage of this argument is that it separates the normative aspects of evidence-based 
policy (i.e. what policies should be chosen, how political objectives should be defined, which 
populations are to benefit, and which other populations must compromise) from the admin -
istrative aspects (i.e. which policy instruments are to be used to deliver the chosen policy 
efficiently and effectively). This works to address the concerns of scholars who caution that 
support for evidence-based policy will result in the rise of an anti-democratic technocracy 
(e.g. Triantafillou 2015). The disadvantage is that this argument precludes the possibility that 
decisions about implementation frequently require normative prescriptions and are founded on 
political objectives as well. For example, Millar et al. (2019) use the case of a social program 
to support single parents to re-enter the workforce in Ireland to show that even seemingly 
administrative aspects of policy implementation can require significant political decision 
making. In the end, it may be more difficult to separate political decisions from administrative 
decisions, even at the implementation stage, than these authors will freely admit.
Addressing Root Problems
The fourth most common argument promoting evidence-based policy is the notion that 
evidence is most useful when it is mobilized to address fundamental social problems, rather 
than, say, modifying existing programs or focusing on secondary issues. Gamoran (2018), for 
example, argues that policies intended to improve education outcomes for black Americans 
would not be successful – no matter how much evidence is deployed – unless the fundamental 
issue of entrenched racial discrimination in the education system is addressed first.
This line of thinking is descended from a much earlier debate, in which commentators 
reacted to Lindblom’s (1959) view that policy problems could never be resolved through 
holistic targeted strategy, but could instead only be addressed by incremental changes at the 
margins. Dror (1964), among others, disagreed, arguing instead that holistic, or even radical, 
policy problem-solving was possible and even warranted in many cases. Foreshadowing the 
current debate on the use of evidence, Dror commented that “increasing the knowledge and 
qualifications of policy-practitioners” and “setting up special ‘think units’ for the improve -
ment of conceptual analytical tools” were essential to improving the “rational” components 
of the policy decision making process (1964: 156 – although he also refers to “extra-rational” 
aspects in this discussion as well).
The core of this argument is appealing, in that it seems to explain why research evidence 
may not have had as much of an impact on policy outcomes as it would be expected to have, 
even when it is used by policy makers. However, on closer inspection it becomes apparent that 
the designation of what is a root problem is somewhat arbitrary. How deep into the phenome-
non must one go to reach the root, and how does one know that this is the right level to act on? 
At some stage it becomes unfalsifiable, and one could always argue that evidence use is not 
improving policy outcomes because the problem is not fundamental enough.
Joshua Newman - 9781839109447
Downloaded from https://www.elgaronline.com/ at 03/17/2025 11:11:03PM
via The World Bank Group
<<<PAGE=5>>>
86 Handbook on the politics of public administration
ARGUMENTS CRITICAL OF EVIDENCE-BASED POLICY
Similarly, there are four main arguments critical of evidence-based policy. All four critical 
perspectives argue that evidence-based policy is impossible, although they give different 
reasons for this point of view.
Evidence Is Subjective
A popular argument in the scholarly literature is that evidence-based policy is impossible 
because there is no such thing as objective evidence. Authors adopting this perspective argue 
that all facts are subjective, and therefore all decisions of a public nature are based on values 
and not truths (e.g. Lancaster and Rhodes 2020: 4–5). Some authors argue that statistical data 
in particular are open to manipulation (e.g. Neylan 2008). Others take a more extreme view, 
that reality itself is unknowable in any objective fashion (Luton 2007).
A corollary of this argument is that anyone who advocates for evidence-based policy is 
actually advocating for one particular set of values over others, which are claimed to be facts. 
The implication is that a call for evidence-based policy is actually a strategic move to sup-
press opposing voices, rather than an appeal to improve society through public intervention 
informed by data (Packwood 2002: 267).
A further corollary of the same argument is that government intervention is ineffective in 
producing desired outcomes (Biesta 2007). If evidence is subjective, then it is impossible to 
prove that government action can ever have an effect on social outcomes. Primary data (gath-
ered before an intervention is designed) and program evaluation (gathered after an intervention 
is implemented) are equally meaningless as facts, reflecting only values in a process that many 
have satirically labeled, “policy-based evidence” (Strassheim and Kettunen 2014).
Of course, it can be difficult to excise all values and biases from any presentation of facts, 
but these arguments do still possess some inherent weaknesses. First, even if facts are always 
value-laden, not all sets of values are equally meritorious. Social outcomes in which children 
die in mass school shootings, in which people require expensive hospital resources to deal with 
the consequences of smoking tobacco, and in which the incidence of domestic violence is on 
the rise are all worse for society than scenarios where these are not happening. To say that the 
data represent values, not facts, is equivalent to arguing that the values that prefer no children 
dying in school shootings are equivalent to the values that prefer children to continue to be at 
risk in this manner.
Second, government interventions certainly do have an effect on society, and different 
interventions produce different outcomes, as the various national responses to the COVID-19 
global pandemic illustrated vividly (Lau et al. 2020). Given then, that government intervention 
can result in particular outcomes, and that some outcomes are better for society than others, it 
stands to reason that some interventions – in other words, policies – are better for society than 
others. That being the case, there is merit in trying to find out which policies produce which 
outcomes, and further advocating for policies that improve society.
The Hierarchy of Evidence
A second argument contends that advocates of evidence-based policy insist on an unreasonable 
hierarchy of evidence, where some forms of knowledge are given more authority than others. 
Joshua Newman - 9781839109447
Downloaded from https://www.elgaronline.com/ at 03/17/2025 11:11:03PM
via The World Bank Group
<<<PAGE=6>>>
Politics, public administration, and evidence-based policy 87
Certainly this hierarchy is pervasive in the health sciences, where data from randomized 
controlled trials are placed at the top, followed by systematic reviews and meta-analyses, then 
studies based on observed correlation, then qualitative data from case studies, then expert 
opinion (Elamin and Montori 2012). Critics argue that evidence-based policy is impossible 
when perfectly valid data from qualitative studies, especially interviews that reveal the lived 
experience of people closely affected by a policy issue area, are discounted, discarded, or 
dismissed (Khosrowi 2019; Lancaster et al. 2017).
Like arguments refuting the existence of evidence, as described above, arguments objecting 
to a hierarchy of knowledge are making claims about the ability of those in positions of power 
to use appeals to evidence as a means of suppressing opposing voices. The difference between 
the two is that the latter set of arguments admits to the existence of objective evidence, but 
protests that some forms of evidence (notably, quantitative data) are unfairly magnified at the 
expense of other forms (namely, qualitative data). This is a valid concern, especially in an era 
in which statistics and other forms of quantitative data are somewhat fetishized. At the same 
time, research that is based on small numbers of individuals recounting their experiences from 
personal memory – useful though it may be for some specific purposes – cannot be as general-
izable as research that spans large numbers of individuals across broader populations. Rather 
than arguing for the credibility equivalence of various kinds of data, it might be more accurate 
(and more helpful) to argue that different studies can make contributions to knowledge in 
different ways. I will return to this point in the next section.
Policy is Political
Probably the most common argument critical of evidence-based policy is that policy can 
never be based on evidence because policy itself is inherently political. Facts and evidence 
may exist, but they are inconsequential in the policy making realm, where the dynamics of 
politics determine the outcomes of public debates. Policy decisions are, according to this 
point of view, mainly about settling differences between rival political interests, assembling 
coalitions, garnering majority support, and other political activities – not about designing and 
implementing the “best” policy strategy based on scientific evidence. Evidence-based policy 
is not possible, according to these authors, because rational-logical problem solving is just not 
how public decisions are made (Cairney 2016; Décieux 2020; Fleming and Rhodes 2018). A 
“two communities” imagining of research and policy is also common here – but these authors 
take the position that the gap is too wide to be bridged (e.g. French 2018).
However, authors arguing that evidence-based policy is impossible because policy is 
political almost never offer an alternative solution. “Politics”, even in the most democratic of 
countries, does not operate in a perfect pluralist liberal utopia, in which all voices have equal 
say and the biggest groups representing the most people rule the day while still completely 
preserving the rights and safety of minorities. Rather, it is a highly problematic maelstrom in 
which things like wealthy partisan benefactors, elite boys’ school chum networks, powerful 
lobbies, media-based influencers, ideologues who set agendas and manipulate the public, 
illiberal culture war baiting, far-right microparties holding the balance of power, and so on, 
control decision making and cause widespread suffering and inequity. Surely improvement 
is possible. Evidence-based policy may not be a panacea, but those who argue that “policy is 
political” are avoiding the tougher questions about how else we should address the pervasive 
failings of modern democratic governance.
Joshua Newman - 9781839109447
Downloaded from https://www.elgaronline.com/ at 03/17/2025 11:11:03PM
via The World Bank Group
<<<PAGE=7>>>
88 Handbook on the politics of public administration
Rules Do Not Extend Across Individuals
A slightly more obscure fourth argument contends that evidence-based policy is by definition 
impossible, because for every policy problem there can be no single solution that works for 
every individual. The best that can be achieved is a policy that will be beneficial for some 
people, but not all – and may in fact be harmful to some others. From this point of view, 
evidence-based policy can never be implemented in actual practice. Instead, policy based on 
evidence about whole populations is applied as a default, and case-by-case exceptions are 
made as necessary. The argument is that this is not really evidence-based policy at all – it is 
case-by-case judgement, which is the opposite of evidence-based policy (Anjum and Mumford 
2017; Bal 2017).
WHAT’S MISSING?
Scholarship on the use of evidence in policy making has become so focused on the specific 
points of contention outlined above, that scholars have lost sight of the bigger research ques-
tions. Are we, as scholars and as citizens, generally satisfied with public policy decisions 
in advanced democracies? How can decision making be improved? Who is responsible for 
effecting this improvement? In situations where politicians feel they cannot follow the recom-
mendation that evidence suggests, how could they determine a “second-best” solution? We 
cannot begin to answer these questions without giving attention to two key issues, which have 
been mostly avoided by the bulk of scholarly writing in this area to date.
Administration and Politics
As discussed above, some of the arguments relating to evidence-based policy focus on 
administrative aspects of the policy process, while others target the political, but none ade-
quately accounts for both. The vast majority of analyses use the term “policy maker” without 
elaborating on who that might be. Does this include administrators as well as politicians? Is 
a conservation scientist working for the Department of Environment the same kind of policy 
maker as a Minister of Natural Resources? Most of the writing on evidence-based policy is 
silent on the difference between these types of actors, instead lumping them together as anon-
ymous members of the “policy” community, which is seen as being collectively responsible 
for decision making.
In reality, the distinction is highly significant. If the people who use evidence to inform 
decision making are not identified, then it is impossible to determine how evidence can be 
used better. Knowledge translation, for instance, may be a useful strategy to target public 
sector research scientists, but it may be entirely inappropriate in the context of departmental 
chief executives. Improving policy capacity may help with planning and implementation 
within a department, but it may have little effect on decision making at the ministerial level. 
On the other side of the debate, arguments that policy is inherently political do not account for 
public sector activities in which huge numbers of public servants in non-partisan roles either 
make decisions under predetermined bureaucratic rules and processes or craft advice for senior 
administrators or political decision makers.
Joshua Newman - 9781839109447
Downloaded from https://www.elgaronline.com/ at 03/17/2025 11:11:03PM
via The World Bank Group
<<<PAGE=8>>>
Politics, public administration, and evidence-based policy 89
Instead of attempting to capture the entire policy decision making process under a single 
label, it may be more realistic to recognize that public policy comprises multiple processes, 
roles, and dynamics. Public sector science agencies, like Australia’s Commonwealth Scientific 
and Industrial Research Organisation or the Canada Space Agency, spend significant budgets 
on research and development, most of which is geared toward public policy applications. 
Planners and project managers working in government departments make administrative 
decisions in the delivery of public services like roads, schools, and health care. Regulators, 
for instance in the European Commission’s Department of Health and Food Safety, create and 
enforce rules that govern industry and protect citizens. Internal auditing and review agencies, 
like the United States’ Office of Management and Budget, provide advice and conduct eval -
uations of existing government programs. Political actors, such as elected officials but also 
including senior administrative executives who may be political appointees, make decisions 
that may be influenced by partisan forces, political ideology, strategies to win votes, or other 
dynamics. Judiciaries affect policy by interpreting laws in ways that constrain public decision 
making, and litigating through the courts is yet another way to influence the direction of public 
policy (Gerston 2010: 52–53).
I do not mean to imply that some aspects of policy decision making are more evidence-based 
(or conversely, more political) than others. Likewise I am not suggesting that these activities 
are completely discrete or that they fit together neatly like pieces of an engineered device. 
There are numerous ways for the various parts of policy decision making to overlap, operate in 
isolation, or contradict each other. The point is that policy decision making is a massive under-
taking, activated by huge resources of personnel working in numerous roles, and constrained 
by multiple simultaneous dynamics – including both administrative rules and processes and 
political or partisan considerations. Any analysis of “evidence-based policy” would have to 
specify what aspect of “policy” the author wishes to examine, and the discussion would have 
to be tailored to that activity. Analyses that group all parts of the policy process under “policy 
making” – as many currently do – are not contributing much to the debate.
Accumulation of Knowledge
A substantial amount of scholarship on evidence-based policy is devoted to debating the 
superiority of one particular form of knowledge over another. Doleac (2019) for example, 
argues for more randomized controlled trials and places them at the top of the hierarchy of 
knowledge. Deaton and Cartwright (2018), on the other hand, provide an exhaustive review 
of the limitations of randomized controlled trials. Lancaster et al. (2017) argue that, in their 
research area of drug policy, an emphasis on quantitative data privileges elite observers with 
no firsthand knowledge of drug abuse and crowds out the voices of actual drug users, whose 
lived experience might better inform policy. Conversely, Breunig (2018: 73) cautions against 
anecdotal reports, and instead defines evidence as “quantifiable information pertaining to the 
costs and benefits of a policy”.
The crucial fact that these authors have not acknowledged is that different research methods 
produce different kinds of information and are rarely in competition. Randomized controlled 
trials are good for demonstrating causality and also for quantifying average effect – but they 
are not at all useful for determining the personal experience of the people receiving the inter -
vention. Average effect is important for many policies, because it allows for a quantification 
of costs and benefits: if the policy is rolled out across a population of x million people, and it 
Joshua Newman - 9781839109447
Downloaded from https://www.elgaronline.com/ at 03/17/2025 11:11:03PM
via The World Bank Group
<<<PAGE=9>>>
90 Handbook on the politics of public administration
costs y dollars per person, and produces z outcome, it may be possible to use this information 
to calculate some form of value in money terms. Qualitative interviews with recipients of the 
intervention, like drug users in the example given above, can give an in-depth account of how 
people experience the intervention personally, which is a kind of detail that a quantitative 
assessment of effect through a randomized controlled trial cannot provide. These two different 
forms of information can be combined to produce a fuller picture of a policy’s outcomes on 
society.
Politicians may find it convenient to brandish single studies supporting their viewpoints, as 
if that is all it takes to settle a debate. More accurately, knowledge is an accretion heap that has 
material added to it piecemeal, and at varying speeds. Individual studies should be interrogated 
for errors and omissions, beyond the academic peer review process, and evidence of a particu-
lar effect or outcome can build up as multiple analyses are logged and added to the corpus of 
knowledge, in a process Pawson (2002) calls the “realist synthesis”. Single studies are rarely 
conclusive in any meaningful sense.
CONCLUSION
All of the arguments in support of and critical of evidence-based policy have merit. Too often, 
however, they are written in needlessly adversarial tones. Instead, these arguments can, and 
should, be made to work together.
Good research is critical. However, values, prejudices, and biases must be identified, and 
normative prescriptions recognized for what they are. Quick answers are unlikely to appear; 
instead, knowledge builds up over time, and the results of individual studies should be ques-
tioned, investigated, and verified or refuted by further scholarship. Different forms of knowl-
edge and different methods of collecting data can be constructively combined to produce fuller 
pictures of policy-relevant phenomena.
Furthermore, public policy is a complex, multifarious endeavor that comprises many 
different activities performed by numerous actors in varying roles. Some of these actors 
and activities are administrative, and some are political, and they will use information in 
diverse ways. There is no single strategy for improving the use of evidence in policy making. 
Communicating research will work in some contexts, whereas organizational change will be 
necessary in others. Still other aspects will require lobbying efforts, public education, or media 
campaigns.
It is possible to bring all of these points together to form a single narrative. If we are 
interested in improving outcomes in society, we must recognize that it is possible to improve 
the system that uses public intervention to influence these outcomes. Better information, 
and better use of information, are both achievable, and can contribute to better outcomes. 
However, this will necessarily only happen as smaller pieces, addressing various different 
aspects of a policy problem, and aimed at different public sector activities and processes, are 
put together constructively rather than combatively.
Joshua Newman - 9781839109447
Downloaded from https://www.elgaronline.com/ at 03/17/2025 11:11:03PM
via The World Bank Group
<<<PAGE=10>>>
Politics, public administration, and evidence-based policy 91
REFERENCES
Andrews, L., 2017. How can we demonstrate the public value of evidence-based policy making 
when government ministers declare that the people “have had enough of experts”? Palgrave 
Communications, 3(1), 1–9.
Anjum, R. L. and Mumford, S. D., 2017. A philosophical argument against evidence ‐based policy. 
Journal of Evaluation in Clinical Practice, 23(5), 1045–1050.
Bal, R., 2017. Evidence-based policy as reflexive practice. What can we learn from evidence-based 
medicine? Journal of Health Services Research & Policy, 22(2), 113–119.
Biesta, G., 2007. Why “what works” won’t work: Evidence‐based practice and the democratic deficit in 
educational research. Educational Theory, 57(1), 1–22.
Breunig, R., 2018. Why do we need evidence-based public policy? In M. Fabian and R. Breunig (eds.), 
Hybrid Public Policy Innovations: Contemporary Policy Beyond Ideology . New York: Routledge, 
pp. 73–88.
Cairney, P., 2016. The Politics of Evidence-Based Policy Making. London: Palgrave Macmillan.
Caplan, N., 1979. The two-communities theory and knowledge utilization. American Behavioral 
Scientist, 22(3), 459–470.
Cherney, A., Head, B., Povey, J., Ferguson, M. and Boreham, P., 2015. Use of academic social research 
by public officials: Exploring preferences and constraints that impact on research use. Evidence & 
Policy, 11(2), 169–188.
Deaton, A. and Cartwright, N., 2018. Understanding and misunderstanding randomized controlled trials. 
Social Science & Medicine, 210, 2–21.
Décieux, J. P. P., 2020. How much evidence is in evidence-based policymaking: A case study of an 
expert group of the European Commission. Evidence & Policy, 16(1), 45–63.
Doleac, J. L., 2019. “Evidence-based policy” should reflect a hierarchy of evidence. Journal of Policy 
Analysis and Management, 38(2), 517–519.
Dror, Y., 1964. Muddling through: “Science” or inertia? Public Administration Review, 24(3), 153–157.
Elamin, M. B. and Montori, V. M., 2012. The hierarchy of evidence: From unsystematic clinical obser-
vations to systematic reviews. In J. Burneo, B. Demaerschalk and M. Jenkins (eds.), Neurology. New 
York: Springer, pp. 11–24.
Engel, G., 2017. Plotting the policy path for recreational cannabis. Policy Options, June 8. https:// 
policyoptions .irpp .org/ magazines/ june -2017/ plotting -the -policy -path -for -recreational -cannabis/ . 
Accessed 1 March 2021.
Fleming, J. and Rhodes, R., 2018. Can experience be evidence? Craft knowledge and evidence-based 
policing. Policy & Politics, 46(1), 3–26.
French, R. D., 2018. Lessons from the evidence on evidence ‐based policy. Canadian Public 
Administration, 61(3), 425–442.
Gamoran, A., 2018. Evidence-based policy in the real world: A cautionary view. The Annals of the 
American Academy of Political and Social Science, 678(1), 180–191.
Gerston, L. N., 2010. Public Policy Making: Process and Principles. New York: Routledge.
Grimshaw, J. M., Eccles, M. P., Lavis, J. N., Hill, S. J. and Squires, J. E., 2012. Knowledge translation 
of research findings. Implementation Science, 7(1), 1–17.
Hahn, R., 2019. Building upon foundations for evidence-based policy. Science, 364(6440), 534–535.
Just, D. R. and Byrne, A. T., 2020. Evidence-based policy and food consumer behaviour: How empirical 
challenges shape the evidence. European Review of Agricultural Economics, 47(1), 348–370.
Khosrowi, D., 2019. Trade-offs between epistemic and moral values in evidence-based policy. 
Economics & Philosophy, 35(1), 49–78.
Lancaster, K. and Rhodes, T., 2020. What prevents health policy being “evidence-based”? New ways 
to think about evidence, policy and interventions in health. British Medical Bulletin, 135(1), 38–49.
Lancaster, K., Seear, K., Treloar, C. and Ritter, A., 2017. The productive techniques and constitutive 
effects of “evidence-based policy” and “consumer participation” discourses in health policy pro-
cesses. Social Science & Medicine, 176, 60–68.
Lau, L. L., Hung, N. and Wilson, K., 2020. COVID-19 response strategies: Considering inequalities 
between and within countries. International Journal for Equity in Health, 19(1), 1–3.
Lindblom, C. E., 1959. The science of “muddling through”. Public Administration Review, 19(2), 79–88.
Joshua Newman - 9781839109447
Downloaded from https://www.elgaronline.com/ at 03/17/2025 11:11:03PM
via The World Bank Group
<<<PAGE=11>>>
92 Handbook on the politics of public administration
Luton, L. S., 2007. Deconstructing public administration empiricism. Administration & Society, 39(4), 
527–544.
Millar, M., Crosse, R. and Canavan, J., 2019. Understanding, negotiating and navigating the politici -
sation of evidence-based policy research: The case of Irish research on lone parent labour market 
activation policy. Evidence & Policy, 15(4), 559–577.
Newman, J., 2014. Revisiting the “two communities” metaphor of research utilisation. International 
Journal of Public Sector Management, 27(7), 614–627.
Newman, J., 2017. Deconstructing the debate over evidence-based policy. Critical Policy Studies, 11(2), 
211–226.
Newman, J., Cherney, A. and Head, B.W., 2017. Policy capacity and evidence-based policy in the public 
service. Public Management Review, 19(2), 157–174.
Neylan, J., 2008. Social policy and the authority of evidence. Australian Journal of Public Administration, 
67(1), 12–19.
Packwood, A., 2002. Evidence-based policy: Rhetoric and reality. Social Policy and Society , 1(3), 
267–272.
Pawson, R., 2002. Evidence-based policy: The promise of “realist synthesis”. Evaluation, 8(3), 340–358.
Poot, C. C., van der Kleij, R. M., Brakema, E. A., Vermond, D., Williams, S., Cragg, L., van den Broek, 
J. M. and Chavannes, N. H., 2018. From research to evidence-informed decision making: A system-
atic approach. Journal of Public Health, 40(suppl. 1), i3–i12.
Richards, G. W., 2017. How research–policy partnerships can benefit government: A win–win for 
evidence-based policy-making. Canadian Public Policy, 43(2), 165–170.
Smits, P., Denis, J. L., Préval, J., Lindquist, E. and Aguirre, M., 2018. Getting evidence to travel inside 
public systems: What organisational brokering capacities exist for evidence-based policy? Health 
Research Policy and Systems, 16(1), 1–6.
Strassheim, H. and Kettunen, P., 2014. When does evidence-based policy turn into policy-based evi-
dence? Configurations, contexts and mechanisms. Evidence & Policy, 10(2), 259–277.
Triantafillou, P., 2015. The political implications of performance management and evidence-based poli-
cymaking. The American Review of Public Administration, 45(2), 167–181.
Weiss, C. H., 1999. The interface between evaluation and public policy. Evaluation, 5(4), 468–486.
Joshua Newman - 9781839109447
Downloaded from https://www.elgaronline.com/ at 03/17/2025 11:11:03PM
via The World Bank Group