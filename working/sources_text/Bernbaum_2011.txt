<<<PAGE=1>>>
By Marcia Bernbaum, Ph.D. and Kurt Moses
EQUIP2 Lessons Learned
in Education
A Guide to Education Project Design, 
Evaluation, and Implementation Based on 
Experiences from EQUIP2 Projects in 
Malawi, Uganda, and Zambia
Education Management 
Information Systems
<<<PAGE=2>>>
EQUIP2: Educational Policy, Systems Development, and Management is one of three USAID-fund-
ed Leader with Associates Cooperative Agreements under the umbrella heading Educational Quality 
Improvement Program (EQUIP).  As a Leader with Associates mechanism, EQUIP2 accommodates 
buy-in awards from USAID bureaus and missions to support the goal of building education quality at 
the national, sub-national, and cross-community levels.
FHI 360 is the lead organization for the global EQUIP2 partnership of education and development or-
ganizations, universities, and research institutions.  The partnership includes fifteen major organizations 
and an expanding network of regional and national associates throughout the world: Aga Khan Founda-
tion, American Institutes for Research, CARE, Center for Collaboration and the Future of Schooling, 
East-West Center, Education Development Center, International Rescue Committee, Joseph P . Kenne-
dy, Jr. Foundation, Michigan State University, Mississippi Consortium for International Development, 
ORC Macro, Research T riangle Institute, University of Minnesota, University of Pittsburgh Institute of 
International Studies in Education, Women’s Commission for Refugee Women and Children.
<<<PAGE=3>>>
EQUIP2 Lessons Learned
in Education
Education
Management
Information systems
Marcia Bernbaum, Ph.D. and Kurt Moses
2011
This paper was made possible by the generous support of the American people through 
the United States Agency for International Development (USAID) under Cooperative 
Agreement No. GDG-A-00-03-00008-00. The contents are the responsibility of FHI 
360 through the Educational Quality Improvement Program 2 (EQUIP2) and do not 
necessarily reflect the views of USAID or the United States Government.
<<<PAGE=4>>>

<<<PAGE=5>>>
Table of Contents
i
Contents
Acronyms 1
Acknowledgments 4
Executive Summary  7
Background  19
A. Introduction to EMIS  19
B. Methodology   22
C. Highlights of EQUIP2 Associate Award experiences   24
Findings, Lessons Learned, Strategies & Insights  31
A. Lessons Learned from the EQUIP2 Associate Awards 31
B. Lessons Learned from Broader Experience  48
Emerging Technologies and Approaches  53
A. Cell Phones 53
B. Tablet Computers 53
C. Google Earth and Digital Mapping 53
D. Planning Simulation and Business Intelligence 54
E. Open Source Software 54
F . Access to the World Wide Web 55
Annex 1: Sample EMIS Outputs - Historical and Future  57
Annex 2: EQUIP2 Associate Award Case Studies  75
Annex 3: Interview Protocol 127
Annex 4: Individuals Interviewed  131
Annex 5: References  135
<<<PAGE=6>>>

<<<PAGE=7>>>
1Acronyms
Acronyms
AIDS   Acquired Immune Deficiency Syndrome
AIR   American Institutes of Research
AOTR   Agreement Officer’s T echnical Representative
BBC   British Broadcasting Company
DFID   Department for International Development (Great Britain)
CIA   Central Intelligence Agency
EDC   Education Development Center
EDSA   Education Decentralization Support Activity
EFA   Education for All
EMIS   Education Management Information System
EQUIP   Education Quality Improvement Program
FTI   Fast T rack Initiative
GDP   Gross Domestic Product
GIS   Geographic Information System
GTZ   German Agency for International Development 
HDR   Human Development Report
HIV   Human Immunodeficiency Virus
IT   Information T echnology
JICA   Japanese International Cooperation Agency
LAN   Local Area Network
M&E   Monitoring and Evaluation
MOES   Ministry of Education and Sports
NDP   National Decentralization Policy
NESP   National Education Sector Program
NGO   Non Government Organization
PEA   Primary Education Advisors
PIF   Policy Investment Framework
PLE   Primary Leaving Examination
PMEC   Payroll and Establishment Control System
QTS   Questionnaire T racking System
RFA   Request for Application
SMS   Short Message Service
SWAp   Sector Wide Assistance Program
UNDP   United Nations Development Program
UNICEF  United Nations International Children’s Emergency Fund
<<<PAGE=8>>>
2
EQUIP2 Lessons Learned in Education: EMIS
UNESCO  United Nations Educational, Scientific and Cultural   
   Organization
UNEB   Uganda National Examinations Board
USAID   United States Agency for International Development
WAN   Wide Area Network
<<<PAGE=9>>>
3Acronyms
<<<PAGE=10>>>
4
 EQUIP2 Lessons Learned in Education: EMIS
Acknowledgments
The authors would like to take this opportunity to express their sincere 
thanks and appreciation to the many individuals that made this report 
possible. Audrey-Marie Schuh-Moore, FHI 360 EQUIP2 Director, took 
the lead in providing excellent oversight and guidance from the inception 
of this exercise through to reviewing and commenting on several versions of 
the report. Erik Lundgren of FHI 360’s Global Education Center, provided 
invaluable assistance in organizing the interviews, obtaining background 
documentation, and providing feedback on initial drafts. Brian Dooley, also 
of FHI 360’s Global Education Center assisted in finalizing the report and 
preparing it to be sent to print.
T wenty three individuals involved in the design and implementation of the 
four EQUIP2 projects focusing on education management information 
systems that form the focus of this report graciously set aside time to be 
interviewed for this study and, in many instances, to review the interview 
write ups to ensure their accuracy as well as approve quotes that appear in 
this report. These individuals include USAID personnel assigned to Uganda, 
Malawi, and Zambia involved in designing the EQUIP2 projects and 
overseeing their implementation, FHI 360 personnel stationed in Uganda, 
Malawi, and Zambia (Chiefs of Party and technical advisors) and Washington 
(home office Project Directors), and former Ministry of Education personnel. 
Their observations and insights, which form the principal source of 
information for this report (supplemented by available documentation), have 
been invaluable. The names of these individuals appear in Annex 4 of the 
report.
A special thanks to the following individuals who took the time to review the 
final draft of the report for accuracy and readability: We received a number 
of excellent comments and suggestions that we have incorporated into the 
report. These individuals are: Audrey-Marie Schuh-Moore (FHI 360), Felix 
Alvarado (FHI 360), Sergio Sommerville (FHI 360), Anthony Bloome 
(USAID, and Christine Pagen (USAID).
<<<PAGE=11>>>
5Acknowledgements
Finally, a note of appreciation to Patrick Collins and Kristi Fair, USAID 
EQUIP2 Agreement Officer’s T echnical Representatives in Washington, who 
provided the inspiration for this exercise and provided overall conceptual 
guidance.
<<<PAGE=12>>>

<<<PAGE=13>>>
7Executive Summary
Executive Summary
We undertook reviews from November 2010 to January 2011 of four 
EQUIP2 Associate Awards implemented in Uganda, Malawi (2), and Zambia 
from 2003 to the present. Each reviewed project focused on education 
management information systems (EMIS) or had an EMIS component. The 
principal objective was to gain insights and lessons learned from experienced 
development practitioners on designing, implementing, and evaluating 
projects that focus on EMIS or have EMIS components. The review did not 
focus on technical aspects of EMIS—databases, languages, etc., as this is best 
left to technical specialists. The primary audience for this work is USAID 
education officers.
This work involved both document review, and semi-structured interviews 
with 23 individuals who designed and implemented these Associate Awards, 
including: USAID staff responsible for designing them and overseeing 
implementation, monitoring, and evaluation; the EQUIP2 Chief of Party, 
technical advisors, and AED home office backstops; and current or former 
Ministry of Education (MOE) officials involved in implementing the 
Associate Awards.1 
EQUIP2 Associate Awards That Focus on EMIS or Have an EMIS 
Component
1 More information on the methodology may be found in pages 3 to 5 of this report.
MALAWI: Education Sector Policy, Planning, EMIS Support Activities, and Higher 
Education Strategic Plan Development
Funding: $1,985,620, increased to $2,704,581
Time frame: 2003–2008
Purposes: Improve strategic planning and management for Policy Investment 
Framework (PIF) implementation, strengthen EMIS, and develop strategic business 
plans for the University of Malawi and Mzuzu University.
MALAWI: Education Decentralization Support Activity
Funding: $11,559,643
Time frame: 2009–2012
Purpose: Strengthen the decentralization implementation at the Ministry of Education 
headquarters, district and school levels to support system progress in attaining 
National Education Sector Plan 2008–2018 goals.
<<<PAGE=14>>>
8
EQUIP2 Lessons Learned in Education: EMIS
Below is an organizing framework for understanding the EMIS lessons—
which are summarized under eight topics — for designing and implementing 
incipient or emerging Education Management Information Systems. T wo 
additional lessons address challenges in designing programs to support 
Ministries of Education that require more sophisticated data for decision 
making. The key conclusions for each lesson learned are listed below followed 
by implications for USAID education officers.
This Executive Summary, and the report, end with recent innovations that, 
while not necessarily a part of past and current EMIS projects, provide 
valuable options for the future.
ORGANIZING FRAMEWORK
All EMIS work is composed of three basic components: people, process, and 
technology, as is illustrated in Figure 1.
In most development work, the combination of the people (leadership, 
managerial, and technical) and process (administrative requirements, 
timelines, job skills, and funding) are frequently the most difficult to align 
with the goal of EMIS, namely: providing quality education information in 
a timely, cost-effective, and sustainable manner, at all administrative levels, 
and to support selected operational functions. What ultimately drives EMIS 
success is being able to answer the questions that education stakeholders raise, 
and providing consistently understandable answers. Therefore, while new 
technologies are making certain factual information more readily available, 
there remains a key requirement to develop the capacity for interpretation 
and analysis of these resulting “facts.” Making information accessible to 
UGANDA: Strengthening of Uganda Education Management Information 
System
Funding: $999,243, increased to $1,506,390
Time frame: 2003–2005
Purpose: Conduct a school mapping exercise (GIS); institutionalize the EMIS; 
increase the level of training for EMIS; create a twice-yearly primary school mini-
census; complete a Wide Area Network (WAN) using cellular techniques; and 
coordinate and supervise a long-term education Strategic Investment Plan.
ZAMBIA: Support to the Ministry of Education Strategic Plan in Improving 
Imformation and Strengthening Policy Implementation
Funding: $13,973,991, increased to $26,473,991
Time frame: 2004–2011
Purpose: Improve information for efficient resource management and strengthen 
education policy implementation.
<<<PAGE=15>>>
9Executive Summary
a broad audience, with varying levels of preparation and numeracy, is the 
continuing challenge of any EMIS effort. Since education fundamentally 
occurs at the school level, and can only, fundamentally, be measured by 
its positive effects on students, the change in student learning must be the 
fundamental basis for understanding education systems operation.
Figure 1. What EMIS Requires
What EMIS Requires 
 
 
Process 
 
 
 
People 
 
 
 
Technology 
EMIS 
LESSONS LEARNED FROM THE EQUIP2 ASSOCIATE AWARDS
1. With adequate external assistance Ministries of Education with 
incipient EMIS systems can generate Annual School Census reports 
and good response rates within two to three years. However, in the 
absence of ongoing external support (particularly in countries that 
have not reached a certain stage of resources maturity – human, 
technology, processes) and strong political will linked to a commitment 
to measure progress, these results can slip.
Implications for USAID education officers
When designing support for an incipient EMIS effort, build in sufficient 
resources and adequate technical assistance over a three- to five-year period so 
that systems can show concrete results in a relatively short period to produce 
“this year’s data this year” along with good response rates (response from 
over 90% of individual schools is an appropriate target). However, without
<<<PAGE=16>>>
10
EQUIP2 Lessons Learned in Education: EMIS
continued political will, resources, and managed effort (either by the MOE 
and/or donors), these gains can quickly erode.
2. Achieving data quality begins at the school level and takes more time, 
attention, and funding than one might expect.
Implications for USAID education officers
Ensuring the quality of the data collected from schools and the perception 
that these data are of high quality are key for credibility and need to be an 
important part of any EMIS donor support. EMIS project designs should 
ensure that headmasters who provide school-based data understand the 
use, importance, and relevance of annual or more frequent EMIS exercises. 
Projects should include technical assistance and training for EMIS staff to 
develop the capacity to verify data and to assist with initial data verification 
exercises. This training should always include the closest administrative 
support unit, e.g. county or district, and, where possible, the participation 
of parents or local stakeholders. Parents can also be part of concrete steps to 
assist MOEs to perform data verification and to build a budget “line item” 
into yearly EMIS budgets to fund such work.
3. EMIS support should extend to the district and school levels. However, 
EMIS support at more local levels should not be at the expense of the 
central Ministry EMIS.
Implications for USAID education officers
In designing an EMIS program that focuses, as it should, on support at the 
sub-national level (provinces, districts, and schools), examine the needs of the 
EMIS in its entirety. Is USAID’s support both strengthening data gathering 
and use at the school, district, and provincial levels and contributing to 
utilizing these data for decision making at these levels? Is the central EMIS 
communicating adequately with district and provincial EMIS and are these 
data also being used for decision making at the center? Does the center have 
the capacity, without external assistance, to continue generating timely, 
credible data and are these data being used for decision making?
4. The challenge of education management information systems is finding 
a way to ensure that “hard data” generated from the systems are 
factored into decision making.
Implications for USAID education officers
In working with host country counterparts, invest in appropriate training 
and knowledge development for those who interpret information and make
<<<PAGE=17>>>
11Executive Summary
it available to senior and mid-level managers for use in taking important 
decisions. T raining should include preparing “just-in-time” briefs, eye-
catching reports and presentation of data, and other strategic communication 
methods. Design EMIS programs so that project-supported EMIS technical 
advisors guide their counterparts to use EMIS data for decision-making.
5. Fundamental for EMIS success is a comprehensive and ongoing 
capacity building program for Ministry of Education staff at multiple 
levels that factors in the inevitable staff turnover, and ensures that 
existing staff acquire new skills as new requirements emerge.
Implications for USAID education officers
Build in sufficient funding and support to train staff and provide capacity 
building at various levels, including “training-of-trainer” as well as “on-line” 
or mediated instruction (DVD or CD libraries) capabilities, to account for 
the inevitable staff turnover. As time goes on, staff that has already been 
trained will need to be trained in new technologies. Look for creative, 
user-friendly, and lower cost ways of making training available, including 
“power user” EMIS groups and HELP screens. Where possible, build in a 
mechanism for evaluating the skills individuals acquired as opposed to just 
keeping track of number of individuals trained on different topics. T racking 
skill development will allow programs to better align training programs and 
measure the cost effectiveness of resource use. Finally, find ways for MOEs 
to fund ongoing training at all levels in EMIS operations and to use EMIS 
information in decision making.
6. Having the information required to establish realistic targets and to 
track progress in reaching these targets in a donor-supported program 
creates strong incentives for USAID and other donors to support the 
establishment and/or strengthening of EMIS systems.
Implications for USAID education officers
Where sector support programs, financed by multiple donors, require 
accurate and timely data for establishing targets and tracking implementation 
progress it is critical to support the establishment/strengthening of EMIS 
systems. In designing a program to support EMIS capabilities, USAID 
and/or other donors should collaborate with MOEs to establish frequent 
measurements of key performance indicators so that education systems have 
some warning regarding their performance before a high-stakes outcome 
affects a donor decision to withhold funding when the MOE has not met 
agreed-upon targets (see Annex 1 for examples of target setting, dashboards, 
and Key Performance Indicator use).
<<<PAGE=18>>>
12
EQUIP2 Lessons Learned in Education: EMIS
7. Sustainability approaches require ongoing effort and need to be a part 
of EMIS projects from the very early stages
Implications for USAID education officers
Sustainability approaches that include comprehensive training programs, 
creative approaches to human resource issues, and changes in policies and 
procedures, as appropriate, need to be a part of projects from the very early 
stages. When senior management requires, understands, and uses information 
generated, others see that the information is of importance to the operation 
of the education system. Good information models (which may focus on 
product and outputs) establish a concrete sense of the goals of an effective 
EMIS. A valuable role for USAID may be to build into project design 
assisting the MOE to work with the Ministry of Finance to build recurrent 
costs for EMIS into annual MOE budgets.
8. New technologies and increasingly sophisticated demands on EMIS 
systems will periodically require technical expertise that may not be 
available within the government or from local contractors.
Implications for USAID education officers
When designing an education program, determine whether existing Ministry 
of Education information systems have the capacity to generate and process 
increasingly sophisticated demands for information as well as take advantage 
of new information technologies. If this capacity does not exist and this 
information is critical for broader project tracking/monitoring, consider 
building into project design assistance (technical, software, staff support, 
other) required to meet these needs. In addition, look for ways to assist 
MOEs to identify financial resources and technical expertise to address 
future needs for increasingly sophisticated information and technologies. 
Missions should consider empowering the local private sector to provide 
more specialized expertise—for example, in Central America, some private 
contractors are now providing continuing support to Ministries for certain 
elements of their EMIS systems. By rebidding contracts for this support at 
least every three years, it is possible to create a more “level” competitive field, 
and encourage healthy competition. This means, however, that Ministry 
personnel need to become better “technical managers” rather than just 
generalist or even technicians.
<<<PAGE=19>>>
13Executive Summary
ADDITIONAL LESSONS FROM BROADER EXPERIENCE
9. Increasingly, political and policy leaders rely on Key Performance 
Indicators (such as student-teacher ratios, percent of students reading 
at grade level) to make policy decisions. EMIS systems need to be 
prepared to assist in channeling questions in a way immediately 
relevant to their needs.
Implications for USAID education officers
Be aware of the kinds of information that policymakers increasingly need to 
make decisions, such as trends on Key Performance Indicators. Build in to 
the project design support MOE staff will need to obtain timely and credible 
information, packaged so that policymakers can use it. This may go beyond 
providing what has traditionally been support for timely collecting and 
reporting on basic education statistics.
10. The requirement to provide “quality education” means additional, 
important demands on EMIS and the allocation of more and more 
consistent resources for information.
Implications for USAID education officers
In designing EMIS support, examine whether key decision makers (MOE, 
other ministries, Districts or Provinces (under decentralization), USAID, 
other donors) are going to need data, available on a sequential basis, to assess 
changes in education quality. If the answer is yes, explore options (including 
the implications for cost, level of effort, and time to generate the data) for 
assisting MOEs to generate data that make it possible to assess changes in 
education quality over time. One option includes linking EMIS databases 
with national performance testing databases. Another option is to identify 
Opportunity to Learn (OTL) and Literacy indicators and set up a means 
of collecting and interpreting data on these indicators on an ongoing basis 
through the EMIS.
EMERGING TECHNOLOGIES AND APPROACHES
The following technologies and approaches hold great promise for developing 
country EMIS as they all tend to both democratize, and provide information 
faster and in more useable formats:
•	 Cell Phones. Cell phone use has increased exponentially in the 
developing world. There are now more cell phones in use in 2nd and 
3rd world nations than in the entire “developed” world. Cell phones 
already reach more schools than computers have or will in the next 
five years—and will form an essential part of any future EMIS. Cell
<<<PAGE=20>>>
14
EQUIP2 Lessons Learned in Education: EMIS
phones are already used to “log” school locations and to communicate 
key information such as “attendance or enrollment data” to district or 
national offices rapidly. They are typically more “sustainable” because 
people want them for multiple reasons (virtually every person or family 
wants to communicate)—but mainly because they allow for relatively 
cheap communication. Cell phones can also provide a relatively low cost 
option for communicating between users and suppliers of key school 
necessities. Some major journals have begun to call Cell Phones, the 
“computers for Africa” as just one example of the understanding of both 
the commercial feasibility, but as well the widespread acceptance and use 
of such devices.
•	 Tablet Computers. Tablet computers, and, to some extent “netbooks,” 
hold the promise of both lower cost and highly portable and adaptable 
instruments to place more information into more stakeholders’ hands 
than ever before. Tablets lend themselves to classroom observation, easy 
presentation of graphics, can be used with minimal training, and lower 
the cost for moving educational information closer to the school and 
classroom level. They also support the Regional and National level’s need 
to be informed.
•	 Google Earth and Digital Mapping. This extremely powerful 
geographic presentation application, now available on almost any 
computing device, allows a rapid presentation of the “status” of any social 
sector, but particularly education for very low cost. Virtually any digital 
data (photos, facts, video) can be linked to its geographic locus—and 
allow even modestly trained personnel to understand the significance 
of allocating resources. It also provides, through highly visual means 
the opportunity to plot progress. Annex 1 includes several examples of 
“digital mapping” already successfully in use.
•	 Planning Simulation and Business Intelligence. Simulation/
projection has been a “staple” of five year plans for many years. The 
dramatic increase in the power of EXCEL spreadsheets (which now 
incorporate many advanced features) and other tools allows EMIS 
systems to routinely accommodate forward planning. Hence, while 
current, managerially oriented information remains at the heart of an 
EMIS, the ability to quickly translate accurate “base information” into 
projected future outcomes is increasingly important. Several examples 
of both EXCEL based projection approaches that are highly graphical 
are provided in Annex 1. Moreover, the use of Business Intelligence 
software (which can “assemble” data from a variety of sources—both
<<<PAGE=21>>>
15Executive Summary
digital and manual) can dramatically increase the speed and ease of use of 
information. T ools such as Business Objects, Hyperion, or advanced SAS, 
have all proved effective in this regard. One element of these programs 
is the ability to not only provide graphs and charts, but to create 
“dashboards” that dynamically indicate progress or decline according 
to established targets. This information can, in turn, be communicated 
either to Web sites, or sent to cell phones with “smart” capacity. However, 
these more sophisticated tools only make sense if they continue to answer 
quickly and accurately (which is dependent upon solid information from 
schools and teachers) the questions that policymakers or stakeholders are 
asking.
•	 Open Source Software. Developed as an alternative to proprietary 
software driven by specific commercial interests (and often requiring 
both high licensing and maintenance fees), “open source software” has 
become more widespread and increasingly present in many educational 
applications. A number of NGO-led efforts have made use of “open 
source” free software to create special applications. Many university 
and pre-university programs now train personnel in “open source” 
approaches. Many EMIS systems will likely become a mixture of both 
“open source” and proprietary software for the near-term future—
open source often requires more training for the user, whereas many 
proprietary systems often require a large commitment and more funds 
“up front” in exchange for organized training and certain performance 
guarantees. The key is to provide points within EMIS technology where 
different applications can be accessed or exported so that alternatives are 
available over time. Examples of some recent, generally “open source” 
software approaches include: Android, Linux, Java, and a massive variety 
of open source applications available on the Web.
•	 Access to the World Wide Web. Increased access to the Internet is the 
wave of the future—every nation, with rare exception, aspires to access 
to the information and economic benefits that the Internet provides. 
While it clearly has transformative effects on the culture, not all of which 
can be predicted, the Web is a powerful adjunct to better education 
systems—both administratively and academically. Its introduction in a 
formal system of education needs to be calibrated to enhance and not 
undo positive practices. The Web can dramatically increase the ability to 
be responsive to education need and shortages—if linked to appropriate 
political and administrative units. Accordingly every future EMIS system 
needs to plan for and incorporate it as countries increase access to the 
Web.
<<<PAGE=22>>>
16
EQUIP2 Lessons Learned in Education: EMIS
The next ten years will see more technological and political progress 
capable of improving education than has occurred in the last ten years. This 
progress can empower students, teachers, parents and schools to be more 
competent than ever before. The EMIS challenge is to adapt to a much 
more decentralized, democratic and self-empowered education system whose 
demands for quality will drive the next wave of education for all.
<<<PAGE=23>>>
17Executive Summary
<<<PAGE=24>>>

<<<PAGE=25>>>
19Background
Background
Between November 2010 and January 2011, documents were reviewed and 
semi-structured interviews were carried out with 22 individuals involved 
in designing and implementing four EQUIP22 Associate Awards carried 
out between 2003 and the present in Uganda, Mali, and Zambia. All four 
Associate Awards either focused on building or strengthening education 
management information systems (EMIS) or had an EMIS component. 
The principal objective of this review has been to gain insights and 
lesson learned from experienced development practitioners on designing, 
implementing, and evaluating projects that focus on EMIS or have EMIS 
components.3  The review did not identify lessons on technical aspects of 
EMIS. The primary audience is new USAID education officers.
Section I discusses the review’s methodology and provides individual 
overviews of each of the four EQUIP2 Associate Award experiences. Section 
II discusses findings, lessons learned, and insights as well as additional lessons 
learned from broader experience.
This paper contains four annexes. Annex 1 is a table listing what worked 
and what didn’t work across the country cases. Annex 1 summarizes each 
Associate Award experience in a case study. The interview protocol is in 
Annex 3. A list of the interviewees for each country and their respective roles 
in designing and implementing the Associate Awards is in Annex 4.
A. INTRODUCTION TO EMIS
An Education Management Information System (EMIS) can be defined 
as a comprehensive system that brings together people, practices, and 
technology to provide quality education statistics in a timely, cost-effective, 
2 EQUIP stands for Education Quality Improvement Program. EQUIP2, headed by the Academy 
for Educational Development (AED), is one of three Leader with Associate (LWA) awards. EQUIP2 fo-
cuses on policy, systems and management. EQUIP1 (American Institutes of Research—AIR) focuses on 
classrooms, schools, and community; and EQUIP3 (Education Development Center—EDC) focuses 
on out-of-school youth, learning and earning.
3 Other EQUIP2 associate awards reviews focus on: policy dialogue, decentralization, country-led 
development, professional development, secondary education, and student assessment.
<<<PAGE=26>>>
20
 EQUIP2 Lessons Learned in Education: EMIS
and sustainable manner, at every administrative level, and to support selected 
operational functions.
Although many EMIS issues remain as they were almost 10 years ago, 
donors’ and the world’s attention recently has refocused from access to quality 
in education and the advent of newer technologies. Their rapid and thorough 
adoption in the second and third world was hardly foreseen ten years ago and 
has had an impact on the direction of EMIS.
The key lessons in the next section center on some fundamentals about 
EMIS, including:
•	 EMIS data need to be accurate.
•	 EMIS data need to be timely.
•	 EMIS data need to be reliable.
•	 EMIS data need to be understandable.
Most existing systems are some compromise of the above four factors. 
Accuracy can require more time than is allowed. Timeliness may require some 
relaxation of complete accuracy. Reliability is affected by external factors like 
funding, manpower, and political events. T urning data into information—
creating meaning from “facts”—is a constant challenge of making data, then 
information, then knowledge useful for decision making.
The repeated lesson is that creating a sustainable, workable EMIS depends on 
three factors:
1. The right PEOPLE, motivated to perform and skilled in their work 
2. The right PROCESSES that reduce duplication and reinforce accuracy 
and accountability
3. The right TECHNOLOGY, appropriate to the state of the country, and 
the reliability of its infrastructure
People are frequently the slowest to change and the hardest to affect directly. 
Both technology and processes can be altered quicker, but people can delay 
reinstituting new value structures and working methods. People-related issues 
typically are resolved through:
•	 Modeling “good behavior” in terms of skills use, work habits, and 
approaches to learning new skills
•	 Making appropriate technical assistance available when needed to keep a 
small problem from “festering” and becoming bigger
<<<PAGE=27>>>
21Background
•	 T raining repeatedly and sufficiently until concepts and practices are 
reinforced
Processes are critical for the effective flow of information in a country. 
Multiple layers (national, regional, district, and school) need accurate and 
appropriate information for the responsibilities assigned. For most emerging 
countries, the process around information transfer is extremely burdensome 
for schools; most headmasters receive 10 to 15 requests for almost the same 
information from multiple sources in a given term. This reduces attention to 
managing a school, reduces accuracy, and creates confusion at higher levels. 
Information practices need to follow at least the following:
•	 Processes must ensure that information is available to those who can 
make use of it quickly.
•	 Processes should reduce the number of times schools and districts answer 
the “same question in a slightly different form.”
•	 People at every level should check the data as they are developed, entered, 
edited, and distributed; as many eyes as possible should see the final 
product.
•	 With the increased focus on quality education, accurate and useful EMIS 
information at the school level is even more critical—since only the 
school, ultimately, can engender quality education.
•	 Processes need to shift as the general knowledge environment shifts.
T echnology is often the most noticeable aspect of EMIS, but it is only 
a part of the education information solution. Increasingly, laptops are 
replacing desktop computers (more rugged, just as powerful using less 
power, consolidated into one piece, and often more reliable). As importantly, 
smaller computers (netbooks/“classmates”/even tablet computers) can now 
be used with much lower requirements for cooling, security, and electricity. 
Only some of these technologies have been available over the last six years—
hence their full application has not yet been tested. Cell phones have gotten 
much more powerful—capable of transmitting data via SMS or GPRS—in 
useable formats for “urgent” or high-demand information. Software has also 
improved with simpler to use software like EXCEL, ACCESS, or MySQL 
with enhanced features and better training, offering more options even at the 
school level. For larger systems, there are many more alternatives for school-
based EMIS (from open source and from proprietary vendors) as well as 
integration of all the various technologies—computers, servers, cell-phones, 
and paper make data more manageable.
<<<PAGE=28>>>
22
 EQUIP2 Lessons Learned in Education: EMIS
The experience from the EQUIP2 EMIS Associate Awards is intended to 
make these conclusions more concrete and useful in both the design and 
execution of future USAID projects. The basic requirements for EMIS must 
be supported—since the multiple end users will turn information into better 
actions. 
B. METHODOLOGY 
This study used a qualitative approach to better understand human behavior 
and the reasons that govern it. The qualitative method investigates the why 
and how of decision making, not just what, where, when. The main methods 
used included interviews and document review. 
This review is not based on an in-depth evaluation of each Associate Award. 
Visits were not made to each country to interview a wide variety of actors. A 
comprehensive review was not made of documents generated by or related to 
the Associate Award.
Preparation of interview protocol, summary/matrix, consent form 
for each project 
An interview protocol was developed and piloted. A summary and matrix 
for each country case was developed based on information taken primarily 
from the RFA and AED’s proposal to be used as a reference point during the 
interviews.4  An interviewee consent form was prepared. Key topics raised in 
the interview protocol (available in Annex 3) are in the textbox below.
4 The summary and matrices for each project contain information on: life of project funding, project 
start and end dates, the country and education context, role of other donors, the project purpose and 
key activities.
Topics Addressed in Interview Protocol Related to EMIS
• EQUIP2’s development hypothesis (or what was to be accomplished toward 
the project goal), the assumptions underlying the hypothesis, and their validity.
• Key project activities: what they were, why they were selected, the 
assumptions linked to the activities and their validity, whether the activities led 
to the expected outcomes, if not, why.
• Adequacy of time frame and funding for what the EQUIP2 project wanted to 
accomplish.
• Extent to which the project built in sustainability, the extent to which it was 
achieved and why.
• Whether the project led to outcomes that were expected and, if not, why.  
• Adjustments made, if any, to activities, budget, and timeframe.
• Project monitoring and evaluation: indicators selected to assess project impact 
and track activity progress in EMIS activities, which were most useful and why, 
how the information collected was used, would other indicators have been 
more useful.
<<<PAGE=29>>>
23Background
Interviews carried out using the protocol and summary documents
The protocol was used to carry out interviews of approximately an hour-and-
a-half each. Four to eight individuals were interviewed for each country case. 
The following individuals were interviewed: (1) USAID staff who designed 
the RFAs and oversaw implementation of the Cooperative Agreements; (2) 
AED and sub-contractor staff who prepared EQUIP2’s proposal in response 
to the RFA, implemented the project, and backstopped the project from 
the United States; and (3) where possible host-country counterparts who 
implemented the EQUIP2 Associate Award. A total of 22 individuals were 
interviewed for four EQUIP2 Associate Awards in the three countries.5
Interviews written up and shared with each interviewee
Each interview was written up and shared with the interviewee for review/
comment. Interviewees were assured confidentiality. They were also told 
that if they were quoted (either in name or indirectly) in this or another 
document their approval would be sought in advance. All quotes have been 
reviewed and approved by the individual quoted.
Other sources of information accessed
T o supplement the information obtained for the interviews, several 
documents were reviewed for each EQUIP project. They included: RFAs, 
end of project reports (where available), and quarterly, semi-annual, and/
or annual reports. In addition, where possible, monitoring and evaluation 
(M&E) plans and reports for each project were reviewed. Country searches 
were conducted via Google to identify, download, and review relevant 
documents on each country context, especially as they related to EMIS. In 
addition, basic statistics (education and other) were obtained from the most 
recent United Nations Human Development Report (HDR) and from the 
World Bank’s education statistics database.
5 The four EQUIP2 Associate Awards are: Malawi: Education Sector Policy, Planning, EMIS Support 
Activities and Higher Education Strategic Plan Development; Malawi: Education Decentralization 
Support Activity; Uganda: Strengthening of the Uganda Education Management Information System; 
Zambia: Support to the Ministry of Education Strategic Plan in improving Information and Strength-
ening Policy Implementation
• Successes and challenges: aspects of the project that were most successful 
and why, biggest challenges encountered in managing the project, and how 
addressed. 
• Ability to adapt to changing circumstances or reprogram or change aspects of 
the program.
<<<PAGE=30>>>
24
 EQUIP2 Lessons Learned in Education: EMIS
Analyses carried out
A summary of the interviews was prepared for each EQUIP2 Associate 
Award. This summary listed what each individual had to say on each of the 
main interview topics and looked for commonalities as well as differences in 
responses across interviews. With this information, plus information available 
from the related documents, a summary was prepared for each Associate 
Award (Annex 1). In addition, a list was prepared of what worked and 
challenges across Associate Awards (Annex 1). This information served as the 
basis for Section II (Findings, Lessons Learned, and Insights).
C. HIGHLIGHTS OF EQUIP2 ASSOCIATE AWARD EXPERIENCES 
Each of the four EQUIP2 Associate Awards is summarized on the following 
pages. Longer reviews of each Associate Award may be found in Annex 1.
<<<PAGE=31>>>
25Background
UGANDA: Strengthening of the Uganda Education Management Information System  
The USAID/Uganda two-year (2003–2005) 
$1,506,390 Strengthening of the Uganda 
Education Management Information System 
EQUIP2 Associate Award was a follow on to 
two prior EMIS support programs: EMIS 1 
(1991–2001) financed by the World Bank and 
EMIS 2 (2001–2003) financed by DFID. All 
three programs were implemented by AED 
in collaboration with Africon, a consulting 
firm providing multi-disciplinary, professional 
services in engineering, infrastructure-related 
development, and management based out of 
South Africa.
The Associate Award was designed in the 
context of a Fast Track Initiative (FTI), focus-
ing on strengthening the quality of primary ed-
ucation in Uganda. USAID/Uganda anticipated that more data would be needed to guide 
what the FTI would look like and to guide meeting conditions for donor tranche releases. 
Funding for this activity was not available in the USAID/Uganda education budget. It was 
obtained competitively in 2003 and 2004, in limited amounts, from USAID/Washington to 
support Fast Track Initiatives.
The AED home office Project Director provided technical assistance from a distance and 
through periodic visits to Uganda. Africon, with an office in Kampala, provided day-to-day 
technical assistance, training, and oversight through qualified Ugandan experts hired for 
the project and a highly qualified technical advisor based in South Africa who periodically 
visited Uganda. MOE personnel carried out all data gathering, both for the EMIS and for 
establishing the GIS. 
Key outcomes included:
• Completion of a school mapping exercise (GIS) 
• Intensive trainings in Uganda, South Africa, and the United States for MOE technical 
personnel in running and maintaining the GIS and in EMIS software application 
• Training for policymakers, technical support personnel, district education officers, and 
other district officers in the use of EMIS, GIS, and basic calculation skills related to 
education indicators
• Training for the Statistics Section in developing methodology and procedures for col-
lecting data on a quarterly basis on full and half-day attendance 
• GLOBAL ED*ASSIST extended to calculate survival rates and primary completion 
rates
• EMIS data linked to the Primary Leaving Examination (PLE) results for 2004
• The WAN concept completed and a report prepared for the MOES outlining an ap-
proach to linking the head office and all district offices along with options and pricing 
Outstanding challenges included: the conditions were not met for GIS sustainability—
EMIS staff would get trained and then they would leave the MOE; it was not possible to 
fully decentralize the EMIS; there was insufficient time to ensure the paper-based scan-
ning equipment and systems for capturing attendance data were operational. More criti-
cally, during the period 2006 to 2009, the quality of data collected by the EMIS gradually 
deteriorated, response levels went down, and annual statistical reports stopped becoming 
available on a timely basis. USAID subsequently moved to re assist the MOE to recover 
its performance in the EMIS area starting in 2010.
Funding: $999,243, increased to 
$1,506,390
Time frame: 2003–2005
Purpose: Conduct a school map-
ping exercise  (GIS); institutionalize 
the EMIS, increase the level of train-
ing for EMIS; create a twice-yearly 
primary school mini-census; com-
plete a Wide Area Network (WAN) 
using cellular techniques, and 
coordinate and supervise a long-
term education Strategic Investment 
Plan.
<<<PAGE=32>>>
26
 EQUIP2 Lessons Learned in Education: EMIS
MALAWI: Education Sector Policy, Planning, EMIS Support Activities, and Higher 
Education Strategic Plan Development
The USAID/Malawi five-year (2003–2008) 
$2,704,581 Education Sector Policy, Planning, 
EMIS Support Activities and Higher Education 
Strategic Plan Development EQUIP2 Associate 
Award was designed with three components: 
Improved Strategic Planning and Manage-
ment for PIF Implementation (Component 1), 
Strengthened Education Management Informa-
tion Systems (Component 2), and Development 
of Strategic Business Plans for the University of 
Malawi and Mzuzu University (Component 3). 
Component 3 was completed in May 2004 
and Component 1 prematurely ended in April 
2005, due to a significant reduction of USAID funding to the EQUIP2 program in Malawi. 
EQUIP2 continued to support the MOE on Component 2, strengthening EMIS, through 
2008. 
When USAID decided in 2003 to support Malawi’s EMIS, the MOE had an installed EMIS 
with computers, software, and a skeleton EMIS staff who had received some training, 
having received ongoing EMIS support from donors since the early 1990s. However, there 
was limited credibility in the accuracy/validity of the data the EMIS generated and donors 
were collecting their own data to track project progress. The EMIS portion of EQUIP2 
resulted in a number of outcomes, including:
• By 2008, EMIS had become the only official and authorized education data source for 
all Malawi. 
• By 2008, the EMIS coverage rate for primary schools exceeded 98.5% each year. 
• Education statistics for 2005, 2006, and 2007 were released in November of 2005, 
2006, and 2007 respectively.
• The main EMIS office at the MOE had been refurbished with new servers, worksta-
tions, and a local area network. 
• EMIS software and data sets were installed on almost every computer in the MOE 
and its offices could produce reports according to individual office needs. 
• EMIS data had been published in booklet format for quick reference and digital copies 
were available in PDF format. 
• Numerous trainings had been organized and delivered to the PEAs (primary educa-
tion advisors) and other MOE officials. Intensive training had also been organized for 
district staff. 
• 24 of 33 district-level EMIS offices were directly involved in data collection, entry, and 
production. 
Outstanding challenges included: high levels of MOE senior staff turnover and among 
EMIS staff; limitations in qualified staff to properly support the EMIS without external 
technical assistance; limited senior MOE staff use of the reports the EMIS generated for 
policy dialogue, analysis, and management of schools; inability of the MOE to finance the 
day-to-day operations of the EMIS; limited capacity of district staff to take on the demands 
of the EMIS activities.
Funding: $1,985,620, increased to 
$2,704,581
Time frame: 2003–2008
Purpose: Improve strategic plan-
ning and management for Policy 
Investment Framework (PIF) imple-
mentation, strengthen education 
management information systems, 
and develop strategic business 
plans for the University of Malawi 
and Mzuzu University
<<<PAGE=33>>>
27Background
MALAWI: Education Decentralization Support Activity (EDSA)
USAID/Malawi’s three-year (2009–2012) 
$11,559,643 Education Decentralization Sup-
port Activity (EDSA) EQUIP2 Associate Award 
was designed in the context of a National De-
centralization Policy (NDP) to improve social 
services through decentralization passed by 
parliament in December 1998.
A 2008 USAID/Malawi-supported education 
assessment concluded that decentralization 
is primarily administrative and the devolution 
of power remains largely rhetoric. The center continues to play a significant role in setting 
policies and carrying out routine functions. The assessment also noted that the crucial 
responsibilities of management, finance, and curriculum at the regional, community, and 
school levels continue to be defined by the central MOE.
EDSA is designed to provide assistance at three levels: (1) strengthen policy and strategy 
articulation, interpretation, and implementation (policy support); (2) improve decentraliza-
tion implementation, planning, and data utilization for informed decision making (decen-
tralization and planning); (3) enhance the role and participation of communities in monitor-
ing education service delivery (schools and community). 
USAID/Malawi opted to cease support for EMIS activities centrally, instead concentrating 
resources, under decentralization and planning, on developing EMIS capacities at the 
district and school levels. EDSA is working in 6 of Malawi’s 33 districts. A few donors, such 
as UNICEF, have provided some support to the EMIS activity after USAID ended its major 
involvement at the central level.
Key EMIS outcomes as of October 2010 include having run a trial of a School Assessment 
Chart in rural and urban districts. The chart provides information on key indicators for a 
school, comparing it on these indicators to other schools in the district and national data 
and within the school over time. A Decision Support Tool has also been designed to sup-
port districts in reviewing progress on key indicators among the schools within a district 
and comparing these data with national data on the same indicators. Annex 1 contains 
some sample outcomes.
Outstanding challenges: An emerging EMIS challenge is that it is not clear how the central 
EMIS will fare with limited external assistance. Delays in producing the MOE’s annual sta-
tistical report since external support ceased in 2008 are beginning to have negative reper-
cussions on the ability to generate School Assessment Charts and Decision Making Tools 
with timely national level data. Once the chart and the tool are ready to be shared with 
districts and schools, a key challenge will be to ensure that they will be used. The continu-
ing challenge is to refocus the government leadership on key performance indicators.
Funding: $11,559,643
Time frame: 2009–2012
Purpose: Strengthen the decentral-
ization implementation at the Ministry 
of Education headquarters, district 
and school levels to support system 
progress in attaining National Educa-
tion Sector Plan 2008-2018 goals
<<<PAGE=34>>>
28
 EQUIP2 Lessons Learned in Education: EMIS
ZAMBIA: Strengthening Policy Implementation
The USAID/Zambia seven-year (2004–2011) 
$26,473,991 Support to the Ministry of Educa-
tion Strategic Plan in Improving Information and 
Strengthening Policy Implementation is a follow 
on to a program funded by USAID/Zambia from 
2001–2003, through a contract with AED to 
strengthen the MOE’s EMIS. A fraction of project 
funding was used for EMIS, given that the project 
financed a number of components.
 
Designed to take a demand-driven approach that supports what the MOE needs to imple-
ment its Strategic Plan, EQUIP2 began with three components: policy support, decentral-
ization, and EMIS. Over time, and as increased funding became available and additional 
MOE needs were identified, the Associate Award grew to 11 components. 
 
The highest priorities for the MOE under EMIS have been to: (1) institutionalize the EMIS 
to promote demand for policy-relevant data so that the analysis of these data will be used 
to enhance decision making; (2) develop the Ministry’s capacity to sustain the system with 
no or only minimal outside assistance; (3) extend the EMIS’s reach to make it useful as a 
management and planning tool; and (4) increase the system’s use by planners and deci-
sion makers. 
Key EMIS outcomes as of October 2010 when the project was drawing to a close, include:
• Since 2003 this year’s data has been produced this year, response levels have in-
creased to 99%, and the quality of the EMIS data is less questionable.
• The MOE now invests its own money in paying the Internet bill, procures its new com-
puters, and replaces old ones with its own budget. 
• The district education offices, instead of the provincial education office, captured the 
2010 Annual Statistical Complication; initial indications are that data were more ac-
curate and comprehensive. 
• Capacity building has become more demand-driven as Ministry staff at different levels 
ask for particular kinds of training. 
• A set of tools has been developed to collect data monthly, per term, and annually. 
• The EMIS is being integrated with the Payroll and Establishment Control System so 
that teachers and schools funded by the MOE can be identified and crosschecked. 
• Donors, NGOs, and other civil society units are increasingly accessing the EMIS to 
obtain information for their own planning/program implementation.
• Increasingly, Head Office personnel are owning the system. Districts, long ignored, 
are pleased to be an increased focus for attention and resources.
• The EMIS has been used to monitor MOE performance in achieving Performance 
Action Framework goals; to bring up the worst student–teacher ratios in rural schools; 
to follow teacher attrition to examine conditions, incentives, and policies needed to 
retain teachers in underserved areas. 
Outstanding challenges: Sustainability—a major objective of the Associate Award—re-
mains a challenge. It is hard to keep the level of needed technical skills in Ministry person-
nel as qualified staff move on. The MOE has limited control over who it can hire. There 
has been rapid turnover in Planning Directors. A continuing challenge is accessing and 
outsourcing changes in technology.
Funding: $13,973,991 increased to 
$26,473,991
Time frame: 2004–2011
Purpose: Improve information for 
efficient resource management and 
strengthen education policy imple-
mentation.
<<<PAGE=35>>>
29Background
<<<PAGE=36>>>

<<<PAGE=37>>>
31Findings andLessons Learned
Findings and Lessons 
Learned
The lessons learned included in the first part of this section were derived from 
findings from the four Associate Award experiences, each of which worked 
with incipient or emerging EMIS systems. The second part of this section 
presents two additional lessons learned that address challenges that USAID 
education officers may face in designing programs to support Ministries of 
Education that require more sophisticated data from their EMIS for decision 
making. 
A.  LESSONS LEARNED FROM THE EQUIP2 ASSOCIATE 
AWARDS
Eight lessons learned emerged from the review of the four EQUIP2 
Associate Awards that focus on EMIS. Some are specific to programs that 
focus on EMIS support and strengthening. Some have broader application 
for programs designed with other objectives. The latter are included in 
this review because, regardless of whether or not they are specific to EMIS 
projects, considering them in designing and implementing an EMIS program 
is considered fundamental to achieving program success.
1. With adequate external assistance Ministries of Education with 
incipient EMIS systems can generate Annual School Census reports 
and good response rates within two to three years. However, in the 
absence of ongoing external support (particularly in countries that 
have not reached a certain stage of resources maturity – human, 
technology, processes) and strong political will linked to a commitment 
to measure progress, these results can slip.
This year’s data this year
An important objective of a Ministry of Education EMIS is to collect data 
from schools and make it widely available to those who need it the same 
year that the data were collected, often through an Annual School Census
<<<PAGE=38>>>
32
EQUIP2 Lessons Learned in Education: EMIS
report. This is referred to as “this year’s data this year.” The Annual School 
Census has traditionally served as the principal repository of data on schools, 
students, and teachers used by MOEs, donors, and others to track progress in 
providing access to education for a country’s school-age population.
With a comprehensive program of technical assistance (design, software, 
implementation help, skills and use training, and field support), extensive 
staff training at multiple levels, and AED and Africon computer support 
from under a prior World Bank project, the Ugandan Ministry of Education 
and Sports was able to produce the Annual School Census in October of 
2001, the same year that the data were collected, two years after the initiation 
of external assistance. This pattern was followed over the next five years 
through 2006 with ongoing external assistance from AED and Africon 
financed by DFID and then USAID/Uganda under EQUIP2. 
With a program of technical assistance and extensive staff training provided 
by USAID under the EQUIP2 EMIS, the Malawian Ministry of Education 
was able to release in November of the same year the education statistics that 
were collected in 2005, 2006, and 2007. 
Under a prior USAID-funded TA and training contract with AED (2001–
2004) the Zambian MOE was able to start generating this year’s data this 
year starting in 2003. With continued support under EQUIP2, the Zambian 
MOE was able to continue providing timely Annual School Census reports 
through 2008. 
Producing these timely reports requires valid format and a strategy for 
applying it at the school level to fill in the needed information. Staffs from 
headquarters or from district education offices need to be identified and 
trained to collect the data from schools. In some instances extensive logistical 
support is required to enable data collectors (Ministry officials such as district 
education officers) to get out to the schools to collect data. In some instances, 
local or international NGOs have assisted with data gathering and analysis. 
Initially, outside TA and support are needed to ensure that all are carried 
out in a systematic and timely fashion. External funding is often required 
to mobilize government staff to go out to the schools, or to facilitate school 
headmasters to come to district locations in a timely fashion.
However, in all three countries, once external support ceased, there were 
delays in issuing the Annual School Census on time. In Uganda, these 
delays began almost immediately after the cessation of USAID assistance 
in 2005. In Malawi, when USAID support for the central EMIS came to 
an end in mid 2008, the 2008 and 2009 annual school census reports were
<<<PAGE=39>>>
33Findings andLessons Learned
not issued until the following calendar year. In 2009, when USAID/Zambia 
and EQUIP2 took the conscious decision to let Ministry of Education staff 
start collecting data and produce the annual school census without external 
oversight, publication of the report slipped into the next calendar year. This 
slippage occurred despite analyses that pointed to time critical steps for 
releasing MOE funds for data capture, issuing travel approvals and provisions 
for travel, and for provision of personnel to perform data capture. Other 
funding emergencies or unexpected demands on MOE funds tended to 
“overcome” funding for one or more of these time critical steps.
Response rates
Key to the credibility of data collected and their potential use is the response 
rate, i.e., the percentage of schools that provide data for the Annual School 
Census. Donors are usually concerned with ensuring that the response rate 
from schools is as high as possible.
With external assistance from USAID/Malawi under EQUIP2 coverage rates 
for primary schools in Malawi exceeded 98.5% by 2008. In Zambia, again 
with outside TA under EQUIP2, response rates in 2010 for primary school 
reached 99%.
In Uganda, and with TA from AED and Africon under a prior World Bank 
project, response rates in 2000 were 94% for primary education and 88% 
for secondary education. By the end of the second EMIS project supported 
by DFID, response rates had increased to 98% and 95%, respectively, for 
government-run primary and secondary schools. However, maintaining 
these high response rates can be a challenge in the absence of external 
assistance. After USAID EMIS support ended in 2005 response rates slipped 
significantly. By 2008, secondary response rates had slipped to 64.1% 
and primary response rates to 83.4%. Indications are that direct funding 
for facilitation and rapid movement of funds to the districts during data 
collection reduced the ability to keep the response rate high.
Implications for USAID education officers
When designing support for an incipient EMIS effort it is possible in two to 
three years to show concrete results in producing “this year’s data this year” 
along with good response rates. However, it is critical that sufficient financial 
and technical resources are available to support the effort long term. Without 
continued resources and effort (either by the MOE and/or donors or other 
strategic actors), these gains can quickly erode, unless the Ministry and key 
stakeholders make it clear how critical such accurate data are for funding, 
results, and holding government accountable.
<<<PAGE=40>>>
34
EQUIP2 Lessons Learned in Education: EMIS
2. Achieving data quality begins at the school level and takes more time, 
attention, and funding than one might expect. 
Data quality, a factor key for credibility, begins at the school level, so a 
“culture of accuracy” should be instilled. All three EQUIP2 Associate Awards 
spent considerable time and financial incentives to ensure that headmasters 
understood the use, importance, and relevance of the annual EMIS exercises. 
Many were sensitized to the use of these data at the central level to allocate 
per capita funding. After the first year of operation, every school received 
a questionnaire packet with a one-page summary of the prior year’s results. 
In Malawi and Zambia, this was later expanded to include a comparison 
of the school with other district and national schools. Finally, in Uganda, 
and after one year in Zambia, a sample verification exercise was conducted. 
Approximately 5% of schools were sampled to match questionnaire responses 
with base school records. This additional verification reminded headmasters 
of the importance of the census, and identified some fraudulent responses 
(in the Uganda’s case, per capita allocations to some schools were based on 
reported enrollment figures).
All of these steps required additional funds. Periodically, these funds were 
not available (most recently in Uganda and Malawi) or other more pressing 
matters diverted MOE money originally budgeted for these purposes. In 
almost all instances, verification needed to be combined with other Ministry-
sponsored activity to fully justify taking an extra verification step.
Implications for USAID education officers
Support for ensuring the quality of the data collected from schools and the 
perception that these data are of high quality are key for credibility and need 
to be an important part of any EMIS donor support. USAID should consider 
support to ensure that headmasters who are responsible for making school 
level data available understand the use, importance, and relevance of the 
annual EMIS exercises. In addition USAID should consider providing TA 
and training to relevant EMIS staff to develop the capacity to carry out data 
verification and assist these staff with initial exercises. As part of the project 
design process, USAID should take concrete steps to persuade MOEs to 
build in a yearly EMIS budget line item for funding data verification.
3. EMIS support should extend to the district and school levels. However, 
EMIS support at more local levels should not be at the expense of the 
central Ministry EMIS.
<<<PAGE=41>>>
35Findings andLessons Learned
As countries in Africa and elsewhere begin decentralizing their services, there 
has been a rationale and demand for providing EMIS support at district and 
school levels. As USAID and other donors have found, having information 
capacity locally shortens the time between gathering and using information. 
In addition, District staff experience less turnover. Those who create and 
use information own and understand the data, and demand increases for 
EMIS data for local planning. As decentralization becomes more widespread, 
schools and districts will seek out increased information daily and weekly. 
However, from the EQUIP2 cases it is also clear that the center should not 
be ignored. Donors, MOE and other ministry decision makers, and other 
stakeholders (civil society, NGOs) continue to need timely and credible data 
to track trends in national indicators over time and permit comparisons 
between regions. In addition, to compare their performance with national 
and regional trends, districts and schools will always need access to timely 
and accurate national EMIS data. Lastly, only the national EMIS system can 
create a common vocabulary and set of standards that assists all levels below it 
to develop their vocabulary and standards.
Under the Malawi EQUIP2, Associate Award 24 of 33 district EMIS offices 
were directly involved in data collection, entry, and production for preparing 
the Annual School Census. Under the EQUIP2 follow-on, EDSA is working 
in six districts in two provinces. An important focus is assisting district 
education offices and schools to generate and use data for decision making. 
As of October 2010 in Malawi, a School Assessment Chart had been 
developed and a trial run carried out in rural and urban districts. A valuable 
input to schools for preparing their School Improvement Plans, the chart 
provides information on key school indicators for comparing the school to 
other schools on the district and national data as well as within the school 
over time. A Decision Support T ool has also been designed to support 
districts in reviewing progress on key indicators among the schools and 
within a given district as well as comparing these data with national data on 
the same indicators.
In line with a long-term EMIS goal, EQUIP2 in Zambia assisted in 
ensuring that the 2010 Annual Statistical Compilation were captured by 
district education boards instead of the provincial education offices. Initial 
indications were that these data were more accurate and comprehensive and 
that there was a more pronounced sense of local ownership of the data. In 
addition, a set of tools has been developed to enable district education boards 
to collect data at the school level monthly, per term, and annually. As in 
Malawi, district profiles and school profiles will also be produced. The Lusaka
<<<PAGE=42>>>
36
EQUIP2 Lessons Learned in Education: EMIS
Province has been selected to run a pilot. According to an EQUIP2 quarterly 
report, from the first meeting of the pilot it was “clear that this new system 
induces schools to use information to make decisions.” 
T om Lent, AED home office director for the Zambia Associate Award, 
reflects on the value of not just focusing on working at the central level but 
also supporting activities at the level of the provinces, districts, and schools:
We found that our work at the centralized ministry level would only have 
limited, trickle down impact if we did not try to identify and work with 
the potential dynamism of provinces, districts, and head teachers. We started 
supporting provincial education officers and district officials in their convening of 
stakeholders and putting the issues of low test scores, low performance, and school 
quality on the agenda of schools and education leaders, the private sector, NGOs, 
and civil society. Good provincial leadership was successful in raising awareness 
and indignation around poor school quality, and getting people to commit to a 
new standard and goals. Also, we try not to treat education problems as though 
they only have education solutions. What works and why is fundamentally a 
development issue, and is similar to what we have learned in development over 
the decades about agency, reform, engagement of communities and stakeholders, 
access to quality information, not losing focus on children and understanding 
their context and realities.
Although there are strong reasons to provide support in provinces and 
schools, there are risks in doing this at the expense of ensuring that central 
EMIS activities remain stable. In Malawi, now that USAID is no longer 
supporting the national EMIS but focusing just at the district level, capacity 
at the national level is limited. One manifestation of this weakness in capacity 
is that the publications of the 2008 and 2009 Annual School Census have 
been delayed. For the districts EDSA is working in, this has resulted in 
difficulties in obtaining national data for carrying out comparisons as part of 
the district Decision Support T ool.
Implications for USAID education officers
In designing an EMIS program that supports the sub-national levels, 
examine the needs of the EMIS system in its entirety. Is support provided 
by USAID being delivered that both strengthens data gathering and use 
at the school, district, and provincial levels and contributes to utilizing 
these data for decision-making? Is the central EMIS communicating with 
district and provincial EMIS and are these data being used at the center for 
decision making as well? Does the center have the capacity, without external 
assistance, to continue generating timely, credible data that are being used for 
decision-making?
<<<PAGE=43>>>
37Findings andLessons Learned
4. The challenge of an EMIS is finding ways to ensure that “hard data” 
generated are actually factored into decision-making, particularly for 
the central Ministry.
Factual, objective, structured information is actually a small component of 
most important decisions. Decision makers, as Peter Drucker eloquently 
pointed out in 1982, always begin with opinions. The role of most scientific 
or factual information is to either support or, most often, disagree with 
prevailing opinion. T raditional EMIS often are not designed to “debunk” 
opinions. They are usually oriented to routine, scientifically defined measures. 
T o convert data into information and ultimately knowledge requires human 
interpretation, understanding, and presentation. The skills to interpret and 
present well can be taught, and are increasingly being addressed by medium-
term courses. But these skills need to be planned for as part of a “medium-
term” human resources conversion.
A frequent error has been to assume that data will be sought out and used for 
decision-making. EQUIP2 experience has shown that EMIS data are more 
apt to be used when one or more project components need EMIS data for 
decision-making. A conscious effort is made, often with advisors embedded 
in MOEs, to generate data and analyses to address key problems. An 
alternative is for EMIS projects to build in steps to ensure that MOE staffs 
learn how to use the data for decision-making.
In Uganda the MOE, with assistance of EQUIP2 advisors, used the EMIS 
and GIS data to allocate capitation grants, to determine teacher allocations 
according to a formula, for textbook allocation, and to reallocate teachers. 
Thanks to the school mapping exercise, for the first time, a lay person could 
understand the data: red schools were seen as bad in terms of student/teacher 
ratios or other input indicators, and green schools were seen as good. See 
Annex 1 for some samples of just such presentations.
In Zambia, where EMIS was one of several EQUIP2 components, ample 
use has been made of data generated for MOE decision making as well as 
for NGOs and civil society. EQUIP2 technical advisors supported both 
the EMIS and the other components. Stakeholders, within and outside the 
MOE, now identify the figures and information they need from the EMIS, 
and how they want it packaged. EMIS data have been used to monitor MOE 
performance and effectiveness in achieving goals through the nationally 
agreed-upon Performance Action Framework. 
In teacher recruitment, EQUIP2 in Zambia created a model that looked 
at EMIS data available on every school, including teachers and pupils, and
<<<PAGE=44>>>
38
EQUIP2 Lessons Learned in Education: EMIS
based on these data calculated the total number of teachers that should 
be hired. Based on factual and tested information, EQUIP2 advisors were 
able to show how to bring the worst student–teacher ratios down to 75/1, 
identify which schools should be targeted, and how many teachers for each 
district would be needed to bring the ratio to a uniform standard. This has 
been widely accepted both within the MOE and within the Ministry of 
Planning—which still uses a five-year plan approach to adjust government 
spending and improvement targets. 
A central focus of EDSA in Malawi is to facilitate a process whereby MOE 
staff at the district and school level generate and then utilize local EMIS data 
for decision making. Charles Matemba, EDSA EMIS advisor, reflects on 
both the importance of ensuring that data are used for decision-making and 
the challenges faced:
EMIS data utilization can be looked functionally at least at two levels: at the 
central level and at the district and sub district levels including the school. Given 
that information needs as you move from the school to National level are not 
exactly the same, there is a need for the system to factor that in order to meet the 
core needs at each level and hence increase utilization. Processed data products 
such as charts (districts charts, zone charts, school charts, time series analyses, 
school comparisons etc) need to be available at these levels in modes that render 
them both relevant and easy to use for stakeholder at each respective level.
If the products were made available, a culture of data use and associated skills 
will need strengthening. The challenges include literacy, particularly at community 
level in rural schools and at district level; inevitable political elements in the 
Local Councils. Proactiveness will be important for education managers and civil 
society to champion data utilization culture through understanding and utilizing 
leverages and opportunities within the system in order for the sector to make 
progress. The use of the processed EMIS data from the point of generation (at the 
school) besides improving management also leads to improved data quality as data 
providers will appreciate the value or use of quality data better. 
Implications for USAID education officers
In working with host country counterparts, invest in appropriate training 
and knowledge development for those who interpret information and make 
it available to senior managers for use in taking important decisions. T raining 
should include preparing “just-in-time” briefs, eye-catching reports and 
presentation of data, and other strategic communication methods. Design 
EMIS programs so that project-supported EMIS technical advisors guide 
their counterparts to use EMIS data for decision-making.6
6 Interestingly, the increased focus on quality education, and the focus on numerical measures of it,
<<<PAGE=45>>>
39Findings andLessons Learned
5. Fundamental for EMIS success is a comprehensive and ongoing 
capacity building program for Ministry of Education staff at multiple 
levels that factors in the inevitable staff turnover, and ensures that 
existing staff acquire new skills as new requirements emerge.
In a given Ministry of Education EMIS technical staff and data input 
personnel are usually located in the Planning Directorate. Also located in 
the Planning Directorate are the individuals responsible for analyzing data 
generated by the EMIS system and generating reports incorporating these 
analyses to be used at more senior levels for policy and other decisions. The 
Director of Planning typically plays an important leadership role in ensuring 
that resources are available to collect quality EMIS data on a timely basis; 
that analysts are generating the needed analyses; and in ensuring that these 
analyses reach senior Ministry of Education personnel and individuals in 
other Ministry of Education and other units on a timely basis for decision 
making. In an EMIS project it is important to build into the design 
provisions to ensure that these individuals acquire the skills needed to operate 
and utilize the data generated by the EMIS system.
All four EQUIP2 Associate Awards have included a hefty training or capacity 
building component; not just for EMIS and related staff, but also for other 
MOE staff to ensure that they had the capacity to generate timely data. 
T raining for other staff focused on honing their skills in analyzing the data 
and in using these analyses for decision-making. 
EQUIP2 Uganda built in funding and time for an extensive staff-training 
program. MOES staff received two intensive trainings in using school 
maps for education policy decisions. Key technical MOES personnel were 
given on-the-job training in map maintenance and manipulation. Select 
personnel from the MOES head office and certain district personnel received 
additional training to use maps for more detailed analysis. Three members 
of the Education Planning Division of the MOES were sent for two weeks 
training in South Africa to learn the school map software required to run 
and maintain the system. Nine members of the MOE received extensive 
training in the United States in EMIS software application and maintenance. 
MOE policymakers and technical support personnel were trained in parallel 
on similar but separate skills in training lasting two to three weeks. Finally, 
district education officers and three persons from each district education 
office received three days of training in the use of EMIS, school maps, and 
bode well for a much more intense use of factual information and the systems that support it. In the 
U.S., the “No Child Left Behind” act has dramatically increased the need for student-centered informa-
tion, and has challenged more traditional approaches to averaging general numbers.  Many school 
information systems, and District summaries, have improved dramatically as a result.
<<<PAGE=46>>>
40
EQUIP2 Lessons Learned in Education: EMIS
basic calculation skills related to education indicators. Three years later, at 
least half of these people remained in their posts. Five years later, in 5 to 
10 districts, the original ED*ASSIST software package was still operating 
and being used to produce “planning style” reports. These trainings were 
instrumental in providing these individuals with the skills to operate the 
EMIS system. The subsequent support in selected districts more firmly 
embedded “evidence-based” decision making into the local education culture.
In Malawi, EQUIP2 organized and delivered numerous trainings for 
primary education advisors and other officials from the MOE. District staff 
also received intensive training. T raining activities focused primarily on 
developing MOE staff capacity to use the GLOBAL ED*ASSIST program. 
Data processing training workshops were introduced in 2004 and continued 
successfully over the next three years. In addition, data utilization workshops 
geared towards divisional, district, and zonal heads took place at the end of 
each Annual School Census. EQUIP2 also organized numerous trainings 
for all school heads where they were oriented in how to complete the census 
questionnaire. T rainings for district education staff focused on data collection 
and using datasets for education purposes. During the trainings, CDs and 
booklets were given to the participants explaining how to use the data 
provided through practical examples. By 2008, most district managers were 
regular users of EMIS data and the demand for the data had purportedly 
greatly increased.
Before the EQUIP2 Zambia began in 2004, capacity building in EMIS was 
fragmented. Ministry of Education staff received a great deal of training 
but it was supply driven and not linked to an overall program strategy. By 
2010, with the assistance of EQUIP2 technical advisors, capacity building 
had become more demand driven. Planners, for example, requested training 
in M&E and district statistical officers requested technically specific EMIS 
training. Some of this training was keyed to analyses of allocations to 
districts, and to other initiatives, such as textbook distribution, headmaster 
management training, and an increasing demand from the head office for 
fact-based analysis of special requests. Recently in Zambia, the creation of 
“power user” EMIS groups has been encouraged, as well as “online, built-in” 
HELP screens that can provide simple assistance from the computer directly 
without face-to-face training. However, technology mediated assistance 
remains in its early stages. 
In spite of all the training provided, the EQUIP2 Chiefs of Party and EMIS 
technical staff acknowledged that the training was not sufficient. Even 
by designing training to take into account MOE staff turnover, turnover 
continued during the projects and afterwards. In Uganda, after six years of
<<<PAGE=47>>>
41Findings andLessons Learned
external support only one of three EMIS technical positions were still filled 
by 2009 when USAID/Uganda resumed assistance for the EMIS. In Malawi 
in 2008, when USAID assistance for the central EMIS ended, only one 
qualified EMIS specialist remained in the MOE headquarters. In Zambia, 
seven senior people either left the EMIS operations over a six-year period or 
were transferred to other areas because of their technical skills. In addition, 
there were four Planning Directors in six years. 
Kurt Moses, AED Vice President and a senior EMIS specialist with 
experience supporting EMIS systems in over 40 countries, observes: 
If you think the amount of training needed is X, you should budget for 3X. 
Internal inefficiencies, turnover of personnel, the basic selection process for 
people who get “training and funding” all mitigate against easy and efficient 
training. Additionally, we attempt to build capacity in entire units—not just 
individuals—since a “critical mass” of trained personnel, working together, 
builds more enduring capacity. Ultimately, what you are seeking to engender is 
“competence” among EMIS personnel and units. Competence is a combination of 
skills, knowledge, and motivation—that is what is needed to sustain EMIS. 
Marisol Perez, USAID/Malawi education team leader who designed and 
oversaw the first year-and-a-half of EDSA’s implementation would like to see 
the traditional focus on “training” expanded to “capacity building.”
We are looking at capacity building not just as training (on Excel, GLOBAL 
ED*ASSIST). Training is a first step. We are also looking at capacity transfer, 
and addressing critical questions such as, “how do you know what capacity 
you are building when you don’t have an inventory of where people are, so you 
know you are building their knowledge and skills?” You can conduct training on 
content, but you need to accompany the people trained, sit there with them, and 
go through the process with them. You need to mentor them, coach them, helping 
them network and seek out relevant resources. You need to ask yourself who your 
end user is. Usually it is not just one person. What about the department and/or 
the unit?
Implications for USAID education officers
When designing an EMIS project, build in sufficient funding and support for 
training staff and capacity building at all levels, including building training-
of-trainer capabilities to account for the inevitable staff turnover and training 
in new technologies. Look for creative, user-friendly, and lower cost ways of 
making training available. Some examples include the use of “power user” 
EMIS groups and HELP screens. Where possible, build in a mechanism for 
evaluating the skills acquired by the individuals receiving training, as opposed
<<<PAGE=48>>>
42
EQUIP2 Lessons Learned in Education: EMIS
to just keeping track of number of individuals trained on different topics. 
Finally, look for ways to encourage MOEs to build sufficient funding into 
their recurrent budgets for ongoing training at all levels in EMIS operations 
and the use of information supplied by EMIS systems in decision-making.
6. Having the information required to establish realistic targets and to 
track progress in reaching these targets in a donor-supported program 
creates strong incentives for USAID and other donors to support the 
establishment and/or strengthening of EMIS systems. 
Donors often serve as the impetus for establishing or strengthening EMIS 
systems since they need a mechanism to track progress in achieving the 
project targets. Often donors establish high-stakes targets that must be met 
before issuing additional tranches of funding. These high-stakes outcomes 
can create strong incentives for MOEs to “adjust” EMIS results in favor of a 
Ministry. Donor-encouraged EMIS should include verification exercises as 
well as transparent processes so that accuracy is not an issue. More frequent 
measurement of key performance indicators is useful so that education 
systems have some “warning” regarding their performance before a high-
stakes outcome. 
In Uganda, one motive for designing the EQUIP2 EMIS project was that 
donors were collaborating with the MOE under the Fast T rack Initiative 
(FTI) to develop a comprehensive primary education support program. 
The USAID/Uganda education team leader had limited education funds 
to support the FTI. However, USAID/Uganda did have access to a small 
amount of education funds available from USAID/Washington to support 
FTI. The education team leader had the foresight to see that a valuable 
contribution of USAID/Uganda to the FTI would be a small project to 
strengthen the MOE’s EMIS to assist the Ministry and donors to establish 
FTI targets and track achievement once FTI funding became available. 
His prediction was correct. Donors used the MOE’s EMIS to identify 
underperforming districts and then to target assistance to them under the 
FTI. Donors used education data generated by the EMIS to track progress 
in meeting conditionality under the FTI. When it became apparent that 
agreed-upon EMIS FTI targets were not being met, donors threatened to 
stop funding until the MOE could show what actions it was planning to take 
to address these missed targets.
Malawi has been a key example of very productive donor coordination and 
as a result improvement in the overall information environment. During the 
1990s, donors had become discouraged about their lack of success in assisting
<<<PAGE=49>>>
43Findings andLessons Learned
the MOE to establish a credible EMIS. By the early 2000s each donor had 
established its own system for collecting data to track progress on aspects of 
education that they were supporting. Assistance from USAID/Malawi under 
EQUIP2 to strengthen the MOE’s EMIS, has made it possible to rejuvenate 
donor support for a central EMIS. As of 2008 most donors were using the 
central EMIS system to track progress under their projects instead of relying 
on their own separate data tracking systems. A key lesson has been starting 
by establishing a “unified” vision, followed by timely delivery of a very usable 
product.
In Zambia data from the EMIS is being used in monitoring the effectiveness 
of the MOE in achieving goals established under the nationally agreed upon 
Performance Action Framework (PAF). EQUIP2 advisors have trained MOE 
staff to track student–teacher ratios, a major performance indicator under 
the PAF , to identify how many teachers should be assigned to districts and 
schools and to what location. When donors found out these data were not 
being followed or used by the Ministry to assign teachers and thus failed in 
its performance under this indicator, donors put on increased pressure to 
meet performance targets. In 2007, data from the EMIS showed that net 
enrollments for girls were below targets established under the PAF . With 
donor pressure, the MOE tripled the number of bursaries for girls in grades 8 
and 9 and was able to increase female enrollments by 20,000. 
Kurt Moses reflects on the incentive that significant donor funding provided 
for strengthening Uganda’s MOES EMIS:
Uganda was a fascinating example of donor coordination. You can’t underestimate 
the importance of EMIS especially where donors have a huge stake/investment 
in Ministry of Education operations—at one time donors were supporting 
up to 70% of all operating expenditures. In the case of Uganda, where other 
donor-supported the Fast Track Initiative, the Ministry of Education and Sports 
respected the relationship between the money they received from the donors and 
the targets they had to achieve. These targets were measured through the annual 
EMIS data collections.
Implications for USAID education officers
Having the information required to establish realistic targets, and to track 
progress in reaching these targets in a donor-supported program, creates 
strong incentives for USAID and other donors to support the establishment 
and/or strengthening of EMIS systems. In designing a program to support 
EMIS capabilities, USAID and/or other donors should collaborate with 
MOE to establish frequent measurements of key performance indicators 
so that education systems have some warning regarding their performance
<<<PAGE=50>>>
44
EQUIP2 Lessons Learned in Education: EMIS
before a high-stakes outcome affects a donor decision to withhold funding 
when an MOE has not met agreed-upon targets.
7. Sustainability approaches require ongoing effort and need to be a part 
of projects from the very early stages.
As with any investment, EMIS requires both capital and operating funds—
capital funds to enhance software, replace aging equipment, and retrain 
staff; and operating monies to ensure that gathering, processing, editing, and 
dissemination of information throughout the system continues on a regular 
basis. Some governments understand information’s importance—but many 
still do not. Few countries have, as yet, reliably committed the 3-5% of their 
annual budget that a solid, sustainable EMIS requires. Countries that have 
include South Africa, for a time; Namibia; and several Central American 
countries.
Malawi EQUIP2 covered all financial expenditures in support of EMIS 
activities. When EQUIP2 ended in 2008, the MOE could not finance the 
continuation of the EMIS. With key staff turnover, only one person with the 
required technical skills was left in the EMIS unit to run the EMIS, leaving 
serious doubts regarding prospects for sustainability. 
In Uganda achieving sustainability of EMIS operations was a key focus 
of EQUIP2 and its predecessor funded by DFID. Following the end of 
EQUIP2 support, there was a marked slippage in the EMIS operations and 
capacity. Data integrity problems persisted and the timeliness for annual data 
releases worsened dramatically. Over the same period, the Statistics Section in 
the MOE had also become vulnerable: in 2009 only one of three statistician 
positions were filled. Computers procured in 2003 were still being used in 
2010 and were becoming obsolete without additional capital investment. At 
the District level, monies to facilitate certain operations, such as the District 
operations in support of the collection operations, had disappeared. Districts 
have been forced to find ways to “piggyback” the collection operations on 
other activities – and the result has been a contributing factor to the slower 
data collection and lower response rates. When in 2010 USAID/Uganda 
again assumed support for the EMIS, aside from District commitment and 
remainders of trained personnel, it was a bit like starting again to build a 
timely and credible EMIS system.
In Zambia prospects for achieving sustainability of EMIS and related 
operations are brighter. EQUIP2 initially funded the procurement of 
computers for the central Zambia Ministry, provinces, and districts and
<<<PAGE=51>>>
45Findings andLessons Learned
paid the Internet bill. By 2010 the MOE was investing its own money in paying 
the Internet bill. The MOE was procuring new computers and replacing old 
ones. T o strengthen the sense of ownership and responsibility of the MOE, in 
2009 EQUIP2 reduced its input in the day-to-day running of the GLOBAL 
ED*ASSIST system. Although this resulted in some delay in the production of 
the Education Statistical Bulletin, it has showed what steps the Ministry must 
take to ensure EMIS sustainability. This includes reorganizing the MOE and 
formalizing performance targets to ensure that a specific unit is dedicated to 
deliver timely information. The process has started with the revision of the MOE 
headquarters, provincial education offices, and district education board offices 
strategic plans and organization structures to make the new EMIS sustainable. 
In the last year of the project, Internet-based enhancements to the EMIS system 
have been made to better serve districts, and to speed the data exchange cycle 
using faster electronic methods. An encouraging outcome has been the demand 
from the President’s Office and Cabinet for fact-based updates of the Five year 
Plan, as well as the introduction of systematic measurements of activity at the 
District level. These, too, have driven sustaining the capacity to generate and 
use information. However, even with the above, there are questions about what 
will happen, vis a vis sustainability, when USAID funding under the EQUIP2 
Associate Award for EMIS technical assistance comes to an end. 
The second part of sustainability is high level including parliamentary, 
commitment to more “fact based” decision-making, which will, generally, lead 
to enhanced accountability for elected leaders—whose performance is being 
measured. Facts alone, in any political situation, are not sufficient to move policy 
in a generally better direction. However, they are “necessary” to create a base for 
both transparency and enhanced rationality.
Kurt Moses, AED home office EMIS specialist, reflects on ways MOEs can 
ensure sustainability of EMIS operations in the face of staff turnover: 
You need to view EMIS as a three to five year technical commitment – and a 
longer commitment for changing the internal culture. Another ten years would not 
be unheard of. It needs to be placed, institutionally, with a person who exercises 
leadership, and who is being held accountable for implementation—this is, usually, 
the Planning Director. A key issue with EMIS is that you train specialists in the 
Ministry of Education, provide them good technical and analytical skills, give them 
certifications and respected (world caliber) training, and then they leave for better 
paying jobs elsewhere—usually in the private sector, but sometimes directly with 
donors or NGOs. A possible way around this is to identify both effective career paths 
for such people within the government but, as well, finding secondary level math or 
science teachers, in mid-career, who have shown dedication to education and “second” 
them for EMIS and analytical jobs. Then, rotate them through the Ministry of
<<<PAGE=52>>>
46
EQUIP2 Lessons Learned in Education: EMIS
Education head office for two to three years. The key to personnel sustainability is 
to think of them as a capital investment—which needs continuous support and 
nurturing--not as an “assumed capacity” or as a recurrent expense.
Sri Perrera, Zambia EQUIP2 EMIS advisor reflects on achieving 
sustainability from a systems and processes perspective:
In my last year my focus to improve sustainability was to simplify systems and 
processes as much as possible. We tried to set up an environment that strived for 
continuous improvement but simplified systems. For example, by expanding the 
number of predefined reports we made information more accessible to all users. 
Our goal was to reduce the dependency on scarce skills.... By simplifying some 
of the data cleaning and data management tasks, we made district level data 
management and ownership possible. 
T om Lent, AED home office Project Director for the Zambia EQUIP2 
project reflects on sustainability through the lens of “accompaniment” and 
“graduation.”
The key challenge regarding the best role of projects and the proper role of outside 
foreign technical assistance is much more complex and interesting than “have 
we worked ourselves out of a job?” Ministries almost everywhere have been 
and will be in need of technical assistance in key strategic and technical areas. 
The challenge is “accompaniment” and “graduation.”… Mostly, we try to be 
interactive, and appreciate where the MOE is, where it wants to go, and how 
to get there. We start at one level of need, and then as the MOE becomes more 
competent and moves on to other, more complex issues and needs, and their 
technical needs change and are more complex, we try to graduate to that next level 
of TA as well.
Implications for USAID education officers
Sustainability approaches need to be a part of projects from the very early 
stages: comprehensive staff development and capacity building programs, 
creative approaches to addressing human resource issues (including inevitable 
staff turnover), and changes in policies and procedures as appropriate. Good 
information models with early products and outputs help establish the goals 
of an effective EMIS. When senior management requires, understands, and 
uses information generated others see that the information is of importance 
to the operation of the education system. Sustainability requires that MOEs 
include funding in their budgets to cover recurrent costs of EMIS hardware, 
software, operations, and ongoing training.
<<<PAGE=53>>>
47Findings andLessons Learned
 A valuable role for USAID may be to build into projects assisting Ministries 
of Education to work with Ministries of Finance to build recurrent costs for 
running EMIS systems into annual MOE budget submissions, along with 
funds for “block grants” to Districts or Provinces as part of decentralization 
programs. In several countries, such as Nicaragua and Guatemala, routine 
recurrent funds have been “ring-fenced” to ensure that every year EMIS 
and information efforts receive regular funding. Under decentralization, 
municipal agencies, provinces or districts will all be at different levels of 
both understanding and commitment. Ensuring “ring-fenced” funds for 
information and reporting purposes will become increasingly powerful as a 
means of ensuring sustainability. Additionally, sensitization campaigns that 
remind citizens of the information they are entitled to (a traditional role of 
newspapers) becomes increasingly important. Quality education is not only 
highly dependent upon supply factors (schools, teachers, supplies) but on 
demand factors where parents and families demand a good education and 
provide what a child needs (nutrition, support, space for study, and school 
supplies). 
8. New technologies and increasingly sophisticated demands on EMIS 
systems will periodically require technical expertise that may not be 
available within the government or from local contractors.
As users of EMIS systems become increasingly “savvy” they tend to make 
new demands on the EMIS system. In addition, as new EMIS technologies 
become available, possibilities emerge for new applications of the EMIS 
systems that had not been available previously. This, in turn, often requires 
new programs; new data collection methodologies; and possibly new 
hardware -- all of which require technical expertise that may not be available 
within a given country and very often not within a Ministry of Education.
 A study carried out in Uganda in early 2010, after 10 years of external 
support, identified a number of new EMIS support needs. Among the 
needs identified were the acquisition of emerging technologies that have 
the potential to dramatically alter the way in which data are collected and 
reported back, and to dramatically improve the timeliness of data availability. 
The report indicated that the Uganda EMIS paradigm needs to be changed 
from one based on the annual collection of data via the School Census to one 
where data is “collected when needed” using new technologies such as Cell 
Phone SMS, Smart Phones with ODK style capacity, tablets or netbooks. 
This will achieve dramatic improvements in speed of data availability and 
reductions in cost. However, since the capability doesn’t exist in country, 
external assistance will be required to achieve this paradigm shift.
<<<PAGE=54>>>
48
EQUIP2 Lessons Learned in Education: EMIS
In Zambia, per a recent EQUIP2 report: “A challenge for the future will be 
for the designers of the EMIS data system to be 2-3 years ahead of the process 
and to be able to predict issues, the research agenda, and gaps in knowledge 
and information. The Ministry of Education needs to be anticipating the 
kinds of problems and issues that policy people and other stakeholders will be 
addressing now that there is an institutional cultural shift in ‘policy seeking 
data’ and data informing policy.” It is doubtful, even with progress made by 
the Zambian Ministry of Education in institutionalizing its EMIS system, 
that it will be able to accomplish the above without external assistance.
Implications for USAID education officers
When designing an education program that has an EMIS component, 
determine whether the existing EMIS system has the capacity to generate 
and process increasingly sophisticated demands for information. If it is 
determined that it doesn’t, and if this information is critical for broader 
project tracking/monitoring, build in assistance (technical, software, staff 
support, other) required to meet these needs. In addition, look for ways 
to build in mechanisms for assisting the MOE and decentralized units to 
identify financial resources and the technical expertise that it will require to 
address future needs for increasingly sophisticated information and new data 
technologies. Missions should consider empowering the local private sector 
to provide more specialized expertise—for example, in Central America, 
some private contractors are now providing continuing support to Ministries 
for certain elements of their EMIS systems. By rebidding contracts for 
this support at least every three years, it is possible to create a more “level” 
competitive field, and encourage healthy competition. This means, however, 
that Ministry personnel need to become better “technical managers” rather 
than just generalist or even technicians.
B. LESSONS LEARNED FROM BROADER EXPERIENCE
9. Increasingly, political and policy leaders rely on Key Performance 
Indicators (such as student–teacher ratios, percent of students reading 
at grade level) to make policy decisions. EMIS systems need to be 
prepared to assist in channeling questions in a way immediately 
relevant to their needs. 
EMIS often lags behind changing policy initiatives. T o make responses from 
EMIS more popular as an adjunct to policy studies and policy statements, 
Key Performance Indicators (KPIs) have gotten much wider use. KPIs are 
calculations based on EMIS data such as student–teacher ratio, student–
classroom ratios, percent of students reading at grade level. The view that 
more donors and governments take is that: “…if it cannot be measured,
<<<PAGE=55>>>
49Findings andLessons Learned
then we cannot be sure about real results.” Accordingly, Key Performance 
Indicators now become the first things examined, rather than detailed tables 
generated from annual education statistics or summary graphs of enrollment.
Experience has shown that it takes approximately three years before 
policymakers and the public understands the strengths, weaknesses, and 
meaning of a KPI. Even a simple indicator, such as pupil–teacher ratio is 
often subject to debate. For example, does it include just full-time teachers? 
Part-time teachers? Volunteers or adult “aides”? Government teachers? 
When KPIs drive funding decisions (such as capitation, or compliance with 
an objective, or a portion of an entitlement formula) the effects of such 
an indicator and the ways it can be “gamed” become crucial elements of 
understanding information.
It takes some customizing of KPIs to be sure that they properly measure the 
policy and objectives to which they are attributed. For example, in certain 
countries with a large alternative or adult education program, some KPIs 
are altered by the different ratios and teaching approaches used in these 
programs as opposed to more traditional K–12 programs. In more advanced 
countries, teacher-related KPIs may be altered by “fully or partially mediated” 
instruction, where electronic lessons play a larger role in delivering content. 
Implications for USAID education officers
In designing EMIS programs, be aware of the kinds of information that 
policymakers need to make decisions, including being able to track Key 
Performance Indicators over time and build in the support relevant MOE 
staff will need to provide timely and credible information, packaged so that 
policymakers can use it. In many cases, this will go beyond providing what 
has traditionally been support for collecting and reporting timely basic 
education statistics.
10. The requirement to provide “quality education” means additional, 
important demands on EMIS and the allocation of more and more 
consistent resources for information.
Following the early EFA focus on access for all children to education, 
which remains a challenge for between a quarter and a third of all EFA 
countries, the UN has amended the statement to now state “access to quality 
education.”Worldwide, this has created a host of experiments on defining 
“quality education,” followed by making this term operational and ensuring 
stakeholder understanding of what a quality education means.
<<<PAGE=56>>>
50
EQUIP2 Lessons Learned in Education: EMIS
Quality education has a wide variety of definitions. The most common 
definition typically revolves around literacy and numeracy, and then other 
subject areas, and then critical thinking, learning in a team or group, and 
abstract thinking. Many of the higher order objectives have been difficult 
to implement, and it has become clearer that “systems do not educate 
students….” T eachers and schools educate students. Systems can only set 
standards and support the conditions for learning T raditional EMIS in 
emerging countries tends to measure access and efficiency, but is less well 
developed to measure quality and the components that contribute directly to 
quality of education in schools.
Several information approaches to addressing quality education have become 
popular, and are being worked out in various national settings. One approach 
is based on National T esting Systems, which uses existing testing and 
examinations used to “screen” for the most qualified children for secondary 
or tertiary education based on available places. Several EMIS efforts have 
attempted to link known data on schools, and their inputs, to national 
testing results. This has worked when the national testing/examinations 
units work well with the MOE. However, in a number of countries 
national testing/examinations groups guard their “independence,” making 
it difficult to integrate information they generate with EMIS information 
by student, across schools, and districts. One of the rationales for guarding 
this information is that national testing/examinations units have an absolute 
demand for security, consistency, and annual timeliness. Otherwise, anxious 
parents and students create major political problems.
A second approach now emerging is the use of Opportunities to Learn 
(OTL) theory that categorizes at least eight factors necessary for effective and 
quality learning. Among these factors are: attendance (both students and 
teachers), time on task (reading or writing), adequate materials, and emphasis 
on reading. The major focus of most current systems using an OTL approach 
is on attendance for both student and teacher. Other OTL factors that have 
been captured include hours of school operation, presence of textbooks at 
appropriate ratios, and encouragement of reading through self-reporting.
However, in some instances, these efforts are resulting in massive 
paperwork—too much to be processed by districts, let alone the national 
level. Some countries are moving to electronic recovery via cell phone and 
other electronic means, which provide possible cost savings. The newer 
Uganda EMIS effort is one example, although the cost savings are yet to be 
realized. The key for most OTL factors is that, since they are school based, 
school authorities must be able to do something about changing OTL 
factors.
<<<PAGE=57>>>
51Findings andLessons Learned
Newer EMIS efforts in countries such as Liberia, Senegal, and Equatorial 
Guinea are beginning to adjust to the more detailed demands of OTL 
approaches, as well as accommodating information that is timelier—not just 
once per year, but on a term or even monthly basis. The focus on quality in 
education is demanding more detail and more frequency in monitoring and 
attending to conditions for good schooling.
Implications for USAID education officers
In designing EMIS support, examine whether key decision makers (MOE, 
other ministries, USAID, other donors) are going to need data, available 
on a sequential basis, to assess changes in education quality. If the answer is 
yes, explore options (including the implications for cost, level of effort, and 
time to generate the data) for assisting MOEs to generate data that make 
it possible to assess changes in education quality over time. One option 
includes linking EMIS databases with national performance testing databases. 
Another option is to identify OTL indicators and set up a means of collecting 
and interpreting data on these indicators on an ongoing basis through the 
EMIS.
<<<PAGE=58>>>

<<<PAGE=59>>>
53Emerging Technologies and Approaches
Emerging technologies 
and approaches
The following technologies or approaches already hold great promise for 
developing country EMIS—they all tend to both democratize, and provide 
information faster and in more useable formats.
A. CELL PHONES
Cell phone use has increased exponentially in the developing world. There 
are now more cell phones in use in 2nd and 3rd world nations than in the 
entire “developed” world. Cell phones already reach more schools than 
computers have or will in the next five years—and will form an essential part 
of any future EMIS. Cell phones are already used to log school locations and 
to communicate key information such as “attendance or enrollment data” 
to District or national offices rapidly. They are typically more “sustainable” 
because people want them for multiple reasons—but mainly because they 
allow for relatively cheap communication. Cell phones can also provide a 
relatively low cost option for communicating between users and suppliers of 
key school necessities.
B. TABLET COMPUTERS
Tablet computers, and, to some extent “netbooks,” hold the promise of 
both lower cost and highly portable and adaptable instruments to place 
more information into more stakeholders hands than ever before. Tablets 
lend themselves to classroom observation and easy presentation of graphics. 
They can be used with minimal training and they lower the cost of moving 
educational information to the school and classroom level. They also support 
Regional and National levels need to be informed.
C. GOOGLE EARTH AND DIGITAL MAPPING 
This extremely powerful geographic presentation application, now available 
on almost any computing device, allows a rapid presentation of the “status” 
of any social sector, but particularly education for very low cost. Virtually
<<<PAGE=60>>>
54
EQUIP2 Lessons Learned in Education: EMIS
any digital data (photos, facts, video) can be linked to its geographic locus—
and allow even modestly trained personnel to understand the significance 
of allocating resources. It also provides, through highly visual means the 
opportunity to plot progress. Annex 1 includes several examples of “digital 
mapping” already successfully in use.
D. PLANNING SIMULATION AND BUSINESS INTELLIGENCE 
Simulation/projection has been a “staple” of five-year plans for many 
years. The dramatic increase in the power of EXCEL spreadsheets (which 
now incorporate many advanced features) and other tools allows EMIS 
systems to routinely accommodate forward planning. Hence, while current, 
managerially oriented information remains at the heart of an EMIS, the 
ability to quickly translate accurate “base information” into projected future 
outcomes is increasingly important. Several examples of both EXCEL based 
projection approaches that are highly graphical are provided in Annex 1. 
Moreover, the use of Business Intelligence software (which can “assemble” 
data from a variety of sources—both digital and manual) can dramatically 
increase the speed and ease of use of information. T ools such as Business 
Objects, Hyperion, or advanced SAS, have all proved effective in this regard. 
One element of these programs is the ability to not only provide graphs 
and charts, but to create “dashboards” which dynamically indicate progress 
or decline according to established targets. This information can, in turn, 
be communicated either to Web sites, or sent to cell phones with “smart” 
capacity. 
However, these more sophisticated tools only make sense if they continue to 
answer quickly and accurately (which is dependent upon solid information 
from schools and teachers) the questions that policymakers or stakeholders 
are asking.
E. OPEN SOURCE SOFTWARE 
Developed as an alternative to proprietary software driven by specific 
commercial interests (and often requiring both high licensing and 
maintenance fees), “open source software” has become more widespread 
and increasingly present in many educational applications. A number of 
NGO lead efforts have made use of “open source” free software to create 
special applications. Many university and pre-university programs now 
train personnel in “open source” approaches. Many EMIS systems will 
likely become a mixture of both “open source” and proprietary software 
for the near-term future—open source often requires more training for the 
user, whereas many proprietary systems often require a large commitment
<<<PAGE=61>>>
55Emerging Technologies and Approaches
and more funds “up front” in exchange for organized training and certain 
performance guarantees. The key is to provide points within EMIS 
technology where different applications can be accessed or exported so that 
alternatives are available over time. Examples of some recent, generally “open 
source” software approaches include: Android, Linux, Java, and a massive 
variety of open source applications available on the Web.
F. ACCESS TO THE WORLD WIDE WEB  
Increased access to the Internet is the wave of the future—every nation, with 
rare exception, aspires to access to the information and economic benefits 
that the Internet provides. While it clearly has transformative effects on the 
culture, not all of which can be predicted, the Web is a powerful adjunct 
to better education systems—both administratively and academically. Its 
introduction in a formal system of education needs to be calibrated to 
enhance and not undo positive practices. The Web can dramatically increase 
the ability to be responsive to education need and shortages—if linked to 
appropriate political and administrative units. Accordingly every future EMIS 
system needs to plan for and incorporate it as countries increase access to the 
Web. 
The next ten years will see more technological and political progress 
capable of improving education than has occurred in the last ten years. This 
progress can empower students, teachers, parents and schools to be more 
competent than ever before. The EMIS challenge is to adapt to a much 
more decentralized, democratic and self-empowered education system whose 
demands for quality will drive the next wave of education for all.
<<<PAGE=62>>>

<<<PAGE=63>>>
57Annex 1: Sample EMIS Outputs - Historical & Future
Annex 1: sample EMIS      
outputs - historical &     
future
UGANDA
Showed in map format, both “thematic” and via “point” mapping, is the 
status of schools and Districts according to “key performance indicators 
(KPIs)”, in this case Pupil/T eacher Ratio: 
Thematic Mapping:
<<<PAGE=64>>>
58
 EQUIP2 Lessons Learned in Education: EMIS
Point Mapping by School:
Specialized School Listing with Summary Statistics:
<<<PAGE=65>>>
59Annex 1: Sample EMIS Outputs - Historical & Future
ZAMBIA
While Zambia had a full database and complete reporting package, the 
use of District comparative statistics proved very useful and informative. 
Note the “heuristic” questions that can serve as points of policy and action 
improvement.
<<<PAGE=66>>>
60
 EQUIP2 Lessons Learned in Education: EMIS
Ranking of Schools by Pupil/T eacher Ratio was key in determining need at 
the District Level:
<<<PAGE=67>>>
61Annex 1: Sample EMIS Outputs - Historical & Future
A manual was created to explain key concepts and organize access to 
various reports:
<<<PAGE=68>>>
62
 EQUIP2 Lessons Learned in Education: EMIS
Conveying KEY outcomes is critical to reminding stakeholders what is at 
stake for children.
<<<PAGE=69>>>
63Annex 1: Sample EMIS Outputs - Historical & Future
School Report Card with comparative District, Province, and National 
figures for comparison:
<<<PAGE=70>>>
64
 EQUIP2 Lessons Learned in Education: EMIS
MALAWI
Malawi focused primarily on consolidating various separate data collection 
exercises, and on creating a unified presentation. Considerable effort went 
into creating the annual statistical yearbook—which would be both highly 
accurate and comparative. Data were available in November of the same year 
they were collected and available in hard copy and disk format to all Districts 
and Schools.
<<<PAGE=71>>>
65Annex 1: Sample EMIS Outputs - Historical & Future
<<<PAGE=72>>>
66
 EQUIP2 Lessons Learned in Education: EMIS
Status Summarized on a SINGLE sheet for Schools, T eachers, Classrooms 
and KPIs
<<<PAGE=73>>>
67Annex 1: Sample EMIS Outputs - Historical & Future
The Future - with more recent examples
Google Earth now allows for a more comprehensive, more natural 
presentation of schools and settings. Such presentations also allow for 
inclusion of KPI information through coloring and also at different levels of 
accuracy and resolution. Each school contains specific information:
These details can also be tracked to the city/town level in places where Google 
Earth resolution allows it. These data were gathered using Smart Phones, 
which, carried by one data gatherer captured school pictures, geographic 
coordinates, and basic information—and then transmitted the same via cell 
networks to a central server. These data were available, for viewing, within the 
same day.
<<<PAGE=74>>>
68
 EQUIP2 Lessons Learned in Education: EMIS
Thematic mapping can also be done with Google Earth interfaces to support 
quick overview of both geography and status according to KPIs.
<<<PAGE=75>>>
69Annex 1: Sample EMIS Outputs - Historical & Future
Dashboards are now a more powerful tool for presenting the status of key 
activities. Dials show the relationship between current status and poor, 
improving, and acceptable conditions.
<<<PAGE=76>>>
70
 EQUIP2 Lessons Learned in Education: EMIS
Dashboard presentations recently introduced in the EQUIP2-funded Liberia 
Education Project available at the County and District level.
<<<PAGE=77>>>
71Annex 1: Sample EMIS Outputs - Historical & Future
In South Sudan, the following mixture of dynamic statistics and graphs, 
available on any computer and in hard copy, now assist in showing historical 
trends and making evidence more available.
<<<PAGE=78>>>
72
 EQUIP2 Lessons Learned in Education: EMIS
Increasingly, simulation of outcomes is important for planning and 
budgeting purposes. A proper EMIS provides the core information necessary 
for accurate forward planning—which should be affected primarily by 
assumptions about performance, and not about the historical base. The 
following system is now in use in South Sudan at both the National and State 
Level.
The examples are from key inputs including the numbers of teachers 
required, followed by a summary of the costs for the country.
<<<PAGE=79>>>
73Annex 1: Sample EMIS Outputs - Historical & Future
Summary results for both current and capital costs for South Sudan.
<<<PAGE=80>>>

<<<PAGE=81>>>
75Annex 2: EQUIP2 Associate Award Case Studies
Annex 2: EQUIP2 Associate 
Award Case Studies
A. UGANDA: STRENGTHENING OF THE UGANDA EDUCATION 
MANAGEMENT INFORMATION SYSTEM
Time frame:   November 21, 2003–November 30, 2005
Funding level:  Initial: $999,243; Final: $1,506,390
The information for this review is drawn from interviews with four individuals 
closely associated with the Uganda Support for Education Management 
Information System EQUIP2 Associate Award, including the USAID/Uganda 
education team leader who designed the project and oversaw its implementation, 
AED technical staff in Uganda and Washington, and a former Ministry of 
Education employee directly involved in implementation. It provides the basis for 
the lessons learned and insights found in Section II of this report. 
This case is divided into the following sections: (1) Uganda context, (2) Uganda 
EMIS project design, (3) project implementation, (4) successes and challenges 
(as seen by the interviewees), and (5) Uganda EMIS post-2005. The last section 
(6) reflects on the Uganda EMIS EQUIP2 experience in terms of what can be 
useful for USAID education officers who design and oversee the implementation, 
monitoring, and evaluation of EMIS projects. It is divided into three sub-sections: 
what worked, what didn’t work, and valuable insights. 
The review is written in story form (e.g., what was the context and how did it 
influence the design, what influenced implementation and what was learned 
in terms of successes and challenges, what can be learned from monitoring and 
evaluation).
1. Uganda context
National and education context
Uganda is a land locked country located in northeastern Africa bordered by Kenya 
to the east, Sudan to the north, The People’s Republic of Congo to the west, and 
Rwanda and Tanzania to the south. The colonial boundaries created by Britain
<<<PAGE=82>>>
76
 EQUIP2 Lessons Learned in Education: EMIS
grouped together a wide range of ethnic groups with different political systems 
and cultures. These differences prevented the establishment of a working political 
community after independence was achieved in 1962. 
Uganda has substantial natural resources, including fertile soils, regular rainfall, 
small deposits of copper, gold, and other minerals, and recently discovered oil. 
Agriculture is the most important sector of the economy, employing over 80% of 
the work force. Coffee accounts for the bulk of export revenues. As of 2008, only 
13% of the population lived in urban areas. 
Uganda ranks 143 out of 169 countries on the UNDP Human Development Index 
(UNDP HDI, 2010). According to World Bank statistics (2008) life expectancy is 
53 years and adult literacy is 75%. HIV prevalence rates in Uganda, once among 
the highest in the world (13.8% in 1991) have gone down to 5.4% in 2008 (World 
Bank), thanks in large part to a major policy initiative of the Ugandan government 
backed by donors.
In education net primary enrollments rates are high at 97%, (World Bank, 2008), 
influenced in large part by a 1997 government policy of universal free primary 
education (again backed by the donor community). Net secondary enrollment 
rates, however, remain low at 22% (World Bank, 2008). In 2008 primary 
completion rates were 56%; public expenditures in education as a percentage of 
GDP were 3.8% (World Bank, 2008).
History of EMIS in Uganda and its status at the time of the EQUIP2 EMIS 
design7
The EQUIP2 Uganda EMIS project is the third of three consecutive EMIS support 
programs in Uganda. All three were implemented by AED in collaboration with 
Africon.8  EMIS 1 was financed by the World Bank and implemented between 
1999 and 2001. EMIS 2 was financed by DFID and implemented between 2001 
and 2003.
EMIS 1 (1999–2001)
EMIS 1 had two objectives: (1) introduce EMIS in Uganda at a central level, 
and (2) decentralize EMIS in Uganda to districts. EMIS 1 accomplishments at 
the central level included: (a) building the human, technical, and procedural 
capacities required to institutionalize an operational EMIS capacity in the Ministry 
of Education, and (b) collecting, producing, and disseminating EMIS results, 
7 The information contained in this section comes from a paper entitled, Lessons Learned on EMIS in 
Uganda prepared in 2010 by Douglas Drew under a recent award from USAID/Uganda to continue to support 
Uganda’s EMIS system.
8 Africon is a South Africa-based international consultancy providing multidisciplinary, professional services 
in engineering, infrastructure-related development, and management.  During the implementation of all three 
EMIS projects, AFRICON maintained an office in Kampala, Uganda.
<<<PAGE=83>>>
77Annex 2: EQUIP2 Associate Award Case Studies
based on the 1999 and 2000 Annual School Censuses. At the district level work 
was begun towards decentralization of the EMIS. However, due to delays in the 
procurement of computers (which were beyond the control of the project) and 
other factors, this objective was not fully realized although some progress was 
made. 
For the 2001 Annual School Census, the release of the Statistical Abstract was in 
October of that school year. This timeliness, only nine months after the beginning 
of the school year, was considered good by international standards. Response rates 
were quite acceptable; 93% in primary schools and 88% in secondary schools. 
In terms of institutional capacity, from 1999 onwards, a solid EMIS capacity was 
built up in the Statistics Section of the Planning Department of the Ministry of 
Education. Extensive training was carried out at all levels with project support: 
the principal statistician and another person (who travelled to Washington, DC) 
for data entry staff and supervisors, officers and additional staff members of the 
ministry’s Department of Educational Planning. At the district level, delays in 
arrival and installation of computers in district education offices (outside of the 
project’s control) also resulted in delays in training at the district level due to a 
desire to synchronize training with the availability of computers. By the end of the 
project, computers with the GLOBAL ED*ASSIST software had been installed in 
most districts except in inaccessible regions for security reasons. Piloting of district 
entry of EMIS forms had taken place in 10 districts. 
A key challenge from the beginning was the discrepancy between the population 
estimates produced by the Uganda Bureau of Statistics and the enrollment figures 
generated by the Annual School Census. 
EMIS 2 (2001–2003)
EMIS 2 had seven objectives: (1) foster the development of sound management 
principles in the Ministry (using appropriate statistical information) to ensure 
that commitments towards the improvement of education are met; (2) provide 
technical support to the MOE’s management of the EMIS to ensure monitoring 
and evaluation for the Education Strategic Plan were met; (3) provide technical 
support and capacity building in statistics to the MOES Head Office and districts; 
(4) assist the MOES in the promotion of statistics and their effective use in 
planning, budgeting and management; (5) with the MOES , plan and implement 
skills training on EMIS and facilitate training workshops for different levels of staff, 
both at MOES headquarters and throughout the districts; (6) provide network 
administration and IT management advice at the MOE’s head office and at the 
district level (all 56 districts); and (7) assess the feasibility of WAN usage by regions 
through a pilot.
<<<PAGE=84>>>
78
 EQUIP2 Lessons Learned in Education: EMIS
An important focus of EMIS 2 was on sustainability: the consultant team was 
required to build capacity within the MOES over the 19-month contract period. A 
handover schedule was prepared indicating what skills transfers were required and 
milestones for when they should take place. The handover schedule was monitored 
and analyzed in quarterly project progress reports, and problem areas were flagged 
to be addressed to ensure EMIS sustainability. 
Accomplishments: (1) A new Fact Booklet was introduced with key statistics by 
sub-sector; (2) The 2002 Abstract was redesigned with a new longitudinal analysis; 
(3) An EMIS database was installed at workstations of MOES senior managers 
and EDP members, with training in its use; (4) The Ministry’s Web site was 
redesigned; (5) A LAN was set up which was fully operational with 130 of the 157 
computers in the MOES head office connected to the LAN server; (6) End users 
were trained to use the LAN, Internet, and email; (7) EMIS data were backed up 
on the LAN server, exported to Excel and Word, and made available to all the users 
on the LAN; (8) The 2001 and 2002 Database and Data Dissemination Software 
(GLOBAL ED*ASSIST) were installed on all the district EMIS computers; (9) 
One-on-one training was provided to senior managers at the MOES; staff EDP 
were given three weeks of training to an intermediate level in computer skills 
(Word, Excel, and ACCSS); a plan was developed for EMIS skills training for in 
clerical, technical, operational, and senior management MOES staff, and to district 
education officers and district inspectors; (10) EMIS was extended to cover pre-
primary, post-primary, non formal, and tertiary subsectors; school-level reports 
were introduced to all the software modules; (11) Response rates in 2002 had risen 
to 98% and 95% for government-run primary and secondary schools respectively. 
At the district level, district education officers and district inspectors participated 
in the bi-annual training of senior MOES managers. The GLOBAL ED*ASSIST 
software and copies of the 2001 and 2002 databases were installed on computers in 
the districts. The districts benefited from training in using the system to generate 
reports, and were getting timely access to the data, via the dissemination of CDs. 
In addition, districts were provided school reports for feedback to schools. These 
reports showed the school’s performance for a number of indicators compared to 
district and national performance.
By the conclusion of the project a number of the handovers to the MOES, 
anticipated when the project was designed had not been achieved. Various factors 
contributed to the failure to meet handover milestones: (1) The education system 
had more than doubled over the previous five years resulting in an increased 
workload of the EMIS staff; (2) Changes in the counterpart staff member on the 
Ministry’s side meant handover of tasks for this function had to be repeated; (3) 
The pilot WAN project experienced some major problems that made the transfer 
of skills not possible at this stage; (4) Limitations in staffing did not allow the head
<<<PAGE=85>>>
79Annex 2: EQUIP2 Associate Award Case Studies
office to support problem districts so that the national level data collection did 
not suffer; and (5) There was an absence of needed policy-level guidance regarding 
EMIS in the form of a Ministry-wide mandate. 
2. Design of the Uganda EQUIP2 EMIS project
Design context and process
David Bruns, USAID/Uganda education team leader from 2001–2006 drafted the 
scope of work for the EQUIP2 Associate Award designed as a follow on to EMIS1 
and EMIS 2. At the time of the design the donors were negotiating a Fast T rack 
Initiative (FTI) with the MOES focusing on increasing access to and quality of 
primary education. 
As Bruns observed, “Our sense was that we would need more data to guide what 
the FTI would look like. A lot of the budget support agencies were looking at 
conditionalities for budget release. We at USAID figured that for a small amount 
of money we could be at the table helping the agencies with their tranche releases. 
The donors would only release money if teacher–student, teacher–classroom 
ratios, classroom–textbook ratios were in line. The donors were trying to help 
the MOE with real inputs and needed systems to monitor that would be timely.” 
Funding was not available within the USAID/Uganda education budget to finance 
this activity. However, Bruns was able to obtain, both in 2003 and 2004, limits 
amounts of discrete funding available competitively from USAID/Washington to 
support Fast T rack Initiatives.
In terms of USAID’s role, he observed, “We branched out and also did the 
geographical information system (GIS). One thing is to say what the student–
teachers ratios are; the other thing is the intra-district disparity. We wanted to help 
the MOE decide where to put that extra teacher. This was the genesis for a small, 
discrete program to improve EMIS and link with the GIS.”
EQUIP2 Associate Award objectives/purposes9  
The EQUIP2 Associate Award, financed initially for one year and then extended 
for an additional year, had six objectives:
1. A school mapping exercise (GIS) to improve the credibility of the EMIS data to 
all the stakeholders 
2. A systematic effort at institutionalization of the EMIS, including a detailed 
plan to increase analytical activities, as well as the provision of top-level skills to 
increase the technical sustainability of the existing EMIS systems 
9 The information included in this sub-section and those that follow is drawn from the Uganda EQUIP2 
EMIS RFA.
<<<PAGE=86>>>
80
 EQUIP2 Lessons Learned in Education: EMIS
3. An increased level of training for EMIS, not only at the Ministry headquarters, 
but in Districts as well 
4. Creation of a mini-census for twice yearly updates for primary schools
5. Completion of a Wide Area Network (WAN) concept using cellular techniques
6. Coordination and supervision of a long-term Education Strategic Investment 
Plan
Design assumptions
The RFA did not contain any design assumptions. However, David Bruns who was 
responsible for designing the RFA, identified four assumptions: (1) There would 
be a strong demand for the data, especially from the donors; (2) The MOE would 
support the regional- and district-level training, as well as organize it and co-fund 
or fund it; (3) The GIS, would generate a lot of interest, all the way up to the 
Minister; and (4) People would not be afraid of what the data could show. 
Deliverables
The Program Description provided for five deliverables:
1. A detailed report of not more than 50 pages outlining the progress and 
development of EMIS sustainability at the Ministry of Education and Sports 
2. A functioning geographical information system (GIS) providing a complete 
map (location and education data) of all primary schools in Uganda 
3. A functioning Wide Area Network (WAN) providing internet services between 
all major offices of the MOES 
4. A detailed report of not more 20 pages describing progress made in assisting 
district EMIS development plans and key milestones linked to the district 
development plans 
5. A system developed to facilitate effective management of the teachers’ payroll 
and benefits scheme
3. Implementing the Uganda EQUIP2 EMIS Associate Award
Implementation approach
AED implemented EQUIP2 EMIS in close collaboration with AFRICON, 
building upon progress and addressing challenges from the prior EMIS awards. 
AED provided technical assistance from a distance and through periodic visits 
to Uganda by the home office Project Director. Africon, which had an office in 
Kampala, provided day-to-day technical assistance, training, and oversight through 
qualified Ugandan experts hired for the project and a highly qualified technical 
advisor based in Africon in South Africa who periodically visited Uganda. MOES 
personnel carried out all data gathering, both for the EMIS and for establishing
<<<PAGE=87>>>
81Annex 2: EQUIP2 Associate Award Case Studies
the GIS. T raining for Ministry of Education staff was carried out in Uganda, 
Washington, DC, and South Africa. 
During the first year, the decision was taken to substitute the creation of a mini-
Census for twice-yearly updates for primary schools with School Attendance 
Registers, with data to be collected quarterly, which was more relevant to the 
Ministry’s current needs.
When the results of the main school mapping exercise were presented to 
education stakeholders and their partners during November 2004, near the 
end of the one-year Associate Award period, the need for additional work was 
highlighted. USAID/Uganda, again seeking centrally funded FTI monies available 
competitively, was able to obtain an additional $507,000 to: (1) Map additional 
education sites, including 570 coordinating centers; (2) Introduce new education 
quality indicators, including survival rates, P7 Completion Rate and Schools P7 
Examination Performance Index, disaggregated by sex; (3) Create linkages between 
the EMIS, the Uganda National Examinations Board (UNEB), and the GIS system 
– a critical step for sustainability; (4) Produce additional GIS maps for districts 
and the proposed Parliamentary presentation; (5) Provide intensive technical 
training for GIS maintenance and enhancement to support the district teams; and 
(6) Create core analytical and training teams and support additional district level 
training to improve analytical skills and data collection and updating. 
Adequacy of time frame and budget and effectiveness in building sustainability
As was mentioned above, USAID/Uganda was able to obtain small amounts of 
discrete funding ($999,000 in 2003 and another $507,000 in 2004) to finance the 
EMIS initiative. However, as all interviewees pointed out, this was not sufficient 
to achieve the objectives of the Associate Award, especially looking toward 
sustainability of actions carried out.
Key Outcomes
Most of the objectives were achieved, as listed below:
1. The school mapping exercise (GIS) was completed. A master list of schools 
was linked to the EMIS database. GIS equipment and software were acquired 
for the Education Planning Department. A number of thematic maps were 
produced, for the Ministry of Education headquarters, other users, and for 
districts. 
2. During 2005 there were two specific, intensive trainings in the use of maps, 
and the concepts behind map use for education policy decisions. In addition, 
key technical MOES personnel were given on-the-job training in map 
maintenance and manipulation. Selected personnel from the MOES head
<<<PAGE=88>>>
82
 EQUIP2 Lessons Learned in Education: EMIS
office and certain district personnel were given additional training in the use of 
GIS Maps for more detailed analysis.
3. Three members of the Education Planning Division of the MOES were sent 
for two weeks training in South Africa, to develop skills in the GIS software 
required to run and maintain the system (although it was subsequently found 
that those sent to receive this training did not have the requisite skills to fully 
understand it). 
4. Nine members of the MOES received extensive training in the United States in 
EMIS software application maintenance. 
5. Policymakers and technical support personnel were trained in parallel on 
similar but separate skills for between two and three weeks. 
6. District Education Officers and three persons from each district office received 
three days of training in the use of EMIS, GIS, and basic calculation skills 
related to education indicators.
7. Replacing the mini-census, the project provided technical assistance to the 
Statistics Section in the development of methodology and procedures to 
collected data on a quarterly basis on full and half-day attendance. Although 
the collection of information was operational by the conclusion of the project, 
the scanning and production of data were not yet operational, although all the 
pieces were in place. 
8. GLOBAL ED*ASSIST was extended to calculate survival rates and P7 
completion rates.
9. EMIS data was linked to the PLE exams results for 2004.
10. The WAN concept was completed: a report was prepared outlining an approach 
to linking head office and all district offices along with options and pricing, for 
consideration and decision taking by MOES.
11. An expert was contracted who provided the required assistance in preparing 
ESIP-II.
4. Factors within and outside USAID and EQUIP2 control that favored 
accomplishments and served as deterrents
Interviewees were asked to reflect on elements of the Uganda EQUIP2 EMIS 
Associate Award that were successful and on challenges. The following is taken 
from a longer list of reflections provided by the interviewees.
Factors that were seen as favorable
•	 “This year’s data” continued to be available “this year” (2003 and 2004)
•	 Uganda was able to use data from the EMIS and the GIS to make decisions. 
For example, a number of districts reallocated teachers based on the mapping 
exercise. Thanks to the school mapping exercise, for the first time a lay person
<<<PAGE=89>>>
83Annex 2: EQUIP2 Associate Award Case Studies
could understand the data: red schools were seen bad in terms of student/ratios 
and other indicators and green schools were seen as good. 
•	 Donors used the education data the EMIS generated to track progress in 
meeting conditionality under the Fast T rack Initiative and the Ministry of 
Education responded in kind by taking actions to improve performance on key 
conditionalities.
•	 Thanks to the GIS, district education staff now knew where all their schools 
were located. District education staff put the GIS maps on their walls. For the 
first time it was possible to used population statistics for providing backstop 
support to schools.
Challenges 
•	 The conditions for meeting sustainability were not met.
•	 It would appear that there were not enough resources for skills transfer.
•	 The Director of Planning sat on the school maps for several months, frustrating 
district education staff who wanted to receive their school maps as soon as they 
came out. 
•	 Certain staff responsible for collecting the EMIS data refused to do the job. 
Although they received the requisite training some lost interest. They didn’t 
maintain the discipline required to collect the data. 
•	 EMIS and other MOES staff would get trained and then they would leave the 
MOE. 
•	 It was not possible to fully decentralize the EMIS. 
•	 At the time the project ended MOES staff were just beginning to use the 
GIS; MOE staff did not acquire the skills needed to maintain the GIS. Three 
Planning staff members received three weeks of training towards the end of the 
project, but the training was viewed as too technical, and the full skill transfer 
was not successful. 
•	 In terms of quarterly collection of attendance data there was not sufficient 
time in the EQUIP2 project to ensure the scanning equipment and systems for 
capturing attendance data were operational.
5.   Uganda EMIS post-2005
In 2006, after USAID support for EMIS ended, the MOES Planning and Data 
Unit, with the support of the UNESCO Institute for Statistics, installed UIS EMIS 
software to replace the GLOBAL ED*ASSIST software used up until that point. 
The UIS software was available free of charge, and support in installation of the 
software was provided by UIS, also free of charge. This software was in use for the 
period 2006–2009.
<<<PAGE=90>>>
84
 EQUIP2 Lessons Learned in Education: EMIS
When this software was installed it was seen as having some advantages over 
GLOBAL ED*ASSIST being used. UIS software was server based, so as each 
data entry clerk completed a form, it would be directly uploaded to the database. 
GLOBAL ED*ASSIST was based on an ACCESS database, which also operates 
in a server mode, but was not initially configured for that purpose. A second 
advantage of the UIS system was that the database was longitudinal in design, 
containing data for all years and all sub-sectors of education in a single database. 
In contrast GLOBAL ED*ASSIST had a separate database for each year. The main 
advantage of a multi-year database was to permit multi-year or longitudinal data 
analysis. 
Although the new software had the above advantages over GLOBAL ED*ASSIST 
software, there were other aspects where GLOBAL ED*ASSIST performed much 
better. These included the Questionnaire T racking System (QTS), which provided 
control over which forms had been received and which remained outstanding. In 
fact, the Statistics Section managed to integrate the QTS module into the new 
software environment, and is still using it. GLOBAL ED*ASSIST was also found 
to be easier to use than the UIS system for overall report production. 
During 2005–2009 there was a marked slippage in operations and capacity in the 
EMIS in Uganda. Data integrity problems persisted and the timeliness of data 
releases worsened. The response rates for private secondary schools continued to be 
a problem, and some response rates for primary schools worsened. In 2008, only 
about half of private secondary schools (50.4%) responded, yielding an overall 
response rate of 64.1% for secondary schools. For primary schools the response rate 
slipped to 83.4%.
The Statistics Section also became vulnerable; in 2009 only one of three statistician 
positions were filled. The LAN, which was set up and operational by the end of the 
EQUIP2 EMIS project, was working but not all personnel were connected. The 
MOES had turned to the Internet as a means of providing access to EMIS data, 
both internally and externally. However, Internet connectivity became slow and 
unreliable. 
At the district level, monies to facilitate certain operations, such as the district 
operations in support of the collection operations, disappeared. As a result, districts 
have been forced to find ways to piggyback the collection operations on other 
activities. The result has been a contributing factor to the slower data collection 
and lower response rates. In addition, production of CD’s (that were sent to the 
district annually in prior years) and school reports stopped in 2006. The only 
other feedback districts receive is via the occasional presentation of EMIS results 
in workshops organized on other topics. Districts no longer receive facilitation 
money to help offset the costs associated with distributing and gathering the School
<<<PAGE=91>>>
85Annex 2: EQUIP2 Associate Award Case Studies
Census forms. Efforts during project periods to build EMIS capacity in districts 
were not sustained. 
In April 2010 the MOES selected Agile Learning Company to design and develop 
a new decentralized national EMIS. Under a Memorandum of Understanding 
signed between USAID, the MOES, and Microsoft, the Ministry is embarking on 
decentralizing its EMIS solution to its 81 existing districts, and 17 newly created 
districts. Agile’s responsibilities include designing and developing the decentralized 
EMIS–GIS solution, installing the solution and providing specialized training on 
EMIS–GIS to national and decentralized education stakeholders. 
6.  Reflecting on the Uganda EQUIP2 EMIS experience in terms of what 
can be useful for other USAID EMIS projects
What worked
•	 Continuity in terms of the key-implementing actors (AED and AFRICON) 
from prior projects was useful, even though they received funding from 
different external entities (World Bank, 1999–2001; DFID, 2001–2003; 
USAID, 2003–2005).
•	 “This year’s data” was produced “this year” (in 2003 and 2004) with the help of 
outside TA. 
•	 Data generated by the EMIS and GIS was used for decision making by the 
MOES to allocate teachers and textbooks districts; and by donors to hold the 
Ministry of Education accountable for conditionalities established under the 
FTI. 
•	 The EMIS/GIS produced easy-to-read printouts for use at the district and other 
levels.
•	 There were high EMIS coverage rates: reaching 98 and 99%.
What did not work
•	 It was not possible to achieve sustainability without some type of graduated 
ongoing assistance.
•	 Designing the project on a yearly basis with unclear funding for future years 
makes it difficult to engage in longer-term activities, such as training and 
planning; among other problems, it is harder to keep qualified local and 
external technical assistance.
•	 Continuity is also more difficult without qualified Directors of Planning who 
remain in their positions.
•	 Staff turnover in the EMIS unit and other EMIS-related units is an endemic 
problem; people get trained and then leave the MOES for higher paying jobs in 
the private sector.
•	 MOES staff have limited capability to interpret/use data without external 
donor assistance.
<<<PAGE=92>>>
86
 EQUIP2 Lessons Learned in Education: EMIS
Valuable insights from interviewees
On achieving sustainability:
If there was a slight Achilles heel to the project, that was it. Even though there was a 
demand for information and happiness that it was there, the project required more 
resources to be a sustainable activity. We didn’t meet that threshold in terms of resources. 
(David Bruns, USAID/Uganda education team leader)
On where donors have a large stake in data generated by an EMIS:
Uganda was a fascinating example of donor coordination. You can’t underestimate 
the importance of EMIS especially where donors have a huge stake/investment in 
Ministry of Education operations—at one time donors were supporting up to 70% 
of all operating expenditures. In the case of Uganda, where other donor supported the 
Fast Track Initiative, the Ministry of Education and Sports respected the relationship 
between the money they received from the donors and the targets they had to achieve. 
These targets were measured through the annual EMIS data collections. (Kurt D. 
Moses, AED Vice President and Washington EMIS specialist).
<<<PAGE=93>>>
87Annex 2: EQUIP2 Associate Award Case Studies
B. MALAWI: EDUCATION SECTOR POLICY, PLANNING, EMIS 
SUPPORT ACTIVITIES AND HIGHER EDUCATION STRATEGIC PLAN 
DEVELOPMENT
Time frame:  July 8, 2003–June 20, 2008
Funding:  Initial: $1,985,620; Final: $2,704,581
The information for this review is drawn from interviews with seven individuals 
(including USAID/education staff, EQUIP2 staff and technical advisors in Malawi 
and AED/Washington; and former Ministry of Education staff) closely associated 
with the Malawi Education Sector Policy, Planning, and EMIS Support Activities 
and Higher Education Strategic Development EQUIP2 Associate Award. It 
provides the basis (for the lessons learned and insights found in Section II of this 
report. 
This case is divided into the following sections: (1) Malawi context, (2) Malawi 
EMIS project design, (3) project implementation, and (4) successes and challenges 
(as seen by the seven interviewees). The last section (5) reflects on the Malawi 
EMIS EQUIP2 experience in terms of what can be useful for USAID education 
officers who design and oversee the implementation, monitoring, and evaluation 
of EMIS projects. It is divided into three sub-sections: what worked, what didn’t 
work, and valuable insights. 
This review is written in story form (e.g., what was the context and how did it 
influence the design, what influenced implementation and what was learned 
in terms of successes and challenges, what can be learned from monitoring and 
evaluation).
1. Malawi context
National and education context
The Republic of Malawi is a landlocked country in southeast Africa that was 
formerly known as Nyasaland. It is bordered by Zambia to the northwest, Tanzania 
to the northeast, and Mozambique on the east, south, and west. The country is 
separated from Tanzania and Mozambique by Lake Malawi. Its size is over 45,560 
square miles with an estimated population of more than 13,900,000. 
Malawi was first settled during the 10th century and remained under native rule 
until 1891 when it was colonized by the British who ruled the country until 1964. 
Upon gaining independence it became a single-party state under the presidency 
of Hastings Banda, who remained president until 1994, when he was ousted from 
power.
<<<PAGE=94>>>
88
 EQUIP2 Lessons Learned in Education: EMIS
Malawi is among the world’s least developed and most densely populated countries. 
The economy is heavily based in agriculture with around 85% of the population 
living in rural areas. More than one-third of GDP and 90% of export revenues 
come from agriculture. The Malawian government depends heavily on outside aid 
to meet development needs, although this need (and the aid offered) has decreased 
since 2000. The Malawian government faces challenges in growing the economy, 
improving education, health care, and the environmental protection and becoming 
financially independent. 
Malawi is ranked 153 of 169 countries in the United Nations Human 
Development Index (2010), ranking in the “low human development” category. 
Malawi has a low life expectancy of 50.3 years and high infant mortality. Adult 
literacy rates are at 72%. There is a high prevalence of HIV/AIDS (11.9%) that is a 
drain on the labor force and government expenditures. The HIV/AIDS pandemic 
has aggravated the overall human resource situation, disproportionately affecting 
teachers, who represent one of the largest networks of civil servants in the country 
and disproportionately high numbers of children. Among school-aged children 
from 6 to 14 years, about 14% are classified as OVC (orphans or victims of 
conflict), over half of whom are estimated to be AIDS orphans. 
Between 1994 when Malawi’s new president declared free universal primary 
education and 2003 student enrollments at the primary level increased 
dramatically; however, it led to substantial negative effects to the quality of 
education given, among others, the inability of the education system to find 
sufficient qualified teachers to match dramatically increased enrollments. In 2006 
net primary enrollment rates were at 75% having increased from 58% in 1992. 
High teacher student ratios and the quality of education varied substantially 
between rural and urban areas. Education expenditure in 2003 was 5.8% of GDP 
(World Bank).
Status of Malawi’s Education Management Information Systems (EMIS) at the 
time of the Malawi EMIS EQUIP2 design
When USAID decided in 2003 to support strengthening Malawi’s EMIS system, 
the Ministry of Education (with support from a progression of donors since 
the early 1990s) had an installed EMIS system with computers, software, and a 
skeleton EMIS staff who had received some training. However, there was limited 
credibility in the accuracy/validity of the data being generated by this system. GTZ 
therefore, which was supporting teacher training in Malawi, had started collecting 
its own data on teachers. The Canadians, who were supporting infrastructure, 
were collecting their own data on facilities. The French, who were supporting 
textbook development and distribution, were collecting their own data on textbook 
production and distribution. The Danes, who were supporting programs focusing 
on student health, were collecting their own statistics on student health.
<<<PAGE=95>>>
89Annex 2: EQUIP2 Associate Award Case Studies
Although there was common agreement that a unique data source was required, 
preferably housed in the MOE, to collect credible data that both the MOE and 
donors could use for planning purposes and to track investments, no one had 
stepped forward to assist in doing this.
2. Design of the Malawi EMIS project
Design context and process 
Bill Mvalo, USAID/Malawi education team leader from 2002 to 2005 reflects on 
the origins of the Malawi EMIS project. “The Ministry of Education did not have 
up-to-date information on many aspects of education in the country. Information, 
where available, was either out of date or unreliable. In other instances education 
data was non-existent. In 2002, the Government of Malawi had embarked on 
developing a Policy Investment Framework for the education sector to address the 
need for a well-designed long-term national education strategy. Due to the lack 
of an effective education management information system in the Ministry, policy 
direction and investments in education would possibly not have had a proper 
basis. We said, Let’s help the Ministry of Education establish an effective EMIS for 
purposes of having a platform for education planning and for education assistance.”
During the design process, USAID secured an agreement from the Ministry of 
Education and other donors that with USAID support the MOE would set the 
stage for creating a common EMIS. All donors agreed with this and turned over 
their historic files. At the time the EMIS portion of the project was being designed, 
the MOE’s Planning Division had 16 vacancies. T wo Malawians ran the central 
EMIS, located in the Planning Division.
Associate Award purpose and assumptions underlying the design10
The purpose of the EQUIP2 Associate Award was to address key constraints 
to system improvement—in policy, systems and strategies, and organizational 
capacity. It was envisioned that EQUIP2 would help improve strategic planning 
and management for the Policy Investment Framework implementation, 
strengthen the EMIS, and develop strategic business plans for the University of 
Malawi and Mzuzu University. In addition, it was envisioned that the Associate 
Award would establish systems and capacity in the MOE Planning Department 
team to support decentralized planning and management at the district level. In 
particular, the EQUIP2 Associate Award would assist in developing an integrated 
EMIS that would support the development of the Policy Investment Framework, 
the Malawi Poverty Reduction Strategy, Malawi’s Education for All plan, and 33 
10 The information included in this sub-section and those that follow is drawn from the Malawi EMIS 
EQUIP2 Proposal prepared by AED.
<<<PAGE=96>>>
90
 EQUIP2 Lessons Learned in Education: EMIS
district education plans linked to district development plans. The initial design 
called for project that would last a year and a half. 
Assumptions underlying the design of the EQUIP2 Associate Award
The USAID RFA did not contain any design assumptions. However, Bill Mvalo, 
during the interview for this study, identified three assumptions: (1) adequate 
technical assistance would be available; (2) the Planning Unit in the Ministry 
would be committed to carrying out the project; and (3) the statistical unit itself 
must have the capacity.
Implementation strategy for the EMIS component
The implementation strategy for the EMIS component called for the following 
sequence of activities: an initiation seminar, an introduction of an enhanced EMIS 
version, training of EMIS staff in the application of the enhanced version, and 
developing institutional capacity at the division/district level. Specific actions under 
each activity may be found in the textbox below.
Initiation Seminar
• Set the collaborative tone and establish a common understanding of concepts and goals of 
activity. 
• Demonstrate how EMIS can support MOEST and encourage active support/assistance of 
other donors
• Identify key “political” deadlines to which EMIS will need to respond
• Develop parameters for EMIS Needs Assessment
Modify Existing EMIS/Introduce Enhanced Version 
• Continue to produce needed information while upgrading capacity to generate/use it
• Simplify parts of the information gathering process
• Alter locus of collection of data
• Maintain, enhance, modify existing EMIS software
• Identify elements of other systems to incorporate
• Generate a series of standard, vetted, school level-reports and comparable summaries
• Introduce quality control features at multiple levels to ensure higher quality base information
Train Ministry Staff
• Develop a detailed training plan on the findings of the EMIS Needs Assessment
• Use a series of curriculum “masters” from Microsoft to assess actual working skills
• Use a series of structured observations/questions to determine training needs
• Link training process to organizational capacity to achieve key priorities of Planning Division
• Implement through courses offered by in-country providers as well as working seminars 
conducted by consultants
Institutional Capacity at Division/District Level
• Assure that Ministry of Education staff can use existing information effectively.
• Ensure that districts have necessary institutional, human, technical, financial resources to 
perform their jobs
• Train division/district staff in the production/use of data, upgrade data management 
equipment
<<<PAGE=97>>>
91Annex 2: EQUIP2 Associate Award Case Studies
3. Implementing the Malawi EQUIP2 EMIS Associate Award
  
Design choices that guided implementation of the EMIS component
In preparing the Malawi EQUIP2 RFA, and as is referenced above, USAID/
Malawi made a number of design choices and assumptions that would guide ERP 
implementation. They included: 
1. That there would be adequate technical assistance; 
2. That the Planning Unit would be committed to carrying out the project; 
3. That the statistical unit itself would have the needed capacity to maintain an 
credible and timely EMIS; and 
4. That with a credible and timely EMIS that other donors would cease collecting 
their own data and look toward the Ministry of Education’s EMIS as THE 
source of information on Malawi education statistics.
As will be seen in the sections that follow, design choices 1 (that there would be 
adequate technical assistance) and 4 (that donors would look toward the Ministry 
of Education’s EMIS as THE central source of credible information on Malawi 
education statistics) were born out. However, for reasons outside of the project’s 
control, design choice 2 (that the Planning Unit would be committed to carrying 
out the project) and 3 (that the statistical unit itself would have the needed capacity 
to maintain a credible and timely EMIS) were only partially born out.
Implementation approach
The Malawi EQUIP2 project, under its initial design, had the Policy Planning 
and University of Malawi and Mzuzu components under the responsibility of the 
Education Development Center (EDC), and the EMIS component that was the 
responsibility of AED. The Chief of Party was from EDC. When funding came to 
an end after 18 months USAID decided to extend it, focusing exclusively on the 
EMIS component. Yearly extensions were provided up until 2008.
Starting in 2005, responsibility for implementation of the yearly extensions was 
vested with the AED EMIS technical advisor, Fahim Akbar, who became Chief 
of Party. Fahim collaborated with Kurt Moses, the AED home office backstop 
in Washington, DC (who had many years of experience supporting countries 
to install and maintain EMIS systems). T ogether they provided all the training, 
technical assistance, as well as hardware and software backstop support to keep the 
project running. MOE staff were responsible for the annual data collections.
Thomas LeBlanc, USAID/Malawi education team leader between 2005 and 
2007, recalls EMIS implementation during the time he was in Malawi, “We were 
focusing on EMIS, the collection and processing of data for decision making at the 
national and district level. In terms of policy, Kurt Moses came periodically to do
<<<PAGE=98>>>
92
 EQUIP2 Lessons Learned in Education: EMIS
workshops for senior decision makers. Fahim Akbar was running implementation 
on the ground working in the Ministry of Education. Fahim did a fantastic job was 
training people to do all aspects of the work. Fahim was able to collect, process, 
and produce data within the same year, which was completely unheard of at the 
time. Kurt would come along to demonstrate what the Ministry of Education 
could do with the data.”
In 2007 when T om LeBlanc departed for his next USAID he was replaced by 
Marisol Perez as USAID/Malawi education team leader. Perez extended the 
Associate Award for another six months, preferring starting in 2009 to initiate a 
new EQUIP2 Associate Award centered on education decentralization. Support for 
EMIS continued but focused at the district level. 
Adequacy of time frame and budget and effectiveness in building sustainability
Although a five-year time frame did not seem to be an issue, the amount of 
yearly funding (approximately $500,000) limited the activities that the project 
could carry out. Combined with an inability to plan beyond one year since 
the project was extended year by year starting in 2005, these were seen as 
important constraints to re-establishing the MOE’s EMIS and setting the base for 
sustainability.
EMIS outcomes 
The EMIS portion of the EQUIP2 Malawi Associate Award resulted in a number 
of significant outcomes:
•	 The EMIS had become the only official and authorized education data source 
for all Malawi. 
•	 The coverage rate for primary schools exceeded 98.5% each year. 
•	 Education statistics for 2005, 2006, and 2007 were released the same year in 
November of 2005, 2006, and 2007 respectively, and 2008 data collection was 
scheduled to be completed by the end June 2008. 
•	 GLOBAL ED*ASSIST Malawi CD’s were produced for 2004, 2005, 2006, 
and 2007 and released in November of each year.
•	 The main EMIS office at the Ministry of Education had been refurbished with 
new servers, workstations, and a local area network. 
•	 Malawi GLOBAL ED*ASSIST software enabled the production of more than 
100 reports on almost every section included in the EMIS questionnaire. 
•	 The EMIS software and data sets had been installed on almost every computer 
in the Ministry of Education.
•	 The Ministry of Education had the capability to produce reports according to 
individual office needs. 
•	 Data had been published in booklet format for quick reference, and digital 
copies were available in PDF format.
<<<PAGE=99>>>
93Annex 2: EQUIP2 Associate Award Case Studies
•	 Numerous trainings had been organized and delivered to the PEAs (primary 
education advisors) and other officials from the MOE. Intensive training had 
also been organized for district staff. 
•	 24 out of 33 district-level EMIS offices were directly involved in data 
collection, entry, and production.
4. Factors within and outside of USAID and the Malawi EMIS control 
that favored project accomplishments and served as deterrents
Interviewees were asked to reflect on elements of the Malawi Associate Award that 
were successful and on challenges. The list below includes successes and challenges 
that were not mentioned above.
Factors that were seen as favorable
•	 The Associate Award was able to stabilize the core EMIS system and in so 
doing stabilize donor requirements. 
•	 It was possible to articulate future EMIS needs.
•	 The EMIS data brought to light student– teacher ratio disparities in rural areas 
and the EMIS data were fed into district planning.
Challenges
•	 The fact that the project was funded yearly meant that the USAID/Malawi 
education office never knew if it was going to get the correct amount of 
funding from USAID/Washington. This made it difficult to plan long term or 
to arrange for needed ongoing MOE staff training.
•	 Staff turnover at senior levels was high; during the five years of the project 
there were four Ministers of Education and four Permanent Secretaries.
•	 MOE senior management made little use of the various reports the EMIS 
generated for policy dialogue, analysis, and management of schools. 
•	 With frequent changes in Malawi EMIS staff, the day-to-day operations of 
the Ministry of Education EMIS came to depend inordinately on the EMIS 
advisor; thus by the end of the project the MOE still lacked the qualified staff 
to support the EMIS independent of EQUIP2.
•	 By the end of EQUIP2, the MOE could not finance the EMIS. Between 2003 
and 2008, EQUIP2 had been responsible for all financial expenditures to 
support the EMIS activities. 
•	 Most schools had poor records that made it difficult to fill out the EMIS 
questionnaire properly.
•	 Most district staff were either unqualified or had limited capacity to take on 
the demands of the EMIS activities.
•	 Five years were not long enough to fully institutionalize the EMIS within the 
MOE and create the capability in all districts to input data for the EMIS and
<<<PAGE=100>>>
94
 EQUIP2 Lessons Learned in Education: EMIS
use the results for decision-making. Given the personnel turnover along with 
major shifts in policy, developing a sustainable culture of information might be 
a 15 year plus process. 
5. Reflecting on the Malawi EQUIP2 EMIS experience in terms of what 
can be useful for other USAID EMISprojects that focus on EMIS or have 
an EMIS component.
What worked
•	 “This year’s data” was produced “this year” (in 2005, 2006, and 2007) with the 
help of outside TA. 
•	 Donors, for the most part, stopped collecting their own data and came to rely 
on the Ministry of Education’s education statistics as THE source of education 
data.
•	 High EMIS coverage rates were achieved, exceeding 98.5% for primary 
education.
•	 Malawi GLOBAL ED*ASSIST software enabled the production of more than 
100 reports on almost every section included in the EMIS questionnaire. 
•	 The EMIS software and data sets had been installed on almost every computer 
in the Ministry of Education.
•	 The Ministry of Education had the capability to produce reports according to 
individual office needs. 
What did not work
•	 It was not possible to achieve sustainability, without ongoing assistance; by the 
end of EQUIP2, the MOE could not finance support for the EMIS.
•	 Designing the project yearly with unclear funding for future years makes it 
difficult to engage in longer term activities, such as training and planning.
•	 Continuity is more difficult with constant changes (nearly annually) at the level 
of the Minister of Education and Permanent Secretary.
•	 Staff turnover in the EMIS unit and other units related to EMIS is an endemic 
problem: people get trained and then they leave the MOE for higher paying 
jobs in the private sector.
•	 MOE staff had limited capability to interpret/use data without external donor 
assistance.
<<<PAGE=101>>>
95Annex 2: EQUIP2 Associate Award Case Studies
Valuable insights from interviewees
On the effect of frequent turnover at senior levels:
The MOE was weak in terms of human resource capacity and financial resources. In 
a two-year period they had four Ministers and four Permanent Secretaries. It is hard 
to get decision-making done with so much staff turnover. They are barely figuring out 
the job when they are transferred elsewhere. (Thomas Le Blanc, USAID/Malawi 
education team leader)
On conditions for achieving sustainability:
You need to view EMIS as a three to five year technical commitment – and a longer 
commitment for changing the internal culture. Another ten years would not be unheard 
of. It needs to be placed, institutionally, with a person of leadership capacity who is 
being held accountable for implementation, usually the Planning Director. And, the 
resources—at all levels (village, county, District, and National) need to be appropriate. 
Usually on larger donor efforts, the center gets the funds, and they are reduced as you go 
“lower” in the system. (Kurt D. Moses, FHI 360 EMIS specialist).
<<<PAGE=102>>>
96
 EQUIP2 Lessons Learned in Education: EMIS
C. MALAWI: EDUCATION DECENTRALIZATION SUPPORT ACTIVITY
Time frame:   February 20, 2009–February 28, 2012
Funding level:  $11,559,643
The information for this review is drawn from interviews with eight individuals 
closely associated with the EQUIP2 Malawi EDSA Associate Award, including 
USAID/ staff, EQUIP2 staff in Malawi and from EDC and AED in the United 
States, and a former Ministry of Education employee. It provides the basis for the 
lessons learned and insights found in Section II of this report. 
This case is divided into the following sections: (1) Malawi context, (2) EDSA 
project design, (3) EDSA EMIS project implementation, (4) EDSA EMIS 
successes and challenges (as seen by the eight interviewees), (5) monitoring and 
evaluation. The last section (6) reflects on the experience in terms of what can be 
useful for USAID education officers who design and oversee the implementation, 
monitoring, and evaluation of EMIS projects. It is divided into three sub-sections: 
what worked, what didn’t work, and valuable insights. 
This review is written in story form (e.g., what was the context and how did it 
influence the design, what influenced implementation and what was learned 
in terms of successes and challenges, what can be learned from monitoring and 
evaluation).
1. Malawi context
Malawi national and education context
Gaining independence from Britain in 1964, Malawi spent three decades under 
a one-party rule but has been a multi-party democracy since 1994 (CIA World 
Factbook). Malawi held parliamentary and presidential elections in May 2009, 
which were meant to influence both the opportunity for policy dialogue and 
implementation as well as leadership. Malawi is broken up into 28 districts, and 
there exists a great urban-rural divide, even though only 19% of the population 
lives in urban areas (CIA World Factbook). Malawi is ranked 153 of 169 countries 
in the United Nations Human Development Index (2010), ranking in the “low 
human development” category.
Malawi grapples with one of the worst situations of HIV/AIDS, which is prevalent 
in about 12% of adults (CIA World Factbook). The HIV/AIDS pandemic has 
aggravated the overall human resource situation, disproportionately affecting 
teachers, who represent one of the largest networks of civil servants in the country 
and disproportionately high numbers of children. Among school-aged children
<<<PAGE=103>>>
97Annex 2: EQUIP2 Associate Award Case Studies
6 to 14 years, there are about 14% classified as orphans and vulnerable children), 
over half of which are estimated to be AIDS orphans. Other problems include an 
increasing population, increasing pressure on agricultural lands, and significant 
levels of corruption. 
 In responding to the 1990 and 2000 EFA commitments, Malawi’s student 
enrollment has increased dramatically, but has led to substantial negative effects 
to the quality of education. At project start-up, primary gross enrollments were at 
120% with over 3.3 million students enrolled in just over 5,200 schools, taught 
by 43,000 teachers. High student–teacher ratio and the quality of education vary 
substantially between rural and urban areas. In 2007, the student–teacher ratio was 
43:1 in urban areas but 84:1 in rural areas. The low number of qualified teachers 
compounds the situation. In trying to counteract these problems in education, 
MOE leadership has begun taking strides towards a Sector Wide Approach 
(SWAp), as seen most explicitly through progress and efforts in finalizing its 
National Education Sector Plan (NESP). Education expenditure in 2003 was 5.8% 
of GDP (CIA World Factbook). 
Status of Malawi’s Education Management Information Systems (EMIS) at the 
time of the EDSA design 
When EDSA was being designed, a prior EQUIP2 project focusing on EMIS was 
winding down. USAID and AED were successful in taking a fragmented EMIS 
system where each donor collected information to track of its own activities and 
converted it to a centralized system in the MOE—the only official and authorized 
education data source for all Malawi. By 2008 when the project ended, coverage 
rates for primary schools exceeded 98.5% each year. Education statistics for 2005, 
2006, and 2007 were released the same year in November of 2005, 2006, and 
2007 respectively. The main EMIS office at the MOE had been refurbished with 
new servers, workstations, and EMIS software and data sets had been installed 
on almost every MOE computer. The MOE could produce reports according to 
individual office needs. Numerous trainings on EMIS had been organized and 
delivered to primary education advisors and other MOE officials and intensive 
training had been organized for district staff. T wenty-four out of 33 district EMIS 
offices were directly involved in data collection, entry, and production. 
However, as the project drew to a close, a number of challenges remained. High 
MOE senior staff turnover (four Ministers of Education and four Permanent 
Secretaries in five years) posed a challenge for EMIS continuity. MOE senior 
management made little use of the reports EMIS generated for policy dialogue, 
analysis, and management of schools. With frequent changes in Malawi EMIS 
staff, the day-to-day operations of the MOE EMIS came to depend inordinately 
on the EQUIP2-funded EMIS advisor. Most district staff were either unqualified 
or had limited capacity to take on the demands of the EMIS activities. The EQUIP
<<<PAGE=104>>>
98
 EQUIP2 Lessons Learned in Education: EMIS
2 project had been responsible for financing all EMIS activities. By the end of the 
project the MOE could not finance support for the EMIS. The MOE still lacked 
the qualified staff to properly support the EMIS system independently of EQUIP2. 
Five years at funding levels provided by USAID was not enough time to fully 
institutionalize the EMIS within the MOE and create the capability in all districts 
to input data for the EMIS and use the EMIS results for decision making.
2. Design of the EDSA project
Design context and process
EDSA, a follow on to the EQUIP2 EMIS project referred to above was designed 
in late 2008 in close collaboration with a Ministry of Education technical working 
group on governance and management. There were consultations with the Director 
of Planning, JICA, and GTZ. Over a series of technical working group meetings, 
USAID came up with framework for the EDSA RFA. Clear from the start was that 
EDSA would work as a discrete project in a highly collaborative fashion under the 
upcoming education SWAp. 
During the EDSA design USAID/Malawi recognized that further assistance was 
needed to strengthen and sustain the Ministry of Education’s central EMIS but 
decided to focus on six pilot districts that the new project would be work in. 
USAID understood at the time that UNICEF would provide assistance to ensure 
the strengthening and continuity of the central EMIS. 
EDSA purpose/objectives and approach
The purpose of EDSA as stated in the USAID/Malawi RFA was to “Strengthen the 
decentralization implementation at the Ministry of Education headquarters, district 
and school levels to support system progress in attaining National Education 
Sector Plan 2008–2018 goals.” EMIS was included as a set of illustrative activities; 
however, EMIS was not mentioned either in the purpose or as a component.
EDSA was designed to provide support at three levels, each defined as a separate 
component:
1. Strengthened policy and strategy articulation, interpretation, and 
implementation (policy support)
2. Improved decentralization implementation, planning, and data utilization for 
informed decision making (decentralization and planning) 
3. Enhanced role and participation of communities in monitoring education 
service delivery (schools and community)
<<<PAGE=105>>>
99Annex 2: EQUIP2 Associate Award Case Studies
The first reference to EMIS in the EDSA RFA appears under the description of 
Component 2 (decentralization and planning) as follows:
The current EMIS system is one of the few EMIS systems in any developing 
country to provide “this year’s data this year.” This activity should feature an 
eventual phase out of EMIS support from USAID at the central, headquarters 
levels. The focus should be to strengthen district-to-school EMIS capacity and 
use with strong coherence and input to sector M&E frameworks and the NESP 
targets and indicators, a weakness in the previous EMIS decentralization 
effort. Phase -out activities will comprise limited central TA technical assistance 
at the central level for EMIS, as well as completing the EMIS -oriented 
decentralization activities begun under the EMIS support activity (e.g., 
equipment and initial training to 10 remaining districts). 
Illustrative decentralized EMIS support activities related to decentralized EMIS 
support include:
•	 Build on and improve the EMIS accomplishments to date.
•	 Ensure that EMIS is linked to sector M&E and NESP targets and 
indicators.
•	 Review and assess the capacity of central-, division-, district-, and school 
-level information managers and decision makers to analyze and use data.
•	 Bolster the ability and capacity of division; district and school level 
information managers to analyze and utilize use data better and more 
explicitly inform planning processes.
•	 Coordinate with and support efforts to link the tT eacher EMIS and the 
national EMIS.
Illustrative EMIS indicators related to EMIS:
•	 Strengthened district planning systems and linkages to zonal and school 
plans and improvements, including equipment, capacity, and skills support 
to decentralized EMIS activities in 10 districts.
•	 Guidance developed and provided for improved EMIS/information 
production, analysis, and management and use at decentralized levels.
<<<PAGE=106>>>
100
 EQUIP2 Lessons Learned in Education: EMIS
Assumptions underlying the design of EDSA
The EDSA RFA did not specifically articulate any assumptions underlying project 
design. However, the USDH education team leader who played a significant role in 
preparing the RFA, articulated the following assumptions. None focused on EMIS:
1. The Ministry of Education would continue with its reform agenda, National 
Education Sector Plan (NESP), and sector approach to implementing the plan.
2. The Ministry of Local Government and Local Development would continue to 
roll out its decentralization policy.
3. Communities would continue the momentum and that an approach to help 
communities to link up to larger policies so momentum would continue.
Decisions around time frame and funding
The rationale for $11.6 million in funding for EDSA, according to the education 
team leader who helped design the RFA, was based on a combination of analyses, 
the best guess of those who designed EDSA, and the education funding that the 
USAID/Malawi mission anticipated it would receive from USAID/Washington. 
Drawn from the National Education Sector Plan (NESP), the Education Sector 
Implementation Plan (ESIP) provided the rationale for the EDSA three-year time 
frame (ESIP is the GOM four-year sector program that was in its first year of 
implementation when EDSA was designed).
Provisions for sustainability
Sustainability was implicitly a major component of the EDSA design. The notion 
was that USAID should build on the body of support and activities that had come 
before, be responsive to key priorities in the MOE’s plans and minimize doing 
anything outside of those plans. Capacity building and capacity transfer under the 
Associate Award were key. This included individual training, mentoring, coaching, 
and assistance with networking. 
Per Marisol Pérez, the USAID/Malawi education team leader, sustainability went 
beyond individuals: “It’s not just this person. What about the department and/or 
the unit? In EDSA part of the capacity building approach is the ability to solidify 
relationships, patterns of meetings, operational guidelines, habits. We asked and 
continually ask throughout implementation of this activity, ‘How do people use 
information and knowledge?’ ‘How do people use information and how do they 
build on each other?’”
<<<PAGE=107>>>
101Annex 2: EQUIP2 Associate Award Case Studies
3. Implementing the Malawi EDSA Associate Award
Design choices that are guiding EDSA implementation
There were, as can be seen from the contents of the previous section, a number of 
design choices built into EDSA that are guiding its current implementation:
•	 That support for decentralization would be most effective if USAID took the 
conscious decision to operate simultaneously at the central, district, and school/
community level.
•	 That, with limited resources and time, EDSA would not work with all districts 
and divisions but instead 6 out of 28 districts located in two of Malawi’s 6 
education divisions. 
•	 That the Ministry of Education would continue with its reform agenda, NESP 
and the SWAp approach to implementing planning and that USAID would 
support these agendas and approaches. 
•	 That to do the above, USAID needs to be responsive to Ministry of Education 
requests as well as collaborate closely with other donors.
•	 That UNICEF would pick up where USAID left off, under a prior EQUIP2 
project, in supporting the institutionalization of the EMIS system at the central 
Ministry of Education level.
•	 That EDSA would be the “seed” that germinates interest and successfully 
validates innovative approaches to decentralization, with this “germination” 
other donors would ideally pick up and expand the decentralization support 
provided under EDSA.
•	 That EDSA would support the Ministry of Local Government and Local 
Development in rolling out its decentralization policy. 
•	 That communities would continue with momentum that had already been 
built to support decentralization and that an approach to help communities 
to link up to larger policies would be carried out under EDSA so that this 
momentum would continue. 
•	 That civil society had an important role to play in supporting EDSA 
implementation, among others, funds for the schools would be channeled 
through NGOs.
•	 That an important part of the project would be the creation of a feedback loop; 
information to be collected through monitoring and evaluation would feed 
back into joint project decisions made by USAID, EQUIP , and the Ministry of 
Education.
•	 That building in sustainability was fundamental.
<<<PAGE=108>>>
102
 EQUIP2 Lessons Learned in Education: EMIS
Design choice #5 (that UNICEF would pick up where USAID left off, under a 
prior EQUIP2 project, in supporting the institutionalization of the EMIS system 
at the central Ministry of Education level) is the only design choice that refers 
specifically to EMIS. This design choice has not been borne out. UNICEF has not 
provided the anticipated assistance to the central EMIS, and the central Ministry 
of Education (now no longer with outside technical assistance to ensure that “this 
year’s data is provided this year”) is now several months behind in issuing yearly 
data. This, among others, is producing challenges at the district level under EDSA, 
where current year national data are required in order for the decision making tool 
and the school assessment charts being prepared with EDSA assistance to be used 
effectively.
Implementation approach/progress
At the time of drafting this case study, EDSA was a year and three quarters into 
implementation of a three-year project. AED implemented the project under the 
EQUIP2 mechanism represented by the Chief of Party who reports to AED. A 
sub-grant with the Research T riangle Institute provides TA for decentralization and 
EMIS through three short-term RTI consultants who visit Malawi periodically 
to design and oversee specific activities. RTI hired two Malawians who carry out 
decentralization and EMIS activities on the ground.
Implementation activities to date have been highly collaborative. The USAID staff 
enjoy a very close and collegial working relationship with the EQUIP2 COP . All 
three may frequently be found at key MOE meetings. In addition, the EQUIP2 
COP (with the support of USAID/Malawi staff) works very closely with other key 
donors involved in implementation.
The EMIS project has made a promising start in setting the base for strengthening 
the use of information already being collected from the schools both at the school 
and the district level. The Malawian EMIS advisor has been able to identify the 
information that the districts collect from the schools and what they use it for 
strengthening their capacity to collect the information and use it efficiently. 
With assistance from EQUIP2 technical advisors, a Decision Making T ool is being 
developed that calculates data being tracked nationally and compares it with data 
being collected in the districts and makes comparisons possible among schools 
at the district level. Once it’s ready, the Decision Making T ool will identify the 
number of teachers to send to each school based on student enrollments and the 
number of teachers to achieve equity in the distribution of limited resources. With 
delays in generating data at the national level, however, it is difficult to complete 
the information required to generate the T ool on a timely basis. (This critical 
interdependence was often mentioned during the prior AED-led EMIS effort.)
<<<PAGE=109>>>
103Annex 2: EQUIP2 Associate Award Case Studies
EDSA technical advisors also help to generate School Assessment Charts so schools 
can carry out their own planning. The Chart is one page with a set of graphs 
printed on either side. The first page compares the school to other schools within 
the same zone based on six indicators. The second page has the same six indicators 
but looks at trends in the school over time. When this study was carried out, school 
staff were beginning to receive training to use the Charts. 
Decision Support T ool and the School Assessment Chart still need to be 
implemented. One person interviewed pointed out that the challenge is 
creating a widespread demand at all levels (civil society, elected officials, parents, 
communities, chiefs, government departments etc) to use the information available 
through both. 
Adequacy of time frame and budget, effectiveness in building sustainability 
It is premature to assess whether EDSA’s time frame and budget are adequate. 
Funding levels appear to be sufficient for the three-year project. However, as one 
interviewee pointed out, three years are not sufficient to provide intensive and 
prolonged engagement. Another observed that for the “actual changes we have 
to go through not just the Ministry of Education system but the government of 
Malawi system for policies to be changed and implemented. There are aspects not 
up to the project. We can’t say with assurance they will adopt them.”
When queried on the three-year time frame given what the project would like 
to accomplish, the USAID education team leader acknowledged that during the 
design phase, she and her team, in consultation with key MOE counterparts, 
determined that a three-year activity would be but a start. She indicated that 
USAID had begun to think about designing a follow-on activity focusing on 
decentralization, contingent on what would be accomplished and learned during 
the rollout of this activity. It is premature to comment on the effectiveness of 
EDSA in building sustainability.
Key outcomes
EDSA and its project outcomes have not yet been completed. However, a recent 
EDSA quarterly report provided a snapshot of accomplishments for the second 
quarter of 2010 (April–June of 2010).
Improved decentralization implementation, planning and data utilization for in-
formed decision making
• Trial run of School Assessment Chart in rural and urban districts
• Revised Decision Support Tool (version 2)
• Gap assessment of completed Data Entry Windows/DSTs among EDSA districts 
in terms of data entered to date; all six districts reviewed 2009 EMIS data to make 
certain Decision Support Tools were updated with correct information
• Reviewed monthly data collection forms (from schools) and worked with the EMIS 
Unit to revise accordingly; streamlining the data collection forms and timetable could 
improve reporting efficiency, accuracy, and use for schools and districts
• Demonstrated to district education managers how Double-Shifting Guidelines may be 
implemented using the Decision Support Tool.
<<<PAGE=110>>>
104
 EQUIP2 Lessons Learned in Education: EMIS
4. Factors within and outside of USAID and EQUIP2 control that 
favored accomplishments and served as deterrents
As part of the EQUIP2 lessons learned exercise interviewees were asked to reflect 
on successes and challenges. The following is a summary.
Factors that were seen as favorable
•	 Stability of actors within USAID: the USAID/Malawi Mission Director, 
education team leader, and AOTR who presided over the EDSA design 
continue up to this point during implementation
•	 Stability of actors among the EQUIP2 staff (COP , Malawian staff, external 
short-term assistance)
•	 Having a Cooperative Agreement that allowed EQUIP2 to work with the 
MOE when EQUIP2 was developing its proposal; EQUIP2 staff could 
circulate drafts and get feedback from development partners and the MOE 
•	 Excellent communications between the EQUIP2 COP , USAID/Malawi 
education staff, and key Ministry of Education staff
•	 A Mission Director who supports the project’s working within a SWAp 
environment
•	 USAID/Malawi’s willingness to be flexible, adaptable 
•	 Tying the national and local levels through the feedback loop; EDSA lessons 
learned in six districts for system refinement and for developing operation 
guidance manuals.
Challenges
•	 Limitations in staffing at the Ministry of Education: the MOE has many 
vacancies; the very capable Director of Planning, who assisted in designing 
EDSA, left the MOE
•	 USAID did not foresee the catalytic funding application to the Fast T rack 
Initiative that the MOE had to set aside time to prepare, which took a year and 
detracted from other MOE activities including implementing EDSA nationally 
•	 Significant delay in approval of the districts that the project would work in; 
due to presidential elections there was a delay in approval of having grants go 
through district education officers
•	 Delays on the USAID side and at AED in getting the same approvals
•	 Resistance to decentralization: convincing the government to devolve authority, 
control, and responsibilities for making decisions on finance to local levels that 
involves changing a culture
•	 USAID systems need to be made more conducive to working with a SWAp. 
USAID mechanisms, such as PMP indicators, are still rooted in a direct 
implementation approach
<<<PAGE=111>>>
105Annex 2: EQUIP2 Associate Award Case Studies
•	 Convincing MOE counterparts that, although USAID is committed to 
supporting MOE activities, USAID has time lines and targets that it must meet
•	 Concern that project technical assistance may be doing some of the work that 
should be done by MOE staff
•	 The Decision Support T ool is Excel based; in most the places where the MOE 
works there are few computers; electricity is not constant
•	 Lack of clarity on how the central EMIS system will fare without external 
assistance; delays in producing the annual statistical report are already having 
negative repercussions on producing a timely school-based Decision Making 
T ool.
5. EDSA Performance Monitoring and Research Plan (PMRP)
In May of 2009 EQUIP2 presented a Performance Monitoring and Research 
Plan (PMRP) to USAID/Malawi. The PMRP has two assumptions about how 
monitoring and evaluation will be carried out: (1) EDSA will follow the MOE 
logical framework approach, as outlined in the NESP Monitoring and Evaluation 
Plan; and (2) EDSA will align its output, outcome, and impact targets with those 
of the MOE, where applicable. 
The PMRP combines the collection of qualitative and quantitative data. It also 
contains several studies that nourish the EDSA feedback loop, thus ensuring that 
data collected are used to reflect on project progress, inform key MOE and other 
actors on key issues, and be used to make adjustments in project implementation. 
In addition, the PMRP anticipates that evaluations under EDSA will focus on how 
the information and feedback loop contributes to national policy dialogue and how 
information is used for district planning and budgeting. 
The PMRP includes 21 indicators as listed below. Some are context indicators; 
others are for reporting to USAID/Washington under different funding streams 
(basic education, PEPFAR). Three (highlighted in italics and bold) relate to EMIS 
activities:
1. Extent to which decentralization of specific processes/responsibilities correlate 
with improvements in quality and learning at the school
2. BEF: Number of learners enrolled in USG-supported primary schools in EDSA 
districts
3. BEF: Drop-out rate in EDSA districts
4. BEF: Completion rates by primary schools (PSCLE)
5. PEPFAR: Number of eligible adults and children provided with a minimum of 
one care service
6. PEPFAR: Number of eligible children with education and/or vocational 
training
<<<PAGE=112>>>
106
 EQUIP2 Lessons Learned in Education: EMIS
7. PEPFAR: Quality of life for OVC in learning environment
8. IR 1: Effectiveness of AED policy/dialogue feedback loop to contribute to 
national policy dialogue
9. IR 2: Use of information for planning and budgeting at the district level
10. IR 3: Percentage of communities active in school decision making
11. BEF: Number of laws, policies, regulations, or guidelines developed or 
modified to improve equitable access to or the quality of education services
12. BEF: Number of policy briefing papers developed and accepted by MOE/
CSCQBE which contribute to articulation of policy framework 
13. BEF: Number of host country institutions with improved management 
information systems as a result of USG assistance
14. BEF: Number of host country institutions that have used USG-assisted MIS 
system information to inform administrative/management decisions
15. BEF: Number of people trained in other strategic information management 
with USG assistance
16. PEPFAR: Number of District Education Plans which contain an HIV/AIDS 
component
17. BEF: Number of Parent-T eacher Associations or similar ”school” governance 
structures supported
18. BEF: Number of SIP small grants implemented
19. PEPFAR: Number of OVC grants disbursed
20. PEPFAR: Number of T’LIPO members given training to build their 
organizational and HIV/AIDS and OVC skills.
21. BEF and PEPFAR: Assessment of gender lens applied to ensure gender-
sensitive approaches and strategies are integrated into all activities
6. Reflecting on the Malawi EQUIP2 EDSA experience in terms of what 
can be useful for other USAID EMIS projects that focus on EMIS or have 
an EMIS component.
What has worked thus far
•	 The Decision Support T ool and the School Assessment Charts appears to hold 
promise for providing useful information to district education staff and schools 
for planning purposes
What has not worked thus far
•	 Three years appears to be an insufficient to accomplish project objectives, 
including those related to district EMIS support.
•	 Lack of central support for EMIS appears to be having negative repercussions 
for EMIS activities at the district level.
<<<PAGE=113>>>
107Annex 2: EQUIP2 Associate Award Case Studies
•	 Absent a compelling administrative structure that ties funds to receipt of both 
information and systemic improvement, the role/importance of information for 
education is diminished.
Valuable insights from interviewees
On utilization of EMIS data:
EMIS data utilization can be looked functionally at least at two levels: at the 
central level and at the district and sub district levels including the school. 
Given that information needs as you move from the school to National level are 
not exactly the same, there is a need for the system to factor that in order to meet 
the core needs at each level hence increase utilization. Processed data products 
such as charts (districts charts, zone charts, school charts, time series analyses, 
school comparisons, etc.) need to be available at these levels in modes that render 
them both relevant and easy to use for stakeholder at each respective level. 
If the products were made available, a culture of data use and associated 
skills will need strengthening. The challenges include literacy, particularly at 
community level in rural schools and at District level; inevitable political 
elements in the Local Councils. Pro activeness will be important for education 
managers and Civil Society to champion data utilization culture through 
understanding and utilizing leverages and opportunities within the system in 
order for the sector to make progress. The use of the processed EMIS data from 
the point of generation (at the school) onwards besides improving management, 
also leads to improved data quality in the system as data providers will 
appreciate the value or use of quality data better. (Charles Matemba, EQUIP2 
EMIS advisor)
On capacity building:
We are looking at capacity building not just as training (on Excel, GLOBAL 
ED*ASSIST). Training is a first step. We are also looking at capacity transfer, and 
addressing critical questions such as, “how do you know what capacity you are building 
when you don’t have an inventory of where people are, so you know you are building 
their knowledge and skills?” You can conduct training on content, but you need to 
accompany the people trained, sit there with them, and go through the process with 
them. You need to mentor them, coach them, helping them network and seek out 
relevant resources. You need to ask yourself who your end user is. Usually is not just one 
person. What about the department and/or the unit? (Marisol Pérez, USAID/Malawi 
Education T eam Leader)
<<<PAGE=114>>>
108
 EQUIP2 Lessons Learned in Education: EMIS
 D.  ZAMBIA: SUPPORT TO THE MINISTRY OF EDUCATION 
STRATEGIC PLAN IN IMPROVING INFORMATION AND 
STRENGTHENING POLICY IMPLEMENTATION
Time frame:  March 1, 2004–March 30, 2011 
Funding level:  Initial: $13,973,991; Final: $26,473,991
The information for this review is drawn from interviews with eight individuals 
closely associated with the Improving Information and Strengthening Policy 
Implementation EQUIP2 Associate Award, including USAID/education staff, the 
EQUIP2 Chief of Party and technical staff in Zambia, and the AED home office 
director, and two former Permanent Secretaries. It provides the basis for the lessons 
learned found in Section II of this report (along with insights from state-of-the-art 
research on EMIS). 
This case is divided into the following sections: (1) Zambia context, (2) EQUIP2 
Zambia project design, (3) project implementation, (4) successes and challenges (as 
seen by the eight interviewees), (5) monitoring and evaluation, and (6) reflections 
on what can be useful for USAID education officers who design and oversee the 
implementation, monitoring, and evaluation of EMIS. It is divided into four 
sub-sections: what worked, what didn’t work, interesting strategies, and valuable 
insights. 
This review was written in story form (e.g., what was the context and how did 
it influence the design, what influenced implementation and what was learned 
in terms of successes and challenges, what can be learned from monitoring and 
evaluation).
1. Context
Zambia national and education context
The Republic of Zambia is located in southeastern Africa. It is bordered by Malawi 
and Mozambique to the east, Zimbabwe and Botswana to the south, Angola to the 
west, and The People’s Republic of Congo and Tanzania to the north. Zambia went 
“from being a major copper producer and potentially one of the continent’s richest 
countries at independence in 1964 to one of the world’s poorest” (BBC Country 
Profile). Politically, it changed from a colonial government into an era of one-
party rule lasting 27 years. A multi-party system emerged in the early 1990s (BBC 
Country Profile). Even though the late president, Levy Mwanawasa, won respect 
for his anti-corruption drive, the current government under President Rupiah 
Banda has been unable to fully curb political and economic problems. The collapse
<<<PAGE=115>>>
109Annex 2: EQUIP2 Associate Award Case Studies
of world copper prices in 1975, mismanagement, debt, and disease have resulted in 
negative effects on the economy (BBC Country Profile). 
Zambia rates 150 of 169, on in the low human development category in the 
UNDP’s Human Development Index (2010). Adult literacy is 71% (World Bank, 
2008). With a population consisting of more than 70 ethnic groups, as well as 
tens of thousands of refugees from the Democratic Republic of Congo (DRC) and 
Angola, Zambia faces multi-faceted population concerns (BBC Country Profile). 
Not only is life expectancy less than 39 years of age, but Zambia also has the 
seventh highest prevalence of HIV/AIDs among its adult population (CIA World 
Factbook). 
Zambia’s weak economy has led to widespread poverty across the country and 
stagnated rural development. This poverty visibly affects the education and health 
sectors. In particular, limited Ministry of Education financial resources (1.3% of 
GDP in 2009 for education, World Bank statistics) have had negative impacts 
on girls’ education. High rates of net primary enrollment (91% in 2009, World 
Bank statistics) have led to detrimental effects in the quality of education, as 
student–teacher ratios are up to 99:1 in some districts. The HIV/AIDS pandemic 
exacerbates the problem of quality of education; many teachers leave or die each 
year largely due to HIV and AIDS and many students are orphaned or affected.
In 2003, the MOE began implementing an integrated sector-wide approach 
(SWAp) utilizing three funding channels: direct sector support (pool funding), 
designated support funds, and support funds from existing bilateral agreements 
with donors who may not be signatory partners with the MOE. Under the SWAp 
several key joint MOE–cooperating partner committees meet regularly to review 
MOE programs, plans, budgets, progress, and expenditures, and to reach joint 
MOE–cooperating partner decisions. 
Status of Education Management Information Systems (EMIS) at the time of 
the EQUIP2 Zambia design
A needs assessment conducted in 1999 revealed that most of the MOE’s existing 
information systems were not in electronic form. The few computerized systems 
that existed provided only department-specific information, with significant 
duplication of effort across units, which tended to undercut the integrity and 
consistency of the information systems. Some systems were based on incomplete or 
outdated data sets. Most databases were centrally located with no links to local-level 
systems. Personnel lacked familiarity with database management; record-keeping 
and general management capacities were limited. No standards for computer 
software and hardware existed.
<<<PAGE=116>>>
110
 EQUIP2 Lessons Learned in Education: EMIS
In 2001, USAID/Zambia, through a contract with AED, initiated a program to 
strengthen the MOE’s EMIS. Between 2001 and early 2004, it was possible to 
integrate the previous heterogeneous systems to create an effective, efficient, and 
sustainable system at the MOE. This program had five focus areas: (1) EMIS 
development (training, data collection, data analysis, hardware, software, and TA); 
(2) capacity building (training, development of demand for information, business 
processes, and technical assistance); (3) assessment; (4) community data collection 
and use (leverage of funding and collaboration with implementation partners); and 
(5) provision of data and reports for semiannual and “on-demand” monitoring. 
When the project began in March 2004, the EMIS was working in the MOE’s 
headquarters, (both stand-alone and on the headquarters LAN), in two pilot 
provinces (Southern and Eastern), and in all seventeen districts within the pilot 
provinces. The MOE was able to complete its annual education statistics report the 
same year the school census data were collected.
2. Design of the Zambia EQUIP2 project
Design context and process
Relatively new to working in education in Zambia, USAID/Zambia found itself 
designing what became the EQUIP2 Associate Award and two other education 
programs (CHANGES, with AIR, on school health and nutrition and QUESTT , 
with EDC, an interactive radio instruction program for out of school children) in a 
SWAp environment. Unable to participate with budget support, as the other major 
donors were doing, USAID was initially greeted with suspicion and resistance both 
on the part of other major donors and the MOE. A major challenge in the early 
design was to find a way to be an accepted actor in this environment.
Unlike the other two stand-alone USAID-funded education programs, the 
approach in designing the project was to support, respond to, and augment, not 
lead or interfere with, the MOE’s plans and priorities in keeping with the intents 
of the SWAp. It was envisioned that, “The proposed implementation of this project 
will move away from traditional supply-driven, service-delivery models of project 
support to a demand-driven model that enhances the ability of the Ministry and its 
professional staff to lead, to grow, and to prosper as they achieve their professional 
goals and Zambia’s national aspirations for its educational system.”11  
The Associate Award built on and continued progress made with EMIS under a 
prior contract with AED. In addition, USAID/Zambia built in two additional 
components: policy reform and decentralization.
11 EQUIP2 Zambia Associate Award, dated March 11, 2004.
<<<PAGE=117>>>
111Annex 2: EQUIP2 Associate Award Case Studies
Associate Award objectives/purposes12
The purpose of the Associate Award was to, “Improve information for efficient 
resource management and strengthen education policy implementation.”The intent 
was to “extend EMIS to all Districts within the country, support decentralization 
through empowerment of the Districts, support policy implementation through 
enhanced monitoring at multiple levels and support evaluation and monitoring.” 
In addition it was envisioned that the project would also improve access, gender 
equity, and quality in basic education; improve quality and efficiency in secondary 
and tertiary education; develop relevant skills and enhanced learning achievement 
by all learners; decentralize decision making, procurement, and financial 
management to districts and schools; and management/mitigation of the impact of 
HIV/AIDS.
EMIS implementation strategy
When the EQUIP2 Associate Award was designed, it was envisioned that the 
activities in each area would share a common goal—working with and through 
Ministry staff, enhance the MOE’s capacity to utilize education information 
effectively, decentralize administration of education systems, and successfully 
implement relevant policy, programs, and plans. Rather than prescribe a long list 
of intended activities, the proposed approach emphasized the MOE’s leadership in 
planning its future and provided flexibility for assisting the MOE to carry out its 
priority activities and tasks.
Also envisioned was that in some areas the MOE may choose to assist all provincial 
and district offices. At the discretion of the MOE, for example, the project could 
deploy local technical advisors to support financial management or EMIS at all 
provincial offices, or upgrade the information and communications technology 
(ICT) infrastructure at all provincial and district offices to a minimum standard. In 
other areas the Ministry may choose to focus project resources on selected schools, 
districts, or provinces to create and test models that the MOE can later take to scale 
nationally. All activities will provide the vehicle through which a strategy to develop 
capacity would be realized. 
Assumptions and premises
The EQUIP2 Associate Award did not include any specific assumptions. However, 
Kent Noel, the USAID/Zambia education team leader at the time who was 
responsible for designing the EQUIP2 identified four: (1) All the donors would 
be strongly supporting the MOE and the SWAp; (2) USAID would continue 
to support education in Zambia at the same or a higher level of effort; (3) The 
Zambian government would be stable and continue to work on corruption; and (4) 
The Zambian government would continue to make an effort to stem the effects of 
HIV on teachers and students.
12 The information included in this sub-section and those that follow is drawn from the ERP RFA.
<<<PAGE=118>>>
112
 EQUIP2 Lessons Learned in Education: EMIS
Rationale for time frame and budget
When the project was designed, USAID/Zambia selected a five-year time period in 
keeping with its five-year country strategy. Just under $14,000,000 was budgeted 
for implementation, reflecting what the mission anticipated would be required 
to implement the three components and what the USAID/Zambia mission 
anticipated would be available. However, even at the time of project design, it was 
clear that flexibility had to be built in to expand activities and increased funding 
levels as the MOE identified new activities and additional education funds became 
available from USAID/Washington. 
Provisions for sustainability
Sustainability was built in front and center in the Associate Award design as can be 
seen in the next section of this write up.
3. Implementing of the Zambia EQUIP2 Associate Award
Design choices and assumptions that guided implementation
In preparing the Zambia EQUIP2 RFA, and as is referenced above, USAID made a 
number of design choices and assumptions that would guide ERP implementation. 
They included:
1. That all the donors would strongly support the Ministry of Education in the 
context of the SWAp;
2. That USAID would continue to support education in Zambia at the same or a 
higher level of effort;
3. That the Zambian government would be stable and continue to work on 
corruption;
4. That the Zambian government would continue to make an effort to stem the 
effects of HIV on teachers and students; 
5. That EQUIP2 would support the Ministry’s priorities, complement its 
structures, and follow its operational procedures; and
6. That all efforts should enhance the Ministry’s human capacity to achieve 
Zambia’s educational aspirations in a timely and efficient manner, be responsive 
to local and national requirements, thus reflecting a demand-driven focus, and 
promote long-term sustainability.
With the exception of design choice #3, all of the other design choices were born 
out in implementation: all donors strongly supported the Ministry of Education 
and the SWAp (design choice # 1); USAID/Zambia continued to support 
education in Zambia and in fact increased it level of effort (design choice #2); with 
USAID’s support under the EQUIP2 Associate Award the Zambian government 
continued to make an effort to stem the effects of HIV on teachers and students 
(design choice # 4); EQUIP2 supported the Ministry’s priorities, complemented
<<<PAGE=119>>>
113Annex 2: EQUIP2 Associate Award Case Studies
its structures, and followed its operational procedures (design choice # 5); and the 
EQUIP2 Associate Award focused on enhancing the Ministry’s human capacity to 
achieve Zambia’s educational aspirations in a timely and efficient manner by being 
responsive to local and national requirements (design choice # 5).
In the case of design choice #3 (that the Zambian government would be stable and 
continued to work on corruption), the government has remained stable. However, 
insufficient progress has been made in working on corruption witnessed, in the 
education sector, by a recent decision in 2010 by donors to withhold disbursements 
to demonstrate their dissatisfaction.
Evolution of the EQUIP2 Zambia Associate Award between 2004 and 2010
Between 2004 and 2006 EQUIP2 Zambia continued to build on progress on 
EMIS strengthening completed under a prior contract with AED. The project 
also included policy research, institutional management, continuous assessment, 
and integrated information management. In addition, in 2005 an HIV/AIDS 
workplace program was added, using PEPFAR funding. USAID provided a small 
amount of sector program assistance (SPA). The Associate Award was amended 
in 2007, with special funding available from USAID/Washington to work on an 
MOE institutional response to community schools. The Secretariat of Community 
Schools had closed a year earlier because of charges of corruption, and community 
schools were not within the purview of the MOE. 
Responsibilities were added in 2008 when the MOE and the USAID asked 
EQUIP2 to 1) build up a school health and nutrition component, 2) design and 
delivery an education leadership and management course (for primary school 
principals), 3) design and set up an M&E system for the MOE and stakeholders 
and agree upon national education indicators, and 4) an electronic human 
resources information system that would replace the archaic and dysfunctional 
paper filing system for more than 80,000 employees (including teachers). T o widen 
and deepen the impact and effectiveness of the education system and to reach 
underperforming schools and districts in a systemic way, in 2009 a provincial 
advisor component was added to the program strategy. 
By showing that EQUIP2 would be an MOE-led and driven project, USAID and 
AED were able to gain the confidence of the MOE and the other donors. EQUIP2 
did not have an independent vision, goal and strategy, but developed its plans and 
objectives with the MOE. By providing timely and appropriate technical assistance 
behind the scenes, the project convinced others that it could play a constructive 
role in supporting the government’s priorities and the implementation of the 
SWAp. EQUIP2’s long term technical advisors, who were embedded in the MOE, 
came to become trusted advisors to Ministry staff and on several occasions assisted 
other donors with implementation issues they were experiencing in supporting the
<<<PAGE=120>>>
114
 EQUIP2 Lessons Learned in Education: EMIS
SWAp. This was possible because key actors at USAID/Zambia with the support of 
the Africa Bureau in USAID/Washington committed themselves early on to take 
a demand-driven approach that responded to the needs of the MOE instead of 
following a predefined and rigid project implementation plan.
EMIS implementation approach
During project design, stakeholders in the MOE acknowledged the significant 
progress that had been made with EMIS in a relatively short time under the 
preceding project, and noted its positive impact on improving planning processes. 
The highest priorities for the MOE under EQUIP2 EMIS were to: (a) 
institutionalize the EMIS in such a way that it promoted demand for policy-
relevant data and that the analysis of these data would be used to enhance decision 
making; (b) develop the MOE’s capacity to sustain the system with no or only 
minimal outside assistance, (c) extend the EMIS system’s reach to make it useful 
as a management and planning, tool (to include linkages with human resources 
and exams and extend to districts and schools); and (d) increase the system’s use by 
planners and decision makers. “Fundamentally, the EMIS effort needs to shift from 
a ‘supply of information’ driven approach, to a ‘demand for information’ effort.”13 
These priorities were to be accompanied by three implementations strategies as seen 
below.
13 Ibid
Key EMIS implementation strategies
System sustainability was to be improved by simplifying ED*ASSIST, ensuring that 
technical advisors would have not only counterparts, but also professional teams, with 
whom to work. By Year 4, implementation responsibilities would be transferred to Zam-
bian MOE staff. After the resident advisors withdrew, the project would continue to provide 
short-term consulting support as required to extend training and provide troubleshooting.
 
System extension would help the Ministry broaden the system to link with key areas 
such as human resources, exams, finance, payroll, and assessment, thereby increasing 
the system’s integration and utility. School mapping through the geographical information 
system (GIS) was to be extended. The project would deepen the system by strengthen-
ing its links down to the district, zonal, and school levels, and incorpor¬ate data on pupil 
achievement wherever possible. 
 
Enhancing system use required a paradigm shift, on the part of both Ministry personnel 
and external advisors, from a supply-driven to a demand-driven mode. The focus would 
be on how planners and managers can best use the information generated by the sys-
tem. Enhancing system use would also require capacity building among all key decision 
makers on how such information can increase their professional effectiveness, refine their 
decision making, increase their ability to consider alternatives, and contribute to higher 
rates of pupil achievement.
<<<PAGE=121>>>
115Annex 2: EQUIP2 Associate Award Case Studies
Strategies for Capacity Building
Capacity building was an integral element of project implementation. However, 
instead of one strategy for capacity building, many strategies and interventions 
could help the MOE build the capacity it needed to improve its systems. EQUIP2 
would work closely with the MOE to develop strategies and work plans, and select 
the most appropriate interventions for each area of operation. The following were 
envisioned as capacity building strategies:
For enhancing organizational resources:
•	 Needs assessments and skills audits to identify current and future job 
requirements, determine gaps, and plan for filling such gaps.
•	 Organizational development (through advisors, consultants, and/or training—
particularly those locally based) to enhance the Ministry’s capacity to 
accomplish its objectives and to absorb project inputs. 
•	 Short-term TA (consultants) from Zambia, the region, or elsewhere, to provide 
specific services or deliverables on a “one-off” basis (or, at least, with a clear exit 
strategy). 
•	 As an alternative to long-term technical advisors, develop institutional contract 
(outsourcing) mechanisms to fill gaps in the Ministry’s staffing that cannot be 
filled in other ways, with a clearly defined exit strategy to ensure sustainable 
capacity after USAID’s assistance ends. 
•	 A program of grants to cooperating agencies (possibly community-based 
organizations or even schools testing new approaches) to support skills 
development and to reinforce goals such as creating demand for quality or 
focusing on learner achievement.
For enhancing human resources:
•	 Systematic mentoring programs to leverage counterpart relationships and 
ensure skills transfer to entire work teams wherever possible.
•	 Long-term technical advisors (local, regional, or overseas with preference 
for local experts where available) to build capacity, share new skills and 
perspectives, and facilitate the achievement of the Ministry’s objectives. 
•	 Overlapping positions, using a long-term advisor temporarily to fill critical 
posts for which the Ministry does not yet have permanent positions, with a 
guarantee that such positions will be established and filled within a specified 
period of time. 
•	 Short-term technical assistance (consultants), whether from Zambia, the 
region, or elsewhere, to provide specific services or deliverables on a “one-off” 
basis (or, at least, with a clear exit strategy). 
•	 A program of grants to cooperating agencies (possibly CBOs or even schools 
testing new approaches) to support skills development and reinforce goals such 
as creating demand for quality or focusing on learner achievement.
<<<PAGE=122>>>
116
 EQUIP2 Lessons Learned in Education: EMIS
•	 In-country training to meet clearly specified requirements at the central, 
provincial, district, or zonal levels.
•	 Study tours and short courses to meet clearly identified needs, within Zambia, 
elsewhere in the region, or overseas.
•	 Diploma and degree courses to meet identified needs, also within Zambia, 
elsewhere in the region, or overseas. 
For enhancing equipment and ICT resources:
•	 Needs assessments and commodity audits to identify current and future 
equipment requirements, determine gaps, and plan for filling such gaps.
•	 Procurement of equipment and commodities. For example, the MOE could 
use project funds to bring the ICT systems at all provincial and district offices 
to a minimum standard.
Adequacy of time frame and budget 
In keeping with an MOE-led process, and as was anticipated when the project 
was designed, the EQUIP2 Associate Award evolved over time. Activity areas 
increased14  and as additional USAID education funding became available, the 
life of project funding nearly doubled from $ $13,973,991 to $ 26,473,991. The 
implementation period was subsequently extended from September 30, 2008 to 
March 31, 2011. 
When asked whether the time frame and funding were appropriate, all interviewees 
agreed that the funding was appropriate. However, concern was expressed that to 
embed the EMIS thoroughly in the Ministry of Education would require three 
additional years.
Effectiveness in building sustainability under EMIS
By all accounts, the EQUIP2 Zambia Associate Award made significant strides in 
building sustainability under the EMIS component. 
Sri Pererra, a long-term advisor who was in charge of the EMIS component 
for four years, pointed to four important approaches that have contributed to 
sustainability with the EMIS. They include: (1) sitting down together and solving 
problems, by being a part of a team learning from one another; (2) raising the bar 
of expectations, creating an environment where all stakeholders expected a new 
level of productivity/quality; (3) simplify, for example, by establishing a database 
with predefined reports data use was simplified, or by developing programmed 
14 By 2010 there were eleven components, up from three when the Associate Award was designed: (1) Policy 
and Research; (2) Institutional Development and Management; (3) Monitoring and Evaluation;  (4) Education 
Leadership and Management; (5) Continuous Assessment; (6) Provincial Activities; (7) Integrated Informa-
tion Management (comprising of EMIS, HRIS and Bursaries Systems); (8) ICT Infrastructure and Network; 
(9) School Health and Nutrition;  (10) HIV/AIDS Workplace Programme; and (11) Project Management and 
Administration
<<<PAGE=123>>>
117Annex 2: EQUIP2 Associate Award Case Studies
interfaces to import and manage data, the system was easier to manage; and (4) 
through the Associate Award, hiring people and paying them with the intent that 
they would later be absorbed by the Ministry of Education.
Kurt Moses, AED/Washington home office technical advisor for EMIS activities, 
adds, 
Increasingly, we are seeing “embedding or decentralizing of information 
responsibility” to districts and provinces as a way to dramatically increase 
sustainability. For one, they tend to not have as much personnel turnover as 
the Head Office, and they are often more accountable because they are closer 
to the schools and the actual “educational action.” Their work can be seen and 
assessed by many. As importantly, you multiply the talent pool when you involve 
multiple districts and counties—this means that you can identify and nurture 
talent for the whole system—and this often breeds “power users” who become a 
“horizontal” resource for other districts and counties. This tends to strengthen 
the whole system. In addition, we have gradually Zambianized the project. We 
have a Zambian Chief of Party, three of the long terms advisors are Zambians.
However, there have also been blocks to sustainability as they relate to activities 
carried out in support of EMIS:
•	 Keeping the level of skills needed in MOE personnel: good people tend to 
move on, those with less capacity tend to remain; 
•	 The MOE has not had control over its staff; they are named either by the 
Ministry of Finance or the President’s Office. As a result, there have been 
vacant positions for the whole time of the project
•	 A continuing challenge is accessing and outsourcing changes in technology.
Key Outcomes
A report recently developed under the EQUIP2 Associate Award entitled, 
Strengthening the Capacity of the Ministry of Education to Reach National and 
International Goals, The Story of EQUIP2 Zambia” points to outcomes related to 
EMIS as of September, 2010 when the report was prepared. These outcomes are 
listed below:
•	 T o strengthen the sense of ownership and responsibility of the Ministry of 
Education, the EQUIP2 project reduced its input in the day-to-day running 
of the ED*ASSIST system. Although this resulted in some delay in the 
production of the Education Statistical Bulletin, it showed what steps must be 
taken to ensure sustainability of the EMIS. 
•	 The Ministry of Education invests its own money in paying the Internet bill, 
procures its new computers, and replaces old ones with its own budget.
<<<PAGE=124>>>
118
 EQUIP2 Lessons Learned in Education: EMIS
•	 In line with the long-term goals in the development of the EMIS, the district 
education office instead of the provincial education office captured the 2010 
Annual Statistical Compilation. Initial indications show that data were more 
accurate, more comprehensive, and with a sense of local ownership. 
•	 There is less questioning of the quality of data.
•	 Now Ministry staff at different levels is asking for particular kinds of training. 
Capacity building is become more demand-driven. 
•	 MOE staff from different levels are actively giving feedback on how to improve 
the EMIS.
•	 T o provide more timely data, a set of tools have been developed to collect data 
monthly, per term, and annually. The Lusaka Province is selected to run the 
pilot. 
•	 The EMIS is being integrated with the Payroll and Establishment Control 
System (PMEC) so that teachers and schools funded by MOE can be identified 
and crosschecked. For example the monthly staff returns are being tested to 
match the payroll and provide information to investigate disparities. 
•	 The ownership of data entry and utilization has increasingly passed down 
to provinces and districts. Now provinces and districts have ideas on how to 
improve data collection, entry, and use.
Equally significant are the ways in which the EMIS has been used for routine day-
to-day management at the MOE and as input for policy:
•	 Ministry of Education staff use email and Internet to access data and research, 
plan and convene meetings.
•	 The cooperating partners, the Ministry of Finance, and MOE officers are now 
looking at district data, not just national data.
•	 EMIS data have been used to monitor performance effectiveness of the MOE 
in achieving goals through the nationally agreed-upon PAF (Performance 
Action Framework). 
•	 During and after the 2008 Joint Annual Review, civil society organizations 
contacted the MOE information unit, wanting numbers and data to put into 
their presentation (whereas in previous years they were constantly questioning 
the validity and timeliness of that data). 
•	 ZANEC, the umbrella organization of NGOS and civil society organizations 
working in education, is using the EMIS data provided by the MOE as part of 
its analysis and presentation. 
•	 Stakeholders, within and outside the MOE, identify what figures and 
information they really need from the EMIS, and how they want it packaged. 
•	 In teacher recruitment, the project created a model that looked at every school 
in the country, teachers and pupils, and the total number that could be hired. 
The project showed how to bring up the worst ratios up to 75, which schools
<<<PAGE=125>>>
119Annex 2: EQUIP2 Associate Award Case Studies
should be targeted, and how many teachers for each district would be needed 
to bring the ratio to a uniform standard. This was accepted. 
•	 EMIS data shows that the MOE has achieved the net enrollment ratio and 
bursary goals; but that it did not achieve the target student–teacher ratio at the 
district level, nor the Gender Parity Index. 
•	 EMIS data are showing that the MOE deployed enough teachers, however 
attrition is getting worse. This has caused a shift of stakeholder attention from 
recruitment to attrition in those areas, and to see what conditions, incentives, 
and policies will retain teachers in underserved areas. 
•	 The MOE and EQUIP2 District Profile Strategy has been initiated to provide 
more data and analysis for district and school-based solutions. Rather than 
thinking that one national strategy or response for broader problems will 
address the diverse range of causes, the National Performance Framework will 
try to bring the dialogue and search for specific solutions to the district and 
school level.
4. Factors within and outside of EQUIP2 Zambia control that favored 
project accomplishments and served as deterrents
Interviewees were asked to reflect on elements of the EQUIP2 Zambia Associate 
Award that they considered successful and on challenges. T o avoid duplication this 
list is limited to topics not addressed in the prior section: 
Factors seen as favorable
Specific to EMIS
•	 Limited turnover in the EMIS unit, the IT manager has been around for the 
duration of the project. 
•	 Good quality EMIS training, it has been simplified as much as it could be.
•	 The project prepared easy-to-read/understand district comparisons.
EMIS contributed to
•	 Education planning documents/decision making.
•	 The project was able to get the MOE to recognize importance of incorporating 
community schools in their census – an inclusion that some other countries 
resist (believing their task is to focus on government schools).
•	 A decision was made, based on EMIS data, not to provide free secondary 
education – both because of overall per student cost, and the related factors 
associated with secondary school attendance. 
•	 More students are qualifying for high school but not getting a place. EMIS 
data were used to prepare information on student–teacher ratios and class sizes
<<<PAGE=126>>>
120
 EQUIP2 Lessons Learned in Education: EMIS
These data were able to show that schools in some parts of the country had 
spaces, whereas in other areas the schools couldn’t absorb more students.
•	 Districts use data from the EMIS to prepare their budgets.
•	 The project is working on a system so that districts can get personnel data on a 
monthly basis.
•	 The MOE has more influence on its budget allocation because the Ministry of 
Finance believes it knows what is going on in its schools.
•	 The districts EQUIP2 is working in better understand inputs and performance 
in comparison to other districts.
Related to EMIS
•	 The first couple years were about building working relationships. The project’s 
biggest input was the quality of the technical advisors and the relationships 
they built. 
•	 The project was MOE-led and driven, it has responded to MOE needs.
•	 It was possible to embed staff in the Ministry of Education.
•	 Over time the project was successful in demonstrating to the MOE and other 
donors that it could respond to their requests and serve their priority needs by 
providing TA with no other agenda attached. 
•	 Over time the project earned the trust not just of USAID and the MOE but 
also of the other key donors.
•	 The USAID education staff received strong support from senior management 
(Mission Director, Deputy Director, other superiors) throughout the program 
for supporting as MOE demand-driven approach.
Specific to EMIS
•	 Limited turnover in the EMIS unit, the IT manager has been around for the 
duration of the project. 
•	 Good quality EMIS training, it has been simplified as much as it could be.
•	 The project prepared easy-to-read/understand district comparisons.
Challenges
•	 T urnovers in the position of Director of Planning within the Ministry of 
Education—three during the life of the project.
•	 In the second year of the project, there were problems accessing funding from 
USAID due to pipeline issues and uncertainty regarding USAID funding. 
•	 There are problems of Internet connectivity at the district and school level.
•	 Limited capability among MOE staff to interpret data in the early years of the 
project.
•	 The MOE itself is very slow moving, there has been an enormous bureaucratic 
inertia.
<<<PAGE=127>>>
121Annex 2: EQUIP2 Associate Award Case Studies
•	 Extremely low MOE salaries, which has made it difficult to attract qualified 
personnel.
5. Monitoring and evaluation
Initially the EQUIP2 Zambia M&E plan was a set of PMP indicators, a checklist 
that was completed at the end of each year. However, in 2007 USAID/Zambia 
took the decision to add a more robust M&E component to the EQUIP2 project. 
Designed in close collaboration with MOE directorates and donors who formed a 
steering committee and now manages the process, this M&E system adopted the 
MOE’s M&E vision and indicators agreed upon by a collaborative process in the 
education sector. Rather than developing a yearly plan that specified anticipated 
indicators through the end of the Associate Award in 2010, the decision was taken 
to develop a framework that listed indicators at the output, process, outcome, and 
impact levels but leave flexibility for targets to be established annually. 
There was one EMIS indicator at the outcome level: “Improved use of Information 
Management for Efficient Resource Management.” “Improved use of information” 
includes improvements in timeliness (data analyzed and used within a year), 
validity, reliability (stable and consistent data collection processes over time), 
precision (acceptable margin of error), integrity (free of manipulation), and 
utilization of information by decision makers. “Efficient Resource Management” is 
defined as the MOES’s capacity to plan and implement activities based on accurate 
data.
At the output level, EMIS indicators varied by year depending on the yearly targets 
established. The following indicators were developed for 2010:15 
•	 EMIS information utilized (percent of stakeholders utilizing information 
statistics at headquarters, district, school, and provincial levels)
•	 Improved publication and access to EMIS data achieved (percent of 
stakeholders finding the EMIS useful and timely)
•	 School used EMIS data to prepare requests for resource, at meetings with 
community (PTA), and for annual plans (percent of requests quoting evidence 
from EMIS for justifying requests from district education boards)
•	 District education boards and schools reduce errors and delays (average 
number of rejected submissions at MOE headquarters on confirmations and 
retirements)
•	 Establishment revised and corrected (establishment submitted to the 
Management Development Division and approved)
•	 Pilot STMS completed (pilot provinces selected and implemented)
•	 STMS rolled out (all schools, colleges and administrative offices use STMS)
15 EQUIP2: 2010 July – September progress report, AED, October, 2010
<<<PAGE=128>>>
122
 EQUIP2 Lessons Learned in Education: EMIS
•	 Schools, districts, and provinces trained on STMS (number of schools, district 
education board, provincial education office trained in STMS)
•	 Human resources information system (HRIS) based on PMEC funding secured 
(number of human resources modules to be implemented)
•	 HRIS modules implemented (number of modules configured, tested, and 
implemented)
6. Reflecting on the Zambia EQUIP2 experience in terms of what can be 
useful for other USAID EMIS projects.
What worked
•	 USAID wisely took the decision to support MOE needs and in so doing 
adopted a flexible implementation approach.
•	 Due in large part to the above, and the fact that EQUIP2 staff was embedded 
in the MOE, USAID and EQUIP2 staff developed both the trust and close 
working relationships required for effective implementation.
•	 In the case of EMIS, it was helpful to have continuity in terms of the key-
implementing actors from a prior USAID project financed by USAID/Zambia 
and channeled through AED. 
•	 “This year’s data” continued to be produced “this year” with the help of outside 
TA. 
•	 EMIS data acquired increased credibility and became accessed frequently by 
entities outside of the MOE (donors, NGOs, civil society) for their particular 
needs.
•	 In addition to an EMIS component, it was helpful to have other components 
that generated the need for EMIS data (policy, management, decentralization).
•	 It was helpful to have long- and short-term advisors who worked closely with 
their MOE counterparts and knew how to access and use the EMIS data to 
contribute to policy and other decisions.
•	 The MOE district staff made increased use of EMIS data for planning/
programming.
•	 Data generated by the EMIS and GIS was used for education planning and 
decision making: to get the MOE to recognize the importance of incorporating 
community schools in their census and as a part of the national school system, 
which needed support; to decide not to provide free secondary education; to 
allocate students qualified for high schools to areas of the country where there 
were spaces for them; to assist districts to prepare their budget; to influence the 
Ministry of Finance to increase its budget allocation to the MOE.
<<<PAGE=129>>>
123Annex 2: EQUIP2 Associate Award Case Studies
What didn’t work
•	 Although significant progress was made toward sustainability, some aspects are 
being sustained and some to varying degrees, some have not, and others remain 
to be seen.
•	 Continuity is difficult without qualified and committed Directors of Planning 
who receive institutional support and resources.
•	 Staff turnover in the EMIS unit and other related units was an endemic 
problem: people got trained and then left the MOE for higher paying jobs 
elsewhere.
•	 Given that the MOE did not have control over the personnel that they named, 
vacancies remained in key offices for long periods of time; when individuals 
often lacked the skills to carry out the job.
•	 There was limited capability among MOE staff to interpret/use data without 
external donor assistance.
Valuable insights from interviewees
On contributing to sustainability
The most effective part was just sitting down together and solving a problem. 
By being a part of a team you all learn from each other. It’s not a one-way 
thing, you debate, argue, and a better product emerges. As advisors, we tried 
not to work independently but we were prepared to work within the realities 
of the MOE environment. We were a part of the team and we worked under 
the direction of the MOE leadership, even if that meant working together with 
MOE colleagues on a last minute assignment late at night or over the weekend. 
(Sri Perrera, EQUIP2 EMIS advisor)
In my last year my focus to improve sustainability was to simplify systems and 
processes as much as possible. We tried to set up an environment that strived 
for continuous improvement but simplified systems. For example, by expanding 
the number of predefined reports we made information more accessible to all 
users. Our goal was to reduce the dependency on scarce skills. The more we could 
build into the predefined reports, the more people could access that information 
without having to depend on individuals with database query skills. By 
simplifying some of the data cleaning and data management tasks, we made 
district level data management and ownership possible. (Sri Perrera, EQUIP2 
EMIS advisor)
The key issue is more complex than whether or not technical assistance is still 
needed, can the Ministry sustain what has been introduced, or have we worked 
ourselves out of a job. Ministries almost everywhere have been and will be in 
need of technical assistance in key strategic and technical areas. Our challenge 
is “graduation.” We work together with the MOE to address a set of issues and 
challenges in one point in time, and help strengthen their capacity to respond.
<<<PAGE=130>>>
124
 EQUIP2 Lessons Learned in Education: EMIS
Then as they become more competent and move on to other, more complex issues, 
their technical needs change and are more complex. As a project, we need to be 
able to graduate to that next level of demand or need, and to accompany—in 
the most appropriate way—the Ministry as its needs evolve. We, and others, 
must have the ability to keep pace with the maturing needs of the Ministry of 
Education. This was especially the case in EMIS, due in a certain part to our 
success, where the MOE’s needs expanded at a faster rate than we were able 
to keep pace with. What the Ministry of Education needs at a certain time is 
technical assistance to accomplish A, B, and C; and the following year D, E. 
and F . (T om Lent, AED home officer director)
On training
If you think the amount of training needed is X, you should budget for 3X. 
Internal inefficiencies, turnover of personnel, the basic selection process for 
people who get “training and funding” all mitigate against easy and efficient 
training. (Kurt Moses, AED home office EMIS specialist)
On achieving systemic change 
In Zambia, we found that our work at the centralized ministry level would 
only have limited, trickle down impact if we did not try to identify and 
work with the potential dynamism of provinces, districts, and head teachers. 
We started supporting provincial education officers and district officials in 
their convening of stakeholders and putting the issues of low test scores, low 
performance, and school quality on the agenda of schools and education leaders, 
the private sector, NGOs, and civil society. Good provincial leadership was 
successful in raising awareness and indignation around poor school quality, and 
getting people to commit to a new standard and goals. Also, we try not to treat 
education problems as though they only have education solutions. What works 
and why is fundamentally a development issue, and is similar to what we have 
learned in development over the decades about agency, reform, engagement of 
communities and stakeholders, access to quality information, not losing focus on 
children and understanding their context and realities. (T om Lent, AED home 
officer director) 
On maintaining a staff at the Ministry of Education with technical skills to run the 
EMIS
A key issue with EMIS is that you train specialists in the Ministry of Education, 
provide them good technical and analytical skills, give them certifications and 
respected (world caliber) training, and then they leave for better paying jobs 
elsewhere—usually in the private sector, but sometimes directly with donors or 
NGOs. A possible way around this is to identify secondary level math or science 
teachers, in mid-career, who have shown dedication to education and “second” 
them for EMIS and analytical jobs. Then, rotate them through the Ministry
<<<PAGE=131>>>
125Annex 2: EQUIP2 Associate Award Case Studies
of Education head office for two to three years. We did this successfully in 
Zimbabwe in the 1980s. The Head Office gained from people with “real world 
experience” and when the personnel returned to another more decentralized 
position, they carried with them an appreciation of Head Office needs. (Kurt 
Moses, AED Vice President and home office EMIS specialist)
<<<PAGE=132>>>

<<<PAGE=133>>>
127Annex 3: Interview Protocol
Annex 3: Interview 
Protocol
Step 1: Background Information
1. Interview start and end time: 
2. Country and project: 
3. Date of interview: 
4. Name(s) of interviewee(s): 
5. Nature of interviewee(s) participation/involvement in project and over what 
time period: 
6. Context
Step 2: Share with interviewee portions of matrix for country that lists 
the project objective(s) (as stated in RFTOP and in USAID response), key 
activities/results, time frame, and funding level.
1. Ask if this reflects the person’s understanding of initial project objectives and 
planned activities. 
Step 3: Using this information as a point of departure, probe to obtain 
the following information related to project design: 
1. What was the developmental hypothesis (or, What do you think the designers 
wanted the project to achieve? How was it expected to get there?) , was it valid, 
and did it evolve over time?
2. What were the assumptions behind the development hypothesis, were they 
valid, and did these assumptions evolve/change over time?
3. What were the key activities and how was the mix of activities selected (or how 
did you think that by investing in these activities you would achieve the project 
objective(s)? 
4. What were the assumptions underlying selecting the specific mix of activities; 
were they valid; did these assumptions evolve/change over time?
<<<PAGE=134>>>
128
EQUIP2 Lessons Learned in Education: EMIS
5. The project was programmed to last X years with X budget. What was the 
basis for thinking that this time frame and budget would be appropriate for 
achieving your overall objective(s)?
6. When the project was designed were provisions made to ensure sustainability of 
project actions/activities? What were they?
7. (if appropriate) Was there an expectation that XYZ would be achieved during 
the first or second year of the project?
Step 4: With the above information in hand, let’s turn to project 
implementation
(Note: it is possible that some of the topics below may have come up spontaneously 
and been addressed during Step 3. If they have, use this information as a basis for 
deciding to what extent it is necessary to address the questions that follow)
1. Did the project activities lead to the outcomes expected; if not, what were the 
reasons for not achieving expected outcomes?  
2. Did the project build in sufficient resources; if not what were the consequences/ 
trade offs? 
3. Did the project build in sufficient time; if not what were the implications for 
achieving the outcomes expected?
4. Did the project end up adding/modifying project activities, adjusting the 
budget, the time frame?
5. Was sustainability achieved?  Is so in what way?  If not, what were the factors 
that impeded achieving sustainability?
Step 5:  Focusing on Monitoring and Evaluation
(Note: this is for individuals interviewed who had a close knowledge of M&E; it is 
possible that several interviewees did not and therefore may not have much to say)
1. What indicators were selected to assess project impact and track activity 
progress?  Were there any evaluations and, if so, what was their objective?
2. Which were the most useful measures of impact/progress?  Which were not?  
Why?
3. How was the information from the indicators tracking/evaluation(s) used?
4. With the benefit of hindsight were there other/additional indicators that you 
think should have been used?
<<<PAGE=135>>>
129Annex 3: Interview Protocol
Step 6: An examination of successes and challenges, adapting to changing 
circumstances 
(Note: again it is possible that the topic of successes and challenges may have come 
up spontaneously during the interview. If so: indicate to the interviewee that s/he 
has already referred to several successes and/or challenges. Would s/he like to add 
any others or expand on any they have already mentioned?).
1. What aspects of the project were most successful?  Why?
2. What were the key challenges faced during implementation; and was it possible 
to successfully address them?
(Note: Depending on how the interviewee responds, probe in order to identify 
if any of the items below represented challenges. Also make sure to identify the 
source(s) of the challenge: (1) within USAID; (2) within MOE; (3) within FHI 
360); (4) Factors outside of the control of key project actors.
3. How easy was it to adapt to changing circumstances?
4. How easy was it to reprogram or change aspects of the program?
Closing:
1. Is there anything else that you think is relevant that you would like to share?
<<<PAGE=136>>>

<<<PAGE=137>>>
131Annex 4: Individuals Interviewed
Annex 4: Individuals 
Interviewed
UGANDA: STRENGTHENING OF THE UGANDA EDUCATION 
MANAGEMENT INFORMATION SYSTEM 
•	 David Bruns, USAID/Uganda education team leader (2003–2005)
•	 Danie Wium, EQUIP2 Africon technical advisor (2003–2005)
•	 Kurt Moses, EQUIP2 AED Vice President and home office Project Director 
(2003–2005)
•	 Albert Byamugisha, former deputy to the Ministry of Education (2003–2005)
MALAWI: EDUCATION SECTOR POLICY, PLANNING, EMIS 
SUPPORT ACTIVITIES AND HIGHER EDUCATION STRATEGIC PLAN 
DEVELOPMENT
•	 Bill Mvalo, USAID/Malawi education team leader (2003–2005)
•	 T om LeBlanc, USAID/Malawi education team leader (2005–2008)
•	 Marisol Perez, USAID/Malawi education team leader (2007–2008)
•	 Fahim Akbar, EQUIP2 Chief of Party and EMIS technical advisor (2003–
2008)
•	 Kurt Moses, EQUIP2 AED Vice President and home office Project Director 
(2003–2008)
•	 Augustine Kamlangera, Former Director of Planning, Malawian Ministry of 
Education
•	 Martin Masanche, EMIS technical expert, Malawian Ministry of Education 
(2008–)
MALAWI: EDUCATION DECENTRALIZATION SUPPORT ACTIVITY 
(EDSA)
•	 Marisol Perez, USAID/Malawi education team leader (2007–)
•	 Joan Sullivan Omoyowela, EQUIP2 FHI 360 EDSA Chief of Party (2009–)
•	 Alistair Rodd, EQUIP2 RTI EDSA short-term decentralization advisor (2009-)
•	 Grace Banda, EQUIP2 RTI EDSA Malawian decentralization advisor (2009–)
•	 Charles Matemba, EQUIP2 RTI EDSA Malawian EMIS advisor (2009–)
•	 Carrie Willimann, EQUIP2 FHI 360 home office EDSA Project Director 
(2010–)
<<<PAGE=138>>>
132
 EQUIP2 Lessons Learned in Education: EMIS
ZAMBIA: SUPPORT TO THE MINISTRY OF EDUCATION STRATEGIC 
PLAN IN IMPROVING INFORMATION AND STRENGTHENING POLICY 
IMPLEMENTATION
•	 Kent Noel, USAID/Malawi education team leader (2001–2004)
•	 Cornelius Chipoma, USAID/Zambia EQUIP2 AOTR (2004–2010)
•	 Arnold Chengo, EQUIP2 Chief of Party (2004–2009)
•	 Sri Perrera, EQUIP2 Deputy Chief of Party and EMIS technical advisor 
(2004–2008)
•	 Kurt Moses, EQUIP2 AED Vice President and home office EMIS technical 
advisor (2004–2010)
•	 T om Lent, EQUIP2 AED home office project director (2005–2010)
•	 Barbara Chilangwa, Zambian Ministry of Education Permanent Secretary 
(2001–2004)
•	 Lilian Kapulu, Zambian Ministry of Education Permanent Secretary (2004–
2010)
<<<PAGE=139>>>
133Annex 4: Individuals Interviewed
<<<PAGE=140>>>

<<<PAGE=141>>>
135Annex 5: References
Annex 5: References
UGANDA
Africon Limited/AED. (2006). Education Management Information System (EMIS 
3) Final Report.
Africon Limited/AED. (2003). Program Description, Support for the Education 
Management Information System, Quarterly Report for the Period September 1, 2003 
– December 21, 2003.
Drew, Douglas. (Draft). Lessons Learned Study on EMIS in Uganda. Washington 
D.C.: USAID.
MALAWI
AED. (2009). Education Decentralization Support Activity (EDSA) Quarterly Report, 
Quarter 2-FY 2009, January – March 2009. Washington, D.C.: EQUIP2 Malawi 
Education Decentralization Support Activity (EDSA).
AED. (2009). Education Decentralization Support Activity (EDSA) Quarterly Report, 
Quarter 3-FY 2009 April – June 2009. Washington, D.C.: EQUIP2 Malawi 
Education Decentralization Support Activity (EDSA).
AED. (2010). Education Decentralization Support Activity (EDSA) Quarterly Report 
Quarter 2-FY 2010 January – March 2010. Washington, D.C.: EQUIP2 Malawi 
Education Decentralization Support Activity (EDSA).
AED. (2010). Education Decentralization Support Activity (EDSA) Quarterly Report 
Quarter 3-FY 2010 April – June 2010. Washington, D.C.: EQUIP2 Malawi 
Education Decentralization Support Activity (EDSA).
AED. (2010). Education Decentralization Support Activity (EDSA) Quarterly Report 
Quarter 1-FY 2011, July – September 2010. Washington, D.C.: EQUIP2 Malawi 
Education Decentralization Support Activity (EDSA).
AED/EDC. (Draft). EQUIP2 Associate Award: Performance Monitoring Plan 
for the EQUIP2 Education Sector Policy, Planning, EMIS Support Activities 
and Higher Education Strategic Plan Development Project, USAID/Malawi.
<<<PAGE=142>>>
136
EQUIP2 Lessons Learned in Education: EMIS
Washington, D.C.: EQUIP2 Malawi Education Decentralization Support Activity 
(EDSA).
AED. (2010). Performance Monitoring and Research Plan Malawi Education 
Decentralization Support Activity (EDSA). Washington, D.C.: EQUIP2 Malawi 
Education Decentralization Support Activity (EDSA).
AED. (2009). USAID/Malawa, Education Decentralization Support Activity 
(EDSA), Work Plan: Year 1, 2009. Washington, D.C.: EQUIP2 Malawi Education 
Decentralization Support Activity (EDSA).
Akbar, Fahim. (Draft). EQUIP2 Associate Award: Final Report for the EQUIP2 
Education Sector Policy, Planning, EMIS Support Activities and Higher Education 
Strategic Plan Development Project, USAID/Malawi. Washington, D.C.: Academy 
for Educational Development and Education Development Center.
USAID/Malawi. (2009). Education Decentralization Support Activity Program 
Description. Washington, D.C.: EQUIP2 Malawi Education Decentralization 
Support Activity (EDSA).
ZAMBIA
AED. (2010). EQUIP2 Zambia: 2010 Work Plan & Budget. Washington, D.C.: 
EQUIP2 Zambia.
AED. (2010). EQUIP2 Zambia: January - March, 2010 Quarterly Report, May 
2010. Washington, D.C.: EQUIP2 Zambia.
AED. (2010). EQUIP2 Zambia: July - September, 2010 Quarterly Report, October 
2010. Washington, D.C.: EQUIP2 Zambia.
AED. (2010). EQUIP2 Zambia: Monitoring and Evaluation Plan 2007 – 2010, 
January 2007. Washington, D.C.: EQUIP2 Zambia.
AED. (2009). Strengthening the Capacity of the MOE to Reach National and 
International Education Goals: The Story of EQUIP2 Zambia, 2004-2009. 
Washington, D.C.: EQUIP2 Zambia.
AED. (2004). USAID/Zambia Program Description: Support to the Ministry 
of Education Strategic Plan in improving Information and Strengthening Policy 
Implementation. Washington, D.C.: EQUIP2 Zambia.
<<<PAGE=143>>>
137Annex 5: References
<<<PAGE=144>>>

<<<PAGE=145>>>

<<<PAGE=146>>>
USAID
Patrick Collins
EGAT/ED/BE, USAID 
Washington
1300 Pennsylvania Ave., NW
Washington, DC 20532
T el: 202-712-4151
The EQUIP2 Lessons Learned in Education Series: Guides to Education Project Design, 
Implementation, and Evaluation Based on Project Reviews of USAID-funded EQUIP2 
Associate Awards. Other topics in this series include:
•	 Decentralization
•	 Policy Dialogue
•	 Secondary Education
•	 Student Assessment
•	 T eacher Professional Development
FHI 360
Audrey-marie Schuh Moore
EQUIP2 Project Director
1825 Connecticut Ave., NW
Washington, DC 20009
T el: 202-884-8187
Email: aumoore@fhi360.org
Web: www.equip123.net
For more information, please contact: