<<<PAGE=1>>>
Advances in Social Sciences Research Journal – Vol. 10, No. 12 
Publication Date: December 25, 2023 
DOI:10.14738/assrj.1012.16130 
 
Kanyamuna, V., Simui, F., Mubita, A., & Musanda, P. (2023). Essentials of Functional Whole -of-Government Monitoring and 
Evaluation Systems: The Zambian Case. Advances in Social Sciences Research Journal, 10(12). 370-383. 
Services for Science and Education – United Kingdom 
 
 
 
 
Essentials of Functional Whole-of-Government Monitoring and 
Evaluation Systems: The Zambian Case 
 
Vincent Kanyamuna 
School of Humanities and Social Sciences,  
Department of Development Studies,  
University of Zambia, Lusaka, Zambia 
 
Francis Simui 
Institute of Distance Education,  
University of Zambia, Lusaka, Zambia 
 
Aurick Mubita 
School of Humanities and Social Sciences,  
Department of Social Work and Sociology,  
University of Zambia, Lusaka, Zambia 
 
Paul Musanda 
School of Humanities and Social Sciences,  
Department of Development Studies,  
University of Zambia, Lusaka, Zambia 
 
ABSTRACT 
Since the turn of the 21 st century in the year 2000, it has become increasingly 
impossible to design and implement a development intervention, be it a project, 
programme or policy without articulating a sound monitoring and evaluation 
framework. More demanded are functional monitoring and evaluation (M&E) 
systems. It is f or that reason that governments, civil society organisations, non -
governmental organizations, bilateral and multilateral agencies have all adopted 
the agenda of strengthening their systems for M&E. Among others, known benefits 
from implementing sound M&E i nclude enhancing accountability, feedback and 
learning. This paper articulates essentials development agencies, and their 
respective stakeholders need to put in place for their M&E systems to function well. 
More so, focus is on building stronger whole -of-government M&E systems. 
Essentially, a typical M&E system would have two sides, both of which would be 
crucial for a successful and functional whole-of-government M&E system. These are 
the supply -side and the demand -side. In addition, there are known essent ials 
deemed crucial to a successful whole-of-government M&E system. These include the 
political and technical issues associated with implementing country systems for 
M&E. Another essential is the ownership of M&E systems. Further, the paper also 
presents a comprehensive section showing the fundamental ten steps for building 
a functional whole-of-government M&E system. When these aspects are understood 
by governments and carefully institutionalised across structures, M&E would prove 
to be a useful tool to pr omote accountability, feedback and learning. It also goes
<<<PAGE=2>>>
371 
Kanyamuna, V., Simui, F., Mubita, A., & Musanda, P. (2023). Essentials of Functional Whole -of-Government Monitoring and Evaluation Systems: 
The Zambian Case. Advances in Social Sciences Research Journal, 10(12). 370-383. 
URL: http://dx.doi.org/10.14738/assrj.1012.16130 
without saying, that, in the absence of a stronger system for M&E, governments will 
most likely not tell success from failure, not see success and would fail to reward it. 
As such, governments would  probably never recognize its failures, thus failing to 
correct it and ultimately fall short of demonstrating development results. Once 
these happen, such governments would not win public support.  
 
Keywords: monitoring, evaluation, demand & supply -sides, whole-of-government, M&E 
system, Zambia  
 
INTRODUCTION 
Monitoring and Evaluation (M&E) functions have become a requirement for development 
interventions, regardless of whether they were being implemented by government, civil 
society, non-governmental organisations (NGOs), bilateral or multilateral agencies. Therefore, 
development organisations have created, and more are working to strengthen their systems for 
M&E to increase accountability, feedback and learning mechanisms. However, to ensure that 
M&E systems are stronger to meet the desired outcomes, there is need to put in place certain 
essential features and components which need to work together as a unified system. It is for 
that reason that we have in place government-wide (whole-of-government) M&E systems, non-
governmental organisation M&E systems, civil society M&E systems, bilateral and multilateral 
agency M&E systems, etc. [66] defines a WoGM&ES as a robust system that not only provides 
an integrated and all -encompassing framework of M&E practice s, principles and standards to 
be used throughout government institutional structures, but also functions as an apex -level 
system for information and draws from the component systems in a framework meant to 
deliver essential M&E products tailored to satisfy information needs of users. 
 
Thus, it is important that good understanding exists about the essential underpinnings of 
monitoring and evaluation systems and how these systems are supposed to be organised if they 
are to provide information that would he lp to transform a country’s good governance reform 
agenda. Such essential ingredients represent a significant trajectory in terms of clarifying areas 
of success that need to be embraced as Zambia works to develop and sustain its whole -of-
government monitor ing and evaluation system (WoGM&ES). Any other country system for 
M&E would also benefit from the utilisation of the M&E essentials.  
 
Essentially, a typical M&E system would have two sides both of which are crucial for a 
successful and functional WoGM&ES. These are the supply-side and demand-side. In addition, 
the paper articulates the essentials deemed crucial to a successful WoGM&ES. These include 
the political and technical issues associated with implementing country systems for M&E. 
Another essential is the ownership of M&E systems. Further, the paper presents a 
comprehensive section showing the fundamental ten steps for developing a functional 
WoGM&ES. The conclusion stresses the importance of these aspects.   
 
OVERVIEW AND BACKGROUND 
Several experts and development practitioners alike, as well as organisations including 
governments have stressed the desire for stronger M&E systems. The Zambian Government 
must build a functional and robust WoGM&ES that seeks to comprehensively provide the much-
needed information to support development processes at all levels of governance, namely a
<<<PAGE=3>>>
372 
Vol. 10, Issue 12, December-2023 Advances in Social Sciences Research Journal (ASSRJ) 
Services for Science and Education – United Kingdom 
system that will meet the development expectations of players and stakeholders in the 
economy and beyond.  
 
The significance of functional national level M&E systems is that benefits are widespread, 
including giving crucial decision -making information in the course of policy, programme and 
project implementation. When used properly, information from these systems could help to 
stimulate development debate throu gh constructive brainstorming on challenges affecting an 
intervention. In that regard, development managers obtain valuable information for 
improving their deliverables, thereby assuming control and ownership of development 
processes [2,46]. 
 
Since government busi ness is generally implemented across the country, a functional 
WoGM&ES is needed to help with resource allocation to the neediest areas through evidence -
based data and information and results -focused feedback loops [12]. Once this is achieved, it 
is envisaged that the Zambian Government’s predictability in terms of positive public service 
delivery should be well anchored on a results-based management approach and the capability 
of sustaining the desired national development path should be pursuable realisti cally. 
 
A strong view is held among M&E advocates and practitioners that countries should always 
deliberately try to lead and sustain the building of their WoGM&ESs. It is even preferred that 
such systems should be owned and led by key stakeholders in the country so that external 
stakeholders such as donors do not enforce their interests [52]. Elements such as determining 
what is to be evaluated, which evaluation questions must be asked, which methods should be 
used and which analytical approaches should be employed are important for countries to own 
and control. In addition, the manner in which M&E findings are communicated, shared and 
used is supposed to be in the jurisdiction of the government and its internal structures.  
 
DEMAND AND SUPPLY SIDES OF MONITORING AND EVALUATION SYSTEMS 
Monitoring and evaluation (M&E) systems comprise two parts: the supply side and demand 
side. From the supply side, information that feeds into decision -making processes is 
generated and disseminated to those that use it on  the demand side of the system. Therefore, 
a good match is required between the supply and demand sides when building and sustaining 
systems for M&E [16, 17, 48].  
 
The supply side involves human skills and capacity development, including adapting 
appropriate technologies and tools and supporting institutional frameworks [15]. In other 
words, the supply side of an M&E system generally refers to a range of systemic and 
institutional aspects such as data collection, capacity, sequencing, leadership, coordinat ion, 
regulation and oversight [42]. Further, the demand side is concerned with the use of M&E 
information by actors that include governmental agencies, parliaments, NGOs, civil society 
organisations, research institutions, universities, the donor community  and the general 
population [23, 42,24]. Similarly, this means that the ways in which these entities are involved 
to stimulate demand for information could be useful in strengthening the demand side of an 
M&E system [3,47] . Therefore, care should be taken by ensuring that M&E standards, 
procedures, tools and principles conform to local requirements. For instance, indicator 
choices are better developed when they are anchored on country -specific values and norms.
<<<PAGE=4>>>
373 
Kanyamuna, V., Simui, F., Mubita, A., & Musanda, P. (2023). Essentials of Functional Whole -of-Government Monitoring and Evaluation Systems: 
The Zambian Case. Advances in Social Sciences Research Journal, 10(12). 370-383. 
URL: http://dx.doi.org/10.14738/assrj.1012.16130 
Where they are employed from international age ncies, indicators must be appropriate and 
adapted to local conditions [15, 62]. 
 
However, developing M&E systems that respond to the expectations of stakeholders is not easy. 
For that reason, governments and stakeholders must have solid plans and incentives to compel 
them to invest in such systems. Building an M&E system is not a one -off activity, but a long 
process that requires focus and commitment from government and stakeholders. Section 4.4 
outlines some of the key aspects that governments must address when building M&E systems. 
These are considered essentials for building successful M&E systems for the public sector. This 
is followed by a discussion of the ten steps for building a robust WoGM&ES. 
 
ESSENTIALS OF A FUNCTIONAL WHOLE-OF-GOVERNMENT MONITORING AND 
EVALUATION SYSTEM 
The Political Aspect of Monitoring and Evaluation  
Monitoring and evaluation (M&E) issues are predominantly politically motivated. This aspect 
is usually embedded in the nature of information that M&E systems provide. Monitoring 
information and evaluation findings tend to give detailed indications of how public resources 
are being utilised. However, most implementers do not like to place such information in the 
public domain for fear of being victimised or condemned by the public and other stakeholders 
for possible misappropriation. [28] concluded that when results-based information is brought 
into the public arena, it could change the dynamics of institutional relationships, pers onal 
political agendas, planning, budgeting and resource allocations, and general public perceptions 
of government effectiveness. As a consequence of these strong and deep -rooted vested 
interests, counter-reformers may emerge in and outside government to o ppose all efforts to 
build systems for M&E.  
 
Governments need to ensure that there are strong institutional arrangements so that the M&E 
function is implemented with the expected quality. But this requires a long -term M&E system 
characterised by sustained strategising and planning. M&E systems are often considered 
threats to government officials and project managers because staff reductions, budget cuts and 
criticism from higher levels such as donors and civil society groups may arise after poor 
evaluation findings [29,30,3]. These political dynamics in the management of M&E systems, if 
not managed well, could lead to poor governance with a broken -down public accou ntability 
system allowing vices such as corruption and misapplication of resources. As a result, 
developing countries have to address this aspect if their WoGM&ESs are to function well 
[37,32]. 
 
The Technical Aspect of Monitoring and Evaluation  
The te chnical issues surrounding the functionality of M&E systems are crucial aspects that 
require good care by governments and organisations. The areas of concern when designing and 
building an M&E system include producing relevant, trustworthy and timely information about 
the performance of government projects, programmes, and policies. Relevant and adequate 
institutional capacities and skills are also significant in determining a well -performing M&E 
system. For instance, capacities of successful and comprehens ive construction and utilisation 
of performance indicators denote an important competence [28,27].
<<<PAGE=5>>>
374 
Vol. 10, Issue 12, December-2023 Advances in Social Sciences Research Journal (ASSRJ) 
Services for Science and Education – United Kingdom 
Consequently, governments should have well -trained employees who are able to carry out 
these functions effectively. For many developing countries, this may  be a challenge, but 
governments need to invest significantly in these areas to ensure M&E responsibilities are 
handled by technically qualified civil servants. [65] cautions that failure to have in place 
technically skilled managers and government officer s in building successful national M&E 
systems that are credible and trustworthy to bring high-quality information is a challenge.  
 
Ownership of Monitoring and Evaluation Systems 
The incapability of developing countries to build and sustain their own  M&E systems is 
probably the leading factor in creating institutions and systems that promote good governance 
and poverty reduction [60,42,15] . There are notable levels of satisfaction from among 
development actors around the globe that control and ownersh ip of M&E systems by 
governments themselves would provide stable and sustainable enjoyment of the benefits 
offered by such systems [24,23]. But the reality is that many poor countries rely on donor 
support to conduct M&E functions and build M&E systems. It is even more problematic because 
these countries borrow almost every aspect of M&E from the developed countries [28]. This is 
not to say it is unnecessary to seek improved ways of building M&E systems, but the challenge 
concerns the dependence that poor countries have given themselves to developed nations. 
 
 “Countries in the developing world often look to the richest countries, the members of the 
OECD, and adopt the public sector management tools that these countries typically employ, 
such as M&E and performance budgeting” [36]. This situation is obviously going to lead to more 
problems regarding the sustainability of these M&E systems in developing countries. As a 
better and more sustainable alternative, [28] contend that developing countries first need t o 
create greater demand for M&E information and to utilise it proactively to inform policy and 
decision-making processes. Through such use of M&E, these countries would then inculcate a 
culture of building and strengthening their own results -based M&E syst ems in their 
institutions, and this would lead to stronger ownership of these systems. This will be 
unavoidable because the experience of creating these M&E systems would differ in dynamics 
and scope between the developing countries and their counterparts in the developed countries, 
despite the practical lessons that could be drawn from successfully implemented systems in 
developed countries [39,59].  
 
TEN STEPS FOR BUILDING A WHOLE-OF-GOVERNMENT MONITORING AND EVALUATION 
SYSTEM 
The work that goes into building and sustaining a functional WoGM&ES is immense and long 
term in nature. The clear steps on how to build such systems are still matters of debate among 
practitioners because countries are at different stages of developing M&E systems. However, 
M&E practitio ners and experts in the field have elaborated stages that are crucial to 
developing functional M&E systems. It is therefore important in this research study to bring 
out the general aspects that comprise steps towards building and sustaining a country’s 
WoGM&ES. When assessing and analysing Zambia’s WoGM&ES, appreciating the stages the 
system has undergone or requires to undergo becomes significant. [28] have elaborated a 
classical ten-step process to consider when building a national M&E system for governm ents. 
Figure 1 below elaborates.
<<<PAGE=6>>>
375 
Kanyamuna, V., Simui, F., Mubita, A., & Musanda, P. (2023). Essentials of Functional Whole -of-Government Monitoring and Evaluation Systems: 
The Zambian Case. Advances in Social Sciences Research Journal, 10(12). 370-383. 
URL: http://dx.doi.org/10.14738/assrj.1012.16130 
This paper therefore adopts the ten steps and uses them to establish a basis for understanding 
the process of building and sustaining a successful WoGM&ES for Zambia’s public sector.  
 
 
Figure 4.1: Ten generic steps for building a country monitoring and evaluation system 
Source: Kusek and Rist, 2004, p.39 
 
Step 1: Conducting a Readiness Assessment  
A readiness assessment is the first critical aspect that needs to be considered when building 
any strong and sustainable M&E system [28,53]. Likened to the construction of a building, the 
readiness assessment stag e represents an important part, beneath the ground, not seen, yet 
critical in holding all that is above it. The focus of this stage is on undertaking a thorough 
assessment of a country’s current status in terms of understanding, capacity, and use of existing 
M&E arrangements. The readiness assessment is therefore the analytical framework on which 
the holistic status of a country’s M&E capacity is determined and a plan for improvement is 
drawn and implemented [34,65]. Therefore, the undertaking of a r1eadiness assessment is not 
intended to examine whether a country may develop a WoGM&ES, but to assess the current 
status of that country’s M&E arrangements.  
 
To that extent, a readiness assessment usually considers such aspects as existing 
organisational, political, policy, legislation and cultural factors and  contexts. In other words, a 
readiness assessment addresses issues such as whether M&E champions were present, the 
barriers threatening the creation and building of M&E systems, ownership issues and who was 
likely to oppose the systems [18,56]. For [3], these complexities and nuances of the wider 
country contexts are usually ignored, yet are critical for the rest of the preceding stages. Hence, 
[28] observe that many approaches recommend governments and organisations to go straight 
into building systems for M&E, disregarding the critical step of readiness assessment. Thus, 
without first taking stock of what is working and what is not leads many development agencies 
into building systems that fail to give expe cted information, thereby becoming redundant and 
unsustainable in the long run [34,63,64,33,49]. 
 
Further, the readiness assessment step is explicit in what it aims to achieve. This stage advances 
a strong argument against most experts, who look only at the ‘what’ questions: for instance, 
what are the goals? What are the indicators? Such experts forsake the critical ‘why’ questions, 
for example, why do we want to measure something? Why is there a need in a particular country 
to think about these issues? Why do we want to embark on building sustainable results -based 
M&E systems? It is because of these pertinent ‘why’ questions on which the readiness
<<<PAGE=7>>>
376 
Vol. 10, Issue 12, December-2023 Advances in Social Sciences Research Journal (ASSRJ) 
Services for Science and Education – United Kingdom 
assessment step is premised [28]. There is more work to actualise this kind of objective, yet the 
results of such efforts are key to the development of a successful results -based M&E system 
[28,63,12,13]. 
 
Step 2: Agreeing on Outcomes to Monitor and Evaluate  
Governments implement develop ment interventions with the aim of achieving results that 
influence citizens’ living standards positively. Otherwise, without being certain of the intended 
outcomes, government efforts would not be challenged for quality assurance by stakeholders. 
In Alice’s Adventures in Wonderland, Lewis Carroll (1865) stated: ‘If you do not know where you 
are going, any road will take you there’ [1]. Step 2 builds on the first and assumes that a country 
or organisation is in a position to move forward in building a resul ts-based M&E system. The 
second important undertaking is to agree on the outcomes so that where the country is going 
in the long term is known. 
 
For a given WoGM&ES to be built and sustained, it is essential that outcome setting is done 
appropriately. Such  results-based M&E systems are developed according to a deductive 
approach in which inputs, activities, and outputs are all derived and flow from the setting of 
outcomes and the ultimate desired impact(s). [28] add that indicators, baselines and targets 
(covered in subsequent steps), including all crucial elements of the performance framework 
are derived from and based on the setting of clear outcomes. Thus, the setting and articulation 
of outcomes first provides a good platform for designing measurable per formance indicators 
[16,26].  
 
A government, in consultation with stakeholders, thus has the task of ensuring that appropriate 
outcomes are well chosen and defined. A WoGM&ES that is developed with good outcomes has 
a high chance of collecting, analysing and providing information (feedback) that is useful to 
influence various processes for stakeholders positively [32,13].  
 
Step 3: Selecting Key Performance Indicators to Monitor Outcomes  
A successful M&E system is supposed to have a well -chosen and collectively shared set of 
performance indicators to serve as the basis for change or result measurement. ‘Indicators’ 
refer to variables that are quantitative or qualitative, simply  and reliably designed to measure 
achievement of a given intervention under implementation [28,58]. The tracking of 
performance changes is made in relation to an organisation’s stated outcomes [28,31,37]. After 
the outcomes are determined in the process of building a WoGM&ES, the next task is to choose 
and define the indicators. Essentially, indicators should be developed for all levels of a results-
based M&E system to have certainty that those indicators are in place to monitor and measure 
progress against all the elements of a results chain (that is, inputs, activities, outputs, outcomes 
and impacts). This kind of indicator tracking and measurement is critical to providing evidence-
based feedback, on which transformational improvements would be made [60,63,7].  
 
Indicator selection and definition are important requirements for a successful WoGM&ES. 
Otherwise, it becomes challenging to recognise success or achievement when it occurs. Also, 
the assurance as to whether institutional effort is leading towards a chieving outcomes is not 
certain in the absence of clearly defined indicators [28,65,53]. Governments need to be precise 
and committed to the process and type of overall and specific indicators adopted in their 
WoGM&ES [6,12].
<<<PAGE=8>>>
377 
Kanyamuna, V., Simui, F., Mubita, A., & Musanda, P. (2023). Essentials of Functional Whole -of-Government Monitoring and Evaluation Systems: 
The Zambian Case. Advances in Social Sciences Research Journal, 10(12). 370-383. 
URL: http://dx.doi.org/10.14738/assrj.1012.16130 
Step 4: Setting Baselines and Gathering Data on Indicators  
When the identification and selection of key performance indicators (KPIs) to monitor 
outcomes are done, the next crucial phase is establishing baseline data (Step 4). During this 
step, the present status of a given indicat or relative to the overall outcome is measured and 
appreciated. For [28], the significance of this stage is that no one can project progress or any 
form of performance into the future (target setting) without establishing an appropriate 
baseline. According to [23], the first measurement of an indicator is what denotes a baseline. 
Thus, this condition assists in determining or projecting future changes and upon which 
progress tracking is anchored. Therefore, by using well -measured baselines, decision makers 
and other development actors get to know about current circumstances long before they 
project targets for an intervention. In this way, setting realistic targets works for all 
development efforts, giving governments an edge in leading the process of nation building and 
inclusive development because they understand the recent levels and patterns of performance 
[47,58,22]. 
 
The process of determining the baseline starts by i) establishing or generating baseline data on 
selected indicators; ii) building inform ation for each indicator baseline; iii) identifying data 
sources for indicators; iv) designing, planning and comparing chosen data collection methods; 
v) establishing the significance of conducting pilots; and incorporating vi) data collection and 
use of lessons from successfully implemented WoGM&ES [28,21,33]. 
 
Step 5: Planning for Improvement and Setting Realistic Targets  
A target is “a specified objective that indicates the number, timing and location of that which is 
to be realized” [28]. In other word s, targets are the quantifiable and qualifiable levels of the 
indicators that a country, society or organisation wants to achieve by a given time [25,28]. The 
process of determining targets against stated indicators is another significant task for a 
successful WoGM&ES. To be precise, target setting is the final step in the process of building 
performance frameworks. Target setting follows a deductive process of breaking down the 
selected indicators into what is achievable in a specified period towards the a ttainment of a 
given outcome [9,29]. 
 
Hence, an M&E system with indicators whose targets are not well selected and defined will not 
provide credible information for use in decision making. Targets are vital for measuring 
changes against the agreed -upon ind icators throughout the process of implementing an 
intervention [63,65].  
 
Step 6: Monitoring for Results  
Step 6, monitoring for results, follows the selection of targets and completion of the 
performance-based framework. In this step, a system that ensure s that the data required to 
inform various processes of decision making are described and collated. Thus, the data from 
this system are used as evidence for performance tracking and measurement of changes for 
development interventions. The primary intentio n of this step is to appreciate requirements 
for a results -based M&E system. Such a system is understood to be necessary to inform and 
better manage all governmental and organisational resources [1,5,4]. In addition, at this stage 
it becomes significant to  acquire and critically manage all programme and project inputs, 
activities, outputs and the intermediate outcomes. [6] share this view when they emphasise 
that often development implementers use a variety of organisational tools such as inputs,
<<<PAGE=9>>>
378 
Vol. 10, Issue 12, December-2023 Advances in Social Sciences Research Journal (ASSRJ) 
Services for Science and Education – United Kingdom 
staffing p lans, budgets and activity plans. However, for this kind of management to work, a 
results-based WoGM&ES would require appropriate alignment with annual plans and other 
organisational strategies.  
 
The crucial aspects of emphasis under Step 6 include: i) id entifying key monitoring types and 
levels; ii) providing linkages between implementation -monitoring and results-monitoring; iii) 
incorporating key principles in building an M&E system; iv) identifying the needs of every 
system for M&E; v) taking into accou nt the data quality triangle; vi) performing data analysis; 
vii) attaining results using partnership; and viii) conducting pre -tests for data collection 
instruments [28]. 
 
Step 7: Evaluative Information to Support Decision Making and Results Culture  
In the previous steps, the focus was on ‘monitoring’, and not on ‘evaluation’. The emphasis was 
on articulating the need to organise a robust M&E system that could provide continuous 
tracking of performance to help managers administer their duties informatively  [7-11]. 
However, since monitoring data do not provide the basis for ascribing causality and 
attributions for change, evaluation findings become critical to bridge this gap. [46] defined 
evaluation as an assessment of a planned, ongoing or a completed inte rvention with a view to 
determining its relevance, effectiveness, efficiency, impact, and sustainability. The 
incorporation of lessons learned into decision -making processes is the major intention of 
commissioning and undertaking evaluations for developmen t interventions. Thus, it is now 
appropriate to examine the evaluation function in M&E systems. The emphasis should be on 
the complementarity of evaluation to monitoring exercises. Therefore, as complementary and 
methodologically different undertakings, it is important that governments that should seek to 
develop their results-based WoGM&ES should attend fully to both monitoring and evaluation. 
More importantly, these systems need to be built with a known intention, that of obtaining 
evidence-based evaluati on findings and information for use by government officials and 
partners on informing decisions such as those pertaining to public resource management [28, 
14, 19-22].  
 
Step 8: Analysing and Reporting Findings  
“Reporting is too often the step to which evaluators give the least thought” [28]. To that extent, 
analysis and reporting ensure that performance information, which is derived from monitoring 
and evaluation, is utilised as a tool for management. The underta king and commitment to in -
depth analysis and reporting performance findings is supposed to be given prominence since 
they determine a number of success factors, such as the content of reports, periods of reporting, 
and the targeted audience for disseminating the reports. In addition, the technical capacities of 
government and organisations are assessed based on the methodological dimensions of 
gathering, assessing, analysing and reporting [65,26,25]. Aspects of focus under Step 8 include: 
i) utilisation o f monitoring information and evaluation findings; ii) identifying the audiences 
and providing them with appropriate information; iii) presenting performance data in a non -
technical and understandable format; and iv) managing poor performance results 
appropriately [28,31]. 
 
Step 9: Using the Findings  
The fundamental aim of building and sustaining a stronger WoGM&ES is to utilise the results 
and findings generated from it. Such results -based M&E systems are crucial to performance
<<<PAGE=10>>>
379 
Kanyamuna, V., Simui, F., Mubita, A., & Musanda, P. (2023). Essentials of Functional Whole -of-Government Monitoring and Evaluation Systems: 
The Zambian Case. Advances in Social Sciences Research Journal, 10(12). 370-383. 
URL: http://dx.doi.org/10.14738/assrj.1012.16130 
improvement by development a gencies, including governments. Organisations and 
governments endeavour to create M&E systems not only to produce continuous results -based 
data and information, but ultimately to have those results and feedback in the domains of 
appropriate users in a timely manner to inform public management processes [28,35,38,40,41]. 
In summary, therefore, the focus of Step 9 is on: i) the way in which performance findings are 
used; ii) the added benefits of utilising the findings: and iii) the availability of strategie s for 
information sharing [43-45].  
 
Step 10: Sustaining the Monitoring and Evaluation System Within Government  
Step 10 is the final stage of the model and has to do with sustaining the WoGM&ES. The 
emphasis is that instead of being regarded as short-term undertakings, M&E systems should be 
seen as long -term efforts [50,51]. Thus, sustaining such systems in governments and 
organisations recognises the long-term process involved in ensuring M&E data and information 
uptake. Of particular interest under Ste p 10 are i) six critical components of sustaining 
WoGM&ESs, which are results oriented (demand clear roles and responsibilities, trustworthy 
and credible information, accountability, capacity, incentives); ii) the role of incentives and 
disincentives; iii)  challenges in sustaining a results -based M&E system; iv) evaluation and 
validation of M&E systems and information; and v) positive cultural change experienced or 
stimulated by M&E in governments and organisations [28,54-56].  
 
CONCLUSION 
The main aim of  the paper was to provide a discussion of the essentials needed to build a 
stronger whole -of-government M&E system in general and the Zambian case in particular. 
Accordingly, it articulated the most important aspects by providing an understanding that 
M&E systems are crucial to keeping up with good governance tenets of transparency and 
accountability and inclusive and participatory sustainable development towards the 
attainment of poverty reduction and improved living standards of people. Conceptually, the 
paper highlighted elements that governments must address if their WoGM&ESs were to be 
robust, sustainable and relevant to their development processes and aspirations.  The paper 
discussed the need for governments to ensure that the supply and demand sides of their M&E 
systems were fully developed in a balanced manner. Should an M&E system have a more 
developed supply side than a demand side, it risked being redundant for non -uptake of its 
results. Another challenge involves a strengthened demand side, while  the supply side is 
weak. In such instances, stakeholders or users may continue to make decisions informed by 
information without evidence, thereby implementing failed policies, programmes and 
projects [4,58,57]. In addition, the paper cautioned that polit ical and technical issues and 
ownership of M&E systems constitute central determinants of success. The paper ends by 
listing the ten steps that are significant when building a robust WoGM&ES [28,61,44].  
 
References  
[1]. Bamberger, M. 1991. The politics of evaluation in developing countries. Evaluation and Program Planning, 
14 (1): 325–339. 
 
[2]. Bamberger, M. 2010. Institutionalising Impact Evaluation. A key element in strengthening country -led 
monitoring and evaluation systems. In M. Segone (Ed.). From Policies to Results: Developing capacities for 
country monitoring and evaluation systems. Geneva: UNICEF.
<<<PAGE=11>>>
380 
Vol. 10, Issue 12, December-2023 Advances in Social Sciences Research Journal (ASSRJ) 
Services for Science and Education – United Kingdom 
[3]. Bedi, T., Coudouel, A., Cox, M., Goldstein, M. & Thornton, N. 2006. Beyond the numbers: Understanding the 
institutions for monitoring poverty reduction strategies. The World Bank.Washington, D.C.  
 
[4]. Booth, D. & Lucas, H. 2002. Good Practice in the Development of PRSP Indicators and Monitoring Systems, 
ODI Working Paper 172. Overseas Development Institute, London.  
 
[5]. Kanyamuna, V. & Sibalwa, G. (2023) An Investigation of Factors that Contribute to Qualified External Audit 
Reports at The University of Zambia, Advances in Social Sciences Research Journal 10 (1), 279-301.  
 
[6]. Booth, D. 2005. Missing links in the politics of development: Learning from the PRSP experiment, ODI 
Working Paper No. 256. Overseas Development Institute, London.  
 
[7]. Kanyamuna, V. & Kone, Y, D, Z. (2022) Reforming the Public Financial Management System for Better 
Performance Budgeting in Ivory Coast, Advances in Social Sciences Research Journal, 9 (8), 101-121.  
 
[8]. Briceno, B. 2010. Defining the Type of M&E system: Clients, Intended uses and actual utilisation. Prem 
Notes, Special series on the Nuts and Bolts of M&E systems. The World Bank, Washington, D.C.  
 
[9]. Brushett, S. 1998. Evaluation Capacity Development in Zimbabwe: Issues and Opportunities. OED, World 
Bank, Washington, D.C.  
 
[10]. Zulu, K., Kanyamuna, Chunga, C.K. & Simenti-Phiri, E. (2023) The Changing Paradigms of Zambia’s National 
Development Planning: An Enigma or A Necessity? World Journal of Social Sciences and Humanities, 9 (1), 
34-47.  
 
[11]. Burdescu, R., Villar, A., Mackay, K., Rojas, F. & Saavedra, J. 2005. Ins titutionalizing Monitoring and 
Evaluation Systems: Five experiences from Latin America. Prem Notes, The World Bank, Washington, D.C.  
 
[12]. Castro, M. F. 2009. Insider Insights: Building a Results-Based Management and Evaluation System in 
Colombia. ECD Working Paper 18, The World Bank, Washington, D.C.  
 
[13]. Castro, M.F., Lopez-Acevado, G., Busjeet, G.B. & Ardonez, X.F. 2009. Mexico's M&E System: Scaling up from 
the sectoral to the National Level. Evaluation Capacity Development. IEG. The Word Bank, Washington, 
D.C. 
 
[14]. Banda, S., Chanda, J. & Kanyamuna, V. (2022) African Parliaments Systems of Evidence in Practice- 
Zambia: Parliamentary Institutions and Implications for Evidence Use .  
 
[15]. Development Bank of Southern Africa. 2000. Selected Proceedings from a Seminar and workshop 
organised by the Development Bank of Southern Africa, the African Development Bank and t he World 
Bank on Monitoring and Evaluation Capacity Development in Africa. In Monitoring and Evaluation 
Capacity in Africa (pp. 25–29). Johannesburg, South Africa: African Development Bank and the World 
Bank.  
 
[16].  Engela, R. & Ajam, T. 2010. Evaluation Capacity Development: Implementing a Government-Wide 
Monitoring and Evaluation System in South Africa, Working Paper Series No. 21 No. 21. OED, The World 
Bank, Washington, D.C.  
 
[17]. Feinstein, O. & Zapico-Goñi, E. 2010. Evaluation of Government Performance and Publi c Policies in Spain. 
ECD Working Paper No. 22. The World Bank, Washington, D.C.  
 
[18]. Görgens, M. & Kusek, J. 2009. Making Monitoring and Evaluation Systems Work: A Capacity Development 
Toolkit. IBRD World Bank, Washington DC. 
 
[19]. Bwanga, C., Kanyamuna, V. & Qutieshat, A. (2023) Effect of Leadership and Performance Management on 
Public Service Delivery in Zambia, World Journal of Social Sciences and Humanities, 9 (2), 48-56.
<<<PAGE=12>>>
381 
Kanyamuna, V., Simui, F., Mubita, A., & Musanda, P. (2023). Essentials of Functional Whole -of-Government Monitoring and Evaluation Systems: 
The Zambian Case. Advances in Social Sciences Research Journal, 10(12). 370-383. 
URL: http://dx.doi.org/10.14738/assrj.1012.16130 
[20]. GRZ. Ministry of National Development Planning. 2016. 2015 Annual Progress Report for the Revised 
Sixth National Development Plan 2013-2016: People Centred Economic Growth and Development. 
Lusaka: Ministry of National Development Planning. 
 
[21]. Harry, H. 2010. Key steps in Designing and Implementing a Monitoring and Evaluation Process for 
Individual Country Service Agencies. Prem Notes, Special series on the Nuts and Bolts of M&E sys tems. 
The World Bank, Washington, D.C. 
 
[22]. Hwang, H. 2014. Building Monitoring and Evaluation Capacity in young systems: The experiences of 
Rwanda, Vietnam and Yemen. The World Bank, Washington, D.C.  
 
[23]. Kanyamuna, V. 2013. Sector Monitoring and Evaluation Syst ems in the context of Poverty Reduction 
Strategies: A comparative case study of Zambia’s Health and Agriculture sectors. MSc –dissertation, 
University of Antwerp, Antwerp, Belgium. 
 
[24]. Kanyamuna, V., Mubita, A., Ng’andu, E., Mizinga, C. & Mwale, A. 2018. An Ass essment of the Demand-Side 
of the Monitoring and Evaluation System of the Health Sector in Zambia. World Journal of Social Sciences 
and Humanities, 4(2): 75–86. 
 
[25]. Karel, V. & Holvoet, H. 2000. Glossary of selected Monitoring and Evaluation Methods and Mechan isms. 
University of Antwerp, Antwerpen. 
 
[26]. Kumar, K. & Casley, D. J. 1988. The Collection, Analysis and use of Monitoring and Evaluation Data. The 
World Bank, Washington, D.C.  
 
[27]. Kusek, J. Z. & Rist, R. C. 2002. Building Results-Based Monitoring and Evaluation Systems: Assessing 
Developing Countries Readiness. Zeitschrift Für Evaluation, 1 (1): 151 –158. 
 
[28]. Kusek, J. Z. & Rist, R. C. 2004. Ten Steps to a Results-Based Monitoring and Evaluation Systems. A 
Handbook for Development Practitioners. The World Bank. Washin gton D.C. 
 
[29]. Lahey, R. 2010. The Canadian M&E system: Lessons Learned from 30 years of Development, ECD Working 
Paper No. 23. The World Bank, Washington, D.C.  
 
[30]. Lahey, R. 2011. The Canadian Monitoring and Evaluation System. Prem Notes, Special series on the Nuts 
and Bolts of M&E systems. The World Bank, Washington, D.C.  
 
[31]. Kanyamuna, V., Siamabele, B., Phiri, M., Mubita, A., & Kalonje, V. (2023). Planning, Monitoring and 
Evaluation Arrangements in Zambia’s Public Sector: Shifting Sands or a Solid Rock? Advances in Social 
Sciences Research Journal, 10(11), 382–413. https://doi.org/10.14738/assrj.1011.15905 
 
[32]. Leiderer, S. 2013. Donor coordination for effective government policies? Implementation of the new aid 
effectiveness agenda in health and education in Zambia. United Nations University.  
 
[33]. Liverani, A. & Lundgren, H. E. 2007. Evaluation Systems in Development Aid Agencies: An Analysis of DAC 
Peer Reviews 1996-2004. Evaluation, 13(2): 241–256. 
 
[34]. Mackay, K. 1999. Evaluation Capacity Development: A Diagnostic Guide and Action Framework, ECD 
Working Paper Series No. 6. The World Bank, Washington, D.C.  
 
[35]. Kanyamuna, V., Siakalima, S., Phiri-Mumba, R. & Munsanda, P. (2022) Understanding Research Methods in 
Development Context: A Synthesis Paper on Research in Development Aren as, Advances in Social Sciences 
Research Journal, 9 (1), 349-358. 
 
[36]. Mackay, K. 2007. How to Build M&E Systems to Support Better Government. The International Bank for 
Reconstruction and Development and World Bank. The World Bank, Washington D.C.
<<<PAGE=13>>>
382 
Vol. 10, Issue 12, December-2023 Advances in Social Sciences Research Journal (ASSRJ) 
Services for Science and Education – United Kingdom 
[37]. Mackay, K. 2011. The Australian Government’s Performance Framework, ECD Working Paper No. 25. The 
World Bank, Washington, D.C. 
 
[38]. Mackay, K. 2011. The Performance Framework of the Australian Government, 1987 –2011. OECD Journal 
on Budgeting. 
 
[39]. Mark, K. & Pfeiffer, J. 2011. Monitoring and Evaluation in the United States Government: An overview, ECD 
Working Paper No. 26. The World Bank, Washington, D.C.  
 
[40]. Zulu, K., Simenti-Phiri, E. & Kanyamuna, V., Chitembo, K. C. & Tembo, H. (2022) Application of Benefit 
Incidence Analysis (BIA) as a Tool to Evaluate Climate Action Spendi ng on Climate Smart Agriculture 
Initiatives: An Experimental Study of the Usage of BIA on Agriculture-Related Spending in Zambia, 
International Journal of Environment and Climate Change 12 (9), 23 -34.  
 
[41]. May, E., Shand, D., Mackay, K., Rojas, F. & Saavedra, J. (Eds.). 2006. Towards the Institutionalization of 
Monitoring and Evaluation Systems in Latin America and the Caribbean: Proceedings of a World Bank 
Conference. The World Bank, Washington D.C.  
 
[42]. Naidoo, I. 2010. Monitoring and Evaluation in South Africa. Many purposes, multiple systems. In M. 
Sergone (Ed.). From Policies to Results: Developing capacities for country monitoring and evaluation 
systems. New York: UNICEF: pp. 303–320. 
 
[43]. Kanyamuna, V., Mulonda, M. & Mulele, C.S. 2019. Monitoring and Evaluation Le gislation in Zambia–Gap 
Analysis. International Journal of Humanities, Art and Social Studies, 4(1): 15 -25.  
 
[44]. Naidoo, I. 2011. The role of monitoring and evaluation in promoting good governance in South Africa: A 
case study of the Department of Social Development: PhD–Thesis submitted to the Graduate School of 
Public & Development Management in fulfilment of the requirements for doctorate degree. University of 
Witwatersrand. 
 
[45]. Moyo, F., Kanyamuna, V. & Mubita, A. (2023) Role of Social Science Research in National Development: A 
Review of Relevant Literature, Advances in Social Sciences Research Journal 10 (6), 42-76 
 
[46]. OECD/DAC. 2010. 2008 Survey on Monitoring the Paris Declaration: Effective Aid by 2010? What it will 
take - Vol. 1 Overview. Paris.OECD Publications. 
 
[47]. Ongevalle, J. V., Huyse, H. & Boutylkova, E. 2012. Dealing with Complexity through ‘act or focused’ 
Planning, Monitoring and Evaluation (PME): From Results -Based Management towards Results-Based 
Learning. PSO, Leuven: PSO, Leuven. 
 
[48]. Porter, S. 2012. ‘The Growing Demand for Monitoring and Evaluation in Africa’, in Centre for Learning on 
Evaluation and Results CLEAR (ed.), African Monitoring and Evaluation Systems: Exploratory Case Studies 
(Johannesburg: University of the Witwatersrand). 
 
[49]. Segone, M. (Ed.). 2008. Bridging the gap: The role of Monitoring and Evaluation in evidence -based policy-
making. UNICEF, Geneva. 
 
[50]. Siakalima, S. & Kanyamuna, V. (2022) Community Schooling System in Zambia: Its Evolution and 
Stakeholder Perspectives, American Journal of Educational Research, 10 (9), 571-578.  
 
[51]. Kanyamuna, V., Chawapiwa, O. & Bwanga, C. (2023) The Effectiveness of Service Delivery in Fast Moving 
Consumer Goods Supply Value Chain: A Case Study of Brands Africa Zambia Limited Company , Advances in 
Social Sciences Research Journal, 10 (2), 420- 446. 
 
[52]. Segone, M. (Ed), 2010. From policies to results. Developing capacities for country monitoring and 
evaluation systems. UNICEF, DevInfo, IDEAS, ILO, IOCE, UNDP, UNIFEM, WFP and World Bank.
<<<PAGE=14>>>
383 
Kanyamuna, V., Simui, F., Mubita, A., & Musanda, P. (2023). Essentials of Functional Whole -of-Government Monitoring and Evaluation Systems: 
The Zambian Case. Advances in Social Sciences Research Journal, 10(12). 370-383. 
URL: http://dx.doi.org/10.14738/assrj.1012.16130 
[53]. Shepherd, G. 2011. Conducting Diagnosis of M&E systems and Capacities. Prem Notes, Special series on 
the Nuts and Bolts of M&E systems. The World Bank, Washington, D.C.  
 
[54]. Kanyamuna, V., KONE, Y, D, Z. & Mubita, A. (2022) Linking Budget and Policies: The Case of Ivory Coast, 
Advances in Social Sciences Research Journal, 9 (4), 244-266. 
 
[55]. Stern, E., Stame, N., Mayne, J., Forss, K., Davies, R. & Befani, B. 2012. Broadening the Range Designs and 
Methods for Impact Evaluations: Report of a study Commissioned by the Departments for International 
Development, Working Paper 38. DFID, United Kingdom. 
 
[56]. Talbot, C. 2010. Performance in Government: The evolving system of Performance and Evaluation 
Measurement, Monitoring and Management in the United Kingdom, ECD Working Paper No. 24. The 
World Bank, Washington, D.C.  
 
[57]. UNDP. 2002. Handbook on Monitoring and Evaluating for Results. UNDP Evaluation Office, New York. 
 
[58]. Kanyamuna, V., KONE, Y, D, Z. & Mubita, A. (2022) Evaluation of Budget Execution Process in Ivory Coast, 
International Journal of Humanities and Social Science Invention, (IJHSSI) 11 (5), 36-49 
 
[59]. Wong, C. 2012. Toward Building Performance – Oriented Management in China: The critical role of 
Monitoring and Evaluation and the Long Road Ahead (ECD Working Paper No. 27). The World Bank, 
Washington D.C.  
 
[60]. World Bank. 1996. Monitoring and Evaluation Guidelines for World Bank – GEF International Waters 
Projects. The World Bank, Washington, D.C.  
 
[61]. Phiri, M., Lemba., Chomba, M.C. & Kanyamuna, V. (2022) Examining differentials in HIV transmission risk 
behaviour and its associated factors among men in Southern African countries , Humanities and Social 
Sciences Communications, 9 (295), 1-12.  
 
[62]. World Bank. 1996. Monitoring and Evaluation Guidelines for World Bank –GEF International Water 
Projects. International Water Series. The World Bank, Washington, D.C.  
 
[63]. World Bank. 2003. A User’s Guide to Poverty and Social Impact Analysis, Poverty Reduction Group. The 
World Bank, Washington, D.C 
 
[64]. World Bank. 2003. A user’s guide to poverty and social impact analysis: The World Bank, Poverty 
Reduction Group (PRMPR) and Social Development Department (SDV). The World Bank, Washing ton D.C. 
 
[65]. World Bank. 2012. Designing a Results Framework for achieving Results: A How -To-Guide. IEG, 
Washington, DC. 
 
[66]. Republic of South Africa. 2008. Basic Concepts in Monitoring and Evaluation. Public Service Commission, 
Pretoria, South Africa.