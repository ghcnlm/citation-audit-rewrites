<<<PAGE=1>>>
www.twendembele.org
How to Establish a 
National 
Evaluation System
GUIDELINE
6 DECEMBER 2021
<<<PAGE=2>>>
1 
 
 
Twende Mbele: Using M&E to improve performance and accountability of African governments. 
Hosted by the University of Witwatersrand, Johannesburg, South Africa 
www.twendembele.org  / @TwendeMnE 
  1    1  GUIDELINE: HOW TO ESTABLISH A NATIONAL EVALUATION SYSTEM 
 
Addressed to African governments who are considering establishing  a national  evaluation 
system (NES). Development partners interested in supporting a NES.  
Purpose The purpose of this Guideline is to give practical guidance on how to develop 
a national evaluation system.  
Contact person 
for this guideline 
Cara Waller, Programme Manager 
E-mail: information@twendembele.org.za 
 
 
Contents 
1
 Introduction .......................................................................................................................... 2 
2 Purpose of the guideline ........................................................................................................ 2 
3  What is meant by evaluation? ............................................................................................... 2 
3.1 What is evaluation? ............................................................................................................... 2 
3.2 What is meant by an evaluation system? .............................................................................. 3 
3.3 And what is a National Evaluation System? .......................................................................... 3 
4 Why is it important to have an NES ........................................................................................ 4 
5 When is a NES relevant .......................................................................................................... 4 
6 What can be the components of a NES .................................................................................. 5 
7 Diagnosing the situation and how a NES may be relevant ...................................................... 7 
8 Approach to establishing a NES .............................................................................................. 8 
9 Phases in establishing a NES .................................................................................................. 8 
9.1 Implementing a NES - example of Benin ............................................................................... 8 
9.2 Implementing a NES - example of South Africa ................................................................... 10 
9.3 Moving towards a NES – example of Ghana ....................................................................... 11 
9.4 Examples of challenges in the establishment of NESs ................................................................ 12 
9.5 Suggested phasing for a country planning a NES ................................................................ 14 
10 Critical success factors ......................................................................................................... 15 
11 Basic conditions for establishing a NES ................................................................................ 17 
Annexes ....................................................................................................................................... 18 
Annex 1: References .................................................................................................................. 18 
Annex 2:  M&E System Analysis tool (MESA) .............................................................................. 20 
Twende Mbele Guideline No 1 
How to establish a National Evaluation 
System 
 
 
Created 6 December 2021 
Updated
<<<PAGE=3>>>
1 
 
 
Twende Mbele: Using M&E to improve performance and accountability of African governments. 
Hosted by the University of Witwatersrand, Johannesburg, South Africa 
www.twendembele.org  / @TwendeMnE 
  2    2  GUIDELINE: HOW TO ESTABLISH A NATIONAL EVALUATION SYSTEM 
1 Introduction  
 
Twende Mbele supports African governments to learn from each other and use monitoring and 
evaluation (M&E) to improve government performance and accountability. Evaluation in particular 
seeks to understand whether interventions are working and why and how to improve them. 
Evaluation systems seek to embed evaluations into a permanent system where evaluations are 
undertaken and used. A national evaluation system (sometimes referred to as an ecosystem) is one 
where this is established for the country as a whole.  
 
This guideline seeks to help countries who are thinking of establishing a national evaluation system  
(NES) and suggests the minimum requirements for doing so . At present in Africa there are three 
countries with  established NESs, Benin, Uganda and South Africa. These systems are outlined in  
Goldman et al., (2018) . This guideline draws from the experience of the three countries and more 
widely, drawing on authors from those countries
1. 
 
The g
uideline covers what an evaluation system is (section 3), why it is important (section 4), when it 
is relevant  (section 5), the components of a NES  (section 6), diagnosing the situation prior to 
establishing a NES (section 7), the approach to establishing a NES (section 8), phases in establishing a 
NES (section 9), critical success factors (section 10) and the basic conditions needed (section 11). 
2 Purpose of the guideline 
 
The purpose of the guideline is to provide practical guidance for governments in Africa on establishing 
a NES. It links to other resources which can assist governments and their development partners in this 
endeavour. 
3  What is meant by evaluation? 
 
3.1 What is evaluation? 
 
“Evaluation is an applied inquiry process for collecting and synthesising evidence that culminates in 
conclusions about the state of affairs, value, merit, worth, significance, or quality of a programme, 
product, person, policy, proposal, or plan. Conclusions made in evaluations encompass both an 
empirical aspect (that something is the case) and a normative aspect (judgement about the value of 
something). The fact that evaluation measures the merit or worth of something distinguishes 
evaluation from other types of inquiry, such as basic science research, clinical epidemiology, 
investigate journalism, or public polling.” (Fournier, 2005: 140). Scriven (1996) suggests  that 
evaluation focuses on three key questions: What? So what? Now what?”. ‘What’ explains wh at 
happened in the implementation process of a programme, project or policy; while ‘so what’ 
determines what the findings mean, and why they happened. ‘Now what’ is concerned with providing 
recommendations based on the findings? (Patton, 2012:3).  The purp ose of evaluation is to elicit 
evidence that is reliable and can be used for decision making and improvement of interventions e.g. 
policies, strategies, and projects. A utilisation focus of evaluation is key as it allows for sound evidence, 
learning, transparency and accountability to inform decision making (European Commission, 2015).  
 
                                                            
1 Contributors to the guideline include Ian Goldman, Takunda Chirau, Aloyce Ratemo, Cara Waller, Thokozile 
Masangu, Stanley Ntakumba, Abdoulaye Gounou, Nana Opare-Djan, Kwabena Agyei Boakye.
<<<PAGE=4>>>
1 
 
 
Twende Mbele: Using M&E to improve performance and accountability of African governments. 
Hosted by the University of Witwatersrand, Johannesburg, South Africa 
www.twendembele.org  / @TwendeMnE 
  3    3  GUIDELINE: HOW TO ESTABLISH A NATIONAL EVALUATION SYSTEM 
Evaluations can apply to specific public policies  (e.g. understanding drivers of COVID -19 vaccination 
hesitancy), programmes (e.g. public employment schemes), projects ( e.g. sanitation infrastructure 
projects) or systems e.g. government coordination systems. 
 
3.2 What is meant by an evaluation system? 
 
Arnold and Wade (2015) define a system as an interdependent group of items forming a unified whole. 
Each element of a system is unique but contributes to the ultimate purpose of the whole, and there 
is no single element that has monopoly over the other.  
 
An evaluation system is “ one in which evaluation is a regular part of the life cycle of public polic ies 
and programmes ….. conducted in a methodologically rigorous and systematic manner in which its 
results are used by political decision-makers and managers, and those results are also made available 
to the public”. (Lá zaro, 2015) . In other  words, evaluation systems are permanent frameworks, 
processes and cultures that institutionalise and standardises evaluation (Furubo & Sandahl, 2002). 
There are certain characteristics of an evaluation system which include but are not limited to: 
presence of evaluation in the political, administrative and social discourse; existence of a common 
epistemological framework; organisational responsibility and permanency (Lazaro, 2015). Evaluation 
systems acknowledge that the system should provide sound evidence (supply) and also should possess 
individual and institutional capacity to use information (demand), and that supply and demand need 
toi= be mediated by knowledge brokers, such as government M&E Units (Goldman et al., 2021). 
 
3.3 And what is a National Evaluation System? 
 
National evaluation systems (NES) are formal processes that guide how evaluations are selected, 
implemented and utilised at a country level (Goldman et al, 2018). Formalised/informal systems  are 
recognised or not recognised through the formalisation of policy. Centrally coordinated systems have 
a central champion  who coordinate the system . Sectoral evaluation systems are systems within a 
broader system for example e ducation and health sector evaluation systems. These systems can co -
exist with each other.  
 
A NES implies that elements of the systems
2 articulate with each other through clear institutional 
roles, responsibilities and expected contributions. A well coordinated NES contribute to improved 
coordination of policy development and programme implementation using evidence. Hence a 
coordination role is a key element of the system. 
 
Wh
ile not always the case, NES commonly operate through the framework  provided by a national 
evaluation policy (NEP) which structures, systematises and institutionalises the practice of evaluation. 
A policy outlines the purpose, responsibilities and organisation for which public sector evaluators can 
carry out evaluations in a national evaluation system (Chirau,  Waller & Blaser-Mapitsa, 2018). In this 
sense, NES find their normative framework in the NEP. The presence of a national evaluation strategy 
or plan further institutionalises evaluation across the public sector. This is because evaluations will no 
longer be undertaken on an ad hoc basis (Lazaro, 2015) but in a structured and systematised manner. 
 
Institutionalisation of evaluation normally happens through a central institution which coordinates 
the practice of both monitoring and evaluation across the public sector, for example the Office of the 
Prime Minister (OPM) in Uganda, Department of Planning, Monitoring and Evaluation (DPME) in South 
Africa.   
                                                            
2 Marelize Gorgens & Jody Zall Kusek (2009) Making Monitoring and Evaluation Systems Work: A capacity 
development toolkit. The World Bank, Washington DC.
<<<PAGE=5>>>
1 
 
 
Twende Mbele: Using M&E to improve performance and accountability of African governments. 
Hosted by the University of Witwatersrand, Johannesburg, South Africa 
www.twendembele.org  / @TwendeMnE 
  4    4  GUIDELINE: HOW TO ESTABLISH A NATIONAL EVALUATION SYSTEM 
4 Why is it important to have an NES  
 
Countries face the question of the adequacy of public policy and complex socio-economic challenges 
like poverty, climate change, economic inequality, joblessness, lack of economic growth and 
corruption (so-called wicked problems). Evaluation is critical to help understand and explain policy 
and programme performance and generate evidence that can inform policy and decision-making, and 
help to improve performance and impact . In this sense it is being used for learning to improve 
performance.  Evaluation is also important in terms of accountability by government on the 
performance of its policies and programmes.   
 
Having a NES means that evaluation for both learning and accountability forms part of the public 
management process. Hence a mature NES is embedded in a system of results -based management 
and implementation of a country, which also incorporates budgeting and other accountability 
systems.   
 
In some cases NESs have been championed by development partners, including UN agencies, African 
Development Bank and the evaluation capacity development community (e.g. Twende 
Mbele/AfREA/CLEAR). However, one of the key features of the NES is that it must be government-led 
rather than donor -led and should be implemented in partnership with all key stakeholders in the 
evaluation ecosystem of that country.   
5 When is a NES relevant  
 
In general most countries start using monitoring to keep track of what their policies are supposed to 
be doing. Once monitoring systems ha ve started to take root, more in-depth  systems of M&E might 
be relevant, especially if there is a growing pool of skilled personnel within the country that can be 
drawn upon (both local and international). The next step is where evaluative questions are being asked 
such as are programmes working or not working and why, and how they can be improved. Typically 
this starts in particular sectors, often where development partners have been funding programmes. 
 
As governance systems mature, and a culture of accountability grows, governments have a need to 
provide evidence of results to parliament, citizens  or development partners. Evaluation s start to 
become more widespread, but this often happens in an ad hoc way, often driven by development 
partners.  
 
Building a national evaluation system is particularly relevant when policy makers  want to improve 
government performance, and they need to understand how to improve policies and programmes, 
and increase the impact on citizens. They have to be prepared to face failure and learn from mistakes. 
This is a big challenge and some countries are not willing to acknowledge problems.  
 
Even in the countries most advanced in evaluation in Africa there is still some way to go for a learning 
culture to become embedded.  Goldman et al., (2020) define M&E culture as “ a shared set of ideas, 
values, beliefs, and practices at an organisational level about M&E’s role, functions and practice, and 
use of the knowledge generated for managing, reporting, learning and accountability and to improve 
performance.” In Benin, Uganda and South Africa respondents to a survey conducted by Twende 
Mbele on M&E indicated that half of managers said ‘problems are never/rarely treated as an 
opportunity for learning and improvement’.  
 
if there is a budget cut you will find that some entities will first think about cutting M&E 
because don’t appreciate the importance of M&E in their work. There are some civil
<<<PAGE=6>>>
1 
 
 
Twende Mbele: Using M&E to improve performance and accountability of African governments. 
Hosted by the University of Witwatersrand, Johannesburg, South Africa 
www.twendembele.org  / @TwendeMnE 
  5    5  GUIDELINE: HOW TO ESTABLISH A NATIONAL EVALUATION SYSTEM 
servants who look at M&E function as witch -hunting and they would not like to be 
associated with such a function.” (Uganda respondent 3) 
 
Table 1 shows that o verall the value of M&E to help improve organisational performance was 
recognised by around half of managers, who are open to change, using evidence from evaluation, and 
using problems as opportunities for learning. However the other half of managers are indicating  
stringent hierarchies, closed compliance cultures and lack of appreciation of learning from experience 
by the management, which is a serious impediment to improvement.  
 
Table 1: Values and culture barriers to the effective use of evaluation in decision -making, learning 
and accountability in your department 
Are the following a barrier? % of respondents saying 
always/often in 
SA Benin Uganda 
There is no consistent demand for evaluation from ministers and management 23.1 28.2 32.0 
Time pressure means decisions are often taken without proper diagnosis of the 
problem 42.3 44.3 41.3 
Resistance from senior management to transparent decision -making 
processes 27.9 35.6 33.3 
Senior management do not champion M&E and honesty about performance 41.4 40.3 34.7 
Little respect for evidence-based decision-making in the department 27.9 30.9 34.7 
The hierarchy makes it difficult to openly and robustly discuss performance  38.5 40.3 42.7 
Managers fear admitting mistakes or problems 54.8 49.0 46.7 
Problems not treated as an opportunity for learning and improvement 40.4 45.0 46.7 
The concealing of findings is a barrier to the effective use of M&E 31.7 24.2 34.7 
Source: Goldman et al (2020). 
 
Not all governments are ready to heavily invest in a national evaluation system and for some countries 
it is neither relevant or appropriate. What is critical  for an evaluation system to take root  is that 
governments welcome findings on areas that are not working, recognising that this enables addressing 
blockages, improving implementation, and improving impacts on citizens.   
 
A country should develop a national evaluation system that is relevant to their country context, 
including recognising capacities, government openness to critiques and use of evidence, resources, 
and structure of government. For example, where there is no political support for feedback on 
government policies or programs, a government -wide evaluation system may not be appropriate. 
Similarly, in very resource constrained settings, formal evaluation systems may not be a priority for 
government spending. 
6 What can be the components of a NES  
 
Table 2 outlines the main components of the evaluation system  in Benin, Uganda and South Africa . 
This shows the range of elements in a NES ecosystem.
<<<PAGE=7>>>
1 
 
 
Twende Mbele: Using M&E to improve performance and accountability of African governments. 
Hosted by the University of Witwatersrand, Johannesburg, South Africa 
www.twendembele.org  / @TwendeMnE 
  6    6  GUIDELINE: HOW TO ESTABLISH A NATIONAL EVALUATION SYSTEM 
Table 2: Main components of the evaluation systems in Uganda, Benin and South Africa 
Component Benin Uganda South Africa 
Policy    
National evaluation 
policy 
National Evaluation 
Policy Framework, 2012 
revised 2019. 
National M&E Policy 
2013 
National Evaluation 
Policy Framework, 2011 
revised 2019. 
National evaluation plan No No Annual since 2012/13 
Other evaluation plans Strategic action plan for 
both central and 
decentralised level 
Some sectors have 
plans, eg. Health Sector 
Evaluation Plan 
All provinces and some 
departments have 
evaluation plans. 
Methodology    
Guidelines A national evaluation 
methodology guide  
 
National Evaluation 
Guidelines, 2015 
Training, reporting and 
methodological 
guidelines – approx 3 
30 guidelines and 
templates 
Organisation    
Central champion 
coordinates 
BEPPAG (moved 
between Presidency and 
Ministry of Planning) 
Office of Prime Minister DPME in Presidency 
Line ministries Have M&E units Have M&E units Have M&E units 
Decentralised levels Communes Line ministries have 
M&E Units. District-level 
M&E is within Planning 
Units 
Provincial M&E units, 
and in cities 
Capacity    
Competences Yes Yes (+ Scheme of service 
for M&E) 
Yes 
Capacity building plan Yes No (In progress) Yes  
Short courses  Yes, run through Civil 
Service College 
5+ courses developed 
now run through 
National School of 
Government 
Postgraduate courses Masters in evaluation 
run through national 
universities and two 
certificates 
Post-graduate course six 
universities  
Postgraduate courses in 
M&E and in evaluation 
Availability of local 
evaluators 
Yes Yes Yes 
Participation of actors 
outside government 
   
Parliament No formal role. 
Evaluations not sent to 
Parliament once gone to 
Cabinet 
Informal requirement 
that all evaluation 
reports go to 
parliament, after 
Cabinet 
 
No formal role. 
Evaluations sent to 
Parliament once gone to 
Cabinet 
VOPE Two exist but not really 
active 
Very active VOPE with 
close links to 
government 
Very active VOPE and 
DPME has close links 
Civil society Close participation in 
activities with 
government and 
evaluation courses 
Active member in 
National Evaluation 
Working Groups, eg. 
National M&E Technical 
No formal role. 
Participate in steering 
committees of some 
evaluations
<<<PAGE=8>>>
1 
 
 
Twende Mbele: Using M&E to improve performance and accountability of African governments. 
Hosted by the University of Witwatersrand, Johannesburg, South Africa 
www.twendembele.org  / @TwendeMnE 
  7    7  GUIDELINE: HOW TO ESTABLISH A NATIONAL EVALUATION SYSTEM 
Component Benin Uganda South Africa 
Working Group, National 
Evaluation 
Subcommittee 
Quality and use    
Evaluation standards Yes  Yes Yes. Also quality 
assessment of national 
evaluations. 
Improvement plans No No Improvement Plans. 
Follow-up 
recommendation 
implementation after 6 
months. 
Govt Annual 
Performance Review 
also used to track 
recommendations and 
use. 
For national evaluations. 
Some provinces also use. 
7 Diagnosing the situation and how a NES may be relevant  
 
A NES is part of the government-wide/country-wide monitoring and evaluation system, which should 
be an integral part of the public sector performance management system 3. As a pre -condition for 
designing and implementing a National Evaluation System (NES), it  is crucial to have a contextual 
understanding of how evaluation fits for a particular country and its government and how the system 
might develop. For example in 2020 Benin undertook an assessment to inform development of their 
system. 
 
Th
e situation analysis is conducted to understand the state of evaluation and other aspects which act 
as enablers and constraints of undertaking, institutionalising and systematising evaluation in a 
country. The table below indicates some of the steps that are key when performing a diagnostic.   
 
The Global Evaluation Initiative (GEI) has developed a Monitoring and Evaluation Systems Analysis 
(MESA) Diagnostic Tool Guidance Note which provides guidance for undertaking a M&E situation 
analysis. The guidance can be accessed here
4 and the outline of the report proposed is in Annex 2. 
Some key steps are: 
 
T
able 3: Steps in undertaking a diagnostic  
Steps  What gets done 
Getting agreement on the situation 
analysis and what should be covered 
Meeting with stakeholders including those who may be funding this 
to agree what should be covered and the methods and process, and 
partners to work with 
Possibly agreeing a steering structure 
to oversee the diagnosis and possibly 
later implementation 
Consider whether an existing structure is appropriate to play a 
steering committee role for the diagnosis. If appropriate develop a 
new structure. 
Preparation for in country fieldwork 
for the diagnosis 
Identification of local organisation or consultant and briefing or 
training. This could be a partner like a CLEAR centre, who may 
employ a local consultant.  
                                                            
3 Babete Rabie & Ian Goldman (2014) The context of evaluation management. In: Fanie Cloete, Babette Rabie 
& Christo de Coning (2014) Evaluation Management in South Africa. Sun Media, Stellenbosch.  
4 Link to be provided soon
<<<PAGE=9>>>
1 
 
 
Twende Mbele: Using M&E to improve performance and accountability of African governments. 
Hosted by the University of Witwatersrand, Johannesburg, South Africa 
www.twendembele.org  / @TwendeMnE 
  8    8  GUIDELINE: HOW TO ESTABLISH A NATIONAL EVALUATION SYSTEM 
Determine stakeholders to be 
interviewed and key documents 
Establish stakeholders to be interviewed for the situation analysis 
and key documents to be reviewed on the planning, M&E systems 
Conduct the diagnosis Data is collected using an agreed report structure and tool, like the 
GEI MESA 
Validation workshop Draft report is presented in the country to stakeholders 
 
Once the situation analysis has been conducted a plan may well be prepared for how to take forward 
the NES. 
8 Approach to establishing a NES  
 
A key question is w hat authorisation is needed to establish a system, for example a law or a policy. 
Neither Benin, Uganda nor South Africa yet have a law, although Morocco does have evaluation in the 
Constitution. It is helpful to have  some guidance but a full poli cy is not necessarily needed when 
starting a system. Key stakeholders in the system  in government and wider are shown in Table 2, and 
ideally all these stakeholders should be involved when anticipating creating a NES.  
 
A utilization-focused approach  is key for an evaluation system to have impact . Goldman & Pabari, 
(2020) point to lessons from institutionalising evidence use, including from evaluations. A co-creation 
and ownership building approach  are key, so that stakeholders own the system, and that policy 
makers are willing to use the evidence. This also points to the importance of systems being locally 
owned, and that development partners help to build national evaluation capacity, rather than just 
implementing their own systems 5. This includes findi ng ways that development partners can fund 
evaluations as well as the development of NESs, ideally creating basket funds to support the system, 
so simplifying the process for national governments.  
 
A
 reflective and action learning approach is important to establishing the system, so that the system 
does not develop by copying a system elsewhere but builds based on local realities, piloting and 
experimenting so that systems that work in the local context are tested before becoming policy. 
9 Phases in establishing a NES  
 
This section provides a picture of how different NESs were developed in Benin and South Africa, and 
the basis of moving torwards a NES in Ghana. This is to give a feel for countries considering developing 
a NES. It concludes by drawing out lessons in the phasing of establishing a NES. 
 
9.1 Implementing a NES - example of Benin6  
 
Creation of the Bureau of Policy Evaluation and Analysis (BEAP) (2007-2010) 
A Bureau of Policy Evaluation and Analysis (BEAP) was established in 2007 which later became the 
Bureau of Public Policy Evaluation (BEPP). The Bureau is mandated to conduct the whole process of 
promoting evaluation, focusing (i) on institutionalization activities,  (ii) the development of norms and 
standards in evaluation, and (III) in capacity building activities . The first evaluations were 
commissioned during this period. Some of the lessons from a 2009 evaluation are discuss ed in 
                                                            
5 A forthcoming report from the UN Evaluation Group draws out lots of lessons on how UN agencies can 
building evaluation capacity. 
6 This draws on a case study by Emmanuel David-Gnahoui for a UNEG Study on support to member states in 
implementation of NECD by UN Agencies since UN Resolution A/RES/69/237 of December 2014: Benin case 
study
<<<PAGE=10>>>
1 
 
 
Twende Mbele: Using M&E to improve performance and accountability of African governments. 
Hosted by the University of Witwatersrand, Johannesburg, South Africa 
www.twendembele.org  / @TwendeMnE 
  9    9  GUIDELINE: HOW TO ESTABLISH A NATIONAL EVALUATION SYSTEM 
Kouakonnou et al (2020). In 2010 the BEPP commissioned an  assessment of evaluation capacities in 
Benin. The situation in 2010 was as in Table 4.  
 
Table 4: Overview of evaluation capacities in Benin - 2010  
LEVEL  Component 
MACRO  
Strategic Institutional National  
Vision  Policy  Legislative framework  
Yes  No  Yes  
MESO  
Organisational Structural  
Evaluative function  Specific budget  Specific skills  
Weak  No  No  
MICRO  
Operational Technical Tools  
Professional resources  Specific training  Quality evaluations  
Weak  Weak  Weak  
 
Evaluative practice takes root (2010-2013)  
Evaluations are being commissioned and institutionalization  is happening with development of an 
evaluation quality charter, the Evaluation Policy and a National Evaluation Council . A study on 
evaluation capacity needs is conducted in 2010 (Davies and Houinsa, 2010). 
 
BEPP becomes a full-fledged ministry (2013-2015) 
BEPP becomes  the Ministry of the Evaluation of Public Policies. Evaluation is now opened  to line 
ministries, parliament and municipalities. Preparatory work for the law on the evaluation of public 
policies starts. A new inventory of evaluation capacities is undertaken. Significant progress is made as 
shown in Table 5.  
 
Strengthening evaluation (2016-2019)  
In 2018 a theory of change is made mandatory to be implemented with effect from 2020. The West 
African Capacity on Impact Evaluation (WACIE) project starts to strengthen impact evaluation capacity 
in the region (Amazou et al, 2020). By this  time m any tools are in place, including:   a s trategic 
evaluation plan; the national methodological guide for evaluation; a methodological guide for the 
development or reconstruction of the theory of change; a methodological guide for gender-sensitive 
evaluation; an e valuation database; an Evaluation Knowledge Management Platform; an evaluation 
communication strategy; control and quality assurance systems on evaluation in Benin, support for 
the Beninese Evaluation Association, development of a specialis ed master's degree in evaluation,  a 
protected budget for evaluation.   In total 21 evaluations have been conducted through the NES. 
 
Table 4: 
Overview of evaluation capacities in Benin - 2016  
LEVEL  Component  
MACRO  
Strategic Institutional National  
Vision  Policy  Legislative framework  
Yes  Yes  Yes  
MESO  
Organisational Structural  
Evaluative function  Specific budget  Specific skills  
Strong  Yes, but …  Yes  
MICRO  
Operational Technical Tools  
Professional resources  Specific training  Quality evaluations  
Average  Average  Average  
 
Developing an Act (
2020-2021) 
The requirement of a theory of change for public programmes and projects requires considerable 
work by ministries and municipal administrations to develop their theories of change. Work on the 
law is progressing. A first draft was produced in July 2021. The generalisation of the theory of change
<<<PAGE=11>>>
1 
 
 
Twende Mbele: Using M&E to improve performance and accountability of African governments. 
Hosted by the University of Witwatersrand, Johannesburg, South Africa 
www.twendembele.org  / @TwendeMnE 
  10    10  GUIDELINE: HOW TO ESTABLISH A NATIONAL EVALUATION SYSTEM 
and the potential passage of the law on the evaluation of public policies and programs are  important 
turning points in the progress of evaluation in Benin.  
 
9.2 Implementing a NES - example of South Africa 
 
The initial work on monitoring in South A frica’s post -Apartheid state was  the codifying of key 
monitoring roles  by National Treasury , initially with a system of strategic plans (SPs) and annual 
performance plans (APPs) with quarterly performance monitoring. In 2007, a Policy Framework was 
published to guide the overarching government-wide M&E System. This included the need for specific 
policy Frameworks for Programme Performance Information (FMPPI)  (developed in 2007), quality of 
statistical data (developed in 2008) , and evaluation  (only developed following the establishment of 
DPME).  Meanwhile evaluation had developed in some departments, and there was a well established 
VOPE (SAMEA) which had focused a lot on evaluation (Phillips et al., 2014).  
 
Establishment of DPME as a M&E champion (2010) 
In 2009 following national elections a new Minist ry of Performance M&E was created in 2009 in the 
Presidency and in 2010 a Department of Performance (later Planning), M&E (DPME), with a mandate 
to use monitoring and evaluation to improve the performance of government. DPME initially focused 
on planning delivery of the priority outcomes, and monitoring these, but in 2011 the pressure was on 
to develop DPME’s evaluation function and to develop the outstanding policy framework (Phillips et 
al., 2014).  
 
Developing the policy framework (2011) 
As one of the first steps in 2010-11 an audit was undertaken to find existing evaluations that could be 
used. The next  step was to develop a policy framework. In early 2011 c onsultations were held with 
departments that were already undertaking evaluations  to find out what was happening at present 
and to determine what should be the next steps . It was decided to learn from peer countries and to 
undertake a study tour  in July 2011 to middle- income countries with well established evaluation 
systems, with Mexico and Colombia  selected. The  team included the Deputy Minister, Director 
General, some DPME staff and the group that had been consulted earlier. Th e study tour was well 
organised as a learning journey and proved very powerful , with agreement reached in the team 
(including the Deputy Minister and Director General) on the type of system needed . The technical 
team met three weeks later to brai nstorm the Policy Framework , which had been edited and was 
ready for public consultation by the end of August. It was finally approved by Cabinet in November 
2011  (Goldman et al., 2015). 
 
The initial concept for an outcomes evaluation and research unit to drive the evaluation system was 
approved in September 2011  which by September 2014 had grown to 15 staff. At the same time as 
the NEPF was being developed the decision was taken to start some pilot evaluations , with the first 
pilot evaluation started in October 2011 and completed in June 2012 (on Early Childhood 
Development, ECD). What was very helpful at this stage was the presence of an evidence-based policy 
programme in the Presidency, which had funds for the audit, study tours etc, as well as technical staff 
with experience of evaluation
7 (Goldman et al., 2015). 
 
D
eveloping evaluation systems 2012-2015 
The experience was used to develop guidelines of how the system should run, e.g. developing terms 
of reference, inception phase, peer reviewers, management response, improvement plan 8. The core 
                                                            
7 https://www.facebook.com/PSPPD/  
8 The 27 guidelines and templates are available at https://evaluations.dpme.gov.za/pages/guidelines-other-
resources
<<<PAGE=12>>>
1 
 
 
Twende Mbele: Using M&E to improve performance and accountability of African governments. 
Hosted by the University of Witwatersrand, Johannesburg, South Africa 
www.twendembele.org  / @TwendeMnE 
  11    11  GUIDELINE: HOW TO ESTABLISH A NATIONAL EVALUATION SYSTEM 
team that worked on the Policy became a  cross-government Evaluation Technical Working Group 
established to support the emerging system. The 2012 and 2013 National Evaluation Plan ( NEP) was 
approved by Cabinet in June 2012, with 8 evaluations , the first of which  were commissioned in 
October 2012. The 2013– 2014 NEP was approved in November 2012 with 15 evaluations and the 
2014–2015 NEP, also with 15 evaluations, in November 2013. During 2012 work started on developing 
competences and also on evaluation standards, funded by GIZ. These eventually were used as the 
basis for a quality assessment system, and a repository of evaluations 9 (Goldman et al., 2015) . An 
evaluation of the national evaluation system was undertaken in 2016/2017 (Goldman et al., 2019). 
 
D
PME’s role under threat 2017-2019, re-emerging in 2020 
During 2017 DPME came under threat due to dynamics between government departments , a new 
director general and minister, and a possible move to close the department. Attempts to create a 
Planning/M&E Law failed to get through Cabinet. Five key staff left the evaluation unit at this point 
and evaluation stagnated . From March  2020 with th e much delayed appointment of key staff to 
replace those who had left DPME once again began to take on again its dynamic role as the champion 
for evaluation in the country. In total there have been 73 national evaluations in National Evaluations 
plans, of which 58 have been finalised. In addition there have been many provincial and departmental 
evaluations conducted
10. 
 
9.3 Moving towards a NES – example of Ghana 
 
Beginning the practice of M&E 
M&E has long been practised in the governance of Ghana. The Public Administration Restructuring 
and Development Implementation Committee (PARDIC) in the early 1980s, Civil Service Performance 
Improvement Programme (CISPIP) and the National Institutional Renewal Programme (NIRP) of the 
1990s contributed to M&E practice through capacity building . The National Development Planning 
Commission was created in 1994, including a M&E function. 
 
Developing the tools guiding M&E (2000-2016) 
Over the years public programmes funded by government or development partners have  adopted 
various approaches, methods and tools for M&E. These include the use of project appraisals, special 
audits, project-specific matrices for measuring of outputs and outcomes, commissioned mid-term and 
end-of-project evaluations. However, in practice development programmes are rarely evaluated for 
decision making and e valuation practice has been driven mainly by development partners. A formal 
monitoring and evaluation framework was introduced to track the Ghana Poverty Reduction Strategy 
1 (GPRS 1) of 2003 by the NDPC . A capacity building programmes was funded by Japanese aid (JICA) 
in 2007. A Manual was developed to guide M&E practice in 2013 which was revised in 2016, which 
combines monitoring and evaluation guidance, e.g. in data collection, but does not have specific 
evaluation guidance
11. The NDPC produced 11 Annual Progress Reports (APRs) for the years 2002 to 
2013 to review government performance and to provide policy options for discussion. All ministries 
and development agencies  now prepare M&E Plans and APRs. The NDPC  uses a checklist to review 
and provide feedback on the draft M&E Plans and APRs to ensure compliance with the key 
requirements of the M&E Guidelines and Report formats. 
 
De
velopment of a political champion for M&E – the 2010s+ 
In the 2010s a unit in the Presidency led the political championing for M&E, focusing on the priority 
initiatives of the President . In 2017 a Ministry of Monitoring and Evaluation  was created, again 
                                                            
9 https://evaluations.dpme.gov.za/evaluations.aspx  
10 Presentation by Thokozile Molaiwa, DPME, at National Evaluation Seminar, 2021. 
11 NDPC, 2016. It does have an example of evaluation TORs.
<<<PAGE=13>>>
1 
 
 
Twende Mbele: Using M&E to improve performance and accountability of African governments. 
Hosted by the University of Witwatersrand, Johannesburg, South Africa 
www.twendembele.org  / @TwendeMnE 
  12    12  GUIDELINE: HOW TO ESTABLISH A NATIONAL EVALUATION SYSTEM 
focusing on political priorities. In January 2021 the responsbilities returned to the Presidency,  under 
the Office of the President for the state. Meanwhile the NDPC continued to provide key M&E 
functions. Successive governments in Gha na have sought to institutionalise M&E practices through 
executive Instruments, legislation and rollout of a number of M&E initiatives. The development of the 
National Monitoring and Evaluation Policy can be described as a critically important milestone 
towards the strengthening of the national evaluation system and improving the demand, supply and 
management of evaluations across the different levels of government especially the sector ministries, 
departments and agencies. The initial draft was produced in 2018 (Ministry of M&E, 2019). This has a 
section on the Evaluation System, and includes:  
 
a)  A 4-year National Evaluation Plan based on the NMTDF, which includes strategic and innovative 
policies, and programmes which  must be approved by Parliament. Ministries, development 
agencies and district assemblies  are also required to prepare and implement evaluation plans 
approved by the respective governance organs.   
b) National/Regional and District  Evaluation Reports (NERs): In order to assess the progress of 
implementation and achievements of government policies and programmes, annual evaluation 
reports  that  details the performance and impacts of the interventions  as well as provide 
recommendations and options, that can enhance future design and implementation of 
government interventions.   
 
However this is yet to be presented to Cabinet for approval , and so Ghana’s system is not yet 
operational, with fragmented ev aluations being conduited, primarily funded by development 
partners. 
 
9.4  Examples of challenges in the establishment of NESs 
 
In looking at some of the challenges facing the establishment of NESs we highlight three experiences 
to learn from : Kenya and Ghana  which ha ve elements of a NES in place but not yet a functioning 
evaluation system ; and South Africa which has a system which has functioned well but suffered a 
major check from 2017-2020, and is now recovering. 
 
The challenges facing institutionalization of evaluation in Kenya 
The national M&E Directorate in the Ministry of National Treasury and Planning is the central 
champion for M&E. A national  M&E Policy is waiting for Cabinet approval, and the M&E Directorate 
are already implementing some aspects of the Policy. These include: organizing annual M&E 
conferences since 2012 to date, developed M&E Norms and Standards for the Public Sector, and 
Developed Evaluation guidelines. Once it's approved one key aspect  that  will benefit M&E in the 
Country is financing of M&E. E valuation guidelines were completed in 2020 ( Kenya Evaluation 
Guidelines, 2020). In December 2021 CLEAR Anglophone Africa (CLEAR-AA)  ran training of trainers to 
roll these out. Norms and standards have also been developed (Monitoring and Evaluation Norms and 
Standards for the Public Sector, 2020).  
 
Key challenges facing Kenya include a lack of or inadequate dedicated M&E budget for monitoring and 
evaluation of policies, programmes and project s at national and devolved levels of government. This 
has hindered the institutionalization of the M&E function in the country despite the M&E Policy 
recommending adequate resources. The M&E Policy provides for all ministries, departments, agencies 
and counties (MDACs) to have a separate budget component for M&E with adequate resources . In 
addition, all development programmes/projects are supposed to  provide budgets earmarked for 
monitoring and evaluation.  This has contributed to delay in the production of M&E information which 
is key for evidence-based decision making. The same applies to conducting evaluations , especially 
impact evaluations which require massive resources.
<<<PAGE=14>>>
1 
 
 
Twende Mbele: Using M&E to improve performance and accountability of African governments. 
Hosted by the University of Witwatersrand, Johannesburg, South Africa 
www.twendembele.org  / @TwendeMnE 
  13    13  GUIDELINE: HOW TO ESTABLISH A NATIONAL EVALUATION SYSTEM 
 
A second problem area is inadequate tec hnical M&E capacity.  Despite the Government of Kenya’s 
efforts in collaboration with partners in strengthening M&E capacities in the country, there are still 
capacity gaps. M&E trainings for both national and county government managerial and technical 
officers have not been regular and continuous as envisaged in the National M&E Policy . This can be 
attributed to inadequate funds for capacity development. These capacity challenges have in one way 
or another contributed to low supply and demand for M&E in the public sector. 
 
Kenya provides an example where there is insufficient capacity and resources  in government, but 
nevertheless sufficient to start enacting the system and implementing the Policy. There is some 
interest in government in NECD, but this needs to be strengthened to create the political will to drive 
an evaluation system. The different actors are fragmented and the elements have not yet coalesced 
effectively to support the NES. The UN agencies are working on NECD, but the collaboration on this 
could be strengthened considerably, as well as with other donors. Many donors are funding 
evaluations and these can be repurposed to build the system.  
 
Example of Ghana  
Despite the appreciation and acceptance of the need have an M&E Policy/ Strategy and the  
enthusiasm  at the conceptualisation stage, the  approval and operationalisation of the Strategy has 
encountered a number of challenges principal among which are: securing and sustaining high political 
support,  lack of  a high level political champion, inadequate resources and fragmented support by 
donors,  
 
Securing and sustaining high political support:  One of the key challenges to the development and 
implementation of the NES has been inadequate ownership and sustained political commitment.  The 
drafting of the Strategy was done within the stipulated time. However, the draft Strategy is yet to be 
submitted for Cabinet approval  as the Strategy was not considered as a priority by the political 
leadership. The situation was further exacerbated by the chan ge in government priorities due to the 
incidence of covid-19. 
 
Lack of high level champion: Although, the technocrats appreciated the value of the NES, the Ministry 
could not secure a dedicated high -level political champion to serve as an advocate and a gatekeeper 
to push and create space for open discussion on the documents as well as mobilise high-level political 
support for the Strategy.  
 
Inadequate resources and donor coordination: One of the key challenges was inadequate funding since 
most of the donor partners were not sure of the likelihood that the Strategy was going to be approved 
soon. In this regard, they were not willing to put in additional resources. Coupled with this was the 
fact that most of the financial support went into the technical components of the process but not the 
required engagements that could have created the needed e nabling environment as well as 
galvanizing leadership support for the approval and operationalisation of the policy. 
 
Inadequate awareness creation and sensitisation of relevant stakeholders: There was not enough 
awareness creation and consultation with the relevant stakeholders especially the media. The process 
focused more on the technical components of the Strategy. Not much was done in terms of sensitising 
key stakeholders including the citizenry on the relevance of the Strategy to the national development 
process.  The development of the National M&E Strategy did not take onboard the key political actors 
right at the beginning of the process. It therefore lacked political buy -in since most of the key actors 
were not aware and had not been involved in the process. 
 
Ensuring continuity across political and administrative transitions
<<<PAGE=15>>>
1 
 
 
Twende Mbele: Using M&E to improve performance and accountability of African governments. 
Hosted by the University of Witwatersrand, Johannesburg, South Africa 
www.twendembele.org  / @TwendeMnE 
  14    14  GUIDELINE: HOW TO ESTABLISH A NATIONAL EVALUATION SYSTEM 
A key challenge is maintaining the system across political and administrative transitions. Earlier it was 
mentioned that DPME in South Africa went through a significant transition from 2017-2020. Although 
the different M&E systems were well establised, rivalries across ministries, and changes in staff and 
minister led to an exodus of staff and a decline in DPME’s status and capacity, which is now recovering. 
Similarly Benin has had a series of transitions with BEPP/BEPPAG moving from different ministries, 
Presidency etc. Ghana established a National Development Planning Commission which took on M&E 
functions many years ago, a Ministry of M&E was created in 20 17 but in 2021 was absorbed into the 
Presidency. Some lessons emerge: 
 
• Make sure there are a range of champions who can carry on with evaluation.  The fact that 
there was a coalition meant that there were sector and provincial champions who carried on 
despite the problems in DPME. This helped when recovery was possible; 
• Once the system is established it is important to embed the system in legislation to 
safeguard continuity. In South Africa’s case development of legislation only started in 2017 , 
7 years after initiation of the M&E system, and in Benin in 2021. In retrospect it would have 
been ideal to do this after around 3 years, when the main systems were established and 
working; 
• Establish the links with Parliament  using evaluations, which can then be embedded in 
legislation, so that Parliament becomes a champion for evaluation. 
 
9.5 Suggested phasing for a country planning a NES  
 
Goldman & Mathe, (2014)  discuss the process elements  required for institutionalisation of M&E 
systems (see Table 6). Building on Table 6 and the country examples the following phases seem to be 
appropriate, starting wth diagnosis. 
 
Table 5: Process elements in a framework for institutionalisation of M&E (Goldman and Mathe, 
2014) 
The process  
1. A clear diagnosis of the existing situation and an understanding of where delivery must improve;  
2. The reform strategy and plan defined before the structure, so a clear policy direction with a 
commitment to results;  
3. The process should not rely on legislation and regulations to be implemented;  
4. A clear and effective implementation strategy;  
5. A talented team to drive the system and solve problems early and rigorously;  
6. The courage to rethink processes completely;  
7. Experimentation, piloting and scaling-up;  
8. A major investment in communication;  
9. Care not to over-engineer the system;  
10. Establishing the culture and capacity to analyse, learn, and use M&E evidence;  
11. Role of structural arrangements to ensure M&E objectivity and quality and reliable ministry data systems.  
  
Diagnosis – undertaking some form of situation analysis, formally or less formally, to understand what 
are the key external factors affecting the appetite for an evaluation system at this time, as well as the 
key elements of the ecosystem: an interested government champion, in the executive or parliament, 
either in the centre of government (e.g. Presidency), in a sector ministry, or in Parliament; an active 
VOPE; source of funding for evaluations and for developing elements of the evaluation system;
<<<PAGE=16>>>
1 
 
 
Twende Mbele: Using M&E to improve performance and accountability of African governments. 
Hosted by the University of Witwatersrand, Johannesburg, South Africa 
www.twendembele.org  / @TwendeMnE 
  15    15  GUIDELINE: HOW TO ESTABLISH A NATIONAL EVALUATION SYSTEM 
evaluators available in the country; training in M&E etc 12. Stakeholder mapping and engagement are 
important components of this phase. 
 
D
eveloping a concept for a system  – this could be a policy where that is essential to even start, or a 
concept to guide experimentation, prior to developing a policy. This should specify the approach (e.g. 
a utilisation-focused approach, evaluations made public), some definition of the types of evaluation 
to be considered (including rapid evaluations); outsourced or internal evaluations or a combination; 
how evaluations will be funded;  how results are made public. It should also have an implementation 
plan. 
 
Building political will to support evaluation, both from ministers and senior managers – this might 
involve exposing them to successful examples elsewhere in Africa, where Twende Mbele can be 
helpful. 
 
Establishing a capable core team to drive the process, which can be enlarged as it proves the value. 
This needs to be supported by a cross-government group to lead on the evaluation system. This means 
that the process is not just about one department but a coalition across government, and potentially 
with other allies like the VOPE, universities teaching evaluation. 
 
Piloting evaluations and using these to test out the concept for the way the system should work. In 
the process, being prepared to rethink processes from scratch for a locally relevant ‘Made in Africa’ 
approach. 
 
Making considerable efforts to communicate within the champion unit/department, with the political 
champion, with allies and across government, so that all have a clear idea of what is being attempted 
and why. Also communicating with the VOPE and universities so that a coalition is built that is wider 
than government. 
 
Developing systems incrementally, such as guidelines for phases of the evaluation process, evaluation 
types, competences and standards, improvement plan system, training courses etc. These should helo 
to build the quality and reliability of evaluations and the system. A complex system is not needed to 
start and it will get more complex with time. One core element is a national evaluation plan/agenda 
to prioritise evaluations to be supported. 
 
Implementing the system  - going through a consolidation phase where evaluations are being 
implemented, capacity to undertake and use evaluations i s built, and a culture of learning from 
evaluation starts to be established. During this phase extending the system to devolved levels can be 
undertaken, eg provinces/regions, and local government. 
 
Learning also means evaluating the system  after 5 or so years. It is good to practice what you preach 
and evaluate how well the system is working and how it can be improved. 
 
‘Freezing’ the system by embedding in legislation  – to minimise the dangers from political and 
administrative transitions once the basic model of the system is tested and known, it would be helpful 
to freeze this in legislation.
 
10 Critical success factors  
 
                                                            
12 Note the Global Evaluation Initiative is developing a M&E System Analysis tool which would be very helpful 
here.
<<<PAGE=17>>>
1 
 
 
Twende Mbele: Using M&E to improve performance and accountability of African governments. 
Hosted by the University of Witwatersrand, Johannesburg, South Africa 
www.twendembele.org  / @TwendeMnE 
  16    16  GUIDELINE: HOW TO ESTABLISH A NATIONAL EVALUATION SYSTEM 
Some key factors emerge as critical success factors, particularly drawing from the progress made in 
Benin, Uganda and S outh Africa and the slower progress in other countries and the framework for 
institutionalisation of M&E in Goldman & Mathe, (2014). Part of this framework is used in Table 7 to 
apply to establishing a NES in Africa, while the process elements are covered in Section 9. 
 
Table 6: Framework for institutionalisation of M&E (Goldman and Mathe, 2014) 
Enabling conditions  Lessons for application 
1. Key role of a 
powerful and 
capable central 
‘champion’ with 
sustained political 
will for the long 
haul and a 
coalition to 
support  
Ideally one starts with a central champion such as BEPPAG, OPM or DPME, to 
coordinate implementation of evaluations across the whole-of-government and 
whole-of-society in a joined-up government fashion.  A department/agency  that 
has dedicated skills, funding and infrastructure are critical for ensuring that 
political championing is complemented by requisite technical competence to 
run the NES. Failing this one can start with a sector champion and use this to 
demonstrate what is possible.  
Political will by government, and possibly parliament, seen in Benin, Uganda and 
South Africa.  
Buy-in of key stakeholders within decision-making authorities like political 
leadership (Cabinets), strategic management in government, VOPEs, think tanks, 
academia, civil society is crucial for ensuring that the NES functions within the 
broader evidence ecosystem. It is important to build a coalition to support the 
system including a range of ministries and possible devolved governments (e.g. 
provinces), which helps to ensure legitimacy, wider use of evaluation, and more 
resilience in the system. In Benin the was the National Evaluation Council, in 
South Africa the Evaluation Technical Working Group. 
2. Utilisation seen as 
the measure of 
‘success’ 
It is critical that a utilisation focus is used from the outset so aiming to ensure 
that evaluations are likely to be used. Key implications include building 
ownership of the evaluations by custodian departments, establishing the 
credibility of the evaluation, ensure the product is usable (e.g. the 1/5/25 page 
summary report used in South Africa), maximising the likelihood of follow-up by 
taking national evaluations to Cabinet, and having an improvement plan which is 
monitored. 
3. Substantive 
government 
demand  
There needs to be demand for evaluations from government. Ideally this would 
be from a central champion, and widely across government. If necessary one 
can start with sector champions or Parliament. Undertaking rapid evaluations or 
synthesising existing evaluations may help to build demand. It is helpful to 
codify the demand in a national evaluation plan or agenda. 
4. The importance of 
establishing 
incentives 
(including the 
ability to use hard 
and soft authority 
effectively to 
enforce change);  
Incentives are key – whether ‘carrot’s, ‘sticks’ or ‘sermons’ (Bemelmans-Videc et 
al., 1998). This means creating positive incentives (carrots) such as using 
evaluations to unblock programmes, celebrating success, enabling access to 
donor funds; sermons such as a President talking about evaluations; or sticks 
such as poor performance in evaluations requiring changes, requiring 
improvement plans from evaluations being reported on. The prevalence of a 
punitive bureaucratic culture often emphasised by audit means these have to be 
handled carefully (see Table 1). 
5. Performance 
management/M&E 
system which is 
dynamic.  
The M&E system must be able to develop to incorporate an evaluation system, 
and ideally a diversity of evaluation tools from rapid evaluations or evaluative 
workshops to rigorous implementation or impact evaluations. 
6. Continuous  
evaluation 
capacity 
development 
(ECD) 
Continuous ECD is also fundamental for ensuring that there is a critical mass of 
evaluators in society and government institutions with necessary evaluation 
systems and resources.  Key elements of ECD include training, learning-by-doing, 
knowledge sharing, coaching, mentoring, internships and learnerships.  Again, 
VOPEs and training providers like universities and consultancies play an 
important role on ECD.
<<<PAGE=18>>>
1 
 
 
Twende Mbele: Using M&E to improve performance and accountability of African governments. 
Hosted by the University of Witwatersrand, Johannesburg, South Africa 
www.twendembele.org  / @TwendeMnE 
  17    17  GUIDELINE: HOW TO ESTABLISH A NATIONAL EVALUATION SYSTEM 
 
11 Basic conditions for establishing a NES  
 
Section 9.6 talks about the suggested phasing of establishing a national evaluation system . The core 
that is needed to establish a system includes: 
 
• A driver – a core government champion to lead the process, with a small team of 2-3 people, 
which can later expand; 
• An initial concept for how the system should work (see 9.6); 
• Some availability of flexible funding , eg from development partners, which can be used to 
fund evaluations to pilot the system, and to develop elements of the system . This needs 
funders who are committed to national evaluation capacity  developmenty (NECD) and are 
prepared to implement their work in such a way that it builds local capacity and systems; 
• Political will to be prepared to face constructive criticism from evaluations , and to support 
evaluations happening, and for a system to develop.  
 
What is key is to start the journey, building on the evaluations that are happening to establish a will 
to develop and widen a system. That needs a central champion with the mandate and political 
support.
<<<PAGE=19>>>
1 
 
 
Twende Mbele: Using M&E to improve performance and accountability of African governments. 
Hosted by the University of Witwatersrand, Johannesburg, South Africa 
www.twendembele.org  / @TwendeMnE 
  18    18  GUIDELINE: HOW TO ESTABLISH A NATIONAL EVALUATION SYSTEM 
Annexes  
 
Annex 1: References 
 
Amouzou, A, Kanté, A, Koffi, A, Maïga, A, Munos, M, Walker, N and Winch, P, 2020. Regional Scoping 
Study for the West Africa Capacity Building and Impact Evaluation (WACIE) Program. 
Arnold, R.D. and  Wade, J.P , 2015. A Definition of Systems Thinking: A Systems Approach. Steven’s 
Institute, New Jersey. 
Bemelmans-Videc, M. -L., Rist, R. C., & Vedung, E. (Eds.). (1998). Carrots, sticks & sermons: Policy 
instruments and their evaluation. Transaction Publishers. 
BEPPAG, 2017. Guide Méthodologique National d’Évaluation. UNICEF. 124 pages. 
Chirau, T., Waller, C., & Blaser Mapitsa, C. 2018. The National Evaluation Policy Landscape in Africa: A 
Comparison. Available: http://wiredspace.wits.ac.za/handle/10539/28240 [Accessed 2 June 2021] 
Davies, I,  Houinsa, D, 2010. Étude diagnostique des capacités nationales en évaluation au Bénin 
European Commission (2015), Better Regulation Guidelines,  Commission Staff Working Document. 
Com (2015) 215 final. 
Fournier, D. (2005). Evaluation. In S. Mathison (Ed.), Encyclopaedia of Evaluation (pp. 139 -140).  
Thousand Oaks, CA: Sage. 
Furubo, J.-E. and R. Sandahl (2002) ‘A Diffusion Perspective on Global Developments in Evaluation’, in 
J.-E. Furubo, R. C. Rist and R. Sandahl (eds) International Atlas of Evaluation, pp. 1 –26. London: 
Transaction Publishers. 
Goldman, I., Byamugisha, A., Gounou, A., Smith, L. R., Ntakumba, S., Lubanga, T., Sossou, D., & Rot -
Munstermann, K. (2018). The emergence of government evaluation systems in Africa: The case 
of Benin, Uganda and South Africa. African Evaluation Journal, 6( 1), 11. 
https://doi.org/10.4102/aej.v6i1.253
 
Goldman, I., Deliwe, C. N., Taylor, S., Ishmail, Z., Smith, L., Masangu, T., Adams, C., Wilson, G., Fraser, 
D., Griessel, A., Waller, C., Dumisa, S., Wyatt, A., & Robertsen, J. (2019). Evaluation2 – Evaluating 
the national evaluation system in South Africa: What has been achieved in the first 5 years? 
African Evaluation Journal, 7(1). https://doi.org/10.4102/aej.v7i1.400
.  
Goldman, I., & Mathe, J. (2014). 12.8 Institutionalisation philosophy and approach underlying the 
GWM&ES in South Africa. In Evaluation Management in South Africa and Africa (1st ed., p. 22). 
Sun Press. 
Goldman, I., Mathe, J. E., Jacob, C., Hercules, A., Amisi, M., Buthelezi, T., Narsee, H., Ntakumba, S., & 
Sadan, M. (2015). Developing South Africa’s national evaluation policy and system: First lessons 
learned. African Evaluation Journal, 3(1), 9. 
Goldman, I., Olaleye,  W., Ntakumba, S., Makgaba, M., & Waller, C. (2020). Mere compliance or 
learning – M&E culture in the public service of Benin, Uganda and South Africa. In Using Evidence 
in Policy and Practice—Lessons from Africa (First). Routledge, Taylor & Francis Group. 
Goldman, I., & Pabari, M. (2020). Lessons for using evidence in policy and practice. In Using Evidence 
in Policy and Practice—Lessons from Africa (First). Routledge, Taylor & Francis Group. 
Goldman, I., Pabari, M., & Amisi, M. (2021). Enhancing the knowledge broker roles of government and 
parliamentary M&E/research units. CLEAR -AA. at 
https://www.wits.ac.za/clear-aa/supporting-
evidence-use-in-policy-and-practice/  
Kouakanou, B, Aguemon, D, Aina, M S, Gounou, A, David-Gnahoui, E.M. The potential and the 
challenges of evaluations to positively influence reforms: Working with producers in the Benin 
agricultural sector, in Goldman, I and Pabari M (eds) (2020), ‘Using Evidence in Policy and Practice 
– lessons from Africa’, available at https://www.taylorfrancis.com/books/oa-
edit/10.4324/9781003007043/using-evidence-policy-practice-ian-goldman-mine-pabari
<<<PAGE=20>>>
1 
 
 
Twende Mbele: Using M&E to improve performance and accountability of African governments. 
Hosted by the University of Witwatersrand, Johannesburg, South Africa 
www.twendembele.org  / @TwendeMnE 
  19    19  GUIDELINE: HOW TO ESTABLISH A NATIONAL EVALUATION SYSTEM 
Lázaro, B. (2015). Comparative study on the institutionalisation of evaluation in Europe and Latin 
America (Collection: Studies n. 15; Series: State of the Art Area: Public Finance). E urosocial 
Programme. 
Ministry of M&E. (2019). Draft National M&E Policy. Ministry of M&E. 
Molaiwa, T, 2021. Reflection on the National Evaluation System (NES). Presentation at National 
Evaluation Seminar, 16 November 2021. 
NDPC. (2016). NATIONAL MONITORING AND EVALUATION MANUAL. National Development Planning 
Commission. 
Patton, M. (2012). Essentials of Utilization -Focused Evaluation. In Q. P. Michael, Essentials of 
Utilization-Focused Evaluation. London: Sage. 
Phillips, S., Goldman, I., Gasa, N., Akhalwaya,  I., & Leon, B. (2014). A focus on M&E of results: An 
example from the Presidency, South Africa. Journal of Development Effectiveness, 6(4), 392–406. 
https://doi.org/10.1080/19439342.2014.966453  
Rabie, B & Ian Goldman (2014) The context of evaluation management. In: Fanie Cloete, Babette Rabie 
& Christo de Coning (2014) Evaluation Management in South Africa. Stellenbosch: Sun Media.  
Scriven, M. (1996). The Theory Behind Practical Evaluation. Evaluation, 2(4), 393-404.
<<<PAGE=21>>>
1 
 
 
Twende Mbele: Using M&E to improve performance and accountability of African governments. 
Hosted by the University of Witwatersrand, Johannesburg, South Africa 
www.twendembele.org  / @TwendeMnE 
  20    20  GUIDELINE: HOW TO ESTABLISH A NATIONAL EVALUATION SYSTEM 
Annex 2:  M&E System Analysis tool (MESA) 
 
Table 7: Structure of the MESA  
1 Introduction to the MESA 
1.1 Introduction to the MESA 
1.2 Objective of the MESA 
1.3 Methodology and process conducted 
1.4 Structure of the report 
2 Country Background  
2.1 Country Profile  
2.2 Government Structure  
2.3 Political economy and link to M&E  
2.4 Organizational culture of government and M&E  
2.5 Interest in M&E at the beginning of the MESA 
3 Overview 
of Planning, Budget and M&E systems 
(PBM&E)  
4 Monitoring and reporting systems 
  
5 Evaluation systems  
3.1 PBM&E legal and policy 
background  
3.2 Key PBM&E actors   
3.3 Planning and budget systems   
3.4 M&E systems  
3.5 M&E stakeholders (national 
statistics, audit offices, VOPEs  
3.6 Statistical and administrative data   
3.7 Resources for M&E  
3.8 Communication of M&E evidence 
3.9 M&E capacity development 
initiatives  
3.10 Equity/gender considerations in 
the PBM&E systems. 
3.11 Climate and environmental 
sustainability considerations in the 
PBM&E systems. 
4.1 Systems for government 
monitoring and reporting at 
national level   
4.2 Systems for government 
monitoring and reporting at 
subnational levels 
4.3 Monitoring of government by 
Parliament   
4.4 Government’s monitoring and 
reporting capacity  
4.5 Civil society role in government 
monitoring system   
4.6 Systems/incentives for acting 
on monitoring  
4.7 Use of monitoring information 
by government  
5.1 Evaluation at national/subnational 
levels   
5.2 Government capacity to manage and 
coordinate an evaluation   
5.3 Government capacity to manage, 
commission or undertake evaluations   
5.4 The systems/incentives for ensuring that 
evaluation is acted upon  
5.5 Capacity to undertake evaluations 
5.6 Systems/ incentives for ensuring that 
evaluation is acted upon 
5.7 Use of evaluations by government   
5.8 Use of evaluations by Parliament  
5.9 Use of evaluations by civil society and 
the media  
5.10 Role of civil society in government 
evaluation system  
6 Overall findings and conclusions  
6.1 An overview of the status of the M&E system 
6.2 Areas working well and areas for improvement  
6.3 Opportunities for interventions which are triggers for wider system change/development outcomes  
6.4 Conclusions
<<<PAGE=22>>>
www.twendembele.org
TWENDE MBELE is a multi-country peer-learning partnership centred on 
country government priorities for building national evaluation systems in an 
effort to improve government performance and accountability to citizens.
Telephone: +27 (0) 11 717 3453 | Email: info@twendembele.org
University of the Witwatersrand
2 St David’s Place, Parktown, Johannesburg
Telephone: +27 11 717 3157; Fax: +27 86 765 5860
@TwendeMnE http://www.twendembele.org
How to Establish a 
National Evaluation 
System