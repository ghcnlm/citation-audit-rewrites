<<<PAGE=1>>>
Empowered lives. 
Resilient nations. 
TOWARDS A BASELINE STUDY:  
Insights on National  
Evaluation Capacities 
in 43 Countries
Independent Evaluation Office
United Nations Development Programme
<<<PAGE=2>>>

<<<PAGE=3>>>
Independent Evaluation Office and the  
International Policy Centre for Inclusive Growth, December 2015
United Nations Development Programme
TOWARDS A BASELINE STUDY:  
Insights on National  
Evaluation Capacities  
in 43 Countries
<<<PAGE=4>>>

<<<PAGE=5>>>
iiiACKNOWLEDGEMENTS
ACKNOWLEDGEMENTS 
This baseline study is the result of a collective 
effort and collaboration of the UNDP Indepen -
dent Evaluation Office (IEO) with the Inter -
national Policy Centre for Inclusive Growth 
(IPC_IG). The study was led and managed 
by Ana Rosa Soares, IEO Evaluation Advisor, 
co-written by lead consultant Claudia Marcondes 
and inputs were provided by Livia Nogueira, 
Project Manager IPC and Silke Hofer, IEO 
Research Analyst.
IEO could not have completed this study without 
the involvement of a wide range of stakeholders  
who generously shared their time and ideas 
throughout the survey and emails exchanges with 
participants of the four previous International 
Conferences on National Evaluation Capacities 
process. We would like to especially thank the 
Governments of the forty three countries who 
were a part of this study and the UNDP staff from 
country offices for their support on this exercise. 
The quality enhancement support provided by 
IEO and IPC-IG colleagues Indran Naidoo, IEO 
Director and Diana Sawyer was also critical in 
ensuring the information was properly presented.
<<<PAGE=6>>>

<<<PAGE=7>>>
v
CONTENTS
CONTENTS
Acronyms and Abbreviations vii
NEC Commitments  xi
Executive Summary  xiii
Introduction   1
1.  Scope and Methodology 1
2.  Study Limitations 2
Country Profiles  5
1.  Africa  5
 1.1 Benin 5
 1.2 Burundi 7
 1.3 Cameroon 7
 1.4 Ethiopia 10
 1.5 Ghana 11
 1.6 Kenya 13
 1.7 Malawi 16
 1.8 Niger 17
 1.9 Nigeria 19
 1.10 South Africa 20
 1.11 Tanzania 24
 1.12 Uganda 25
2.  Arab States 27
 2.1 Egypt 27
 2.2 Lebanon 28
 2.3 Morocco 29
3.  Asia and the Pacific 31
 3.1 Afghanistan 31
 3.2 Bhutan 33
 3.3 India 34
 3.4 Indonesia 36
 3.5 Malaysia 38
 3.6 Mongolia 39
 3.7 Nepal 40
 3.8 Pakistan 43
 3.9 Sri Lanka 45
 3.10 Thailand 48
<<<PAGE=8>>>
vi
 CONTENTS
4.  Europe and the Commonwealth of Independent States 49
 4.1 Albania 49
 4.2 Kyrgyzstan 49
 4.3 Russia 51
5.  Latin America and the Caribbean  52
 5.1 Argentina 52
 5.2 Barbados 54
 5.3 Brazil 55
 5.4 Colombia 57
 5.5 Costa Rica 59
 5.6 Dominican Republic 61
 5.7 El Salvador 63
 5.8 Guatemala 64
 5.9 Honduras 66
 5.10 Jamaica 67
 5.11 Mexico 68
 5.12 Panama 70
 5.13 Saint Lucia 71
 5.14 Suriname 72
 5.15 Uruguay 73
6.  Other Global and UNDP Commitments  74
7. Final Remarks  82
Works Cited  87
Annexes
Annex 1.  43 UNDP Countries and their Commitments  97
Annex 2.  Study Framework  99
<<<PAGE=9>>>
vii
ACRONYMS AND ABBREVIATIONS
ACRONYMS AND ABBREVIATIONS
M&E Monitoring and Evaluation
NEC National Evaluation Capacities
UNDP  United Nations Development Programme
UNICEF United Nations Children`s Fund
AFRICA 
BENIN
BEPP Public Policy Evaluation Office (Bureau d’Évaluation des Politiques Publiques) 
CNE National Council of Evaluation (Conseil National de l’ Évaluation) 
CAMEROON
CaDEA Cameroon Development Evaluation Association
MINEPAT Ministry of Economy, Programming & Regional Planning  
(Ministère de l’Economie, de la Planification et du Développement Régional) 
ETHIOPIA
MoFED Ministry of Finance and Economic Development
GHANA
G-IPEN Ghana Network of Independent and Professional Evaluators 
GMEF Ghana Monitoring and Evaluation Forum 
NDPC National Development Planning Commission 
KENY A
CPPMUs Central Project Planning and Monitoring Units 
MED Monitoring and Evaluation Directorate
NIMES National Integrated M&E System
PMES Performance M&E System 
MALAWI
MGDS Malawi Growth and Development Strategy
OPC Office of the President and Cabinet 
NIGER
BEPP Public Policy Evaluation Office (Bureau d’Évaluation des Politiques Publiques) 
PDES Economic and Social Plan (Plan Economique et Social) 
INS National Institute of Statistics (Institut National de la Statistique)
ReNSE Niger Network of Monitoring and Evaluation (Réseau Nigérien de Suivi Évaluation)
<<<PAGE=10>>>
viii ACRONYMS AND ABBREVIATIONS
NIGERIA
NEA Nigeria Evaluation Association 
NPC National Planning Commission 
SOUTH AFRICA
DPME Department of Performance Monitoring and Evaluation 
NES National Evaluation System
SAMEA South African Monitoring and Evaluation Association
UGANDA
OPM Office of the Prime Minister
ARAB STATES
LEBANON
OMSAR  Office of the Minister of State for Administrative Reform
EGYPT
EREN  Egyptian Research and Evaluation Network 
EGY-EVAL Egyptian Association for National Evaluation
MOROCCO
HPC High Planning Commission (Haut-Commissariat au Plan)
ASIA
AFGHANISTAN
AfES Afghan Evaluation Society 
AMENA Afghanistan Monitoring and Evaluation National Association 
CoE Community of Evaluators (CoE) Afghanistan
GPMES Government-wide Performance Monitoring and Evaluation System 
IDLG Independent Directorate of Local Governance 
BHUTAN
EAB The Evaluation Association of Bhutan 
GNHC Gross National Happiness Commission 
NMES National Monitoring and Evaluation System 
INDIA
DESI Development Evaluation Society of India
PMES Performance Management and Evaluation System
INDONESIA
InDEC Indonesian Development Evaluation Community
<<<PAGE=11>>>
ixACRONYMS AND ABBREVIATIONS
MONGOLIA
MED Ministry of Economic Development
NEPAL
NPCS National Planning Commission Secretariat 
COE/Nepal Nepal Community of Evaluators
PAKISTAN
CoE-Pakistan Community of Evaluators Pakistan
PME Project Monitoring and Evaluation
SRI LANKA
SLEvA  Sri Lanka Evaluation Association 
THAILAND
NESDB National Economic and Social Development Board 
OPDC Office of the Public Sector Development Commission 
TEN Thailand Evaluation Network 
EUROPE AND THE COMMONWEAL TH OF INDEPENDENT STATES
RUSSIA
HSE Higher School of Economics
RIA Regulatory Impact Assessment
LATIN AMERICA AND THE CARIBBEAN
ARGENTINA
APN  National Public Administration (Administración Publica Nacional)
SISEG Integrated System of Management, Monitoring and Evaluation (Sistema Integral de 
Seguimiento y Evaluación de la Gestión)
BRAZIL
MDS Ministry of Social Development (Ministério do Desenvolvimento Social e Combate 
à Fome)
SAGI Secretariat of Evaluation and Information Management (Secretaria de Avaliação  
e Gestão da Informação)
COLOMBIA
DEPP Directorate of Evaluation of Public Policies (Dirección de Evaluación de  
Politicas Públicas)
DPN National Planning Department (Departamento Nacional de Planeación)
SINERGIA National System of Evaluation and Results-based Management (Sistema National 
de Evaluación de Gestión y Resultados
<<<PAGE=12>>>
x
 ACRONYMS AND ABBREVIATIONS
COSTA RICA
SINE National Evaluation System (Sistema National de Evaluación)
MIDEPLAN Ministry of National Planning and Economic Policy (Ministério de Planificación 
Nacional y Política Económica)
DOMINICAN REPUBLIC
MEPyD  Ministry of Economy, Planning and Development (Ministério de Economía, 
Planificación y Desarrollo)
EL SALVADOR
GPR Monitoring, Evaluation and Results-Based Management (Monitoreo, Evaluación y 
Gestión por Resultados)
SNP National Planning System (Sistema National de Planificación)
GUATEMALA
SEGEPLAN Secretariat of Planning and Budgeting of the Presidency (Secretaría de Planificación 
y Programación de la Presidencia) 
HONDURAS
REDHPRESS Honduran Network of Professionals of Planning, M&E and Systematization  
(Red Hondureña de Profesionales de Planificación, Evaluación, Seguimiento  
y Sistematización)
JAMAICA
PMES Performance Management &Evaluation System 
PMEU Performance Management & Evaluation Unit 
MEXICO
CONEVAL National Council for Evaluation of Social Development Policies (Consejo Nacional 
de Evaluación de las Políticas de Desarrollo Social)
SFP Subsecretariat of Public Function (Subsecretaria de la Función Pública)
URUGUA Y
AGEV Directorate of Management and Evaluation (Dirección de Gestión y Evaluación)
APN  National Public Administration (Administración Pública Nacional)
<<<PAGE=13>>>
xi
NEC COMMITMENTS
NEC COMMITMENTS 
 
The NEC commitments are about the following:
NATIONAL DATA SYSTEMS 
Commitment 2 (C2).  Collaborate to build 
and strengthen credible national data systems 
to improve the integrity of such systems, in 
order to better link performance of policies and  
programmes.
FOLLOW-UP ON THE IMPLEMENTATION 
OF EVALUATION RECOMMENDATIONS 
Commitment 3 (C3).  Develop systems to pro -
mote the transparent follow-up of evaluations, 
such as management response tracking systems 
and citizen’s commission that allow for effective 
monitoring of the implementation of evaluation 
recommendations.
THE INSTITUTIONAL SET-UP FOR 
EVALUATION 
Commitment 4 (C4).  Study the alternatives, 
assessing the pro and cons of different options 
of institutional set-ups, such as national evalua -
tion legislation and policies, where appropriate, 
taking the country/cultural context into account 
and establishing a set of minimum requirements 
based on lessons learned.
PEER-TO-PEER SYSTEMS
Commitment 5 (C5).  Develop/strengthen/sup-
port/expand joint peer-to-peer systems and men-
toring programmes among professional association 
of evaluators and government evaluation units.
PROMOTING THE USE OF 
EVALUATIONS
Commitment 6 (C6). Create/strengthen Parlia-
mentarians’ Forum for Development evaluation 
in different regions to advocate for use and con -
duct of evaluations. 
Commitment 7 (C7).  Facilitate partnership/
cooperation between governments, voluntary 
organizations for professional evaluation, par -
liaments and the private sector to strengthen the 
understanding about what evaluation is and how 
it can be useful for different actions.
ETHNIC AND CUL TURAL ISSUES 
Commitment 8 (C8).  Develop approaches 
based on lessons learned on how to incorporate 
cultural dimensions into evaluation in different 
regional and national contexts.
METHODOLOGIES 
Commitment 9 (C9). Develop standards, based 
on lessons learned, to ensure proper triangulation 
of evidence, checks and balances and qualitative 
data use to not be just perception-based.
STAKEHOLDER INVOLVEMENT  
(AND ACCESS TO INFORMATION) 
Commitment 10 (C10). Develop standards, 
based on lessons learned to ensure stakeholders 
involvement while still guaranteeing indepen -
dence of the evaluation.
<<<PAGE=14>>>
xii NEC COMMITMENTS
1 For further information please visit unteamworks.org/NEC.
INTEGRATED PUBLIC REGISTRIES 
Commitment 11 (C11).  Develop/connect 
national registries/national statistical systems to 
M&E systems with increased frequency of data 
collection to support decision-making.
COORDINATION
Commitment 14 (C14). Map and analyse effec -
tiveness of coordination mechanisms and prac -
tices between central evaluation units and sector 
ministry units and local government evaluation.
BUDGETS 
Commitment 16 (C16).  Assign budgets or 
percentages of initiatives to evaluations when 
designing/approving projects/programmes/poli -
cies or assign a percentage of the initiative cost.
INDEPENDENT EVALUATORS 
Commitment 17 (C17). Use independent evalu-
ators to facilitate/moderate self-assessments and 
reviews.
GENDER 
Commitment 18 (C18).  Incorporate gender 
capacities/perspectives in M&E national systems.
OTHER COMMITMENTS
The following were internal commitments car -
ried out by the NEC management unit (IPC-IG 
and the Independent Evaluation Office) during 
2014 and 2015 and as such, were not a focus of 
study.1 Information about the progress made so 
far on these is included in Annex 1. 
Commitment 1 (C1).   Develop and implement 
transparent results based monitoring and evalu -
ation framework to track the efforts and results 
of the implemented commitments proposed in  
this conference.
Commitment 12 (C12). Have an online platform 
(NEC-COP) to present/exchange experiences, 
keep NEC participants connected and follow up 
on commitments.
Commitment 13 (C13).  Translate material on 
evaluation into different languages.
Commitment 15 (C15).  Support joint regional/
national events to take stock of developments 
in these commitments (in 2014), including the 
sharing/learning good practices of validating  
data from multiple sources, managing sensitive 
data and disseminating evaluation results.
<<<PAGE=15>>>
EXECUTIVE SUMMARY
xiii
EXECUTIVE SUMMARY 
2 Countries in which UNDP has programmes.
3 These unofficial commitments were not signed by official government representatives. Rather, they represent key areas 
of intervention for government representatives, policymakers and practitioners as expressed during the Third NEC 
Conference. 
At the UNDP-sponsored Third National Evalu-
ation Capacities (NEC) Conference (São Paulo, 
2013), national government representatives from 
60 countries—including 43 UNDP programme 
countries2—discussed solutions to challenges 
related to evaluation independence, credibility 
and use. The participants developed and signed 
18 commitments (the ‘NEC Commitments’) 
to enhance national evaluation capacities and 
to encourage accountability by calling on coun -
tries and NEC participants to commit to actions  
and collaboration.3
This Study documents the current state of 
national evaluation capacities and existing insti -
tutional set-ups in the 43 UNDP programme 
country signatories of those commitments. Doc -
umenting existing capacities will enable the 
assessment of progress made towards fulfilling 
these evaluation needs in the future. 
‘Capacities’ refers to a national government’s 
technical capacities and current institutional set -
tings, including the legal frameworks in place, 
the organizational structures in which evaluation 
is (or is not) inserted and the existing individual 
technical capacities that make up the enabling 
environment. The term ‘capacity’ refers to creat -
ing an ‘enabling’ environment in which evalua -
tions can be determined or required and the way 
in which they are used as a credible and indepen-
dent function to inform national-level decision- 
and policymaking. 
This Study was conceived of as a descriptive, 
factual document (as opposed to an evaluative 
assessment). The Study focused on compiling 
and assembling a collection of resources by coun-
try to serve as a foundation upon which to build 
a more comprehensive baseline study. Assess -
ment data was collected through a desk review 
of primary and secondary source documents and 
information downloaded from the Internet, com-
plemented and validated through a consultation 
process involving an online survey of UNDP 
Country Offices and government and voluntary 
organization for professional evaluation repre -
sentatives from each country. 
This Study revealed a variety of institutional 
settings and legal frameworks among the coun -
tries analysed. Many combinations are in place, 
reflecting a variety of government interests, polit-
ical contexts and national developmental stages. 
NATIONAL EVALUATION POLICIES
There are many variations of legal framework (or 
‘national evaluation policy’) implementation. Some 
countries (e.g. Benin, South Africa, Uganda, Uru-
guay) have a national evaluation policy; others lack 
a specific evaluation policy but do have national 
evaluation legislation. A number of countries do 
not yet have a national evaluation policy, but have 
proposals or draft policies that are waiting for leg-
islation (e.g. Bhutan, Kenya, Niger). Many coun-
tries (e.g. Colombia, Malaysia, Mexico) formalize 
(or semi-formalize) the legal frameworks upon 
which evaluation functions are built or structured. 
Some countries (e.g. Costa Rica, South Africa), 
have a specific national evaluation system in place. 
There are also a number of countries which do not
<<<PAGE=16>>>
EXECUTIVE SUMMARY
xiv
yet have a national evaluation policy, but have pro-
posals or draft policies waiting for legislation (e.g. 
Bhutan, Kenya, Niger). 
INSTITUTIONAL SETTING
National governments exhibit diverse institutional 
settings. In almost all countries, international 
donor pressure and requirements for evaluation 
have facilitated the creation of a minimum struc-
ture (e.g. Afghanistan, Ethiopia). In many cases, 
even if donors conduct the evaluations themselves, 
national governments have a unit or division 
tasked with monitoring this work. 
Some national governments have developed 
sophisticated structures and policies, incorporat -
ing mechanisms to ensure that evaluation pro -
cesses are both credible and independent. Such 
structures also aim to ensure that evaluation 
results are useful and used for decision-making 
and that they actually assess the performance, 
impact and effectiveness of their programmes 
(e.g. Colombia, Mexico). 
Many countries’ ministries of planning have evalu-
ation units tasked with monitoring; many of these 
units evaluate national plan implementation (e.g. 
Brazil, India, Malaysia, Nepal). In many cases, 
decentralized evaluation units exist across line 
ministries to facilitate this work, such in the min-
istries of social development, education and health. 
A central evaluation unit is not the only possible 
institutional arrangement; such arrangements are 
usually a function of the size and nature of gov -
ernment structures and country contexts. Given 
the complexities in formulating institutional set -
tings, centralized units seem to work well in some 
cases, while in others a decentralized evaluation 
unit enables a variety of perspectives on evalua -
tion work and research. 
EVALUATION USE
In general, evaluations are used widely. Many 
countries that do not have a national evaluation 
policy nonetheless use evaluations on an ongoing 
basis; the lack of a national policy is not an indi -
cation that evaluations are not used. 
The survey results reveal that 13 of the 43 
countries do not conduct national-level evalu -
ations (Albania, Argentina, Brazil, Cameroon, 
Dominican Republic, Guatemala, Lebanon, 
Niger, Pakistan, Panama, Russia, Suriname, 
Tanzania), although survey respondents in some 
countries (e.g. Cameroon, Guatemala, and the 
Kyrgyz Republic) referred to evaluations con -
ducted by donor agencies on national govern -
ment programmes as national-level evaluations. 
Certain countries, including some of the 13, 
conduct sectoral evaluations of national pro -
grammes, evaluations of national development 
plan projects and produce reports on progress 
towards achieving plan goals and targets. There 
is often a general perception that these are also 
national-level evaluations. 
Almost all countries are making efforts to pro -
mote the use of evaluations either by parliamen -
tarians, voluntary organizations for professional 
evaluation, universities, international donors or 
other stakeholders.  Numerous countries have 
a national evaluation society (and some have 
more than one). In some countries, adminis -
trative reform is pushing for modern manage -
ment techniques that incorporate evaluation (e.g.  
Lebanon). In contrast, some governments (e.g. 
Albania, Burundi, Egypt, Russia) do not show 
much work in evaluation use.
Several issues that limit the use of evaluation 
have been identified. For example, some national 
governments have used evaluation as a political 
mechanism or as a marketing tool to assess the 
performance of programmes that are political 
priorities. 
Technical evaluation capacities are important for 
all governments. Many have invested in develop-
ing monitoring and evaluation (M&E) capaci -
ties, guides and methodologies to implement a 
variety of evaluation processes. Some evaluation 
units have managed to gain full respect for the 
quality of their work due to the level of staff
<<<PAGE=17>>>
EXECUTIVE SUMMARY
xv
expertise. In contrast, some governments lack the 
requisite evaluation capacity even if there are calls 
for M&E of national development plans. 
STAKEHOLDER INVOLVEMENT 
Many governments require the involvement of 
representatives of the programmes being evalu -
ated. Some governments have structures in place 
to enable programme beneficiaries to participate 
in evaluation processes. Many countries post 
their evaluation reports on the Internet. In con -
trast, some restrict public access to evaluation 
information. 
BUDGETS 
National budgets often limit evaluation processes. 
There are situations in which budgets are in place 
but are insufficient to conduct the full range 
of evaluation work. There are also situations in 
which although evaluation units ostensibly have 
their own evaluation budgets, the resources are 
not in fact available. Ultimately, budgets are 
highly influenced by government politics. 
GENDER, ETHNIC AND CUL TURAL 
ISSUES
Although some evaluations consider gender issues 
fairly well, many evaluations limit their treatment 
to merely including sex-disaggregated data. With 
a few exceptions, evaluation work seldom con -
siders ethnic and cultural issues  (the exceptions 
include instances where it is the main focus of the 
evaluation). 
DONORS
In some countries, donors had an impact on the 
success of government M&E systems. In addi -
tion to establishing new or stand-alone M&E 
units, international donors have been pushing for 
broader public-sector and administrative reforms 
in support of improved transparency, account -
ability and good management. 
In conclusion, it is important to understand that 
the fabrics out of which countries and national 
governments are made of is not uniform. Sev -
eral shades exist and there is need to think about 
granularity. These granular aspects of ‘national’ 
evaluation capacities are complex and intrin -
sically linked to each country’s development 
agenda, so therefore need to be taken into con -
sideration and incorporated into the develop -
ment of future evaluation agendas. This Study 
found relationships between the stage of demo -
cratic governance in the countries surveyed and 
their governments’ capacities to conduct evalua -
tions and to ensure the independence, credibility 
and use of the evaluation results.
<<<PAGE=18>>>

<<<PAGE=19>>>
1
INTRODUCTION
4 Countries in which UNDP has programmes.
5 These unofficial commitments were not signed by official government representatives. Rather, they represent key areas 
of intervention for government representatives, policymakers and practitioners as expressed during the Third NEC 
Conference. 
INTRODUCTION 
At the UNDP-sponsored Third National Evalu-
ation Capacities (NEC) Conference (São Paulo, 
2013), national government representatives from 
60 countries—including 43 UNDP programme 
countries4—discussed solutions to challenges 
related to evaluation independence, credibility 
and use. The participants developed and signed 
18 commitments (the ‘NEC Commitments’) to 
enhance national evaluation capacities and to 
encourage accountability by calling on countries 
and NEC participants to commit to actions and 
collaboration.5
This Study documents the current state of 
national evaluation capacities and existing insti -
tutional set-ups in the 43 UNDP programme 
country signatories of those commitments. Doc -
umenting existing capacities will enable the 
assessment of progress made towards fulfilling 
these evaluation needs in the future. 
This Study is structured along three major chap -
ters. Chapter 1 includes a description of the 
scope, methodology and limitations of the Study. 
Chapter 2 presents 43 individual country profiles, 
structured around the 18 commitments used as 
an overarching framework. This approach pres -
ents the findings related to government capacities 
to use evaluations, to ensure evaluation indepen -
dence and to ensure evaluation credibility. Chap-
ter 3 presents the final remarks. 
1. SCOPE AND METHODOLOGY
This Study presents a snapshot of national gov -
ernments’ current capacities to conduct evalu -
ations, to ensure evaluation independence and 
credibility, to use evaluation results and to imple-
ment recommendations. The Study includes each 
of the 43 UNDP programme countries that par -
ticipated in the NEC 2013 Conference. 
‘Capacities’ refers to a national government’s 
technical capacities and current institutional set -
ting, including the legal frameworks in place, the 
organizational structure in which evaluation is 
(or is not) inserted and the existing individual 
technical capacities that make up the enabling 
environment. It is a reference to the enabling 
environment in which evaluations can be deter -
mined and the way in which they are used as 
a credible and independent function to inform 
national-level decision- and policymaking. 
As such, ‘national evaluation capacity’ refers to 
national-level evaluations—evaluations led and 
commissioned by the national government (as 
opposed to an evaluation led by the international 
donor community). These evaluations either 
assess progress in specific sectors (e.g. health, 
education, social assistance) or across sectors (e.g. 
evaluations of development plans and policies). 
This Study was conceived of as a descriptive, fac-
tual report (as opposed to an evaluative assess -
ment of country contexts). The Study focused 
on compiling and assembling a collection of 
resources by country to serve as a foundation 
upon which to build a more comprehensive work 
and to further develop a more comprehensive 
baseline study. The further development of this 
foundation will entail more extensive surveys of
<<<PAGE=20>>>
2
INTRODUCTION
6 unteamworks.org/NEC
a larger and more varied number of government 
institutions and more in-depth research (such 
as a detailed review and analysis of government 
policies and documents and a comparison and 
aggregation of information gathered beyond the 
country level). 
As a factual study, the methodology involved 
a desk review of national documents, comple -
mented by an online survey of country repre -
sentatives and other relevant parties. The desk 
review was based on Internet documents and 
websites (in English, French, Portuguese and 
Spanish) of national governments, local and 
regional professional evaluation associations 
within the 43 countries, and UNDP/United 
Nations Evaluation Group and EvalPartners’ 
websites. Existing documents (e.g. UN reports, 
research studies on evaluation, government pub -
lications) were also reviewed as they became 
available through these searches. 
A review of the proceedings of the three NEC 
conferences (held in 2009, 2011 and 2013), the 
online NEC Community UN Teamworks social 
networking platform6 and NEC conference web-
sites were the point-of departure for gathering 
information about a number of countries’ capac -
ities. The list of conference participants also pro-
vided guidance for the desk review, as they listed 
a number of government departments tasked 
with (or interested in) in evaluation. Drawing 
from these sources and building on the Mapping 
Study on National Evaluation Policies completed 
by the Parliamentarians Forum on Develop -
ment Evaluation (Rosenstein, 2015), this Study 
focused on gathering updated information and 
broadening the number of countries reviewed. 
To complement and validate this research, a con-
sultation process was undertaken through an 
online survey of the 43 countries. The Baseline 
Study Survey 2015 was designed as a qualita -
tive survey to gain insight and to obtain updated 
information regarding the current situation in 
each country in relation to each of the 18 com -
mitments. The Survey was not directed to quan -
tify settings and situations or to generalize results 
across countries from the sample population of 
interest. It was distributed to people in the 43 
countries, including at least one representative of 
the UNDP Country Office, one representative of 
a voluntary organization for professional evalua -
tion and one government representative in each 
country. Information was obtained on almost all 
countries. Only Burundi, Malaysia, Mongolia 
and St. Lucia did not respond the survey. 
Survey results were analysed individually, and 
information input in each of the country profiles. 
Data collection and reporting was oriented by a 
framework presenting the key questions of the 
study in line with the 18 NEC Commitments 
(see Annex 2). In many countries, the survey and 
desk review produced information on most of 
the 18 commitments. When the Study does not 
present information on the commitments for a 
country, this is generally due to inconsistent use 
of evaluation by the country surveyed.
2. STUDY LIMITATIONS
The desk review included websites and meta-  
analysis of research previously conducted on 
each of the 18 commitments. The level of avail -
ability of information varied across the countries. 
Some governments make extensive information 
available through frequently updated, publicly 
accessible websites, and actively promote their 
evaluation efforts. 
Language limited the depth of analysis in the 
few cases where information was not in English, 
French, Portuguese or Spanish. To offset these 
issues, the study looked for research information 
in those languages. Online reports and studies in 
one of the four languages were available in most 
cases. When the level of available research mate-
rials was limited, the Study used surveys to com -
plement what information was available.
<<<PAGE=21>>>
3
INTRODUCTION
For many commitments, the desk review val -
idated the information obtained through the 
surveys. However, in the case of certain commit-
ments, such as budgets (C16), independent eval-
uators (C17), stakeholders’ involvement (C10), 
peer-to-peer systems (C5) gender (C18) and 
ethnic and cultural issues (C8), the issues them -
selves had significant variation. This variation 
stemmed from the context and type of evalua -
tion conducted and from survey respondents that 
provided multiple answers. It was therefore not 
possible to fully triangulate; the findings should 
not be generalized. 
In addition, it was not possible to obtain detailed 
information and explanations on these commit -
ments when data was only available through the 
surveys. The surveys used yes or no answers to 
facilitate data collection and analysis of large 
amounts of data. For example, it was not possi -
ble to investigate how peer-to-peer systems were 
used in countries that have them, who used them 
or whether they produced expected results. 
As such, the study was conceived of as a factual, 
descriptive study and not an evaluative exercise, 
particularly as it was not possible to triangulate 
the information and data gathered. This is the 
reason why this document is called “Towards a 
Baseline,” and will require more effort to be prop-
erly considered a baseline assessment. A baseline 
assessment would require triangulation of infor -
mation and additional research for a complete 
picture in each country. This can be done in the 
future, through the continuation of this work or 
the creation of a Wiki-type of online platform, 
where practitioners and government representa -
tives could add information, provide corrections 
and validate the work. 
Lastly, it is important to explain that even 
though this is a factual study, some of the 
research papers reviewed included subjective 
judgements or were somewhat dated (e.g. from 
earlier than 2012). In certain cases, it was pos -
sible to validate those through the triangula -
tion of data gathered through website reviews 
and the surveys. In some cases, validation was 
not possible but the information was included 
because it was considered a useful point of 
departure for the development of future baseline 
work. As much as possible, these are identified 
and explained throughout the document.
<<<PAGE=22>>>

<<<PAGE=23>>>
5
COUNTRY PROFILES
7 See limitations regarding generalizations about certain commitments such as budgets (C16), independent evaluators 
(C17), stakeholders’ involvement (C10), peer-to-peer systems (C5) gender (C18) and ethnic and cultural issues (C8). 
8 Synthese du document de politique aationale d’evaluation 2012-2021, available at http://evaluation-gouv.bj/?p=375
9 It is possible that changes have been in place since the source date. However, website data does not contradict the source. 
As such, this information was included in the study as an important as a point of departure for future work. 
COUNTRY PROFILES 
 
This section provides a snapshot of the status 
of national evaluation capacities in countries in 
Africa, Arab States, Asia and the Pacific, Europe 
and the Commonwealth of Independent States 
and Latin America and the Caribbean.
1. AFRICA
1.1 BENIN
1.1.1  National government’s capacity to use 
evaluations (Use of Evaluation) 7
Institutional set up (C4): Evaluations are used to 
assess the impacts of all government programmes 
and for governments to provide accountability 
for their actions. They are also used for learning 
purposes, to adjust course and to scale up initia -
tives in Benin. (2015)
The Government of Benin developed a 10-year 
(2012–2021) National Evaluation Policy. 8 The 
National Evaluation Policy identifies all those 
involved in evaluation and specifies their roles. The 
Policy aims at promoting the evaluation of pub -
lic policies for management and decision-making 
and at clarifying the roles of evaluation in gov -
ernment actions. The national evaluation pol -
icy scope includes the Strategic Development  
Orientations, the Growth and Poverty Reduc -
tion Strategy 2011–2015, other sectoral policies, 
the activities of public services and the actions of 
decentralized municipalities.
The responsibilities for evaluation are assigned 
to the National Council of Evaluation (Conseil 
National de l’évaluation – CNE) and the Office 
of Evaluation of Public Policy ( Bureau d’éva -
luation des Politiques Publiques  – BEPP). The 
Council provides advice to the government on 
evaluation and promotes evaluation development 
at the national, regional and municipal levels. It 
also supports BEPP in drawing up the govern -
ment’s various evaluation programmes and pro -
motes norms, standards and methodologies. 
BEPP is responsible for evaluating national 
public policies to improve policy management 
in Benin. Reporting directly to the Minister of 
State Responsible for the Coordination of Gov -
ernment Action, BEPP work focuses on priority 
public policies, programmes and major projects 
implemented by the central public administra -
tion, professional practices and the activities 
of public services and development agencies.  
(Djidjoho, 2011)9 
Other government departments are also involved 
in evaluation. The BEPP M&E (monitoring and 
evaluation) focal points and the programming and 
prospection departments of each sectoral ministry 
are responsible for evaluating their ministry’s proj-
ects and programmes. The Social Change Obser-
vatory (L’Observatoire du Changement Social) 
is in charge of evaluating the impacts of poverty 
reduction programmes.  (Djidjoho, 2014) 
The formal evaluation system, integrated into the 
Planning Programming Budget M&E process 
chain, contributes to the evaluation of state proj-
ects, programmes and public policies. This system
<<<PAGE=24>>>
6
COUNTRY PROFILES
10 Document available at: gazelletouch.lagence.de.com/newbepp/wp-content/uploads/2013/10/SYNTHESE-DU-  
DOCUMENT-DE-POLITIQUE-NATIONALE-D%E2%80%99EVALUATION-2012-%E2%80%93-  
2021-05012012.pdf. 
11 For more information, see Insae-bj.org.
works well at the national level, but is less effective 
at the sectoral level—particularly with regards to 
collecting, processing, analysing, centralizing and 
publishing data. To ensure that evaluation activi-
ties remain connected to the public management 
cycle and that evaluations are used correctly, it is 
necessary for the practice of evaluation to become 
more systematic and for it to correspond to the 
government’s planning and budget programming 
timetables.  (Djidjoho, 2014)
Parliamentarians promoting evaluation use 
(C6): Parliamentarians are actively advocating 
and promoting the use and conduct of evalua -
tions. (2015)
Partnerships to strengthen and promote eval -
uation (C7):  Local stakeholders (professional 
organizations, universities, private sector actors, 
NGOs) and international organizations are col -
laborating and jointly advocating and promoting 
the need and demand for and use of national-level 
evaluations. Universities and professional evalua-
tion networks are pushing for the development 
of national policies, structures and frameworks. 
(2015) The Benin Network of M&E (Réseau 
Béninois de Suivi et d’évaluation – ReBSEv) 
mission is to promote evaluation culture through 
capacity building and increased awareness by 
the public sector and civil society regarding the 
importance of evaluation and its institutionaliza-
tion. (IOCE, 2012)
Budgets for evaluation (C16):  The national 
evaluation policy describes financial measures 
to fund sectoral evaluations. Government units 
responsible for evaluation have their own budgets 
to conduct evaluation. Policies allocate budgets 
for evaluation in programme budgets and make 
them available. (2015)
1.1.2  National government’s capacity 
for independent evaluations 
(Independence of Evaluation)
Independent evaluators (C17):  Evaluations are 
conducted by the internal staff of government 
departments and by consultants and indepen -
dent firms. BEPP uses independent consultants 
to guarantee the impartiality of the reports. BEPP 
has drawn up a code of professional ethics inspired 
by international standards. (Djidjoho, 2014) Eval-
uations of policies and strategies of priority eco -
nomic sectors have been conducted by the Office 
of Evaluation of Public Policy with the assistance 
of independent consultants. (Djidjoho, 2011)
Stakeholders’ involvement/access to informa -
tion (C10):  Benin’s national evaluation policy 
is available on the government website. 10 BEPP 
has an evaluation portal in its website. (Govern -
ment of Benin, 2015) Some evaluation reports 
are available on the BEPP website, but many 
reports are not made publicly available—they are 
only available to the government, technical and 
financial partners and professional associations 
in the sectors evaluated. BEPP is interested in 
developing a participative approach to encourage 
better dissemination of information to civil soci -
ety. (Djidjoho, 2014) 
1.1.3  National government’s capacity to 
ensure credible evaluations  
(Credibility of Evaluation)
National data systems (C2): The National Insti-
tute of Statistics and Economic Analysis (Insti -
tut National de la Statistique et de l’Analyse 
Economique) is the central government agency 
responsible for collecting and analysing national 
data (e.g. demographics, economics).11
Integrated public registries (C11): Public reg -
istries and administrative records are not inte -
grated. (2015)
Methodologies (C9):  The national evaluation 
policy refers to the need to advance the profes -
sionalization of evaluation as a necessary step for
<<<PAGE=25>>>
7
COUNTRY PROFILES
12 See limitations regarding generalizations about certain commitments such as budgets (C16), independent evaluators 
(C17), stakeholders’ involvement (C10), peer-to-peer systems (C5) gender (C18) and ethnic and cultural issues (C8). 
13 isteebu.bi
14 See limitations regarding generalizations about certain commitments such as budgets (C16), independent evaluators 
(C17), stakeholders’ involvement (C10), peer-to-peer systems (C5) gender (C18) and ethnic and cultural issues (C8). 
its implementation. The policy also stresses the 
need to create a professional cadre of evaluators 
within the administration. Substantial resources 
have been invested to train and strengthen eval -
uation capacities of more than 150 managers 
working in ministries and municipalities. 
In order to support national institutions and pro-
mote M&E, Benin’s Evaluation Network works 
towards providing methodological support to 
its membership and facilitating the exchange of 
information about evaluation practices. Collab -
orating with BEPP and local and international 
universities, the Network organizes conferences, 
workshops and professional courses. In 2012 and 
in collaboration with BEPP , the Network pre -
pared a study about the evaluation capacities in 
Benin and developed a capacity-building course 
for ministry representatives. (IOCE, 2012) 
In the context of managing the public policy 
evaluation functions, BEPP developed various 
documents to operationalize evaluation proce -
dures. (2015) 
Peer-to-peer systems (C5): Peer-to-peer systems 
are not used in Benin. (2015)
Gender (C18): Some evaluations  take gender 
into consideration and analysis. Programme 
impacts and evaluation data are disaggregated by 
sex. However, gender is not adequately consid -
ered in national-level evaluations. (2015)
Ethnic and cultural dimensions (C8): Ethnic 
and cultural issues are not considered in national- 
level evaluations. (2015)
1.2 BURUNDI
1.2.1  National government’s capacity to use 
evaluations (Use of Evaluation) 12
Institutional set up (C4):  There is no national 
evaluation policy in Burundi. There are no refer-
ences to evaluation, monitoring or accountability 
on government websites. (2015) The Ministry 
of Good Governance is responsible for imple -
menting the 2011–2015 National Strategy for 
Good Governance and Fight against Corrup -
tion (Stratégie Nationale de Bonne Gouver -
nance et de Lutte contre la Corruption). The 
Strategy, adopted by the Ministerial Council in 
2011, identifies M&E mechanisms as essential 
to strengthening government performance. The 
Strategy sets up as a key priority action the insti -
tutionalization of planning, results-based man -
agement and periodic evaluation. (Ministere a la 
Presidence Charge de la Bonne Gouvernance et 
de la Privatisation, 2011)
1.2.2  National government’s capacity to 
ensure credible evaluations  
(Credibility of Evaluation)
National data systems (C2): The Burundi Insti-
tute of Statistics and Economic Studies (Insti -
tut de Statistiques et d’Études Économiques 
du Burundi) is the central government agency 
responsible for collecting and analysing national 
data (e.g. demographics, economics).13 
1.3 CAMEROON
1.3.1  National government’s capacity to use 
evaluations (Use of Evaluation) 14
Institutional set up (C4):  Cameroon does not 
have a national evaluation policy. There are 
several elements (administrative decrees and 
units, positions and programmes) that, taken 
together, may be considered a foundation for 
a more structured approach to evaluation pol -
icy. Some sectoral policies require evaluation of 
specific national programmes. Evaluations are 
used to assess the impacts of all government pro-
<<<PAGE=26>>>
8
COUNTRY PROFILES
grammes, for learning purposes, to adjust course, 
to scale up initiatives and for governments to 
provide accountability for their actions (mostly as 
a requirement from international donors). (2015)      
There is no central government unit in charge of 
conducting evaluations. (2015) The Ministry of 
Economy, Planning and Regional Development 
(Ministère de l’Economie, de la Planification et 
du Développement Régional – MINEPAT) has 
established evaluation units within its adminis -
trative set up, including the General Inspection 
of Performance Evaluation of Services ( Inspec-
teur General de l’évaluation des performances 
des services ) and the General Inspection of 
Evaluation of Services Functioning ( Inspec-
teur General de l’évaluation du fonctionnement 
des services ). The Prime Minister’s Office has 
a technical adviser in charge of a public service 
modernization programme (PROMAGAR) to 
introduce results-based management to the pub -
lic administration. The technical adviser was 
trained in results-based management and works 
with designated focal points in line ministries 
for the implementation of ministry-wide action 
plans to be implemented in each directorate.  
(Yantio, 2013)
All ministries have inspector general positions 
in charge of ‘systematic evaluation’, and the 
General Secretary of the Ministries (Head of 
Administration) has a monitoring unit anchor. 
(2015) The work of inspectors in the ministries 
is complemented by the work of the Ministry of 
Supreme State Control in Charge of Auditing. 
The Supreme Court of Justice also has an audit 
bench that assesses the accounts of all public 
bodies, including ministries and public enter -
prises, and prepares annual reports that are more 
similar to financial audits than programme eval -
uation. (Yantio, 2013)
All ministries have a monitoring unit in addi -
tion to the inspectorates. The unit monitors the 
implementation of the ministry’s road map and 
reports to the Secretary General and the head 
of the administration in the ministry. Neverthe -
less, “rigorous evaluation of governmental poli -
cies, programmes and projects is not yet common 
practice.” (Yantio, 2013, p. 31) 
Evaluations are mostly carried by donors, and 
when locally commissioned they are geared more 
towards fulfilling contractual obligations rather 
than improving organizational and programme 
performance. For example, the Technical Com -
mittee for Monitoring and Evaluation ( Comitè 
Technique de Suivi et Evaluacion ) of the Gov -
ernment’s New Growth and Development Strat-
egy (DSCE) is in charge of such evaluations. 
(2015) There is pressure from international part-
ners on the central government and there is 
growing potential demand at the local govern -
ment level, but there is also “the absence of an 
evaluation culture and insufficient knowledge at 
all layers of the public administration.” (Yantio, 
2013, p. 30)
Parliamentarians promoting evaluation use 
(C6): Parliamentarians are actively advocating 
and promoting the use and conduct of evalua -
tions. (2015)
In 2014, the parliamentarians from Cameroon 
signed a declaration (Yaoundé Declaration of 
African Parliamentarians on Evaluation) recog -
nizing “the important function of evaluation in 
national decision-making and the crucial role of 
parliamentarians in ensuring evaluation evidence 
is used for strengthening decision-making for 
greater development effectiveness and inclusive 
growth.” (Rosenstein, 2015)
Partnerships to strengthen and promote eval -
uation (C7): International organizations and the 
government are working together on a formal 
M&E Framework.  (2015) Other stakeholders 
(professional organizations, universities, private 
sector actors, NGOs) are actively advocating and 
promoting the use and conduct of evaluations.  
(2015) These institutions are coordinating efforts 
and jointly promoting the need and demand for 
and use of national-level evaluations. (2015)
The Cameroon Development Evaluation Asso -
ciation (CaDEA) was founded in 2004 “to raise
<<<PAGE=27>>>
9
COUNTRY PROFILES
15 See comment on limitations regarding generalizations about certain commitments. 
16 statistics-cameroon.org
awareness and demand for evaluation, and build 
a community of evaluation stakeholders [in the 
country]” and “to facilitate the access of Cameroo-
nian evaluation professionals to training opportu-
nities available worldwide in order to strengthen 
their technical capacity.” (IOCE, 2012) Among 
other initiatives, it is pursuing the development of 
strategic partnerships with national and interna -
tional counterparts for advocacy, educating deci -
sion makers and programme managers on the 
nature and benefits of evaluation and collecting 
and disseminating information on M&E prac -
tices in the country. 
Budgets for evaluation (C16):  Some surveys 
indicate that government policies allocate eval -
uation budgets within programme budgets and 
make them available, and that policies, pro -
grammes and projects have evaluation resources 
built into their budgets. Some government units 
responsible for evaluation have their own bud -
gets; other units’ budgets are not in place for the 
conduct of evaluation.15 (2015)
1.3.2  National government’s capacity to 
ensure credible evaluations  
(Credibility of Evaluation)
Independent evaluators (C17):  Evaluations 
are conducted by the internal staff of govern -
ment departments and by independent evaluators 
under contracts. (2015)
Stakeholders’ involvement/access to informa -
tion (C10):  Some evaluation reports are made 
public and are easily available on government 
websites. However, evaluation reports are gen -
erally considered sensitive information and not 
made publicly available. (2015)
Implementation of evaluation recommenda -
tions (C3): There are no systems in place to 
follow up on the implementation of evaluation 
recommendations. (2015)
National data systems (C2):  Cameroon’s 
National Institute of Statistics (Institut National 
de la Statistique du Cameroun) is the central 
government agency responsible for collecting 
and analysing national data (e.g. demographics, 
economics).16
Integrated public registries (C11): Public reg -
istries and administrative records are not inte -
grated. (2015)
Peer-to-peer systems (C5): Peer-to-peer systems 
are not used. (2015)
Methodologies (C9):  There are no technical 
capacities in rigorous internal evaluation of the 
policies, programmes and projects of their respec-
tive ministries. Few qualified professional eval -
uators exist in the country. There are “training 
organizations in the private and public sector that 
provide undergraduate and professional training 
in M&E, although with inadequate curriculum, 
teaching resources, and learning conditions.” 
(Yantio, 2013, p. 33) (2015)
The University of Yaounde II (Soa) and the Sup-
port Centre for Evaluation and Rural Develop -
ment (CAED) are developing a learning course 
for PhD students on Evaluation of Public Poli -
cies. (2015)
Gender (C18):  Some evaluations take gender 
into consideration, analyse programme impacts 
and use gender-responsive evaluation methods.  
Gender is generally requested to be part of eval -
uation design and that evaluation teams have 
gender analysis expertise. However, this is not 
systematically undertaken. (2015)
Ethnic and cultural dimensions (C8):  Evalu -
ations take ethnic and cultural issues into con -
sideration and analysis of programme impacts. 
Evaluation reports discuss ethnic and cultural 
issues that are addressed in the project or pro -
<<<PAGE=28>>>
10
COUNTRY PROFILES
17 See limitations regarding generalizations about certain commitments such as budgets (C16), independent evaluators 
(C17), stakeholders’ involvement (C10), peer-to-peer systems (C5) gender (C18) and ethnic and cultural issues (C8). 
18 Ethiopia developed the Agricultural Development Led Industrialization (ADLI) plan in 1991, followed by the Poverty 
Reduction Strategy process in 2000, and by 2002 it issued the first three-year Sustainable Development Poverty Reduction 
Programme (SDPRP) 2002-2005, the first five-year Plan for Accelerated and Sustainable Development to End Poverty 
(PASDEP) in 2005 and the Plan for Accelerated and Sustained Development to End Poverty 2005/06 to 2009/10. 
19 It  is possible that changes have been in place since the source date. However, website data does not contradict the source. 
As such, this information was included in the study as an important as a point of departure for future work. 
gramme. Evaluation data is disaggregated by eth-
nic and cultural background. (2015) 
1.4 ETHIOPIA
1.4.1  National government’s capacity to use 
evaluations  (Use of Evaluation) 17
Institutional set up (C4): Ethiopia does not have 
a national evaluation policy. (IOCE, 2012) There 
is some emphasis on evaluation as an import -
ant accountability requirement from development 
partners and international financial institutions. 
The national government, through the Ministry of 
Finance and Economic Development (MoFED), 
has the responsibility for project evaluation but 
there is no framework or standards in place. In lieu 
of standardized mechanisms in the public sector, 
project-level evaluations are performed on a case-
by-case basis. 
Evaluations have been mostly driven by devel -
opment partners. Since 1991 and supported by 
international partners, requirements have been 
in place to ensure performance of development 
interventions under the government’s national 
development plans.18 In line with this, the current 
MoFED Growth and Transformation Plan 2011–
2015 includes such M&E requirements. (Govern-
ment of Ethiopia, 2015) The Bureau of National 
Monitoring and Evaluation of the National Plan-
ning Commission is in charge of M&E of the 
overall national development plan. (2015)
MoFED undertakes intensive evaluation studies 
on selected sectors, as these are required for sectoral 
interventions under national plans. These evalua-
tions are collaborative efforts of the ministries, 
regional bureaux and development partners. The 
independent evaluations (conducted by interna -
tional development agencies, bilateral cooperation 
agencies and international financial institutions, in 
accordance with their respective interests) are inte-
grated through the sectoral annual performance 
reports. (Alemu, 2011)19
MoFED plays a coordinating role, consolidating 
and analysing data collected from administrative 
sources and different surveys conducted by the 
Central Statistical Agency. Using administrative 
and survey data sources (which use output and 
impact indicators), MoFED compiles and analyses 
annual progress reports and disseminates them to 
all stakeholders. An M&E Macroeconomic Policy 
Matrix document is also prepared as part two of 
the national plan to monitor and annually eval -
uate indicated targets. There is a “rising demand 
for on-time release of annual progress reports and 
[an] increase[d] use of evaluation results in project 
and programme design and academic research.”   
(Government of Ethiopia, 2015)
Parliamentarians promoting evaluation use 
(C6): In 2014, parliamentarians from Ethiopia 
signed a declaration (Yaoundé Declaration of 
African Parliamentarians on Evaluation) recog -
nizing “the important function of evaluation in 
national decision-making and the crucial role of 
parliamentarians in ensuring evaluation evidence 
is used for strengthening decision-making for 
greater development effectiveness and inclusive 
growth.” (Rosenstein, 2015)
Partnerships to strengthen and promote evalua-
tion (C7): The Ethiopian Evaluation Association 
(EEvA) has been active since 2008, with the mis-
sion “to engage and enable M&E professionals to 
contribute significant part in the socio-economic 
development of the country through knowledge 
generation, awareness creation, capacity building, 
advocacy and rendering model service in evalua -
<<<PAGE=29>>>
11
COUNTRY PROFILES
20 csa.gov.et
21 See  limitations regarding generalizations about certain commitments such as budgets (C16), independent evaluators 
(C17), stakeholders’ involvement (C10), peer-to-peer systems (C5) gender (C18) and ethnic and cultural issues (C8). 
22 ndpc.gov.gh
tion.” (IOCE, 2012) The network has plans (as yet 
unrealized) to engage in influencing and advocat-
ing for governmental evaluation policies and sys-
tems. The Ethiopian Monitoring and Evaluation 
Association (established in 2014) is advocating for 
and promoting evaluation  capacity in Ethiopia. 
(Tesfaye, 2015)
1.4.2  National government’s capacity to 
ensure credible evaluations  
(Credibility of Evaluation)
National data systems (C2): The Central Statis-
tical Agency20 is the government agency respon -
sible for collecting and analysing national data 
(e.g. demographics, economics). The Agency 
works in coordination with the MoFED, sector 
ministries and development partners concerning 
evaluation. (Alemu, 2011)
Integrated public registries (C11):  In order to 
manage socio-economic changes taking place in 
the country and to increase its capacities for infor-
mation generation, the government of Ethiopia 
established the National Statistical System (NSS), 
a national medium-term statistical programme and 
a national strategy for development of statistics.
Coordination practices (C14):  Coordination is 
a challenge between line ministries and regional 
bureaux; it is an obstacle to generating and com -
piling essential evaluation information on time, 
which complicates time-sensitive corrective pol -
icy measures. 
1.5 GHANA
1.5.1  National government’s capacity to use 
evaluations (Use of Evaluation) 21
Institutional set up (C4): Ghana routinely con -
ducts evaluations, but does not have a national 
evaluation policy. (Rosenstein, 2015) Sectoral pol-
icies requiring evaluation of specific national pro-
grammes are in place. (2015) The government 
recognizes the need to use M&E to ensure 
that progress is made towards national policies, 
objectives and interventions. The 1992 Consti -
tution and other public documents gave rise to 
institutional M&E arrangements at the national, 
regional and district levels. (Dery, 2014)
Evaluations are used to assess the impacts of all 
government programmes. Evaluations are also 
used for learning purposes, to adjust course, to 
scale up initiatives and for governments to provide 
accountability for their actions.     
The National Development Planning Commis -
sion (NDPC) is the government department 
charged with responsibilities for national M&E. 
The Commission coordinates the input from 
ministries and agencies to produce national devel-
opment policy frameworks on a three-year basis, 
linking development plans at the sector and dis -
trict levels to the national budget. 22  The M&E 
system provides “feedback and lessons for con -
tinuous improvement of the policy plans and the 
national budget.” (Dery, 2014, p. 204)
National M&E plans assess the progress made 
towards national development plan implemen -
tation. The M&E Division is tasked with the 
oversight of the implementation of develop -
ment policies in order to ensure that the NDPC 
meets its mandate related to national develop -
ment planning. The Division is responsible for 
preparing M&E guidelines, the national and 
NDPC’s M&E plans, national annual progress 
reports and evaluation and participatory assess -
ments of the impacts of select government pol -
icies. (Ghana National Development Planning 
Commission, 2015)
Demand for M&E progress reports is largely 
driven by development partners and by the need 
to comply with internal regulations. The use of
<<<PAGE=30>>>
12
COUNTRY PROFILES
23 See limitations regarding generalizations about certain commitments such as Budgets (C16), Independent Evaluators 
(C17), Stakeholders’ Involvement (C10), Peer-to-peer systems (C5) Gender (C18) and Ethnic and Cultural Issues (C8). 
M&E results for policy formulation and deci -
sion-making and as an integral part of good gov-
ernance is limited in Ghana, as there is no demand 
by parliament or civil society. (Dery, 2014) 
Universities, professional evaluation networks 
and the international donor community are 
pushing for the development of national evalu -
ation policies, structures and framework. (2015)
Parliamentarians promoting evaluation use 
(C6): In 2014, parliamentarians from Ghana 
signed a declaration (Yaoundé Declaration of 
African Parliamentarians on Evaluation) recog -
nizing “the important function of evaluation in 
national decision-making and the crucial role of 
parliamentarians in ensuring evaluation evidence 
is used for strengthening decision-making for 
greater development effectiveness and inclusive 
growth.” (Rosenstein, 2015)
Partnerships to strengthen and promote eval -
uation (C7):  Other stakeholders (professional 
organizations, universities, private sector actors, 
NGOs) are actively advocating and promoting 
the use and conduct of evaluations. International 
organizations are advocating and promoting the 
use of evaluations. (2015)
The National Commission is working with the 
Japanese International Cooperation Agency to 
organize M&E training sessions for senior exec -
utives and political leadership in order to enhance 
their awareness and understanding of the value of 
a national M&E system. (Ghana National Devel-
opment Planning Commission, 2015)
The Ghana M&E Forum (GMEF) and the 
Ghana Network of Independent and Profes -
sional Evaluators (G-IPEN) are the professional 
organizations active in the country. GMEF was 
founded in 2008 and is working to promote open 
dialogue around M&E issues and to positively 
influence development opportunities.      
Early in 2015, the National Planning Commis -
sion held a media dialogue as part of the activ -
ities to commemorate the International Year of 
Evaluation (EvalYear 2015). The Commission 
announced it was launching a major campaign 
to strengthen the environment for evaluation 
by developing a national evaluation policy. The 
event was jointly organized by NDPC, the  
African Evaluation Association, the Ghana 
M&E Forum and UNICEF. (Ghana National 
Development Planning Commission, 2015)
Budgets for evaluation (C16): There are limited 
funds available for M&E activities. (Dery, 2014) 
The government units responsible for evaluations 
lack human, material and financial resources. Eval-
uations are usually ad hoc, and budgets are not in 
place for their conduct (except for donor-funded 
projects that have evaluation budgets). (2015)
1.5.2  National government’s capacity 
for independent evaluations 
(Independence of Evaluation)
Stakeholders’ involvement/access to informa -
tion (C10): The National Development Plan -
ning Commission emphasizes the involvement of 
civil society organizations and development part-
ners in M&E processes as an important feedback 
mechanism. (Dery, 2014) 
The Annual Progress Reports and materials on 
M&E, including M&E plans, are available on 
the NDPC website. Evaluation reports are some-
times made public and available on government 
websites. (2015)
1.5.3  National government’s capacity to 
ensure credible evaluations  
(Credibility of Evaluation)
National data systems (C2): The Ghana Sta -
tistical Service is the central government agency 
responsible for collecting and analysing national 
data (e.g. demographics, economics).23
<<<PAGE=31>>>
13
COUNTRY PROFILES
24 See limitations regarding generalizations about certain commitments such as Budgets (C16), Independent Evaluators 
(C17), Stakeholders’ Involvement (C10), Peer-to-peer systems (C5) Gender (C18) and Ethnic and Cultural Issues (C8). 
Integrated public registries (C11):  Data qual -
ity and management information systems across 
government levels and departments are inade -
quate, and there are issues related to transferabil-
ity of data from one system to another. (Dery, 
2014) Public registries and administrative records 
are not integrated. (2015)
Independent evaluators (C17):  Evaluations are 
conducted by independent evaluators under con-
tracts. (2015)
Methodologies (C9):  The National Com -
mission produces M&E Guidelines and pro -
vides basic M&E training for sector ministries, 
departments, agencies and other levels of 
government to build capacities and establish  
formats, timelines for their preparation of 
M&E plans for their own development plans 
as well as quarterly and annual progress reports.  
(Dery, 2014)
Generally, there is weak capacity to produce eval-
uations; non-compliance with M&E reporting 
guidelines and frameworks is common, due in 
part to developmental partners’ need and sup -
port for sectoral M&E systems (as opposed to a 
national system). (Dery, 2014)
Gender (C18):  Some evaluations take gen -
der into consideration, including analysis of 
programme impacts. Evaluation reports dis -
cuss how gender equality is addressed in the 
project or programme. Evaluation data is dis -
aggregated by sex. Some evaluations use gender-  
responsive evaluation methods. To some extent, 
evaluation teams have gender analysis expertise.  
(2015)
Ethnic and cultural dimensions (C8) Incorpo-
ration of ethnic and cultural issues is limited.  
(2015)
1.6 KENY A
1.6.1  National government’s capacity to use 
evaluations (Use of Evaluation)24
Institutional set up (C4):  Government-wide 
M&E has been used in Kenya since the early 
2000s. With the assistance of the donor com -
munity, the National Integrated M&E System 
(NIMES) was established under the direction 
of the National Steering Committee. The Com -
mittee is chaired by the Permanent Secretary in 
the Ministry of Devolution and Planning, and 
includes representatives from other government 
departments, development partners and civil 
society. (Machuka, 2014)
In 2010, the Kenya Constitution strengthened 
the basis for M&E in the country. By establish -
ing decentralized governance, the Constitution 
created a new layer of county-level government, 
to be supported by a well-functioning evalua -
tion system. (Machuka, 2014) There are ongoing 
efforts to institutionalize evaluation in the coun -
try. There are proposals for a national evaluation 
policy, but they have not yet been institutional -
ized. Some sectoral policies require evaluation of 
specific national programmes.
Evaluations are used to assess the impacts of all 
government programmes, for learning purposes, 
to adjust course and to scale up initiatives. The 
government uses evaluations to provide account -
ability for its actions. (2015)
The Ministry of State for Planning, National 
Development and Vision 2030 in the Office 
of the Prime Minister has responsibilities that 
include implementing Kenya Vision 2030 and 
coordinating and providing leadership for the 
National M&E Framework and the Annual 
Progress Reports coordinating. The Monitor -
ing and Evaluation Directorate (MED) tracks 
and provides feedback on the implementation of 
all government policies, programmes and proj -
<<<PAGE=32>>>
14
COUNTRY PROFILES
ects. It coordinates the development and imple -
mentation of the NIMES at both national and 
decentralized levels and analyses expenditure and 
progress reports from line ministries and districts 
in order to prepare annual M&E reports, Annual 
Progress Reports and Public Expenditure Review. 
The Directorate is also responsible for tracking 
Kenya Vision 2030 and the first Medium Term 
Plan 2008–2012. (Government of Kenya, 2015) 
The Directorate works towards “encouraging the 
culture and practice of M&E and [at] promoting 
accountability in order to enhance public service 
delivery.” (Machuka, 2014, p. 212) 
NIMES focuses more on monitoring aspects 
than evaluation, even though it periodically 
undertakes evaluations of government plans, 
strategies and some specific sectoral interven -
tions. Efforts are under way to bridge this gap 
with a draft national evaluation plan. Each min -
istry also has Central Project Planning and Mon-
itoring Units (CPPMUs), which are expected to 
conduct evaluations in coordination with MED 
once the national evaluation plan is in place. 
County Monitoring and Evaluation Units also 
exist within the 47 county governments, and 
are part of the plans for a County Integrated 
Monitoring and Evaluation System (CIMES). 
(2015) An M&E policy was designed to guide 
the system implementation, addressing issues of 
coordination and involvement of civil society to 
improve reporting and feedback. 
Parliamentarians promoting evaluation use 
(C6): Parliamentarians are actively advocating 
and promoting the use and conduct of evalu -
ations. (2015) In 2014, parliamentarians from 
Kenya signed a declaration (Yaoundé Declaration 
of African Parliamentarians on Evaluation) rec -
ognizing “the important function of evaluation in 
national decision-making and the crucial role of 
parliamentarians in ensuring evaluation evidence 
is used for strengthening decision-making for 
greater development effectiveness and inclusive 
growth.” (Rosenstein, 2015)
Partnerships to strengthen and promote evalu -
ation (C7): Stakeholders (professional organiza -
tions, universities, private sector actors, NGOs) 
and international organizations are actively advo-
cating and jointly promoting the use and con -
duct of evaluations. (2015) International donors 
have been actively promoting M&E in Kenya. 
Kenya is a major focus country for the Africa 
Impact Evaluation Initiative (AIM), given the 
large scope of impact evaluation activities and 
the government’s commitment to evidence-based 
policy -making. (AIM, 2015) 
The Evaluation Society of Kenya has prepared 
a constitution and strategic plan in 2011 in an 
effort to become operationalized. The Society has 
an e-platform, a website and has been engaged in 
a strategic partnership with NIMES. It also col -
laborates with MED to develop events with the 
goal of enhancing the culture and demand for 
M&E in the country. These increase the visibil -
ity of the Society and NIMES as an M&E tool 
for tracking and communicating results. It also 
encourages a culture of dialogue and the sharing 
of experiences and learning. The use of main -
stream and social media is an integral part of the 
Society’s strategy to advance M&E professional 
practice in Kenya. (IOCE, 2012)
Budgets for evaluation (C16): Policies allocate 
budgets for evaluations within programme 
budgets. Policies, programmes and projects have 
resources for evaluation built into their budgets.  
MED receives funding from the national budget 
for its operations and the periodic specific 
evaluations. The future national evaluation 
plan is expected to have built-in budgets for 
the evaluation function to conduct certain 
evaluations. (2015)
1.6.2  National government’s capacity 
for independent evaluations 
(Independence of Evaluation)
Independent evaluators (C17):  Evaluations 
are conducted by the internal staff of govern -
ment departments and by independent evaluators 
under contracts. (2015)
Stakeholders’ involvement/access to informa -
tion (C10): The M&E process in Kenya calls
<<<PAGE=33>>>
15
COUNTRY PROFILES
25 knbs.or.ke
for the participation of civil society, NGOs, aca -
demia and the private sector. (Machuka, 2014) 
Evaluation reports are made public and easily 
accessible on the government website. (2015)
Implementation of evaluation recommenda -
tions (C3): Progress in implementing recom -
mendations is periodically evaluated. (2015)
1.6.3  National government’s capacity to 
ensure credible evaluations  
(Credibility of Evaluation)
National data systems (C2): The Kenya Bureau 
of Statistics is the central government agency 
responsible for collecting and analysing national 
data (e.g. demographics, economics).25
Integrated public registries (C11):  Public reg -
istries and administrative records are not inte -
grated, and challenges exist to harmonize and 
coordinate approaches across all actors for data 
collection, analysis, archiving and use. (2015)
The National M&E system is supported by an 
electronic project management information sys -
tem (which includes project M&E systems at 
the central and decentralized levels). The infor -
mation system contains integrated dissemination 
and communication mechanisms to share the 
findings and results of evaluation processes, with 
a feedback mechanism to support report dissem -
ination. (Machuka, 2014)
Methodologies (C9):  Capacity development to 
manage evaluation is one of the components of 
the National M&E system. There are technical 
courses and manuals available to guide evaluation 
work, and UNDP is supporting the government 
to develop a curriculum at the subnational and 
national levels. The Kenya School of Govern -
ment has developed M&E curricula and intro -
duced courses in M&E. Universities also have 
courses in M&E and many government staff 
and local evaluators are exposed to international 
training opportunities through the International 
Programme for Development Evaluation Train -
ing and other institutions. (2015)
To guide the work of implementing the National 
M&E system and to offset weak capacities, tech-
nical advisory groups have been established in 
all 18 national government ministries and in 47 
counties. These are groups made up of technical 
experts from the government, NGOs and devel -
opment partner agencies, which are expected to 
contribute to a more transparent mechanism for 
the assessment of results. (Machuka, 2014) 
The Monitoring and Evaluation Directorate pre-
pared national M&E indicators to track progress 
through consultation processes. The Directorate 
is collaborating with the Evaluation Society 
of Kenya for peer learning and experience-
sharing in implementing national M&E sys tems. 
The Society is also involved in other learning 
initiatives, such as South-South exchanges. 
(Machuka, 2014)
The Swedish International Development Agency 
has provided support for a Capacity Develop -
ment Programme for the NIMES and recently 
conducted a needs assessment and capacity anal -
ysis of the NIMES. The Assessment reveals that 
“after more than eight years of operations, the 
country still lagged in uptake of M&E culture 
and practices” and that capacities are needed at 
the individual and institutional levels. (Machuka, 
2014, p. 214)
Peer-to-peer systems (C5): Peer-to-peer systems 
are used. (2015)
Gender (C18): The M&E Directorate is work -
ing with UN Women to develop gender-specific 
and gender-sensitive indicators to track progress 
within plan implementation.  (Machuka, 2014) 
Evaluations take gender into considerations and 
analyses of programme impacts, and use gender-  
responsive evaluation methods.  Evaluation 
reports discuss how gender equality is addressed
<<<PAGE=34>>>
16
COUNTRY PROFILES
26 See limitations regarding generalizations about certain commitments such as budgets (C16), independent evaluators 
(C17), stakeholders’ involvement (C10), peer-to-peer systems (C5) gender (C18) and ethnic and cultural issues (C8). 
27 malawi.gov.mw/index.php?option=com_content&view=article&id=47:departments-of-the-ministry-of-develop -
ment-planning-and-cooperation&catid=6:development-planning-a-cooperation&Itemid=51
in the project or programme and evaluation data 
is disaggregated by sex. Evaluation teams have 
gender analysis expertise, but there are still gaps 
in this area (despite the theory being highlighted 
in relevant government documents). (2015)
Ethnic and cultural dimensions (C8):  Evalu -
ations take ethnic and cultural issues into con -
siderations and analyses of programme impacts. 
Evaluation reports discuss ethnic and cul -
tural issues that are addressed in the project or  
programme. Evaluation data is disaggregated by 
ethnic and cultural background. (2015)
1.7 MALAWI
1.7.1  National government’s capacity to use 
evaluations (Use of Evaluation)26
Institutional set up (C4):  Malawi conducts 
M&E routinely, but does not have a national 
evaluation policy. (Rosenstein, 2013) There are 
sectoral policies requiring evaluation of spe -
cific national programmes and there are plans 
to establish (through an act of parliament) a 
National Planning Commission with respon -
sibilities for evaluating national programmes. 
Evaluations are used to assess the impacts of all 
government programmes, for learning purposes, 
to adjust course and to scale up initiatives. (2015)
M&E is a function in the Ministry of Economic 
Planning and Development of the President and 
Cabinet. The Ministry is responsible for eval -
uating the impacts of implementing the Public 
Sector Investment Programmes of the National 
Budget. (Nyasuly, 2014) The M&E division 
has the mandate to carry out M&E exercises 
on all government programmes and projects in 
order to determine if they are achieving their 
intended objectives. It also carries out activities 
such as Malawi Growth and Development Strat-
egy (MGDS) annual reviews, Community Based 
Monitoring and Evaluation (CBME), Public 
Expenditure Tracking Survey (PETS), Perfor -
mance Auditing,27 vulnerability assessments and 
M&E. M&E departments also exist in many 
ministries and departments.
Line ministries and district and city councils 
also conduct evaluations. There are also decen -
tralized M&E units in each local council where 
M&E officers report on the progress of plan 
implementation. 
The Public Finance Management Act (2003) 
mandates that the Ministry of Finance follows 
up on budget implementation in the coun -
try in order to determine the government’s 
level of performance in line with its promises, 
to enhance transparency and to assist in deci -
sion-making. Budgetary M&E is a responsibil -
ity of the M&E Section of the Budget Division 
(Nyasuly, 2014). The Division undertakes the 
monitoring activities by comparing planned 
outputs to delivered outputs by analysing expen -
diture variations and by visiting project sites. 
(Government of Malawi, 2015)  
The Performance Enforcement Department in 
Office of the President and Cabinet (OPC) is 
in charge of monitoring budget implementa -
tion and evaluating organizational performance 
agreements against output commitments set by 
the Office and by line ministries. (Nyasuly, 2014) 
OPC missions include providing strategic leader-
ship in the development of government policies 
and programmes and ensuring implementation 
through M&E. (Government of Malawi, 2015)
The OPC has put in place mechanisms for evalu-
ating government programmes where controlling 
officers of ministries are signing an organiza -
tional performance agreement with the Chief 
Secretary in OPC. Each department is evaluated 
annually. (2015)
<<<PAGE=35>>>
17
COUNTRY PROFILES
28 nsomalawi.mw
29 See  limitations regarding generalizations about certain commitments such as budgets (C16), independent evaluators 
(C17), stakeholders’ involvement (C10), peer-to-peer systems (C5) gender (C18) and ethnic and cultural issues (C8). 
Partnerships to strengthen and promote eval -
uation (C7): Local stakeholders (professional 
organizations, universities, private sector actors, 
NGOs) and international organizations are col -
laborating and jointly advocating and promoting 
the need and demand for and use of national-  
level evaluations. (2015) 
Budgets for evaluation (C16): Some surveys 
indicated that budgets are not in place. Others 
indicated that government units responsible for 
evaluation have their own budgets and that poli -
cies, programmes and projects have resources for 
evaluation built into their budgets. (2015)
1.7.2  National government’s capacity 
for independent evaluations 
(Independence of Evaluation)
Independent evaluators (C17): Evaluations are 
conducted by independent evaluators and the 
National Statistics Office. (2015) 
Stakeholders’ involvement/access to informa -
tion (C10): Evaluation reports are made public 
and are easily available on government websites. 
(2015)
Implementation of evaluation recommenda -
tions (C3): There are no systems in place. (2015)
1.7.3  National government’s capacity to 
ensure credible evaluations  
(Credibility of Evaluation)
National data systems (C2): The National Sta -
tistics Office is the central government agency 
responsible for collecting and analysing national 
data (e.g. demographics, economics).28
Integrated public registries (C11):  Public reg -
istries and administrative records are not inte -
grated. (2015) There is a lack of an M&E 
system to coordinate input from all departments 
involved in M&E processes. (Nyasuly, 2014)
Methodologies (C9): Standards and templates 
to gather information from various ministries 
and departments do not exist. There is need to 
build capacities in the M&E section to develop 
methodologies, to redefine outputs and indica -
tors and to develop specialized evaluation skills 
within M&E offices in order to improve evalua -
tion quality. The focus on monitoring work is in 
part due to the lack of such expertise on evalua -
tion. (Nyasuly, 2014)
Peer-to-peer systems (C5): Peer-to-peer systems 
are in place. (2015)
Gender (C18): Evaluations take gender into con-
siderations and analyses of programme impacts. 
(2015)
Ethnic and cultural dimensions (C8): Accord-
ing to survey results, ethnic and cultural issues 
are not considered in national-level evaluations. 
(2015)
1.8 NIGER
1.8.1  National government’s capacity to use 
evaluations (Use of Evaluation)29
Institutional set up (C4): There has been a draft 
national evaluation policy since December 2010, 
but it has not yet been adopted. Universities and 
Professional Evaluation Networks are pushing 
for the development of national policies, struc -
tures and frameworks. (2015)
There are no national-level evaluations in the 
country, but evaluations are used to assess the 
impact of specific programmes in certain gov -
ernment sectors, for learning purposes, to adjust 
course and to scale up initiatives, usually in the 
context of informing the development of subse -
quent project or programme phases or for donor 
accountability purposes. (2015)
<<<PAGE=36>>>
18
COUNTRY PROFILES
Since 2011, Niger has been engaged in strategic 
planning with the adoption of Development of 
the Economic and Social Plan (PDES)  2012–
2015. The PDES has an enabling mechanism 
for the assessment of the sectoral effects of each 
of its programmes. An M&E system based on 
a participatory approach is part of these efforts. 
(Gouvernment du Niger, 2012) With the goal 
of being a permanent process of dialogue and 
consensus building, the M&E system focuses 
on collecting trustful information that is useful 
for decision-making and leading to corrective 
measures. The system was conceived to mon -
itor the implementation of the Plan and its 
results in order to enable the annual review of 
public spending and mid-term and final evalu -
ations of the relevance, efficiency, effectiveness 
and impact of public policies. Impact assess -
ments will focus on five to ten policies annually 
(ex-ante, ongoing and ex-post). (Ministere du 
Plan Niger, 2015)
There is no central unit that coordinates all 
aspects of the evaluation of public policies. The 
Ministry of the Plan of Territorial Manage -
ment and Community Development (Ministère 
du Plan de l’Aménagement du Territoire et du 
Développement Communautaire) coordinates 
the national development policy. Its Public Pol -
icies Evaluation Office (Bureau de l’Évaluation 
des Politiques Publiques – BEPP) is the unit 
responsible for the M&E activities related to 
PDES implementation. (2015)
Other evaluation units exist in the Ministry 
of Economy and Finance, such as the Gen -
eral Directorate for Evaluation and Programme 
Development (Direction Générale Évaluation et 
Programme de Développement) and the Direc -
torate of M&E of Projects and Programmes 
(Direction Suivi et Évaluation des Programmes et 
des Projets). 
Professional networks, such as the Nigerian 
Network of M&E (Réseau Nigérien de Suivi 
Évaluation – ReNSE) and the Niger Commu -
nity Management of the Results-based Prac -
tice (CoP-NIGER) and government institutions, 
such as the High Commissioner for Modern -
ization of the State, are making efforts to estab -
lish a culture of evaluation and results in Niger.  
(IOCE, 2012)
Partnerships to strengthen and promote evalu -
ation (C7): Stakeholders (professional organiza -
tions, universities, private sector actors, NGOs) 
and international donors are actively advocating 
and promoting the use and conduct of evalua -
tions. (2015)
ReNSE (formalized in 2010) is building on the 
increasing interest in M&E and results-based 
management in the country and on the political 
will to promote an evaluation culture in Niger. 
Budgets for evaluation (C16): Some surveys 
indicate that policies, programmes and projects 
have resources for evaluations built into their 
budgets. Others reveal that budgets are not in 
place for conducting evaluations, but there are 
plans to establish a Mutual Fund for evalua -
tion (with contributions from the state bud -
get and from financial and technical partners).  
(2015)
1.8.2  National government’s capacity 
for independent evaluations 
(Independence of Evaluation)
Independent evaluators (C17): Evaluations are 
conducted by the internal staff of government 
departments and by independent evaluators 
under contracts. (2015)
Stakeholders’ involvement/access to informa -
tion (C10): Evaluation reports are not made 
public and are not easily available on government 
websites. (2015)
Implementation of evaluation recommenda -
tions (C3): Systems are not in place to follow-up 
on these. (2015)
1.8.3  National government’s capacity to 
ensure credible evaluations  
(Credibility of Evaluation)
<<<PAGE=37>>>
19
COUNTRY PROFILES
30 stat-niger.org/statistique
31 See  comment on limited depth and explanations about certain issues.
32 See  limitations regarding generalizations about certain commitments such as budgets (C16), independent evaluators 
(C17), stakeholders’ involvement (C10), peer-to-peer systems (C5) gender (C18) and ethnic and cultural issues (C8). 
National data systems (C2): The National Sta -
tistics Institute ( Institut National de la Statis -
tique – INS ) is the central government agency 
responsible for collecting and analysing national 
data (e.g. demographics, economics).30
Integrated public registries (C11):  The survey 
indicates that public registries and administra -
tive records are integrated. INS releases several 
types of reports; periodically, Niger Info provides 
online information. (2015)
Methodologies (C9):  There are no technical 
courses or manuals available. 31 (2015) ReNSE is 
discussing possible partnerships with the Uni -
versity of Niamey and the National School of 
Administration and Magistracy (Ecole Nationale 
de l’Administration et de la Magistrature). 
The African Development Bank, in collabo -
ration with the Ministry of Planning and the 
African Community of Practitioners in Man -
aging for Results and Performance (AfCoP), 
organized a workshop to launch a community 
of results-based practice in Niger. (Ministere du 
Plan Niger, 2015)
Peer-to-peer systems (C5): Peer-to-peer systems 
are not used. (2015)
Gender (C18): Evaluation data is disaggregated 
by sex, especially in sectors such as health and 
education. In certain areas, evaluation reports 
discuss how gender equality is addressed in the 
project or programme. (2015)
Ethnic and cultural dimensions (C8): There 
are indications that ethnic and cultural issues 
are not adequately considered in national-level 
evaluations. A survey respondent noted that eth-
nic aspects are not considered, although cultural 
aspects are taken in account. (2015)
1.9 NIGERIA
1.9.1  National government’s capacity to use 
evaluations (Use of Evaluation)32
Institutional set up (C4): There are sectoral pol-
icies requiring evaluation of specific national pro-
grammes. (2015) A Draft National M&E Policy 
Framework is awaiting approval and legislation 
by the National Parliament in Nigeria. The coun-
try uses evaluations to assess the impacts of all 
government programmes, for learning purposes, 
to adjust course and to scale up initiatives. (2015)
The Department of M&E was established in the 
Presidency National Planning Commission in 
2010 in order “to improve the  quality and dis -
semination of government performance informa-
tion for accountability and policy improvement 
purposes.” Its responsibilities include developing 
a framework to support M&E and reporting on 
national government performance in line with 
national development goals. The Department is 
responsible for monitoring and evaluating the 
performance of government policies the sectoral 
level, the performance of government institu -
tions and the effectiveness and impact of public 
programmes. The Department of Social Devel -
opment also has responsibilities for M&E of 
their sectoral projects and programmes. (National 
Planning Commission, 2015)
Partnerships to strengthen and promote eval -
uation (C7): Local stakeholders (professional 
organizations, universities, private sector actors, 
NGOs) and international organizations are col -
laborating and jointly advocating and promoting 
the need and demand for and use of national-  
level evaluations. (2015)
The Nigeria Evaluation Association (NEA) was 
founded in 2011 with the goals of developing a 
standardized, professional evaluation practice in
<<<PAGE=38>>>
20
COUNTRY PROFILES
33 nigerianstat.gov.ng
34 See  limitations regarding generalizations about certain commitments such as budgets (C16), independent evaluators 
(C17), stakeholders’ involvement (C10), peer-to-peer systems (C5) gender (C18) and ethnic and cultural issues (C8). 
Nigeria; developing programmes to guide evalu -
ation practice; and helping to build understand -
ing of international developments and trends in 
M&E. The Network also aims at establishing 
and maintaining collaborations and affiliations 
with the public sector and third sector organiza -
tions and institutions. (IOCE, 2012) 
Budgets for evaluation (C16): Some survey 
respondents indicate that there are no budgets in 
place to conduct evaluations. Others mentioned 
that government units are responsible for evalua-
tions and have their own budgets. 
1.9.2  National government’s capacity 
for independent evaluations 
(Independence of Evaluation)
Independent evaluators (C17):  Evaluations are 
conducted by the internal staff of government 
departments. There are cases in which indepen -
dent evaluators under contract conducted eval -
uations.
Stakeholders’ involvement/access to informa -
tion (C10): Annual M&E reports by the M&E 
Department are available on government websites. 
Implementation of evaluation recommenda -
tions (C3): According to the survey, there are no 
systems in place to follow-up on the implemen -
tation of evaluation recommendations. 
1.9.3  National government’s capacity to 
ensure credible evaluations  
(Credibility of Evaluation)
National data systems (C2): The National Bureau 
of Statistics is the central government agency 
responsible for collecting and analysing national 
data (e.g. demographics, economics) in Nigeria.33
Integrated public registries (C11):  Public reg -
istries and administrative records are not inte -
grated. (2015)
Methodologies (C9): The Department of M&E 
of the Presidency National Planning Commis -
sion has the responsibility of developing evalua -
tion capacities across the government, developing 
performance indicators and targets and data 
management systems (including data collection 
tools, identification of data sources, frequency 
of data collection and data transmission plans). 
(National Planning Commission, 2015)
The Nigerian Evaluation Association has goals 
related to developing and strengthening the 
capacity of members through coordinated train -
ings on the fundamentals, tools and method -
ologies of evaluation. It aims to promote high 
quality intellectual, ethical and professional stan-
dards in the evaluation profession in Nigeria and 
to promote the development and adoption of 
M&E approaches and methods suitable to Nige-
ria’s development context.
Peer-to-peer systems (C5): Peer-to-peer systems 
are not used. (2015)
Gender (C18): Survey results indicate that eval -
uations take gender into their considerations and 
analyses of programme impacts; evaluation data 
is disaggregated by sex. 
Ethnic and cultural dimensions (C8):  The sur-
vey reveals that evaluations take ethnic and cul -
tural issues into their considerations and analyses 
of programme impacts.
1.10 SOUTH AFRICA
1.10.1  National government’s capacity to use 
evaluations (Use of Evaluation)34
Institutional set up (C4):  Evaluations are used 
in South Africa to assess the impacts of gov -
ernment programmes, to assess the impacts of 
specific programmes in certain government sec -
tors, for learning purposes, to adjust course and
<<<PAGE=39>>>
21
COUNTRY PROFILES
to scale up initiatives. Evaluations are used for 
governments to provide accountability for their 
actions. (2015)
The Government of South Africa approved the 
National Evaluation Policy Framework in 2011, 
setting the basis for government-wide evaluation 
focused on priority areas. The Framework aims to 
contribute to establishing a culture of continuous 
improvement in service delivery. It establishes the 
foundation for the National Evaluation System 
(NES) and the implementation of the National 
Evaluation Plan. 
The national evaluation system is led by the Evalu-
ation and Research Unit (ERU) of the Department 
of Performance M&E (DPME) and supported by 
a cross-government Evaluation Technical Work-
ing Group. (Government of South Africa, 2015) 
As indicated by the survey, evaluations are con -
ducted by individual government departments in 
partnership with DPME. DPME has focused on 
trying to create a utilization-focused and demand-
driven evaluation system. (UNDP IEO, 2014) In 
addition, an Evaluation Technical Working Group 
has been established to support DPME in taking 
forward evaluation nationally and ensuring broad 
buy-in across government. The Working Group 
is made up of the main departments that have 
evaluation capacity, plus the Public Service Com-
mission, the Department of Public Service and 
Administration, the National Treasury and the 
Auditor General.
Some provinces have evaluation plans that are 
managed in the Offices of the Premier; there 
are initiatives to encourage the development of 
departments’ evaluation plans. (2015)
The government uses evaluations to improve 
policies’ performance and development impact, 
to improve accountability of public expenditures, 
to improve decision-making and to increase the 
knowledge base around the government’s work. 
The National/Provincial Treasury is required to 
utilize evaluation report findings and recommen-
dations as a source of evidence in supporting the 
budget process. The Framework mandates that 
departments use evaluation findings in subse -
quent planning and budgeting processes. (Gov -
ernment of South Africa, 2015)
A 2012 survey by DPME describes M&E infor -
mation as having limited or no influence on 
decision-making and integration with policy 
development as either non-existent or very limited 
(as viewed by 46 percent of respondents). Integra-
tion of M&E with budgeting was also viewed as 
limited (48 percent of respondents). This was con-
sidered a poor environment for the demand and 
use of M&E evidence when viewed as a stand-
alone activity that is detached from other key 
management processes. (Goldman, 2014)
Parliamentarians promoting evaluation use 
(C6): Parliamentarians are actively advocating 
and promoting the use and conduct of evalua -
tions. (2015)
Partnerships to strengthen and promote eval -
uation (C7): Local stakeholders (professional 
organizations, universities, private sector actors, 
NGOs) and international organizations are col -
laborating and jointly advocating and promoting 
the need and demand for and use of national-  
level evaluations. (2015)
The DPME has been stimulating the demand 
for evaluations more widely. It has piloted the 
development of provincial evaluation plans with 
the Western Cape and Gauteng Provinces; three 
departments have developed departmental eval -
uation plans. This aims to stimulate a wider use 
of evaluation than could be covered under the 
national evaluation plan, and also stimulates 
departments and provinces to think of what 
they should undertake themselves (as opposed to 
those with major national interests and that are 
covered in the national evaluation plan).
The partnership between the Government of 
South Africa and the South African M&E 
Association (SAMEA) seeks to develop eval -
uation capacity in the country and to assist in 
the institutionalization of evaluation in various 
sectors of society (government, academia, civil
<<<PAGE=40>>>
22
COUNTRY PROFILES
35 See comment on limitations regarding generalizations about certain commitments. 
36 dpme.gov.za/keyfocusareas/evaluationsSite/Pages/default.aspx
society, private sector consulting firms, founda -
tions and development partners and the donor 
community). The DPME and SAMEA signed 
a general Memorandum of Understanding to 
collaborate on strengthening capacity building 
and enhancing evaluation credibility.  (IOCE, 
2012) There are examples of partnership in tak -
ing evaluation practices forward, such as the 
flagship biennial conference of SAMEA, the 
establishment of provincial chapters, joint proj -
ects and consultative work on the development 
of evaluation frameworks, competencies and 
standards. (2015)
Budgets for evaluation (C16): Government 
units responsible for evaluation have their own 
budgets to conduct evaluation. Policies allocate 
budgets for evaluations in programme budgets 
and make them available; policies, programmes 
and projects have resources for evaluation built 
into their budgets.35 (2015)
1.10.2  National government’s capacity 
for independent evaluations 
(Independence of Evaluation)
Independent evaluators (C17): Evaluations are 
conducted by independent evaluators under con-
tracts. The evaluations are supervised by govern -
ment experts and DPME officials. (2015)
Stakeholders’ involvement/access to infor -
mation (C10): All evaluations in the national 
evaluation plan are implemented through part -
nerships with the custodian departments who 
have committed to implementing improvements 
to programmes and policies informed by evi -
dence generated through the evaluations. (Gov -
ernment of South Africa, 2015)
A Government of South Africa website provides 
insights into the National Evaluation System. 36 
The National Evaluation Policy Framework 
also calls for the communication of evaluation 
results through the development of a strategy 
for the dissemination of the evaluation report, 
including publishing evaluation reports on rele -
vant websites, developing communication mate -
rials on the evaluation and sharing findings 
with key stakeholders and the media. (Govern -
ment of South Africa, 2015) The DPME must 
also ensure that the full evaluation reports are 
posted on their websites and that management 
responses are made public and easily available. 
(2015)
Evaluation audits are made available through 
an evaluation repository on the DPME website. 
There are plans to make all evaluations that were 
undertaken through the national evaluation plan 
public (after the evaluations have been submitted 
to the cabinet). 
Implementation of evaluation recommenda -
tions (C3):  Evaluators must produce improve -
ment plans, which are monitored every six 
months for two years. (2015)
The Evaluation Framework calls for the formu -
lation of recommendations to be prepared with 
stakeholders. Evaluation users should analyse 
and have the right to indicate their agreement 
(or lack of thereof ) with findings and recommen-
dations. Senior government management levels 
should respond to those findings and recommen-
dations and write a management response, either 
accepting the results or indicating where they 
disagree and providing reasons why. After these, 
the department being evaluated should prepare 
an improvement plan in response to the evalu -
ation, detailing necessary improvement actions. 
Progress made in their implementation should be 
monitored by the same department and reported 
to the DPME (or the Offices of the Premier) 
on a three-month basis. (Government of South 
Africa DPME, 2015)
The DPME is required to report to the Cabinet 
and Offices of the Premier on the progress related
<<<PAGE=41>>>
23
COUNTRY PROFILES
37 According to the survey, DPME has also the following tools to monitor implementation of evaluations work: citizens-  
based monitoring, a management performance assessment tool, government-wide M&E, frontline service delivery mon-
itoring, government performance information and a presidential hotline.
38 statssa.gov.za
to evaluations of the national plan (including  
follow-up).37 
1.10.3  National government’s capacity to 
ensure credible evaluations  
(Credibility of Evaluation)
National data systems (C2): Statistics South 
Africa (Stats SA) is the central government 
agency responsible for collecting and analysing 
national data (e.g. demographics, economics).38
Integrated public registries (C11):  Public reg -
istries and administrative records are not inte -
grated. (2015)
Methodologies (C9):  Training has been con -
ducted to ensure evaluation capability in all gov -
ernment departments. Technical courses and 
manuals are available to guide evaluation work. 
The Department of Public Service and Admin -
istration has established the School of Govern -
ment in order to help build the capacities of 
public servants, including in M&E. Universities 
in South Africa have different courses on M&E. 
South Africa has developed a quality assurance 
system for monitoring national statistics. (2015)
The government website includes guidelines 
and templates, evaluation standards, competen -
cies for evaluators and government staff manag -
ing evaluations and a suite of courses that have 
been developed to support the system. The site 
also provides a link to a repository of evaluations 
carried out since 2006 that have been through 
a quality assessment process. (Government of 
South Africa, 2015)
SAMEA organizes workshops and training to 
enhance individual capacity to conduct credible 
evaluations in collaboration with national and 
provincial governments, foundations, universi -
ties and others, including annual capacity build -
ing workshops and a bi-annual conference to 
upgrade evaluation skills and to share best prac -
tices internationally.      
Peer-to-peer systems (C5): All evaluations in the 
national evaluation system must have at least two 
peer reviewers, including one to review the meth-
odology and the other as a sector specialist. They 
review the deliverables throughout the evaluation 
process and assist with ensuring its quality. (2015)
The evaluation framework calls for the establish-
ment of a peer review process for external (and 
some internal) evaluations to ensure that they 
are credible. This can include peer departments 
or a panel of evaluators. Peer reviews look at the 
process as well as the product, and how far the 
conditions for utilization have been established. 
It is recommended that two appropriately qual -
ified people should be critical reviewers of each 
evaluation, which should be budgeted for as part 
of the evaluation budget. They should give feed -
back in a session with the department. It is also 
valuable to undertake a validation process where 
the findings of the draft report are presented 
to a workshop of stakeholders. (Government of 
South Africa DPME, 2015)
Gender (C18): Survey results for this Study 
reveal some variations regarding the extent of 
gender consideration in evaluation. Some indi -
cate that evaluations take gender into their con -
siderations and analyses of programme impacts; 
some indicate that gender is rarely properly con -
sidered. Other responses indicate that evaluation 
reports discuss how gender equality is addressed 
in the project or programme, that evaluation 
data is disaggregated by sex, that evaluation uses  
gender-responsive evaluation methods and that 
evaluation teams have gender analysis expertise.  
The survey also reveals that there is work in prog-
ress related to making evaluation more gender-  
responsive and sensitive.
<<<PAGE=42>>>
24
COUNTRY PROFILES
39 See limitations regarding generalizations about certain commitments such as budgets (C16), independent evaluators 
(C17), stakeholders’ involvement (C10), peer-to-peer systems (C5) gender (C18) and ethnic and cultural issues (C8). 
40 It  is possible that changes have been in place since the source date. However, website data does not contradict the source. 
As such, this information was included in the study as an important as a point of departure for future work. 
Ethnic and cultural dimensions (C8):  Some 
surveys indicate that national-level evaluations 
do not properly consider ethnic and cultural 
issues. Other responses indicate that evaluations 
take ethnic and cultural issues into their consid -
erations and analyses of programme impacts and 
that evaluation data is disaggregated by ethnic 
and cultural background. 
1.11 TANZANIA
1.11.1  National government’s capacity to use 
evaluations (Use of Evaluation)39
Institutional set up (C4):  Tanzania routinely 
conducts evaluations, but does not have a national 
evaluation policy. (Rosenstein, 2015) Although 
there are no national-level evaluations, sectoral 
policies requiring evaluation of specific national 
programmes exist and evaluations are used to 
assess impact of specific programmes in certain 
government sectors. (2015)     
The M&E Section in the Ministry of Finance 
was established in 2000 to monitor and evaluate 
all poverty alleviation strategies and initiatives in 
the country; it has been the primary driver for 
M&E in Tanzania. In 2005, the government ini-
tiated a process to harmonize the requirements 
of planning, M&E and reporting for institutions 
across the government. The ‘Medium-term Stra-
tegic Planning and Budgeting Manual’ was devel-
oped to guide the preparation of strategic plans, 
medium-term expenditure frameworks and mon-
itoring and reporting. (Magembe, 2011)40 
Demand for evaluations increased with the incep-
tion of the Tanzania Development Vision 2025 
and international assistance programmes, such as 
the 2000 Poverty Reduction Strategy Paper and 
the Joint Assistance Strategy for Tanzania, which 
“created a strong ground for a more systematic 
approach to poverty monitoring” and fostered the 
development of a comprehensive Poverty Moni -
toring System. (Magembe, 2011, p. 31)
There is no central government unit in charge 
of conducting evaluations. An M&E Section 
exists in the President’s Office – Public Service 
Management Division that performs M&E 
activities that are mostly linked to the Division’s 
work, such as monitoring the implementation 
of its Annual Plan and Medium-term Strate -
gic Plan and corresponding periodic perfor -
mance reports, in order to provide support for 
the institutionalization of M&E process within 
the division and to conduct impact studies of 
its plans, projects and programmes. The Section 
is also tasked with coordination and M&E of 
the various components of the Poverty Reduc -
tion Strategy Paper. (Government of Tanzania 
PO-PSM, 2015)
The M&E Section of the Ministry of Finance 
has responsibilities to monitor the implementa -
tion of the Ministry’s Annual Plan and Medium- 
term Strategic Plan, to prepare periodic perfor -
mance reports, to provide support for the institu-
tionalization of M&E process within the division 
and to conduct impact studies of plans, proj -
ects and programmes. (Government of Tanzania 
MOF, 2015)
A Planning and Monitoring Division in the 
President’s Office Planning Commission is 
responsible for providing expertise and services 
in planning, implementation, M&E, ensuring 
internal and external evaluation of the Com -
mission’s activities and targets and providing for 
informed decision-making. Its M&E section 
monitors the implementation of the Commis -
sion’s Annual Plan and Medium-term Strategic 
Plan and prepares periodic performance reports. 
(Government of Tanzania Planning Commis -
sion, 2015)
<<<PAGE=43>>>
25
COUNTRY PROFILES
41 nbs.go.tz
42 See  limitations regarding generalizations about certain commitments such as budgets (C16), independent evaluators 
(C17), stakeholders’ involvement (C10), peer-to-peer systems (C5) gender (C18) and ethnic and cultural issues (C8). 
Parliamentarians promoting evaluation use 
(C6): In 2014, Tanzanian parliamentarians 
signed a declaration (Yaoundé Declaration of 
African Parliamentarians on Evaluation) recog -
nizing “the important function of evaluation in 
national decision-making and the crucial role of 
parliamentarians in ensuring evaluation evidence 
is used for strengthening decision-making for 
greater development effectiveness and inclusive 
growth.” (Rosenstein, 2015)
Partnerships to strengthen and promote 
evaluation (C7): Universities and professional 
evaluation networks are pushing for the 
development of National policies, structures and 
frameworks. Local stakeholders (professional 
organizations, universities, private sector 
actors, NGOs) and international organizations 
are collaborating and jointly advocating and 
promoting the need and demand for and use of 
national-level evaluations. (2015) The Tanzania 
Evaluation Society (TanEA) is advocating 
that the government creates and maintains an 
appropriate regulatory M&E framework in the 
country. (IOCE, 2012)
Budgets for evaluation (C16): Budgets are not 
in place for the conduct of evaluations. (2015)      
1.11.2  National government’s capacity 
for independent evaluations 
(Independence of Evaluation)
Independent evaluators (C17):  Evaluations are 
conducted by independent evaluators under con-
tracts with consultancy firms and research insti -
tutions. 
Implementation of evaluation recommenda -
tions (C3):  Follow-up on the implementation 
of evaluation recommendations is considered a 
challenge. (2015)
1.11.3  National government’s capacity to 
ensure credible evaluations  
(Credibility of Evaluation)
National data systems (C2): The National 
Bureau of Statistics is the central government 
agency responsible for collecting and analysing 
national data (e.g. demographics, economics).41
Integrated public registries (C11):  Public reg -
istries and administrative records are not inte -
grated. (2015)
Methodologies (C9):  Technical courses and 
manuals to guide evaluation work are not widely 
available. (Baseline Study Survey, 2015) The gov-
ernment has been making efforts to build capac -
ities of the staff responsible for M&E functions 
across government institutions.      
Peer-to-peer systems (C5): Peer-to-peer systems 
are not used. (2015) 
Gender (C18): Survey respondents indicate that 
evaluations take gender into their considerations 
and analyses of programme impacts and that 
evaluation data is disaggregated by sex. (2015)
1.12 UGANDA
1.12.1  National government’s capacity to use 
evaluations (Use of Evaluation)42
Institutional set up (C4) : Evaluations are used 
to assess the impacts of all government pro -
grammes, for learning purposes, to adjust course, 
to scale up initiatives and to provide accountabil-
ity for government actions. (2015)
The development of M&E in Uganda is linked 
to the government’s need to measure progress 
towards the implementation of its 1997 Plan for 
the Eradication of Poverty (PEAP) and the “need 
to demonstrate performance and responsiveness
<<<PAGE=44>>>
26
COUNTRY PROFILES
43 It is possible that changes have been in place since the source date. However, website data does not contradict the source. 
As such, this information was included in the study as an important as a point of departure for future work. 
44 ubos.org
to citizens’ demands as an indicator of good gov-
ernance.” (Byamugisha, 2011, p. 64) 43 Uganda’s 
National Evaluation Policy was formalized in 
2014. (Rosenstein, 2015) 
The Office of the Prime Minister (OPM) is 
constitutionally mandated to lead government 
business in the parliament. The OPM is also 
responsible for coordinating M&E of govern -
ment policies and programmes. A unit in the 
OPM, the M&E Division of Policy Coordina -
tion, coordinates M&E work to semi-annually 
and annually review the performance of all min -
istries, departments and agencies against stipu -
lated targets. (CLEAR, 2012) 
Parliamentarians promoting evaluation use 
(C6): In 2014, parliamentarians from Uganda 
signed a declaration (Yaoundé Declaration of 
African Parliamentarians on Evaluation) recog -
nizing “the important function of evaluation in 
national decision-making and the crucial role of 
parliamentarians in ensuring evaluation evidence 
is used for strengthening decision-making for 
greater development effectiveness and inclusive 
growth.” (Rosenstein, 2015)
Partnerships to strengthen and promote eval -
uation (C7): Local stakeholders (professional 
organizations, universities, private sector actors, 
NGOs) and international organizations are col -
laborating and jointly advocating and promoting 
the need and demand for and use of national-  
level evaluations. (2015) The Uganda Evalua -
tion Association’s (UEA) mission is “to promote 
the practice, use, quality and ethics of M&E in 
Uganda’s development process.”      
Budgets for evaluation (C16): Evaluation bud -
gets are not always available. (2015)
1.12.2  National government’s capacity 
for independent evaluations 
(Independence of Evaluation)
Independent evaluators (C17): Evaluations are 
conducted by the internal staff of government 
departments and by independent evaluators 
under contracts. (2015)
Stakeholders’ involvement/access to informa -
tion (C10): Evaluation reports are made public 
and are easily available on government websites. 
(2015) A Presidential initiative, Baraza Pro -
gramme, was adopted in 2009 as a platform for 
citizen’s participation in monitoring and demand 
for the use of public resources in local govern -
ment service delivery. The Programme is planned 
to be carried out in 32 districts by the M&E unit 
of the OPM in 2014 and 2015. (Government of 
Uganda OPM, 2015)
Implementation of evaluation recommen -
dations (C3): Monitoring work involves field 
inspections and presentation of findings in a 
report to the relevant minister; recommendations 
are presented to the cabinet. 
1.12.3  National government’s capacity to 
ensure credible evaluations  
(Credibility of Evaluation)
National data systems (C2): The Uganda Bureau 
of Statistics is the central government agency 
responsible for collecting and analysing national 
data (e.g. demographics, economics).44
Integrated public registries (C11):  Public reg -
istries and administrative records are not fully 
integrated. (2015)
Methodologies (C9):  The Uganda Manage -
ment Institute and other institutions offer tech -
nical courses to guide evaluation work. (2015) 
The Uganda Evaluation Association is working 
towards building capacities in M&E through 
formal and informal training, the sharing of lit -
erature, methods, procedures and practical eval -
uation frameworks. Evaluation standards and 
guidelines for the public sector  were developed
<<<PAGE=45>>>
27
COUNTRY PROFILES
45 It is possible that changes have been in place since the source date. However, website data does not contradict the source. 
As such, this information was included in the study as an important as a point of departure for future work. 
46 See  limitations regarding generalizations about certain commitments such as budgets (C16), independent evaluators 
(C17), stakeholders’ involvement (C10), peer-to-peer systems (C5) gender (C18) and ethnic and cultural issues (C8). 
by the OPM in collaboration with the Uganda 
Evaluation Association. (IOCE, 2012)
Gender (C18):  Evaluations take gender into 
their considerations and analyses of programme 
impacts and use gender-responsive evaluation 
methods. Evaluation reports discuss how gen -
der equality is addressed in the project or pro -
gramme, and evaluation data is disaggregated by 
sex. Evaluation teams have gender analysis exper-
tise. (2015). The Uganda Evaluation Association 
has produced evaluation standards that require 
evaluators to incorporate gender approaches. 
(UNDP NEC, 2015)
Ethnic and cultural dimensions (C8): Eval-
uations take ethnic and cultural issues into 
their considerations and analyses of programme 
impacts. Evaluation reports discuss ethnic and 
cultural issues. (2015)
Coordination practices (C14): A recent assess -
ment of monitoring teams within the govern -
ment by the Ministry of Public Service indicates 
that at least twelve central government agencies 
have some role in conducting monitoring of pub-
lic service provision. Further, there are cases of 
duplication of efforts with different Ministries’ 
monitoring agents not necessarily sharing infor -
mation collected or publicly released with each 
other. (Van Hoot, 2012)45 
2. ARAB STATES
2.1 EGYPT
2.1.1  National government’s capacity to use 
evaluations (Use of Evaluation)46
Institutional set up (C4):  There is no legally 
binding institutional set-up for evaluations 
in Egypt. There are proposals in place to 
institutionalize evaluation, but they have not yet 
been legislated. Universities and professional 
evaluation networks are pushing for the 
development of national policies, structures and 
frameworks. (2015)
Efforts to launch an M&E performance-based 
budgeting process in Egypt date back to 2003, 
when the Ministry of Finance formalized 
(through a decree) the setting up M&E units 
within the government administration. 
Egypt subsequently underwent a revolution in 
2011 that increased economic and political insta-
bility, “which not only makes development M&E 
reporting more difficult to conduct because of 
funding constraints, but also undermines its sig -
nificance in the context of a country in crisis.” 
(Abdelhamid, 2014, p. 236) The constitutional 
reforms that followed were also viewed as an 
opportunity for making evaluations mandatory in 
Egypt going forward, although this Study did not 
find information about concrete developments.
Generally, there is lack of interest and under -
standing in Egypt of development M&E and 
its importance in the context of development 
projects. (Abdelhamid, 2014, p. 235) The culture 
of generating, utilizing and exchanging infor -
mation is weak and there is need for stronger 
systems that address transparency, efficiency and 
accountability.      
Partnerships to strengthen and promote eval -
uation (C7): Several institutions (government, 
voluntary organizations for professional evalua -
tion, parliament and private sector entities) are 
coordinating efforts and jointly promoting the 
need and demand for and use of national-level 
evaluation. International organizations are also 
advocating and promoting the use of evaluations. 
The Egyptian Association for National Evalua -
tion (EGY-EVAL) and the Egyptian Research 
and Evaluation Network (EREN) are also pro -
moting evaluation. (2015)
<<<PAGE=46>>>
28
COUNTRY PROFILES
47 For more information, see eg.undp.org/content/egypt/en/home/presscenter/articles/SocialContractCenterNews.html.
48 capmas.gov.eg
49 See  limitations regarding generalizations about certain commitments such as budgets (C16), independent evaluators 
(C17), stakeholders’ involvement (C10), peer-to-peer systems (C5) gender (C18) and ethnic and cultural issues (C8). 
50 Lebanon  is now entering its fifth year facing the economic and social impacts of the Syrian crisis. Over one million 
Syrians, about a quarter of the Lebanese population, have taken refuge in Lebanon. The conflict has been straining 
public finances, service delivery and the environment, among others. For more information on this, see Worldbank.org/
en/country/lebanon/overview.
The International Policy Centre for Inclu -
sive Growth (IPC-IG) worked closely with 
UNDP Egypt and the Egyptian government to 
strengthen monitoring and impact evaluation of 
their development policies and programmes.47 
Prior to 2011, the Ministry of Finance was lead -
ing advocacy work at different levels, including 
the involvement of parliamentary members to 
review progress and overcome obstacles with 
implementing M&E performance-based bud -
geting. The Ministry held press conferences and 
prepared bulletins and publications documenting 
the government’s progress towards creating a cul-
ture of performance. (Abdelhamid, 2014)
EREN is also working to develop the capacities  
of national partners and to disseminate knowledge 
to proliferate evaluation culture and practice. 
The Network has been active advocating for 
evidence-based policies, bridging the gap between 
policy makers and researchers and evaluators. 
The Network has been interested in contributing 
to the creation of an enabling environment to 
professionalize the evaluation function, to improve 
programming and to promote equitable evidence-
based decision-making. (IOCE, 2012)
2.1.2  National government’s capacity to 
ensure credible evaluations  
(Credibility of Evaluation)
National data systems (C2): The Central Agency 
for Public Mobilization and Statistics is the cen -
tral government agency responsible for collecting 
and analysing national data (e.g. demographics, 
economics).48
Methodologies (C9):  In the context of the  
performance-based budgeting, 1,500 government 
officials were trained for the establishment of 
M&E systems. Guidelines and standards are 
not available and there is limited accountability 
regarding professional ethics. EREN is engaged 
in capacity development activities for evaluation 
as mechanism to enhance ownership, harmoni -
zation and sustainability of donor interventions. 
Network activities include developing seminars 
and a one-year professional diploma on research 
and evaluation. (IOCE, 2012)
Gender (C18): Evaluation data is disaggregated 
by sex and evaluation teams have gender analysis 
expertise. (2015)
2.2 LEBANON
2.2.1  National government’s capacity to use 
evaluations (Use of Evaluation)49
Institutional set up (C4): Lebanon does not have 
requirements for evaluations, and they are not sys-
tematically conducted in the country.50  There are 
no efforts in place to develop national policies, 
structures or frameworks requiring evaluation.     
There is no central or decentralized unit in the 
government that is in charge of conducting eval -
uations; the country does not have national gov -
ernment evaluations. (2015)
The Government’s Office of the Minister of State 
for Administrative Reform (OMSAR) seeks to 
develop the institutional and technical capaci -
ties of Lebanese ministries, central bodies, pub -
lic agencies and municipalities. It is in charge of 
identifying, implementing and evaluating devel -
opment projects that translate strategies into 
action. OMSAR is working to implement mod -
ern management techniques in public adminis -
<<<PAGE=47>>>
29
COUNTRY PROFILES
51 For more information, see: cas.gov.lb/index.php.
52 See  limitations regarding generalizations about certain commitments such as budgets (C16), independent evaluators 
(C17), stakeholders’ involvement (C10), peer-to-peer systems (C5) gender (C18) and ethnic and cultural issues (C8). 
tration in Lebanon. One of its future projects is 
to activate public resources management, intro -
ducing quality management concept and adopt -
ing effective mechanisms to combat corruption. 
(Office of the Minister of State for Administra -
tive Reform, 2011)
OMSAR developed the Strategy for the Reform 
and Development of Public Administration for 
Egypt in 2011. The document notes that mon -
itoring, assessment and accountability are not 
practised efficiently or correctly at the public 
administration and that the country lacks politi -
cal commitment to administrative development. 
The Strategy describes the adoption of “seri -
ous accountability and monitoring at the pub -
lic administration” as one of the main principles 
that “ought to be applied.” (Office of the Minister 
of State for Administrative Reform, 2011, p. 8) 
Restructuring and updating the roles and duties 
of monitoring bodies is one of the most important 
goals to reform and develop the public adminis -
tration, along with building institutional capaci -
ties, reinforcing the role of strategic planning and 
making policies and governance transparent and 
accountable. The document also sets a plan to 
reform and develop the public administration. The 
plan is comprised of programmes such as a public 
administration capacity-building programme to 
restructure monitoring bodies and to establish the 
concept of reaching and measuring achievements. 
Partnerships to strengthen and promote evalu -
ation (C7): International organizations are advo-
cating and promoting the use of evaluations. 
(2015)
 Budgets for evaluation (C16):  Budgets are not 
in place for the conduct of evaluations. (2015)
2.2.2  National government’s capacity 
for independent evaluations 
(Independence of Evaluation)
Stakeholders’ involvement/access to informa -
tion (C10): Evaluation reports are not made 
public and are not easily available on government 
websites. (2015)
Implementation of evaluation recommenda -
tions (C3):  There are no systems in place to 
follow up on the implementation of evaluation 
recommendations. (2015)
2.2.3  National government’s capacity to 
ensure credible evaluations  
(Credibility of Evaluation)
National data systems (C2): The Central 
Administration of Statistics is the central gov -
ernment agency responsible for collecting and 
analysing national data (e.g. demographics, eco -
nomics).51 Integrated public registries (C11):  
Public registries and administrative records are 
not integrated. (2015)
Methodologies (C9):  There are no technical 
courses or manuals available to guide evaluation 
work. (2015)
Peer-to-peer systems (C5): Peer-to-peer systems 
are not used. (2015) 
2.3 MOROCCO
2.3.1  National government’s capacity to use 
evaluations (Use of Evaluation)52
Institutional set up (C4):  Sectoral policies 
requiring evaluation of specific national pro -
grammes exist in Morocco. Evaluations are used 
to assess the impacts of all government pro -
grammes. Evaluations are used for governments 
to provide accountability for their actions, for 
learning purposes, to adjust course and to scale 
up initiatives. (2015)
The 2011 National Constitution emphasized 
the need for evaluation of public policies at the
<<<PAGE=48>>>
30
COUNTRY PROFILES
53  hcp.ma/Institut-National-de-Statistique-et-d-Economie-Appliquee_a738.html
national level and evaluation of their implemen -
tation at the local level. Although there is no 
central unit in the government in charge of con -
ducting evaluations, many government depart -
ments conduct evaluations and assessments. 
However, there is no clear and common defini -
tion of evaluation across all institutions. (2015)
The National Programme Evaluation Cen -
tre at the High Planning Commission (Haut-  
Commissariat au Plan) is tasked with develop -
ing evaluation functions in the public sector. The 
Commission has the responsibility for develop -
ing evaluation of public policy, programmes and 
projects in collaboration with the ministries and 
local authorities; for preparing evaluation surveys 
and studies that contribute to the diffusion of 
research and evaluation methodologies; and for 
contributing to evaluations of international coop-
eration programmes. The Centre is also tasked 
with organizing evaluation training and ensuring 
the dissemination of evaluation practices. (High 
Planning Commission Morocco, 2015)
The Audit and Evaluation unit of the General 
Inspection division (Inpection Générale) in the 
High Planning Commission (HPC) is charged 
with evaluating the activities of the HCP and 
then reporting on results against HCP objec -
tives and costs. The Regional Directorates of the 
Commission also have responsibilities for M&E 
of the local and regional plans for social and eco-
nomic development. (High Planning Commis -
sion Morocco, 2015)
Parliamentarians promoting evaluation use 
(C6): Parliamentarians are actively advocating 
and promoting the use and conduct of evalua -
tions. Other stakeholders (professional organi -
zations, universities, private sector actors, NGOs, 
government, voluntary organizations for profes -
sional evaluation, parliament and private sector 
entities), along with international organizations, 
are actively advocating and promoting the use 
and conduct of evaluations and are coordinating 
efforts to promote the need and demand for and 
use of national-level evaluations. (2015) Founded 
in 2008, the Moroccan Association of Evalua -
tion (L’Association Marocaine de l’Évaluation 
– AME) utilized public debates on public pol -
icy evaluation to influence the process of insti -
tutionalizing evaluation of public policies in the 
country.      
Budgets for evaluation (C16): Government units 
responsible for evaluation have their own budgets 
to conduct evaluation. Policies, programmes and 
projects have resources for evaluations built into 
their budgets. (2015)
2.3.2  National government’s capacity 
for independent evaluations 
(Independence of Evaluation)
Independent evaluators (C17): Evaluations are 
conducted by the internal staff of government 
departments and independent evaluators under 
contracts. (2015)
Stakeholders’ involvement/access to informa -
tion (C10): Evaluation reports are not easily 
available on government websites. The publica -
tion of evaluations is not systematic. (2015)
Implementation of evaluation recommenda -
tions (C3):  There are no systems in place to 
follow up on the implementation of evaluation 
recommendations. (2015)
2.3.3  National government’s capacity to 
ensure credible evaluations  
(Credibility of Evaluation)
National data systems (C2): The National Insti-
tute of Statistics and Applied Economy ( Institut 
National de Statistique et d’Économie Appli -
quée) in the High Planning Commission is the 
central government agency responsible for col -
lecting and analysing national data (e.g. demo -
graphics, economics).53
<<<PAGE=49>>>
31
COUNTRY PROFILES
54 It is possible that changes have been in place since the source date. However, website data does not contradict the source. 
As such, this information was included in the study as an important as a point of departure for future work. 
55 See  limitations regarding generalizations about certain commitments such as budgets (C16), independent evaluators 
(C17), stakeholders’ involvement (C10), peer-to-peer systems (C5) gender (C18) and ethnic and cultural issues (C8). 
Integrated public registries (C11):  Public reg -
istries and administrative records are not inte -
grated. (2015) Morocco’s National Observatory 
of Human Development is an information 
system developed in line with results-based 
management-oriented analysis, containing a 
logical framework and objectives against which 
to structure monitoring reports, surveys and 
specific evaluation missions. It is made up of 
a “web portal, a databank, a decision-making 
support system (performance indicators), a vir -
tual documentation centre (electronic document 
registry and a glossary), a geographic informa -
tion system and a system of statistical surveys.” 
(Chafiki, 2011, p. 133)54 Its databank is a central 
integrated data system and is available to exter -
nal users, including government partners and 
the general public. 
Methodologies (C9):  Technical courses and 
manuals are not widely available to guide evalua-
tion work. Some national institutions have valua-
tion techniques in their curriculum modules (e.g. 
Institute National Statistics and Applied Eco -
nomics). (2015)
Peer-to-peer systems (C5): Peer-to-peer systems 
are not used. (2015) 
Gender (C18): “Awareness of the importance of 
integrating gender dimensions into public policy 
in Morocco is the result of a social democratic 
movement where women’s contributions were 
decisive.” (Chafiki, 2011) There are assessments 
that integrate gender; in others, gender is not 
treated due to the lack of (or difficulty in obtain-
ing) data. (2015)
Ethnic and cultural dimensions (C8):  Ethnic 
and cultural issues are not considered in national- 
level evaluations. (2015) 
3. ASIA AND THE PACIFIC
3.1 AFGHANISTAN
3.1.1  National government’s capacity to use 
evaluations (Use of Evaluation)55
Institutional set up (C4):  Afghanistan is in the 
early stages of developing a national evaluation 
policy. (Rosenstein, 2015) Evaluation is carried 
out on a limited scale. High-level international 
support has influenced the operations of all devel-
opment partners in the country, with increased 
spending required to take charge of the country’s 
security after the withdrawal of foreign troops 
in 2014. However, due to the conflict spanning 
the past decade, donors and development part -
ners have not fundamentally focused on applying 
M&E mechanisms when implementing proj -
ects and programmes. In part, this was because 
of limited capacity and understanding of M&E 
within the government to push towards more 
systematic accountability and transparency. This 
resulted in low-quality implementation of pro -
grammes and projects and did not contribute to 
building a culture of having M&E integration. 
(Sarwary, 2014, p. 95)
As such, M&E is a relatively new practice. The 
Ministry of Finance is developing a government- 
wide performance M&E system (GPMES). 
GPMES is a three to five-year reform pro -
gramme under the leadership of the Ministry’s 
Directorate-general of Budget (DGB) that seeks 
to streamline the way in which line ministries 
report on performance to central ministries. To 
inform policy discussions on the development of 
GPMES, the Ministries of Finance and Econ -
omy prepared an assessment of the status of 
M&E activities in 10 line ministries in August 
2014. “M&E processes and systems are highly 
fragmented and the capacity and power of cen -
tral ministry planning of M&E departments to 
consolidate these into unified institution-wide
<<<PAGE=50>>>
32
COUNTRY PROFILES
56 cso.gov.af/en
systems is weak.” (Government of Afghanistan 
Ministry of Finance, 2014, p. iv)
Independent reviews and evaluations “are fre -
quently conducted for donor-funded projects and 
programmes but only cover the work supported 
by these programmes.” (Government of Afghan-
istan Ministry of Finance, 2014, p. iv) There are 
very few cases where entire ministry or agency 
programmes—or even sub-programmes—have 
been periodically independently reviewed for 
management purposes.      
There are experiences to develop a comprehen -
sive M&E framework to measure results, effec -
tiveness and efficiency in the country, such as 
that used for the implementation of the National 
Priority Programme for Local Governance and 
Sub-National Governance Policy in 2012. The 
Policy was developed by the Independent Direc -
torate of Local Governance (IDLG), Afghani -
stan’s lead local governance agency. Developed to 
establish a national M&E system for IDLG and 
its subnational entities, the framework focuses 
on measuring the results and performances of 
the IDLG’s national development programmes, 
which are funded by donors and implemented by 
implementing partners. (Sarwary, 2014) 
There are difficulties in conducting evaluations 
in high-risk locations away from the capital, and 
“the culture of undertaking professional and sys -
tematic evaluations and consequently use of the 
results and information as inputs for effective 
decision-making and planning is still poor in the 
government institutions.” (Rosenstein, 2015)
Parliamentarians promoting evaluation use 
(C6): Afghanistan is participating in the Parlia -
mentarians Forum on Development Evaluation, 
a collective of parliamentarians who are commit-
ted to the development of evaluation in South 
Asian Association for Regional Cooperation 
countries. The Parliamentarians Forum’s goal is 
to advance enabling environments for nation -
ally owned, transparent, systematic and standard 
development evaluation processes that are in line 
with national evaluation policies at the country 
level, thus ensuring aid effectiveness, achieve -
ment of results and development sustainability. 
(Rosenstein, 2015)
Partnerships to strengthen and promote eval -
uation (C7): There are three evaluation associ -
ations in Afghanistan. The Afghan Evaluation 
Society (AfES), the Afghanistan M&E National 
Association (AMENA) and the Community of 
Evaluators (CoE) Afghanistan.      
3.1.2  National government’s capacity 
for independent evaluations 
(Independence of Evaluation)
Stakeholders’ involvement/access to informa -
tion (C10): Government institutions in Afghan-
istan are “typically not very open to sharing 
information with civil society organizations or 
the public.” (Sarwary, 2014, p. 96) The common 
practice is to limit access to reports and informa-
tion to the government. This hampers the use of 
evaluation information and actions on findings 
and recommendations. 
3.1.3  National government’s capacity to 
ensure credible evaluations  
(Credibility of Evaluation)
National data systems (C2): The Central Sta -
tistics Organization is the central government 
agency responsible for collecting and analysing 
national data (e.g. demographics, economics).56
Integrated public registries (C11):  Institu -
tion-wide performance monitoring databases 
containing results-based performance plans, 
baseline data and performance achievement data 
do not exist in Afghanistan.
Methodologies (C9): There are limited evaluation 
skills and knowledge in the country. (Rosenstein, 
2015) There are major issues for implementing 
the IDLG’s M&E framework related to a lack
<<<PAGE=51>>>
33
COUNTRY PROFILES
57 See limitations regarding generalizations about certain commitments such as budgets (C16), independent evaluators 
(C17), stakeholders’ involvement (C10), peer-to-peer systems (C5) gender (C18) and ethnic and cultural issues (C8). 
of M&E technical capacities and government 
employees’ limited understanding of evaluation 
and its values.  (Sarwary, 2014) The assessment 
report by the Ministries of Finance and Econ -
omy indicates limited technical qualifications and 
experience in performance planning and M&E 
within the ministries and agencies. (Government 
of Afghanistan Ministry of Finance, 2014) 
3.2 BHUTAN
3.2.1  National government’s capacity to use 
evaluations (Use of Evaluation) 57
Institutional set up (C4):  The draft national 
evaluation policy, dated from 2014, aims to pro -
vide an overall framework for evaluation in the 
country and detailed steps in the Evaluation 
Protocol and Guidelines. (Royal Government 
of Bhutan, 2015) The policy is an effort of the 
Research and Evaluation Division of the Gross 
National Happiness Commission (GNHC) (the 
former Planning Commission) to institutional -
ize the evaluation system in the country and to 
improve the accountability, efficiency and effec -
tiveness of socio-economic development ini -
tiatives. It is expected that the Policy will be 
launched in the second half of 2015. (Evaluation 
Association of Bhutan, 2015)
Evaluations are used to assess the impacts of 
specific programmes in certain government sec -
tors. (2015) The Royal Government of Bhutan 
efforts to strengthen the M&E system in the 
country started in 2006 with the establishment 
of the National M&E System (NMES) to serve 
as a standard system of monitoring and evalu -
ating developmental plans. (Royal Government 
of Bhutan, 2015) Since then, even though “con -
siderable progress has been made on the moni -
toring front … evaluation culture in the country 
still remains weak.” (Evaluation Association of  
Bhutan, 2015)
The GNHC is the overall coordinating body for 
M&E of development programmes, projects and 
policies. Its Research and Evaluation Division 
is responsible for conducting evaluations in the 
country. (Government of Bhutan, 2015) Since 
2013, the Division has conducted several evalua -
tions of development policies and programmes in 
collaboration with government ministries. (Eval-
uation Association of Bhutan, 2015)
Parliamentarians promoting evaluation use 
(C6): Bhutan is participating in the Parliamen -
tarians Forum on Development Evaluation, a 
collective of parliamentarians who are committed 
to the development of evaluation in South Asian 
Association for Regional Cooperation countries. 
The Parliamentarians Forum’s goal is to advance 
enabling environments for nationally owned, 
transparent, systematic and standard development 
evaluation processes that are in line with national 
evaluation policies at the country level, thus ensur-
ing aid effectiveness, achievement of results and 
development sustainability. (Rosenstein, 2015)
Partnerships to strengthen and promote evalua-
tion (C7): Local stakeholders (professional organi-
zations, universities, private sector actors, NGOs) 
and international organizations are actively advo-
cating and promoting the use and conduct of 
evaluations. (Baseline Study Survey, 2015) There 
are coordinated efforts to promote the need and 
demand for and use of national-level evaluations. 
The Evaluation Association of Bhutan expects to 
“play a critical role in sustainably promoting and 
increasing the demand for evaluations while the 
government bodies, parliamentarians, academia, 
international development partners, media and 
other stakeholders have a key role in building an 
enabling environment for evaluation.” (Evaluation 
Association of Bhutan, 2015)
Budgets for evaluation (C16): Some surveys 
indicate that budgets are not in place; others 
reveal that government units responsible for eval-
uations would have their own budget available. 
(2015)
<<<PAGE=52>>>
34
COUNTRY PROFILES
58 nsb.gov.bt/main/main.php
59 It  was not possible to obtain detailed information and explanations about these, as data was only available through the 
surveys.  This is further explained in the section on study limitations.
60 See  limitations regarding generalizations about certain commitments such as budgets (C16), independent evaluators 
(C17), stakeholders’ involvement (C10), peer-to-peer systems (C5) gender (C18) and ethnic and cultural issues (C8). 
3.2.2  National government’s capacity 
for independent evaluations 
(Independence of Evaluation)
Independent evaluators (C17):  Evaluations 
are conducted by the internal staff of govern -
ment departments and by independent evaluators 
under contracts. (2015)
Stakeholders’ involvement/access to informa -
tion (C10): Evaluation reports are made public 
and are easily available on government websites. 
(2015)
Implementation of evaluation recommenda -
tions (C3):  There are no systems in place to 
follow-up on the implementation of evaluation 
recommendations, but the draft policy has provi-
sions to institutionalize these. (2015)
3.2.3  National government’s capacity to 
ensure credible evaluations  
(Credibility of Evaluation)
National data systems (C2): The National Sta -
tistics Bureau is the central government agency 
responsible for collecting and analysing national 
data (e.g. demographics, economics) in Bhutan.58
Integrated public registries (C11):  Public reg -
istries and administrative records are not inte -
grated. (2015)
Methodologies (C9): The Evaluation Associa -
tion of Bhutan (EAB) was established in 2013. A 
SWOT analysis (Strengths, Weaknesses, Oppor-
tunities and Threats) of Bhutan’s M&E system 
found that “the evaluation system was weak, 
technical capacity to conduct/commission and 
manage evaluations was lacking and demand for 
evaluation was low.” (Evaluation Association of 
Bhutan, 2015) Evaluation in Bhutan is mostly 
donor-driven. 
The EAB has established a Community of Eval-
uators (CoE), an electronic platform to facilitate 
knowledge exchange among those interested in 
evaluation in South Asia, to expand the knowl -
edge and experience base of individuals and the 
region, and to provide opportunities for sharing 
experiences with the international evaluation com-
munity. (Evaluation Association of Bhutan, 2015)     
There are also technical courses and manuals 
available to guide evaluation work.59 (2015)
Peer-to-peer systems (C5): Peer-to-peer systems 
are not used. (2015)
Gender (C18): Evaluations take gender into 
their considerations and analyses of programme 
impacts and use gender-responsive evaluation 
methods. Valuation reports discuss how gen -
der equality is addressed in the project or 
programme. Overall, evaluation data is disaggre -
gated by sex. (2015)
Ethnic and cultural dimensions (C8):  Accord-
ing to survey results, ethnic and cultural issues 
are not considered in national-level evaluations. 
(2015) 
3.3 INDIA 
3.3.1  National government’s capacity to use 
evaluations (Use of Evaluation)
 60
Institutional set up (C4): India has an evolving 
National Evaluation Policy. (Rosenstein, 2015) 
Sectoral policies requiring evaluation of specific 
national programmes exist. Evaluations are used 
to assess the impacts of specific programmes in 
certain government sectors, for learning purposes, 
to adjust course and to scale up initiatives. (2015)
The Performance Management and Evaluation 
System (PMES) was created in 2009. PMES
<<<PAGE=53>>>
35
COUNTRY PROFILES
61 It is possible that changes have been in place since the source date. However, website data does not contradict the source. 
As such, this information was included in the study as an important as a point of departure for future work. 
established a mechanism for M&E on a regu -
lar basis. 61 (Trivedi, 2011) PMES compares the 
achievements of the departments against their 
annual targets. It aims at reducing the frag -
mentation of institutional responsibilities for 
performance management by providing con -
sistencies across multiple objectives. (Govern -
ment of India, 2015) Over the years, PMES has 
developed into a robust system, spreading to 
other levels of governments and other countries. 
(Rosenstein, 2015)
The central unit responsible for evaluation is 
the Programme Evaluation Organization (Niti 
Ayog). Under the direction of the Planning 
Commission, it is tasked with the evaluation of 
selected programmes and schemes under imple -
mentation, as per the requirement of the Divi -
sions of Planning Commission and Ministries/
Departments of the Government of India. The 
evaluation studies are designed to assess the per -
formance, process of implementation, effective -
ness of the delivery systems and the impact of 
programmes. (Government of India National 
Planning Commission, 2015) 
Created in 2014, an Independent Evaluation 
Office (IEO) reports directly to the Cabinet 
Minister (rather than being part of the Planning 
Commission). The IEO independently assess 
the effectiveness, relevance and impacts of gov -
ernment flagship programmes with the goal of 
improving the effectiveness of government pol -
icies and programmes. The IEO is tasked with 
preparing the terms of reference and setting 
guidelines and methodologies for all department 
evaluations. The Office also aims to encourage 
a culture of openness and learning within gov -
ernment systems. The Office is also working to 
connect India to the best international evaluated 
evidence in development practice. (Government 
of India Independent Evaluation Office, 2015)
Parliamentarians promoting evaluation use 
(C6): India is part of the Parliamentarians 
Forum on Development Evaluation, a collec -
tive of parliamentarians who are committed to 
the development of evaluation in South Asian 
Association for Regional Cooperation countries. 
The Parliamentarians Forum’s goal is to advance 
enabling environments for nationally owned, 
transparent, systematic and standard develop -
ment evaluation processes that are in line with 
National Evaluation policies at the country 
level, thus ensuring aid effectiveness, achieve -
ment of results and development sustainability.  
(Rosenstein, 2015)
Partnerships to strengthen and promote eval -
uation (C7): Local stakeholders (professional 
organizations, universities, private sector actors, 
NGOs) and international organizations are col -
laborating and jointly advocating and promoting 
the need and demand for and use of national-level 
evaluations. The Development Evaluation Soci -
ety of India (DESI) was founded in 2002 to build 
the evaluation capacities of national researchers 
and to advocate and create awareness to main -
stream evaluation in governance. (Development 
Evaluation Society of India, 2015)
Budgets for evaluation (C16): Policies allocate 
and make budgets available for evaluations. Min-
istries and departments have their own budgets 
as part of their budgetary allocations. 
3.3.2  National government’s capacity 
for independent evaluations 
(Independence of Evaluation)
Independent evaluators (C17): Evaluations are 
conducted by the internal staff of government 
departments and by independent evaluators 
under contracts. (2015) 
Stakeholders’ involvement/access to informa -
tion (C10): The IEO posts evaluation reports 
and information about ongoing evaluations to 
its website. Most reports are available, although 
some may not be in the public domain. (2015)
<<<PAGE=54>>>
36
COUNTRY PROFILES
62 For more information, see: mospi.nic.in/Mospi_New/site/home.aspx.
63 See  limitations regarding generalizations about certain commitments such as budgets (C16), independent evaluators 
(C17), stakeholders’ involvement (C10), peer-to-peer systems (C5) gender (C18) and ethnic and cultural issues (C8). 
Implementation of evaluation recommenda -
tions (C3): There are systems in place to follow 
up on the implementation of evaluation recom -
mendations. (2015)
3.3.3  National government’s capacity to 
ensure credible evaluations  
(Credibility of Evaluation)
National data systems (C2): The Ministry of 
Statistics and Programme Implementation is the 
central government agency responsible for col -
lecting and analysing national data (e.g. demo -
graphics, economics).62
Methodologies (C9): The PMES establishes 
a “comprehensive view of departmental per -
formance” by measuring short- and long-term 
performance of all relevant aspects of expected 
deliverables. The results framework enables pri -
oritization by attaching weights to the various 
objectives and performance criteria. The frame -
work includes the concept of scale as opposed to 
a single point target, making it simpler to judge 
deviations. The system also provides a method -
ology to calculate “an objective and scientifically- 
based performance score.”  (Trivedi, 2011, pp. 
126-7) Currently, there are no technical courses or 
manuals available to guide evaluation work. (2015)
Peer-to-peer systems (C5): Peer-to-peer systems 
are not used. (2015) 
Gender (C18): Evaluation reports discuss how 
gender equality is addressed in the project or pro-
gramme. Evaluation data is disaggregated by sex; 
ad hoc evaluations use gender-responsive evalua -
tion methods. (2015)
Ethnic and cultural dimensions (C8):  Evalua-
tion reports take ethnic and cultural dimensions 
into consideration in the analysis of programme 
impacts. Evaluation reports discuss the ethnic 
and cultural issues that were addressed in the 
project or programme; evaluation data is dis -
aggregated by ethnic and cultural background. 
(2015) 
3.4 INDONESIA
3.4.1  National government’s capacity to use 
evaluations (Use of Evaluation)
 63
Institutional set up (C4): Most national govern-
ment agencies have established M&E systems and 
are moving towards a structured way to opera -
tionalize their institutional needs in order to fulfil 
donor requirements or to satisfy the demands for 
better performance management. (IOCE, 2012) 
Evaluations are used to assess the impacts of all 
government programmes, for learning purposes, 
to adjust course and to scale up initiatives. (2015)
Legislation on public-sector reforms, such as 
the State Financing (Law No. 17/2003) and the 
National Development Planning System (Law 
No. 25/2004), provide a regulatory framework for 
implementing performance-based planning and 
budgeting and demanding M&E performance 
information and results. (Hayana, 2014) In 2006, 
the government assigned the responsibility for 
developing an M&E system to the Ministry of 
National Development Planning (BAPPENAS). 
(Government of Indonesia, 2015) The govern -
ment also created the position of Deputy of 
Development Performance Evaluation in order to 
formulate and coordinate national development 
M&E, to monitor and assess the annual plan and 
the national development medium-term plan and 
to maintain national development M&E part -
nerships. (Hayana, 2014) Provincial and District 
Development Planning Agencies have decentral-
ized evaluation units. 
The Annual Plan review is a monitoring assess -
ment of the achievement of targeted outputs, 
identifying implementation bottlenecks and con-
straints through information submitted quarterly
<<<PAGE=55>>>
37
COUNTRY PROFILES
64 The MP3EI is an important economic development plan initiated by the President. However, according to InDEC it 
lacks monitoring and evaluation components. 
65 See  comment on limited depth and explanations about certain issues.
by line ministries and provincial governments. In 
an effort to increase low reporting rates and to 
improve system accountability, the government 
introduced an online application (e-Money) in 
order to assist data collection and integration by 
the line ministries. The evaluation of the national 
development plan implementation measures the 
outcomes and impacts of programmes part of 
the plan during the five-year implementation 
horizon. Line ministries conduct evaluations for 
each of their programmes (as a self-evaluation); 
the reporting information is integrated into a  
BAPPENAS evaluation report. (Hayana, 2014)
Decentralization and a higher degree of democ -
ratization have increased the demand for better 
government performance in delivering devel -
opment results. This has been “accompanied 
with the re-emerging New Public Management 
thinking that drives most public organizations to 
find better ways to manage their performance.” 
(IOCE, 2012) At this stage of development, 
“most government agencies in the country have 
moved towards an evaluative culture … but it is 
still a long journey to go with the focus remain -
ing on monitoring for performance and not yet 
on evaluation.” (IOCE, 2012)
International organizations are advocating and 
promoting the use of evaluations. (2015) The 
Indonesian Development Evaluation Community 
(InDEC)  was established in 2009 and launched 
as an organization in 2012. InDEC has been pro-
moting the value of evaluation and awareness of 
good evaluation practices in order to strengthen 
the enabling environment for better evaluation 
in Indonesia and to advocate for national evalua-
tion policies and systems. It is working to engage 
and influence government officials, members of 
parliament, academia, the media and M&E pro-
fessionals working in NGOs, CSOs and projects 
and programmes funded by international donor 
agencies. Advocacy work is also under way for the 
Master Plan for Acceleration and Expansion of 
Indonesia Economic Development (MP3EI). 64 
InDEC is also engaged in advocacy work through 
liaison with the National Development Planning 
Agency and Coordinating Minister for Economic 
Development. (IOCE, 2012) 
Budgets for evaluation (C16):  Policies, pro -
grammes and projects allocate budgets for eval -
uation65 and make them available. Government 
units responsible for evaluation possess their 
own budgets to conduct evaluation. Policies, pro-
grammes and projects have built resources for 
evaluation into their budgets. (2015)
3.4.2  National government’s capacity 
for independent evaluations 
(Independence of Evaluation)
Independent evaluators (C17):  Evaluations 
are conducted by the internal staff of govern -
ment departments and by independent evaluators 
under contracts. (2015)
Stakeholders’ involvement/access to informa -
tion (C10):  BAPPENAS has been organizing 
public consultation meetings since 2012. Civil 
society organizations and universities partici -
pated in the meetings and shared their views 
during the M&E process. (Hayana, 2014) Evalu-
ation reports are made public and are easily avail-
able on government websites. (2015)
Implementation of evaluation recommenda -
tions (C3): There are systems in place to follow 
up on the implementation of evaluation recom -
mendations, but they vary across institutions. 
(2015)
3.4.3  National government’s capacity to 
ensure credible evaluations  
(Credibility of Evaluation)
National data systems (C2): The Central Bureau 
for Statistics is the central government agency
<<<PAGE=56>>>
38
COUNTRY PROFILES
66 bps.go.id
67 It  is possible that changes have been in place since the source date. However, website data does not contradict the source. 
As such, this information was included in the study as an important as a point of departure for future work. 
responsible for collecting and analysing national 
data (e.g. demographics, economics).66
Methodologies (C9): There are technical courses 
and manuals available to guide evaluation work. 
(2015) Challenges exist in Indonesia regarding 
building the capacities of M&E practitioners. 
(Hayana, 2014) InDEC has been conducting a 
limited number of capacity building activities 
on M&E methods and holding discussions on 
M&E qualities and ethical issues. (IOCE, 2012) 
3.5 MALA YSIA
3.5.1  National government’s capacity to use 
evaluations (Use of Evaluation)
Institutional set up (C4):  Malaysia has a 
semi-formalized but well-established national 
evaluation policy. (Rosenstein, 2015) In 2005, the 
government directed all federal- and state-level 
ministries and agencies to undertake outcome 
evaluations of their projects and programmes. 67 
(Ahmad, 2011) In 2009, the government adopted 
an outcome-based approach for planning, resource 
allocation, monitoring and evaluation as part of 
the 10th Malaysia Plan 2011–2015. (Government 
of Malaysia Economic Planning Unit, 2010) The 
system requires annual formative evaluations for 
every ministry and its programmes and activities. 
The evaluations are incorporated into planning 
processes and budgetary processes. The evalua -
tions also serve as supportive information for any 
proposal for policy or programme adjustments 
through the Outcome-based Budgeting System. 
The approach also encourages ministries to con -
duct internalized self-evaluations.     
As per the annual formative evaluations, these 
“outcome evaluations and policy-level evalua -
tions are performed at the end of each Five-Year 
Plan for the Economic Planning Unit in order to 
review and prioritize national planning.”  (Evalu-
ation Office at the UNDP , 2011, p. 17)
Several government agencies, including the Eco-
nomic Planning Unit (of the Department of the 
Prime Minister’s Department), the Public Ser -
vice Department, the Malaysia Administrative 
Modernization and Management Planning Unit, 
the Treasury and the Implementation Coordina-
tion Unit are individually responsible for plan -
ning, implementing, monitoring and evaluating 
national policies. Line ministries are responsi -
ble for implementing, monitoring and evaluat -
ing their own projects, and the Implementation 
Coordination Unit independently monitors and 
evaluates line ministries’ projects and evaluates 
national programme and policy-level interven -
tions. (Majid, 2014) 
The Development Budget Section of the Eco -
nomic Planning Unit (EPU) is responsible for 
monitoring and evaluating the implementation 
status of programme and project performance, 
including financial, physical and outcomes in 
relation to Malaysia’s development budget. 
Improvements related to the M&E outcome-  
based approach is one of the focus areas of the 
11th Malaysia Plan 2016–2020 to enhance proj -
ect management for better and faster outcomes. 
(Government of Malaysia, 2015)
The focus of the Malaysia Administrative Mod -
ernization and Management Planning Unit 
(MAMPU) is on monitoring compliance and 
evaluation. To facilitate this, MAMPU intro -
duced a Star Rating mechanism in order to 
evaluate and rate the performance of the public 
sector. (Malaysia Administrative Modernization 
and Management Planning Unit, 2015)
The Implementation Coordination Unit of the 
Prime Minister’s Department monitors the 
implementation of the national development 
plan through select programme evaluations 
and evaluation reports to the National Action 
Working Committee and the National Action 
Council. (Government of Malaysia ICU, 2015)
<<<PAGE=57>>>
39
COUNTRY PROFILES
68 statistics.gov.my
Evaluation findings are used as feedback in 
short-term planning processes and to prioritize 
programmes. Their aggregate forms part of a key 
performance indicator—a report card, calculated 
at a year-end, on the performance of heads of 
ministries and agencies that prompts them to 
ensure the efficiency and effectiveness of pro -
grammes and projects. (Ahmad, 2011)
Partnerships to strengthen and promote eval -
uation (C7): The Malaysian Evaluation Society 
(MES) has been playing an active role shap -
ing the conceptual and strategic approach to 
evaluation in the country through key partner -
ships with the Ministry of Finance and CeDRE 
International (a private sector group). (IOCE, 
2012) Malaysia’s M&E progresses are also a 
result of media pressure. “The media [has] 
started demanding governmental transparency 
and accountability related to meeting people  
and stakeholders’ needs and expectations.”  
(Ahmad, 2011, p. 82)
3.5.2  National government’s capacity to 
ensure credible evaluations 
(Credibility of Evaluation)
National data systems (C2): The Department 
of Statistics Malaysia is the central government 
agency responsible for collecting and analysing 
national data (e.g. demographics, economics). 68 
A National Indicator Databank enables system 
users to choose their programme or project out -
comes and easily match them to the national key 
result areas. However, not all public registries are 
integrated.     
Methodologies (C9):  The Implementation 
Coordination Unit produced guidelines to guide  
the conduct of outcome evaluations of pro -
grammes. (Ahmad, 2011) Under the new out -
come-based approach and the Outcome-based 
Budgeting system, about 200 middle- and senior-
level officials across the government have been 
trained. The Malaysian Evaluation Society has 
also collaborated with the Ministry of Finance and 
the private sector for capacity-building activities. 
(IOCE, 2012)
Peer-to-peer systems (C5):  Strategic alliances 
are a mechanism used in Malaysia to evaluate 
its ministries. Central Agencies, the Implemen -
tation Coordination Unit, the Auditor General 
Office, the Treasury and the Economic Planning 
Commission comprise a committee that reviews 
the alliances. The government also uses a system 
to appoint an Outcome Evaluation Champion as 
a reference point in each ministry (after he or she 
is certified and trained in outcome evaluation). 
(Ahmad, 2011)
Gender (C18): There are efforts to integrate gen-
der issues into the mainstream public manage-
ment initiatives and there are policies governing 
these. Gender is part of the outcome-based 
system requirement as one of the twelve cross-
cutting issues that need to be addressed by 
ministries and government agencies within their 
strategic plans through specific key indicators. 
(IOCE, 2012)
Ethnic and cultural dimensions (C8):  Sim -
ilarly, equity and cultural sensitivities issues 
are integrated into mainstream public man -
agement initiatives and there are policies gov -
erning these. Cultural issues are part of the 
outcome-based system requirement as one of 
the twelve cross-cutting issues that need to be 
addressed by ministries and government agen -
cies within their strategic plans through specific 
key indicators. (IOCE, 2012)
3.6 MONGOLIA
3.6.1  National government’s capacity to use 
evaluations (Use of Evaluation)
Institutional set up (C4):  Currently, there is no 
national evaluation policy in Mongolia. The dis -
mantling of the institutions of central planning 
in the early 1990s severely weakened the mecha -
nism for overall policy formulation and strategic
<<<PAGE=58>>>
40
COUNTRY PROFILES
69 en.nso.mn
70 See  limitations regarding generalizations about certain commitments such as budgets (C16), independent evaluators 
(C17), stakeholders’ involvement (C10), peer-to-peer systems (C5) gender (C18) and ethnic and cultural issues (C8). 
71 See  comment on limited depth and explanations about certain issues.
planning. Since 2010, the government has been 
improving its M&E system by transitioning into 
a results-based system as an indirect effect of 
the application of the Millennium Development 
Goals-based M&E system. (United Nations Eco-
nomic Social Council, 2015) The transition is at a 
very early stage of development.
The system for monitoring the implementation 
of development plans in Mongolia has improved, 
although there are still large gaps in understand -
ing how to monitor and assess development pol -
icies and undertake mid-course corrections when 
required. Also, there is little or no link between 
data and policy, planning and budgeting and 
monitoring. Use of results-based monitoring 
and assessment is very limited and there is no  
systematic ex-post evaluation. (UNDP , 2015) 
The Ministry of Economic Development MED, 
in partnership with UNDP , has started imple -
menting the Strengthening the Government 
Capacity of National Development Policy and 
Planning project. The project aims at building 
the government’s capacity to improve its eco -
nomic policy formulation, strategic planning 
and monitoring both at national and local levels. 
The project will also guide the preparation of 
various planning documents in order to ensure 
better coordination and harmonization of long-, 
medium- and short-term planning in the coun -
try. (UNDP , 2015)
3.6.2  National government’s capacity to 
ensure credible evaluations  
(Credibility of Evaluation)
National data systems (C2): The National Sta-
tistics Office is the central government agency 
responsible for collecting and analysing national 
data (e.g. demographics, economics).69 
3.7 NEPAL
3.7.1  National government’s capacity to use 
evaluations (Use of Evaluation) 70
Institutional set up (C4): There are sectoral pol -
icies requiring evaluation of specific national 
programmes in Nepal. At the same time, parlia -
mentarians are pushing for the development of 
national policies, structures and frameworks. The 
National Planning Commission has drafted an 
evaluation policy legislation, which is going to be 
included in the new constitution.71 (2015)
Nepal has a well-integrated system linking M&E 
to national development priorities. (Rosenstein, 
2015) Evaluations are used to assess the impacts 
of all government programmes, to assess the 
impacts of specific programmes in certain gov -
ernment sectors and for learning purposes, to 
adjust course and to scale up initiatives. (2015)
Efforts to institutionalize evaluation of develop -
ment interventions began in 1990. M&E have 
been embedded in national planning processes 
and in all stages of project cycle management 
since 2002. There have been increasing efforts 
to institutionalize managing for development 
results approaches in planning processes. This 
was done through the design of results frame -
works and standardized results indicators at the 
sectoral and project levels (Dhakal, 2014). Con -
tinuous improvements have been made in each of 
the national plans to strengthen the system.      
Several government departments are tasked with 
M&E functions; all government ministries have 
M&E Divisions/Sections. The Office of the 
Prime Minister and Council of Ministers has a 
Planning and Monitoring Section assigned with 
the M&E of annual, medium- and long-term 
government policies. The Planning and Mon -
itoring Section is also tasked with developing
<<<PAGE=59>>>
41
COUNTRY PROFILES
indicators, conducting impact studies and prior -
itizing M&E. Some of the ministries also have 
M&E divisions tasked with preparing M&E 
plans, monitoring and evaluating projects imple -
mented by the ministry and conducting reg -
ular evaluations as prescribed by the National 
Planning Commission. (Government of Nepal 
National Planning Commission, 2013)
The National Planning Commission M&E Divi-
sion manages the overall M&E system (including 
information systems and capacities) and under -
takes evaluations of programmes and projects. 
Sectoral divisions of the National Planning Com-
mission Secretariat (NPCS) conduct field inspec-
tions of programmes and projects and undertake 
policy, programme and project-related studies and 
evaluation reports of the sectoral ministry/agency. 
(National Planning Commission, 2015)
Annual programme and project budgets also dis-
cuss evaluation findings. However, they are not 
conducted systematically or with clearly defined 
purposes, such as for specific policy needs. “A 
lack of clear evaluation objectives makes it is 
difficult to frame evaluation questions that will 
generate evidence in areas of interest to policy-
makers. There is lack of a clear and coherent 
evaluation policy that drives systematic selection, 
conduct and use of evaluations. There are also 
weak capacities to demand, facilitate and conduct 
impact evaluations, which results in low-quality 
studies of limited use.” (Dhakal, 2014, p. 140)
The National Planning Commission is currently 
preparing a draft legislative bill on M&E. The 
Commission’s National M&E Guideline is in 
the process of being adopted as the national 
evaluation policy. Universities and professional 
evaluation networks are pushing for the develop-
ment of national policies, structures and frame -
works. (2015) 
Parliamentarians promoting evaluation use 
(C6): Nepal is one of the countries participating 
in the Parliamentarians Forum on Development 
Evaluation, a collective of parliamentarians who 
are committed to the development of evaluation 
in South Asian Association for Regional Coop -
eration countries. The Parliamentarians Forum’s 
goal is to advance enabling environments for 
nationally owned, transparent, systematic and 
standard development evaluation processes that 
are in line with national evaluation policies at 
the country level, thus ensuring aid effectiveness, 
achievement of results and development sustain -
ability. (Rosenstein, 2015)
Partnerships to strengthen and promote eval -
uation (C7): Local stakeholders (professional 
organizations, universities, private sector actors, 
NGOs) and international organizations are col -
laborating, jointly advocating and promoting 
the need and demand of evaluations at the 
national level. The Nepal Community of Eval -
uators (CoE/Nepal) is in constant consultation 
with the National Planning Commission for 
the development of national policies and other 
related documents. (2015) Since 2011, CoE has 
been working to “establish a culture of evalua -
tion at national and international level through 
development and dissemination of knowledge in 
evaluation, capacity building of evaluation stake -
holders, and promotion of evaluation theory and 
practice.” (IOCE, 2012) 
The Nepal Evaluation Society has been working 
since 2009 to develop the evaluation system in 
Nepal as a “capable, strong and main managerial 
instrument in the planned development effort” by 
developing evaluation culture, capacity and com-
mitment; evaluating the results of development; 
and designing results-based instruments to focus 
on delivery to target groups. The Society promotes 
evaluation capacity through M&E training, eval-
uation capacity development programmes, prepa-
ration of M&E guidelines and talk programmes. 
It seeks to influence evaluation culture, capacity 
and commitment in order to enhance an enabling 
environment and increase demand for evaluation. 
It also seeks to influence the development of eval-
uation policies by the government. (IOCE, 2012)
Budgets for evaluation (C16):  Ministries and 
other agencies responsible for conducting M&E 
are tasked with the preparation of monitoring
<<<PAGE=60>>>
42
COUNTRY PROFILES
72 For more information, see: http://cbs.gov.np. 
73 See  comment on limited depth and explanations about certain issues.
74 This  is according to a study done for analysis of 29 project evaluations in various sectors since 1995, as described in 
Dhakal, Theertha, 2014.
plans and provision of resources necessary for its 
implementation in their annual budget. (Govern-
ment of Nepal National Planning Commission, 
2013) Some survey results indicated that budgets 
are not in place for the conduct of evaluations; 
others revealed that policies allocate budgets for 
evaluations in programmes budgeting and make 
them available. (2015)
3.7.2  National government’s capacity 
for independent evaluations 
(Independence of Evaluation)
Independent evaluators (C17): Evaluations are 
conducted by the internal staff of government 
departments and by independent evaluators 
under contracts. (2015) The National Planning 
Commission engages third parties through com-
petitive processes in evaluations. “Steering Com-
mittees, formed for each evaluation facilitate the 
process, approve the terms of reference, select the 
right evaluators, facilitate evaluation processes 
and maintain the quality of evaluations and 
reports.” (Dhakal, 2014, p. 138) 
Stakeholders’ involvement/access to informa -
tion (C10): There are established practices to 
disseminate evaluation findings to policymak -
ers from line ministries and relevant partners 
and to publish evaluation reports on websites. 
(Dhakal, 2014) Evaluation reports are made 
public and are easily available on government 
websites. (2015)
The National Commission Guidelines determine 
provisions ranging from parliamentary commit -
tees to public hearings committees and also an 
M&E Committee in order to ensure informa -
tion is provided to stakeholders on programmes’ 
activities and outputs, and in order to promote 
transparency, social responsibility and account -
ability. (Government of Nepal National Planning 
Commission, 2013)
Implementation of evaluation recommenda -
tions (C3):  The National Commission Guide -
lines call for the implementation of an Action 
Plan for Evaluation. These should include an 
estimate of required resources necessary to 
implement the evaluation recommendations and 
to prepare management responses. (Government 
of Nepal National Planning Commission, 2013)
3.7.3  National government’s capacity to 
ensure credible evaluations  
(Credibility of Evaluation)
National data systems (C2): The Central Bureau 
of Statistics is the central government agency 
responsible for collecting and analysing national 
data (e.g. demographics, economics).72
Integrated public registries (C11):  Public reg -
istries and administrative records are not inte -
grated.73
Proper methodologies (C9):  Evaluation reports 
tend to focus on the results of processes and 
delivery of outputs rather than on outcomes. 
Studies are generally quantitative, and proper 
triangulations are not usually done on the tools, 
their design or data analysis. 74 “Even when an 
evaluation was methodologically sound and 
captured many facts, if its recommendations 
were insufficiently based on rigorous analysis, 
its overall quality and use declined.” (Dhakal, 
2014, p. 139) 
The National M&E Guidelines are a mechanism 
to improve and systematize the M&E process in 
Nepal, making it “more scientific, practical and 
useful.” (Government of Nepal National Plan -
ning Commission, 2013, p. i)
Peer-to-peer systems (C5): Peer-to-peer systems 
are not currently used. (2015)
<<<PAGE=61>>>
43
COUNTRY PROFILES
75 See limitations regarding generalizations about certain commitments such as budgets (C16), independent evaluators 
(C17), stakeholders’ involvement (C10), peer-to-peer systems (C5) gender (C18) and ethnic and cultural issues (C8). 
Gender (C18):  Gender is integrated into the 
outcome indicators, which draw on international 
indicators such as the Gender Development 
Index. In addition, the Guidelines recommend 
the use of gender-disaggregated indicators. 
(Rosenstein, 2015)  
3.8 PAKISTAN
3.8.1  National government’s capacity to use 
evaluations (Use of Evaluation) 75
Institutional set up (C4): Pakistan is in the early 
stages of developing a national evaluation policy. 
(Rosenstein, 2015, p. 38) Sectoral policies requir-
ing evaluation of specific national programmes 
do exist.      
There are no national-level evaluations. The 
national government does not regularly conduct 
evaluations. Nevertheless, they are used to assess 
the impacts of all government programmes and 
to provide accountability for government action. 
Evaluations are used for learning purposes, to 
adjust course and to scale up initiatives. The inter-
national donor community and professional orga-
nizations are pushing for evaluation frameworks. 
According to the survey findings, in the absence 
of an evaluation culture evaluations are mostly 
carried out by international donor agencies. (2015)
The government’s decision-making process is 
clear about the formulation of projects based 
on national needs and in evaluating for policy 
adjustments. Evaluations mostly inform deci -
sion-making regarding budgetary allocations. 
(Khattak, Projects Evaluation in Pakistan, 2014) 
The Monitoring and Evaluation Wing at the Plan-
ning Commission (Ministry of Planning, Devel -
opment and Reforms) is the central unit charge 
of conducting evaluations. Decentralized units in 
the Planning and Development Departments also 
conduct evaluations. (2015) The National Eco -
nomic Council and the Planning Commission 
share the responsibility for monitoring and exe -
cuting policies. The Commission’s other respon-
sibilities include evaluating the implementation 
of major development projects and programmes 
and for organizing research and analytical studies 
for economic decision-making.  (Khattak, Role of 
Monitoring in Social Sector Development, 2012)
Parliamentarians promoting evaluation use 
(C6): Pakistan is one of the countries participat -
ing in the Parliamentarians Forum on Develop -
ment Evaluation, a collective of parliamentarians 
who are committed to the development of eval -
uation in South Asian Association for Regional 
Cooperation countries. The Parliamentarians 
Forum’s goal is to advance enabling environments 
for nationally owned, transparent, systematic and 
standard development evaluation processes that 
are in line with national evaluation policies at 
the country level, thus ensuring aid effectiveness, 
achievement of results and development sustain -
ability. (Rosenstein, 2015). 
The Pakistan Evaluation Network is working 
with parliamentarians towards national pol -
icy development. The Centres of Excellence in 
Afghanistan, Bangladesh and Nepal and the 
Development Evaluation Society of India are the 
other country-level evaluation networks (UNDP 
IEO, 2014).
Partnerships to strengthen and promote eval -
uation (C7): Other stakeholders (professional 
organizations, universities, private sector actors, 
NGOs) and international organizations are 
actively advocating and promoting the use and 
conduct of evaluations. Several institutions (gov-
ernment, voluntary organizations for professional 
evaluation, the parliament and private sector 
entities) are coordinating efforts and jointly pro -
moting the need and demand for and use of 
national-level evaluations. (2015)
The Pakistan Evaluation Network (PEN) has 
been working since 2005 to “catalyse change to 
develop an M&E culture in national organi -
<<<PAGE=62>>>
44
COUNTRY PROFILES
76 pbs.gov.pk
zations for addressing the challenges of trans -
parency, professionalism and performance in 
the development business to serve the people.” 
(IOCE, 2012) 
The South Asian Association for Regional Coop-
eration collaborates with government ministries 
and departments including the Planning Divi -
sion, the Ministry of Social Welfare and Women 
Affaires, the Department of Special Education 
and the social development and sociology depart-
ments of several universities in the country.
The Community of Evaluators Pakistan 
(CoE-Pakistan) focuses on the institutional -
ization of the results chain in the development 
process. It implements several initiatives, such 
as training and capacity building of public and 
private organizations, communities and NGOs 
in collaboration with national and international 
partners, donors and organizations. (Community 
of Evaluators Pakistan, 2015)
Budgets for evaluation (C16): Government 
units that are responsible for evaluation have 
their own budgets. (2015)
3.8.2  National government’s capacity 
for independent evaluations 
(Independence of Evaluation)
Independent evaluators (C17): Evaluations are 
conducted by independent evaluators under con-
tract and by internal government department 
staff. (2015)
Stakeholders’ involvement/access to informa -
tion (C10): Evaluation reports are not made 
public and are not easily available on government 
websites. (2015)
Implementation of evaluation recommenda -
tions (C3): There is no clarity whether there are 
systems in place to follow up on the implementa-
tion of evaluation recommendations. The Mon -
itoring and Evaluation Wing at the Planning 
Commission shares M&E reports with proj -
ect executing agencies to foster remedial action 
as needed. It also submits quarterly reports to 
ECNEC on the M&E of projects and shares 
M&E status of projects with the Public Accounts 
Committee (PAC), Standing Committees of 
National Assembly, Senate and the Prime Min -
ister’s Secretariat. This enables the “identifica -
tion of slow moving projects, resolve the issues 
in projects of strategic importance, re-adjust pri -
orities and allocation of resources for mid-course 
correction in policy, plan as well implementation 
of the projects.” (Khattak, Projects Evaluation in 
Pakistan, 2014, p. 4) 
3.8.3  National government’s capacity to 
ensure credible evaluations  
(Credibility of Evaluation)
National data systems (C2):  The Pakistan 
Bureau of Statistics is the central government 
agency responsible for collecting and analysing 
national data (e.g. demographics, economics).76
Integrated public registries (C11):  Public reg -
istries and administrative records are not inte -
grated. (2015)
Methodologies (C9): “M&E, like planning and 
implementation activities, is undertaken using 
the conventional methods and ad hoc data collec-
tion (not properly analysed). It does not usually 
identify the outcome and impact of the invest -
ment.” (Khattak, Projects Evaluation in Pakistan, 
2014, p. 1) A management information system is 
in place in the Project Wing and the PME cells, 
but data is not updated or accurate. 
The software of Projects M&E System (PMES) 
is highly regarded as a “tool to analyse the data 
and extract results for identification of the out -
come impact, but it needs to be updated to 
meet the targets through integrated results-based 
M&E. The lack of the institutional capacities, 
including lack of state of the art M&E Units, 
absence of qualified staff and technical know-
<<<PAGE=63>>>
45
COUNTRY PROFILES
77 See limitations regarding generalizations about certain commitments such as budgets (C16), independent evaluators 
(C17), stakeholders’ involvement (C10), peer-to-peer systems (C5) gender (C18) and ethnic and cultural issues (C8). 
how hampers the effectiveness of an M&E in 
Pakistan.” (Khattak, Projects Evaluation in Paki-
stan, 2014, p. 1)
In recognition for the need for staff capacities 
in planning and M&E, the Planning Division 
established a Planning and Management Insti -
tute (PPMI). The PPMI is working to improve 
technical and analytical skills and enhance exper-
tise of the federal, provincial and district govern-
ments’ officers through training in various areas, 
including M&E of the development programmes 
and projects. (Government of Pakistan Planning 
Commission, 2015) CoE-Pakistan also develops 
training workshops on evaluation, results-based 
management and other topics. (Community of 
Evaluators Pakistan, 2015) 
Peer-to-peer systems (C5): Peer-to-peer systems 
are not in place. (2015)
Gender (C18): Some surveys indicate that eval -
uation data is disaggregated by sex. Others reveal 
that gender is not considered in national-level 
evaluations. (2015)
Ethnic and cultural dimensions (C8): Accord-
ing to certain surveys, evaluation data is disaggre-
gated by ethnic and cultural background. Others 
surveys indicate that ethnic and cultural issues 
are not considered in national-level evaluations. 
(2015)
3.9 SRI LANKA
3.9.1  National government’s capacity to use 
evaluations (Use of Evaluation) 77
Institutional set up (C4): Sri Lanka was among 
the first countries in the region to develop a 
national evaluation policy. However, it has not 
yet been legislated due to the lack of an enabling 
political environment. (Rosenstein, 2013) As such, 
even though proposals exist to institutionalize 
evaluations (2015), these are not yet fully insti -
tutionalized at the national level in the country 
(Sivagnanasothy, 2014). Changes to personnel and 
government also explain the reasons why efforts to 
have it ratified have not succeeded.      
Evaluations are largely donor-driven and the 
government has little means to commission its 
own evaluations. Nevertheless, evaluations are 
used in the country to assess the impacts of spe -
cific programmes in certain government sectors, 
for learning purposes and to adjust or scale up 
initiatives. (2015)
Evaluations of development policy and pro -
grammes are conducted by line ministries, the 
Ministry of Finance and Planning (Department 
of Project Management and Monitoring), the 
Auditor General’s Department and develop -
ment partners. The Department of Project Man-
agement and Monitoring undertakes ongoing, 
ex-post and impact evaluations of selected mega 
projects (country-led evaluations). Line minis -
tries responsible for implementing development 
programmes and public policy undertake selected 
evaluations through their respective M&E unit. 
(UNDP IEO, 2014)
Decentralized evaluation units exist in the Plan -
ning Divisions within the Provincial Councils; 
District Secretariats have evaluation in their 
mandate. However, this is not the practice yet. 
(2015) 
Country-led evaluations are selected through 
a demand-driven process, in response to pol -
icy maker needs according to criteria that takes 
into consideration factors such as a project’s rel -
evance and usefulness, difficulty in implementa -
tion, innovative intervention and the possibility 
of replicability of the intervention. This is a way 
to ensure that the findings will likely be more 
effectively used in response to policy-making 
needs. (Hashim, 2014)
Parliamentarians promoting evaluation use 
(C6): Sri Lanka is one of the countries par -
<<<PAGE=64>>>
46
COUNTRY PROFILES
78 Details of the Draft National Evaluation Policy can be obtained from SLEvA websites at nsf.ac.lk/sleva/pdf/nepdraft.
pdf and sleva.lk/tmp/SLEvA/DraftNationalEvaluationPolicy.pdf.
ticipating in the Parliamentarians Forum on 
Development Evaluation, a collective of parlia -
mentarians who are committed to the develop -
ment of evaluation in South Asian Association 
for Regional Cooperation countries. The Parlia -
mentarians Forum’s goal is to advance enabling 
environments for nationally owned, transparent, 
systematic and standard development evaluation 
processes that are in line with national evaluation 
policies at the country level, thus ensuring aid 
effectiveness, achievement of results and develop-
ment sustainability. (Rosenstein, 2015) 
The Parliamentary Committee on Public Enter -
prises and Public Accounts has been actively 
emphasizing the need for timely performance 
audits and the evaluation of state institutions and 
development projects. (Sivagnanasothy, 2015)
Partnerships to strengthen and promote eval -
uation (C7): Other stakeholders (professional 
organizations, universities, private sector actors, 
NGOs) and international organizations are coor-
dinating efforts and actively advocating and 
promoting the use and conduct of evaluations. 
(2015)
Sri Lanka civil society participates in evaluation 
through the Sri Lanka Evaluation Association 
(SLEvA). (Rosenstein, 2013) SLEva has a long 
history as a country network in the region and 
works closely with the Government of Sri Lanka 
to strengthen evaluation policy in the country 
and to strongly advocate for a national evaluation 
policy. Its efforts brought up a draft policy at the 
cabinet level. (Hashim, 2014) SLEva has been 
collaborating on the development of the Draft 
National Evaluation Policy. 78 In Sri Lanka, the 
strategy of promoting collaboration among gov -
ernment, parliament and civil society actors to 
increase the visibility of evaluation has had pos -
itive results: “The Government of Sri Lanka has 
given high priority to ensure value-for-money in 
public management. As a result, concepts such as 
Managing for Development Results, Evaluation 
and Performance Audit are getting very high 
focus in public management.” (Sivagnanasothy, 
2014)
Budgets for evaluation (C16): Special budget -
ary provisions are necessary for evaluations in 
Sri Lanka (Sivagnanasothy, 2014), as budgets 
are not in place for the conduct of evaluations. 
(2015). Government units have their own evalu -
ation budgets. Policies, programmes and projects 
have resources built for evaluations. Many orga -
nizations are concerned that allocated budget 
amounts to carry out quality evaluation are not 
sufficient. (2015)
3.9.2  National government’s capacity 
for independent evaluations 
(Independence of Evaluation)
Independent evaluators (C17):  Evaluations are 
conducted by internal government department 
staff and independent evaluators under contracts. 
External evaluations under contract are conducted 
through foreign donor projects and programmes. 
(2015) Specialized evaluations are mostly out -
sourced to independent academic or research 
institutions. The M&E units in line ministries, 
which also conduct or commission evaluations, 
operate independently from other management, 
operational and programme implementation func-
tions and report directly to the Head of the Line 
Ministry. In the case of M&E evaluations, an 
independent expert evaluation team is appointed 
to participate in routine evaluations. The evalua -
tion team is made up of representatives from the 
Department of Project Management and Moni -
toring, external independent sector specialists and 
representatives from academia and research insti-
tutions. (Sivagnanasothy, 2014) 
Evaluations include consultations with stake -
holders for beneficiary feedback as well as work -
<<<PAGE=65>>>
47
COUNTRY PROFILES
79 statistics.gov.lk/
shops for stakeholder comments on findings and 
recommendations. However, not all evaluation 
reports are made public or easily available on gov-
ernment websites.     
Implementation of evaluation recommenda -
tions (C3): In addition to targeting users who are 
expected to take action upon recommendations, 
evaluation reports often also target watchdog 
agencies, the media and civil society represen -
tatives who can play a role in influencing action 
upon recommendations. (Sivagnanasothy, 2014)
Management responses to evaluations are iden -
tified at a high-level progress review meeting 
chaired by a minister. The evaluation findings 
and recommendations are reported to the exec -
utive branch as part of the Auditor’s General 
annual report, tabled to the Cabinet of Ministers 
and discussed at the parliament. “Ministries are 
gradually expanding utilization-focused evalua -
tions and management responses are taken seri -
ously.” (Sivagnanasothy, 2015)
3.9.3  National government’s capacity  
to ensure credible evaluations  
(Credibility of Evaluation)
National data systems (C2): The Department of 
Census and Statistics is the central government 
agency responsible for collecting and analysing 
national data (e.g. demographics, economics).79
Integrated public registries (C11):  The absence 
of country-level centralized data for evaluation is 
a challenge in Sri Lanka. A web-based evaluation 
information system on a sector-wide basis is nec-
essary to make adequate evaluation information 
available. (Sivagnanasothy, 2014)
Methodologies (C9):  Constraints exist in Sri 
Lanka regarding lack of skills, methodologies, 
data systems, manuals and guidelines for evalua -
tion. (Sivagnanasothy, 2014) Nevertheless, SLEva 
runs professional capacity-building workshops 
and international conferences. As such, it pro -
vides space for peer-to-peer learning. SLEvA’s  
capacity-building efforts target government offi -
cials, NGO workers, academics and students. 
Activities include biannual national-level con -
ferences, international conferences and seminars 
and professional development workshops with 
renowned international experts. 
Evaluations undertaken by the government and 
development partners include evaluation experts 
and sector specialists. Selection is based on com -
petencies, skills and expertise. Generally, evalua -
tions follow OECD/DAC quality standards and 
use multiple data collection methods for trian -
gulation and to validate data and findings. Uni -
versities incorporated development evaluation as 
an important module in their postgraduate and 
masters degree programmes. (Sivagnanasothy, 
2015)
Peer-to-peer systems (C5):  Peer reviews by 
evaluation specialists within or outside the gov -
ernment is a practice in Sri Lanka. Peer reviews, 
management and reference groups are used to 
avoid conflict of interest or pressure. (Sivagnan -
asothy, 2014) However, the peer review mecha -
nism may not be widely known as, according to 
the survey, they are not used. (2015)
Gender (C18):  Gender-sensitiveness is one of 
the considerations for the selection of evalu -
ators to undertake government evaluations in 
Sri Lanka. (Sivagnanasothy, 2014) Nevertheless, 
gender is not properly considered in national-  
level evaluations. Evaluation data is disaggre -
gated by sex in the evaluations of international 
donor programmes. (2015) 
Ethnic and cultural dimensions (C8):  Accord-
ing to the survey results, ethnic and cultural 
issues are not considered in national-level eval -
uations. Nonetheless, ethnicity is one of the 
considerations for the selection of evaluators to 
undertake the government evaluations in Sri 
Lanka. (Sivagnanasothy, 2014)
<<<PAGE=66>>>
48
COUNTRY PROFILES
80 See limitations regarding generalizations about certain commitments such as budgets (C16), independent evaluators 
(C17), stakeholders’ involvement (C10), peer-to-peer systems (C5) gender (C18) and ethnic and cultural issues (C8). 
81 web.nso.go.th
3.10 THAILAND
3.10.1  National government’s capacity to use 
evaluations (Use of Evaluation) 80
Institutional set up (C4):  Sectoral policies 
requiring evaluation of specific national pro -
grammes exist in Thailand. Evaluations are 
used to assess the impacts of all government 
programmes, to assess the impact of specific 
programmes in certain government sectors, for 
learning purposes, to adjust course and to scale 
up initiatives. (2015)
In its Eleventh National Economic and Social 
Development Plan (2012–2016), the govern -
ment describes the need to develop “efficient, 
transparent and participatory systems of M&E 
at all levels.” Responsibilities for developing, 
monitoring and evaluating the implementation 
of the Plan fall under the Office of the Prime 
Minister and its National Economic and Social 
Development Board (NESDB). The Strategic 
Unit is responsible for monitoring and evalu -
ating government policies and for formulating 
national-level development strategies and policy 
recommendations and action. (Govermnent of 
Thailand NESDB, 2015)
Partnerships to strengthen and promote eval -
uation (C7): Local stakeholders (professional 
organizations, universities, private sector actors, 
NGOs) are actively advocating and promoting 
the use and conduct of evaluations. (2015)
The Thailand Evaluation Network (TEN) was 
created in November 2010. (Thailand Eval -
uation Network, 2015) It is working towards 
promoting an evaluation culture in the coun -
try, enhancing the enabling environment for 
evaluation, providing support to national eval -
uation systems and strengthening the demand 
for use of evaluations by policymakers. TEN is 
also working towards promoting transparency 
of government programmes so that it becomes 
a standard practice in the country. It is endeav -
ouring to build up other partnerships, especially 
with government agencies such as the Office of 
the National Economic and Social Development 
Board (NESDB).      
Budgets for evaluation (C16): Government 
units responsible for evaluation have their own 
budgets to conduct evaluation. (2015)
3.10.2  National government’s capacity 
for independent evaluations 
(Independence of Evaluation)
Independent evaluators (C17): Evaluations are 
conducted by the internal staff of government 
departments and by independent evaluators 
under contracts. 
Stakeholders’ involvement/access to informa -
tion (C10): Evaluation reports are not made 
public and are not easily available on government 
websites. (2015)
Implementation of evaluation recommenda -
tions (C3): There are no systems in place to 
follow-up on the implementation of evaluation 
recommendations. (2015)
3.10.3  National government’s capacity to 
ensure credible evaluations  
(Credibility of Evaluation)
National data systems (C2): The National Sta -
tistical Office is the central government agency 
responsible for collecting and analysing national 
data (e.g. demographics, economics).81
Gender (C18): Evaluations take gender into 
their considerations and analyses of programme 
impacts. (2015)
Ethnic and cultural dimensions (C8):  Ethnic 
and cultural issues are currently not considered in 
national-level evaluations. (2015)
<<<PAGE=67>>>
49
COUNTRY PROFILES
82 See limitations regarding generalizations about certain commitments such as budgets (C16), independent evaluators 
(C17), stakeholders’ involvement (C10), peer-to-peer systems (C5) gender (C18) and ethnic and cultural issues (C8). 
83 instat.gov.al/en/Home.aspx
84 See  limitations regarding generalizations about certain commitments such as budgets (C16), independent evaluators 
(C17), stakeholders’ involvement (C10), peer-to-peer systems (C5) gender (C18) and ethnic and cultural issues (C8). 
85 Decree  of the Government of the Kyrgyz Republic No.28 on 26 January 2011.
4.  EUROPE AND THE 
COMMONWEAL TH OF 
INDEPENDENT STATES
4.1 ALBANIA
4.1.1  National government’s capacity to use 
evaluations (Use of Evaluation) 82
Institutional set up (C4):  There are currently 
no existing national evaluation policy or national 
government evaluations. There are, however, 
proposals to institutionalize evaluation in the 
country, but they have not yet been enacted. At 
present, there are no central or decentralized 
units in the government in charge of conduct -
ing evaluations. (2015) The  government is initi -
ating a process to establish a unit to undertake 
M&E, which is expected to be in place by 2017 
with the goal of communicating government 
achievements and connecting a “top down mon -
itoring approach with a bottom up accountabil -
ity to citizens.” (Pelishi, 2014)
Partnerships to strengthen and promote evalu -
ation (C7): Stakeholders (professional organiza -
tions, universities, private sector actors, NGOs) 
are actively advocating and promoting the use 
and conduct of evaluations. (2015)
An Albanian Society of Programme Evaluation 
(ASPE) has existed since 2011, with the goals of 
raising awareness, supply and demand for eval -
uation, and of building a community of evalua -
tion stakeholders. It currently has 15 members, 
including representatives of governments, the 
private sector and civil society and the mission 
to contribute to the development of programme 
evaluation in Albania and to promote the use of 
evaluation in public and private organizations.     
Budgets for evaluation (C16):  Budgets are not 
in place for the conduct of evaluations. (2015)
4.1.2  National government’s capacity to 
ensure credible evaluations  
(Credibility of Evaluation)
National data systems (C2): The Albanian Insti-
tute of Statistics is the central government agency 
responsible for collecting and analysing national 
data (e.g. demographics, economics).83  
4.2 KYRGYZSTAN
4.2.1  National government’s capacity to use 
evaluations (Use of Evaluation)
 84
Institutional set up (C4):  National evaluation 
legislation is in place and evaluations are used 
for learning purposes, to adjust course and to 
scale up initiatives. There are no regulations for 
the operation of government agencies (2015). 
The 2010 Constitution of the Kyrgyz Republic 
provides the key framework for determining the 
role of the state in policymaking and ensuring 
the accountability of government authorities. It 
establishes that the Prime Minister shall submit 
an annual government report to the parliament 
and as such, provides opportunities for institu -
tionalizing the policymaking cycle—including 
M&E. The parameters for the further develop -
ment of an integrated system of drafting, adop -
tion, implementation and M&E of policy are also 
determined by government rules.85 
The regulations contain references to M&E as a 
part of the policymaking process, but their imple-
mentation is pro forma  as there is no evidence 
that indicators are being tracked. Quality assess -
ment of policy impact lacks in public administra-
tion, especially at the central level. 
Regarding policy development, the government 
has no dedicated unit focused on the formula -
tion, assessment or M&E of the implementa -
tion of sectoral and cross-sectoral policies. M&E
<<<PAGE=68>>>
50
COUNTRY PROFILES
86 stat.kg/en
is closely linked with international technical 
assistance programmes that actively support the 
implementation of reforms in the Kyrgyz Repub-
lic. The donor community had long advocated 
the importance of M&E, and with their support 
the government has incorporated this component 
in the implementation plans of national policies 
and programmes. However, government M&E 
efforts are still incipient as a result of the con -
tinued existence of the Soviet governance model 
where control replaces M&E. In addition, there 
is an insufficient number of ministry employees 
capable of engaging in M&E activities (which are 
also not formalized as inputs for decision-making 
processes). (Nogoibaeva, 2014)
As per policy implementation, the Office of the 
Government of the Kyrgyz Republic has a con -
trol function at the policy implementation stage 
and is responsible for monitoring the implemen-
tation of sectorial programmes and strategies. 
However, the country lacks an effective system 
to monitor and evaluate policy implementation. 
(Nogoibaeva, 2014)
Partnerships to strengthen and promote evalu -
ation (C7): Several institutions (government, vol-
untary organizations for professional evaluation, 
parliament and private sector entities) are coordi-
nating efforts and jointly promoting the need and 
demand for and use of national-level evaluations. 
A local voluntary organization for professional 
evaluation exists in the country—the National 
M&E Network of the Kyrgyz Republic has the 
mission of developing professional evaluation 
expertise. (IOCE, 2012) The Network’s mission 
is to influence governmental policies related to 
evaluation by engaging government officials in 
capacity- and awareness-building events orga -
nized by the Network and by participating 
in government-organized discussions of policy 
papers. Specifically, through the preparation of 
two policy briefs, the Network is advocating for 
a country-led M&E system and is pushing for 
effectiveness and transparency of government 
programmes and policies. 
Budgets for evaluation (C16):  Budgets are cur -
rently not in place to conduct evaluations (2015).
4.2.2  National government’s capacity 
for independent evaluations 
(Independence of Evaluation)
Stakeholders’ involvement/access to informa -
tion (C10): Evaluation reports are not made 
public and are not easily available on government 
websites. (2015)
Implementation of evaluation recommenda -
tions (C3):  There are no systems in place to 
follow-up on the implementation of evaluation 
recommendations. (2015)
4.2.3  National government’s capacity to 
ensure credible evaluations  
(Credibility of Evaluation)
National data systems (C2): The National Sta -
tistics Committee of the Kyrgyz Republic is the 
central government agency responsible for col -
lecting and analysing national data (e.g. demo -
graphics, economics).86 However, the institution 
has “limited capacity to collect data needed for 
monitoring.” (Nogoibaeva, 2014, p. 8)
Integrated public registries (C11): Public reg -
istries and administrative records are not inte -
grated. (2015)
Methodologies (C9): The government has lim -
ited evaluation capacities. There are also limited 
capacities within ministries to collect and pro -
cess information. These are challenges in view 
of complexity and cost involved. (Nogoibaeva, 
2014) There is particular need to deepen the 
knowledge and skills of civil servants in devel -
opment of indicators of achievement of goals 
and objectives. (National Council for Sustainable 
Development of the Kyrgyz Republic, 2013)
No higher educational institutions in the country 
offer a comprehensive course on public policy that 
would provide theoretical knowledge and prac -
<<<PAGE=69>>>
51
COUNTRY PROFILES
87 The exception is the Certificate in Policy Analysis four-module programme launched in 2014 by the University of 
Central Asia’s Institute of Public Policy and Administration.
88 See  limitations regarding generalizations about certain commitments such as budgets (C16), independent evaluators 
(C17), stakeholders’ involvement (C10), peer-to-peer systems (C5) gender (C18) and ethnic and cultural issues (C8). 
89 government.ru/en/department/250/events
tical skills needed in evaluation. 87 Methodolog-
ical guides on evaluation issues were produced 
by UNICEF Kyrgyzstan and Soros Foundation  
Kyrgyzstan. The National M&E Network is 
developing methodical evaluation instruments and 
offers online training, local workshops and round 
table discussions with the participation of NGOs 
and government representatives. There are also 
plans to create an electronic library of evaluation 
materials and literature in the Kyrgyz Republic. 
Peer-to-peer systems (C5):  Peer-to-peer sys -
tems do not exist as a system, but the National 
Network of M&E of the Kyrgyz Republic regu -
larly organizes peer-to-peer discussions on eval -
uation instruments and methods among M&E 
specialists, which sometimes includes interna -
tional experts. (2015)
Gender (C18):  The M&E Network developed 
a manual for gender-sensitive evaluation; some 
evaluations use gender-responsive evaluation 
methods. (2015)
4.3 RUSSIA
4.3.1  National government’s capacity to use 
evaluations (Use of Evaluation) 88
Institutional set up (C4):  The Russian govern -
ment recognizes “only one type of evaluation as 
legitimate: regulatory impact assessment (RIA) 
within the government sector.” RIAs have been 
institutionalized in the public sector in the early 
2000s as a methodology to measure the pre- and 
post-effects and impacts of regulations. Since 
then, RIA became multidisciplinary, requiring 
competencies in law, economics, political science 
and sociology. Programme Evaluation as a prac -
tice is gradually evolving from the RIA notion as 
administrative reforms are increasing emphasis in 
management by results and the demand for eval-
uation services in the country is increasing slowly 
as governmental entities become interested in 
“evaluation as an important new management 
tool.” (Kuzmin, 2014, p. 88)
Partnerships to strengthen and promote eval -
uation (C7):  International collaborations have 
been expanded in Russia in the past several years, 
enabling Russian professionals to gain access to 
the most recent evaluation journals and books. 
They also became involved in international dis -
cussions at professional conferences and are able 
to attend training and capacity-building work -
shops. Russian RIA professionals and evaluators 
developed an informal community of practice 
with several online forums. Its members actively 
participate in regional and national evaluation 
conferences. 
The Association of Specialists in Programme and 
Policy Evaluation (IOCE, 2012) was created in 
2014 with the mission “to develop programme 
and policy evaluation into a mature profession” in  
Russia. Among its goals, the association aims at dis-
seminating knowledge in programme evaluation, 
promoting norms and standards for high-quality 
evaluation and facilitating information exchange 
among evaluation specialists in the country. 
4.3.2  National government’s capacity to 
ensure credible evaluations  
(Credibility of Evaluation)
National data systems (C2): The Federal Ser -
vice for State Statistics (Rosstat) is the central 
government agency responsible for collecting 
and analysing national data (e.g. demographics, 
economics).89
Methodologies (C9):  Programme evaluation is 
taught at Moscow Higher School for Social and 
Economic Sciences and in the Masters of Pub -
lic Administration Programme. The Association
<<<PAGE=70>>>
52
COUNTRY PROFILES
90 See limitations regarding generalizations about certain commitments such as budgets (C16), independent evaluators 
(C17), stakeholders’ involvement (C10), peer-to-peer systems (C5) gender (C18) and ethnic and cultural issues (C8). 
91 Whether  the country learns and adjusts course or scale up initiatives with information from evaluations was not verified 
in this study.
92 The  administrative unit tasked with the implementation of the Program is made up of the Sub-secretariat of Management 
and Public Employment, the Secretariat of Evaluation of National Budget and the Sub-secretariat of Evaluation Projects 
with External Financing.
of Specialists in Program and Policy Evaluation 
is engaged in conducting conferences and round 
tables, training events and specialized Internet 
resources (websites, e-zines, blogs and informa -
tion portals). Local specialists and organizations 
capable of conducting high quality evaluations 
exist in the country. (Kuzmin, 2014)
5.  LATIN AMERICA AND  
THE CARIBBEAN 
5.1 ARGENTINA
5.1.1  National government’s capacity to use 
evaluations (Use of Evaluation) 90
Institutional set up (C4):  Argentina routinely 
conducts evaluations, but does not have a national 
evaluation policy. (Rosenstein, 2015) Legislation 
exists that has elements of an integrated system 
to monitor and evaluate public policies defining 
functions, responsibilities and standards, such 
as the laws of Financial Administration and 
Control Systems (Administración Financiera y 
Sistemas de Control) of the National System of 
Public Investment ( Sistema Nacional de Inver -
siones Públicas ) and the law of the Programme 
of Evaluation of the Quality of Expenditure 
(Programa de Evaluación de Calidad del Gasto ). 
(Aquilino, 2015) 
According to the survey, sectoral policies requir -
ing evaluation of specific national programmes 
exist. Universities and professional evaluation 
networks are pushing for the development of 
national policies, structures and frameworks. The 
survey also reveals that evaluations in Argen -
tina are used to assess the impacts of specific 
programmes in certain government sectors, for 
learning, for adjusting course and for scaling up 
initiatives.91  (2015)
Government legislation (Decree 22/2011) assigns 
the responsibility for the M&E of public policies 
to the Head Department of the Nation’s Minis -
ters’ Cabinet ( Jefatura de Gabinete de Ministros). 
(Perotti, 2014) The Jefatura coordinates the work 
of various national government departments 
for sectoral evaluation systems (Government of 
Argentina, 2015) through the Programme of 
Evaluation of Public Policy ( Programa de Eva -
luación de Políticas Públicas ) created in 2013 
with the goal of preparing evaluations of govern-
ment programmes.92 The Programme has several 
aims, including: contributing to the process of 
institutionalizing evaluation within the govern -
ment; improving the capacity of evaluations to 
improve governance and the quality of public 
policies; producing knowledge through applied 
research in evaluation of public policies; promot-
ing awareness; and consolidating an institutional 
agenda for the Administración Pública Nacional 
evaluation of public policies.
A Policy Assessment Programme was also estab-
lished at the Jefatura with the goals of raising 
awareness, positioning the agenda and main -
streaming policy evaluation in public adminis -
tration. There is also work towards establishing 
the Argentinian Network of Evaluation of Public 
Policies, which will integrate 50 national govern-
ment evaluation sectors and develop databanks of 
evaluation experiences. (Mattalini, 2013)
Argentina has three independently operating 
M&E systems: a budget-related system to fol -
low up on budgetary programmes (managed by 
the Ministry of Economy); a social programmes 
M&E system to gather information about ben -
efits, beneficiaries and budgetary expenditures 
(managed by the National Social Policy Coor -
dination Council of the Presidency); and a gov -
<<<PAGE=71>>>
53
COUNTRY PROFILES
93 A few Network meetings have been organized in Buenos Aires. However the Network still lacks a more formalized 
structure. 
ernment M&E system to monitor programme 
management by following up on goals (managed 
by the Jefatura). (Perotti, 2014)
The System of Social Programmes Information, 
Evaluation and Monitoring (Sistema de Infor -
mación, Evaluación y Monitoreo de Programas 
Sociales – SIEMPRO) is used in the M&E of 
social programmes. SIEMPRO uses formative 
and summative evaluations, focusing on pro -
gramme management, the identification of areas 
for improvement and programme relevance and 
effectiveness. The overall goal is to evaluate 
social programmes in their design, implementa -
tion and results phases. (Mattalini, 2013) 
The Integrated System of Management M&E 
(Sistema Integral de Seguimiento y Evaluación 
de la Gestión – SISEG) is used to gather M&E 
information from various government jurisdic -
tions on the implementation of government 
policies and priority programmes. It enables the 
systematization, consolidation, integration and 
processing of information on expected achieve -
ments under the strategic plan. (Perotti, 2014)
The Ministry of Social Development moni -
tors its functional activities in order to identify 
progress made by its social programmes. Other 
ministries are making similar efforts to develop 
the capacity to generate data in order to enable 
assessment of results and to promote the system-
atic evaluation of policies, programmes and ser -
vices. (Mattalini, 2013)
Other sectoral evaluation work is undertaken by 
the Ministry of Education, through its National 
Direction of Information and Evaluation of Edu-
cation Quality ( Dirección Nacional de Infor -
mación y Evaluación de la Calidad Educativa 
– DiNIECE ), and by the Ministry of Health, 
through its Direction of Supervision and Mon -
itoring (Dirección de Supervisión y Monitoreo ). 
(Aquilino, 2015) 
Partnerships to strengthen and promote evalu -
ation (C7): Stakeholders (including professional 
organizations, universities, private sector actors 
and NGOs) are actively advocating and promot -
ing the use and conducting of evaluations. The 
survey indicates that several institutions (e.g. 
government, voluntary organizations for pro -
fessional evaluation, the parliament and private 
sector entities) are coordinating efforts to jointly 
promote the need and demand for and the use of 
national-level evaluations.
The Argentinean Evaluation Network (Red 
Argentina de Evaluación) has been active since 
2005.93 Network membership includes represen -
tatives from the public and private sectors and 
from civil society (e.g. academics and NGOs). 
The Network is interested in promoting eval -
uation culture in different spaces of Argentina. 
In the long term, it aims to influence govern -
mental policies related to evaluation, evaluation 
design and the implementation of M&E systems. 
(IOCE, 2012) 
Budgets for evaluation (C16): The survey indi -
cates that budgets are generally not in place to 
conduct evaluations. However, the survey also 
indicated that some programmes have evaluation 
resources built into their budget. (2015)     
5.1.2  National government’s capacity 
for independent evaluations 
(Independence of Evaluation)
Independent evaluators (C17): The survey indi-
cates that evaluations are conducted by gov -
ernment departments’ internal staff and by 
independent evaluators under contracts. (2015) 
Stakeholders’ involvement/access to informa -
tion (C10): The evaluations of the National 
Social Policy Coordination Council on social 
programmes include the participation of stake -
holders (government representatives in charge of 
the programmes being evaluated) in preparing the 
evaluation agenda and implementing it, includ -
<<<PAGE=72>>>
54
COUNTRY PROFILES
94 indec.mecon.ar
95 See  limitations regarding generalizations about certain commitments such as budgets (C16), independent evaluators 
(C17), stakeholders’ involvement (C10), peer-to-peer systems (C5) gender (C18) and ethnic and cultural issues (C8). 
ing participation in the design, formulation of the 
evaluation questions, research methodology, dis -
cussions related to evaluation recommendations 
and in the preparation of the evaluation report. 
(Mattalini, 2013) Evaluation reports are not made 
public and are not available on government web-
sites.  (Aquilino, 2015) 
Implementation of evaluation recommenda -
tions (C3): There are no systems in place to 
follow up on the implementation of evaluation 
recommendations. (2015) 
5.1.3  National government’s capacity to 
ensure credible evaluations  
(Credibility of Evaluation)
National data systems (C2): The National Insti-
tute of Statistics and Census ( Instituto Nacio -
nal de Estadística y Censos ) is the government 
agency responsible for statistical data in Argen -
tina, including demographic, geographic, eco -
nomic and social data.94
Integrated public registries (C11):  SISEG is 
an information system platform that aggre -
gates information from other data subsystems.  
(Mattalini, 2013) According to the survey, public 
registries and administrative records are gener -
ally not integrated. (2015)
Methodologies (C9):  The Policy Assessment 
Programme of the Jefatura aims to develop eval -
uation capacities in public administration. The 
Programme has conducted training workshops 
for technical officials. (Perotti, 2014). According 
to the survey, technical courses/manuals are avail-
able to guide evaluation work. (2015)
Peer-to-peer systems (C5): According to the 
survey, peer-to-peer systems are not used. (2015)
Gender (C18): Evaluation data goes as far as dis-
aggregating data by sex only. (2015)
Ethnic and cultural dimensions (C8): Nation-
al-level evaluations do not formally or consis -
tently consider ethnic and cultural issues. (2015)
5.2 BARBADOS
5.2.1  National government’s capacity to use 
evaluations (Use of Evaluation) 95
Institutional set up (C4):  Sectoral policies 
that require evaluation of specific national pro -
grammes exist in Barbados. There are proposals 
to institutionalize evaluation in the country, but 
they have not yet been enacted. Evaluations are 
used to assess impacts of specific programmes in 
some government sectors. (2015)
The Research and Planning Unit of the Ministry 
of Finance and Economic Affairs and decentral -
ized units in other government departments are 
tasked with conducting evaluations. (2015) The 
Research and Planning Unit has the responsi -
bility to “monitor, analyse and report on those 
economic and social outcomes which enable the 
public to identify and evaluate Barbados’ perfor -
mance and position, along its development plan.” 
(Ministry of Finance, 2015) 
There is no noticeable integration between plan-
ning and the budget, no system for evaluating the 
results of institutional management and no mon-
itoring system for the government plan. (Lopez, 
2011)
Partnerships to strengthen and promote evalu -
ation (C7): Stakeholders (including professional 
organizations, universities, private sector actors 
and NGOs) and international organizations are 
actively advocating and promoting the use and 
conducting of evaluations. (2015) 
Budgets for evaluation (C16): Budgets are not 
in place for the conduct of evaluations. (2015)
<<<PAGE=73>>>
55
COUNTRY PROFILES
96 barstats.gov.bb
97 See  limitations regarding generalizations about certain commitments such as budgets (C16), independent evaluators 
(C17), stakeholders’ involvement (C10), peer-to-peer systems (C5) gender (C18) and ethnic and cultural issues (C8). 
5.2.2  National government’s capacity 
for independent evaluations 
(Independence of Evaluation)
Independent evaluators (C17): Government 
departments’ internal staff conduct evaluations. 
(2015)
Stakeholders’ involvement/access to informa -
tion (C10): Evaluation reports are made public 
and are easily available on government websites. 
(2015)
Implementation of evaluation recommenda -
tions (C3): There are no systems in place to 
follow up on the implementation of evaluation 
recommendations. (2015)
5.2.3  National government’s capacity to 
ensure credible evaluations  
(Credibility of Evaluation)
National data systems (C2): The Barbados 
Statistical Service is the central government 
agency responsible for collecting and analysing 
national data (e.g. demographics, economics). 96 
“The Statistical Service depends administratively 
on the Ministry of Foreign Affairs.” Even though 
institutional records from ministries and public 
institutions are sent periodically to the Statistical 
Service, “the information is generally two years 
out of date.” (Lopez, 2011, p. 100)  
Integrated public registries (C11):  Public reg -
istries and administrative records are not inte -
grated. (2015)
Methodologies (C9): Technical courses and man-
uals are available, but not formally designated as 
such. (2015)
Peer-to-peer systems (C5): Peer-to-peer systems 
are currently being developed in Barbados. (2015)
Gender (C18): Evaluation data is disaggregated 
by sex. Gender considerations are inextrica -
bly embraced by some national evaluation pro -
grammes. (2015)
Ethnic and cultural dimensions (C8):  Some 
evaluation reports discuss ethnic and cultural 
issues. (2015) 
5.3 BRAZIL
5.3.1  National government’s capacity to use 
evaluations (Use of Evaluation) 97
Institutional set up (C4):  Brazil routinely con -
ducts evaluation, but does not have a national 
evaluation policy. (Rosenstein, 2015) There are 
no efforts in place to develop national policies, 
structures or frameworks requiring evaluations. 
The country does not have national government 
evaluations. (2015) 
Sectoral policies requiring evaluation of specific 
national programmes exist. Universities and pro-
fessional evaluation networks are pushing for the 
development of national policies and structures. 
Evaluations are used for learning purposes, to 
adjust course and to scale up initiatives. The gov-
ernment uses evaluations for accountability. 
There is no central government unit conducting 
evaluations. The Ministry of Planning is respon-
sible for overall national government evaluation, 
but sectoral ministries prepare their own evalu -
ations. The Brazilian federal agencies of control 
(Federal Court of Accounts – TCU) and the 
Office of the Comptroller General are engaged 
in national programme evaluation through per -
formance audits and programme implementation 
evaluation. 
Decentralized units exist in various agencies and 
ministries, such as in the Institute of Economic 
and Applied Research (Instituto de Pesquisa
<<<PAGE=74>>>
56
COUNTRY PROFILES
98 More information on the experience of the TCU can be found at http://web.undp.org/evaluation/documents/NEC/
NEC-2011Proceedings.pdf and http://portal2.tcu.gov.br/portal/pls/portal/docs/2541117.PDF
99 It is possible that changes have been in place since the source date, however website data does not contradict the source. 
As such, this information was included in the study as an important as a point of departure for future work. 
100 The Brazilian Network has been active since 2003. As of 2012, membership includes about 3,660 members from the 
public and private sectors, civil society (academics and NGOs) and international organizations. 
Econômica Aplicada – IPEA), the National Insti-
tute of Studies and Research ( Instituto Nacional 
de Estudos e Pesquisas – INEP), the Ministry of 
Health and the Ministry of Social Development. 
(2015)
There have been successful national-level insti -
tutionalization initiatives, such as those by the 
Ministry of Social Development (Ministério de 
Desenvolvimento Social e Combate à Fome – 
MDS) in relation to its key social programmes 
and by the General Court of Audits (Tribunal de 
Contas da União – TCU).98
The Secretariat of Evaluation and Information 
Management (Secretaria de Avaliação e Gestão 
da Informação – SAGI) monitors and evaluates 
key social development policies and programmes. 
SAGI focuses on the quality of the interven -
tions’ management rather than on their compli -
ance with regulations and legislation. (Vaitsman, 
2011)99 Its activities enable a better understand -
ing of its targeted population, its programme 
logic, problems to be addressed, good practices 
and government results and impacts in the area 
of social development. (Ministerio de Desenvol -
vimento Social, 2015)
The Ministry of Health’s Department of Moni -
toring and Evaluation ( Departamento de Moni-
toramento e Avaliacao do Ministerio da Saude ) 
developed a framework with key national-level 
indicators to monitor the implementation of its 
priority programmes and to measure the devel -
opment and quality of the country’s health sys -
tems. The Ministry of Education has initiatives 
such as a Control Panel ( Simec-Painel de Con -
trole), which contains a set of indicators and 
information that, similarly to SAGI, enable a bet-
ter understanding of its targeted population, its 
programmes’ implementation problems as well as 
the identification of good practices and govern -
ment results in the sector.  (TCU, 2014)
Parliamentarians promoting evaluation use 
(C6): The Brazilian M&E Network (Rede Bra-
sileira de Monitoramento e Avaliação )100 works 
with Brazilian legislative members to demand 
and use more evaluation. (IOCE, 2012)
Partnerships to strengthen and promote eval -
uation (C7): At the national level, several insti -
tutions (government, voluntary organizations for 
professional evaluation, the Parliament and pri -
vate sector actors) are coordinating efforts and 
jointly promoting the need and demand for and 
use of evaluations. (2015)
The Brazilian M&E Network works with civil 
society organizations to enhance their under -
standing of their role in participating in policy 
formulation, monitoring and evaluation, and 
works with the media to ensure they can produce 
better information. (IOCE, 2012)
Budgets for evaluation (C16): Government 
units responsible for evaluation have their own 
budgets to conduct evaluations. (2015)
5.3.2  National government’s capacity 
for independent evaluations 
(Independence of Evaluation)
Independent evaluators (C17):  SAGI evalu -
ations are conducted by independent/external 
institutions, which reduces the risk of political 
influence on evaluation. (2015)
Stakeholders’ involvement/access to informa -
tion (C10): Evaluation processes at SAGI include 
the stakeholder participation (government repre-
sentatives in charge of the programmes being eval-
uated) in the preparation of the evaluation agenda,
<<<PAGE=75>>>
57
COUNTRY PROFILES
101 The Consórcio de Informação Social is a system for the exchange of scientific information about the Brazilian society. 
102 ibge.gov.br
103 See  limitations regarding generalizations about certain commitments such as budgets (C16), independent evaluators 
(C17), stakeholders’ involvement (C10), peer-to-peer systems (C5) gender (C18) and ethnic and cultural issues (C8). 
its implementation (including participation in the 
design, the formulation of evaluation questions, 
determination of research methodology), and in 
discussions related to recommendations and the 
preparation of the evaluation report. Transparency 
and accountability are also promoted through the 
publication of the microdata through the Social 
Information Consortium (Consórcio de Informa-
ção Social).101 This enables comparability of results 
and informal validation of programme informa -
tion. (Vaitsman, 2011) 
Some evaluation reports are made public and are 
easily available on websites; others are not. (2015)
Implementation of evaluation recommenda -
tions (C3):  There are no systems in place to 
follow up on the implementation of evaluation 
recommendations. (2015)
5.3.3  National government’s capacity to 
ensure credible evaluations  
(Credibility of Evaluation)
National data systems (C2): The Brazilian Insti-
tute of Geography and Statistics (Instituto Brasi-
leiro de Geografia e Estatistica – IBGE)102  is the 
central government agency responsible for col -
lecting and analysing national data (e.g. demo -
graphics, economics). 
Integrated public registries (C11):  Although 
public registries and administrative records are 
not fully integrated, there are efforts to integrate 
registries, such as the Unified Registry for Social 
Programmes (Cadastro Único para Programas 
Sociais – CadÚnico). (2015) 
Methodologies (C9):  In order to guide work, 
in-person and online technical courses are avail -
able, as are printed and digital publications and 
products (e.g. data tools, monitoring indicators, 
evaluation research and specific technical studies 
in social development-related topics).      
The Brazilian M&E Network aims to dissem -
inate knowledge and information through an 
annual seminar, publications and by promot -
ing the interaction and exchange of experience 
through participation in other networks and 
regional and international events (such as Red 
de Monitoreo y Evaluación de América Latina y 
El Caribe, IOCE, and others). The Network also 
works towards promoting and supporting capac -
ity development initiatives and public-sector  
policy. ( Joppert, 2012) 
Gender (C18): Some evaluations incorporate 
gender into their consideration and analysis of 
programme impacts. (2015)
Ethnic and cultural dimensions (C8): Some 
evaluations use data that are disaggregated by 
ethnic and cultural backgrounds. (2015)
Coordination practices (C14):  SAGI supports 
technicians and managers from other federal 
government departments, state governments and 
municipalities involved in social development 
policies, in daily management and improve -
ment of the Ministry’s programmes and actions. 
Support is provided regarding the development 
of information tools to organize and provide 
data on Internet, panels of monitoring indica -
tors, evaluation research and specific technical  
studies. 
5.4 COLOMBIA
5.4.1  National government’s capacity to use 
evaluations (Use of Evaluation) 103
Institutional set up (C4):  Colombia does not 
have a national evaluation policy. Evaluations 
are used to assess the impacts of specific pro -
grammes in some government sectors and for 
learning purposes to adjust course or to scale up 
initiatives. (2015)
<<<PAGE=76>>>
58
COUNTRY PROFILES
104 It is possible that changes have been in place since the source date, however website data does not contradict the source. 
As such, this information was included in the study as an important as a point of departure for future work. 
The constitution establishes that the National 
Planning Department ( Departamento Nacio -
nal de Planeación – DPN ) is responsible for the 
organization of systems of evaluation of manage-
ment and for the results of public administration. 
The DNP’s Directorate of Evaluation of Public 
Policies (Dirección de Evaluación de Políticas 
Públicas – DEPP) collects, produces and dissem-
inates information for decision-making related 
to: the design and implementation of policies 
and programmes; estimates of the impact of pol-
icies and programmes on target populations; and 
improvements to public management effective -
ness and efficiency. (Organization of American 
States, 2015)
DEPP monitors the ongoing implementation 
of priority objectives and targets of government 
departments in relation to the national develop -
ment plan. It also undertakes targeted evaluations 
to assess the functioning, impact and evolution of 
the main government policies and programmes. 
One of DEPP’s functions is to design and pro -
vide guidance for strengthening the National 
System for the Assessments of Management 
and Results (Sistema National de Evaluación de 
Gestión y Resultados – SINERGIA). DEPP is 
also tasked with establishing the framework for 
assessing the results of public policies, plans, pro-
grammes and projects. It is also tasked with pro -
viding advice on evaluation techniques and tools 
used by technical divisions of the department and 
other government agencies. (Dorado, 2011)104 
The National Council of Social and Economic 
Policy (Consejo Nacional de Política Económica 
y Social – CONPES) is responsible for deci -
sions regarding a four-year evaluation agenda in 
coordination with the government. It produces 
recommendations for development plans and pro-
grammes, for investment plans and for the general 
annual budget presented to the National Congress. 
(Organization of American States, 2015)
Partnerships to strengthen and promote eval -
uation (C7):  Stakeholders (professional orga -
nizations, universities, members of the private 
sector actors, NGOs) are actively advocating and 
promoting the use and conduct of evaluations. 
(2015)
The Colombian Network of Systems for Infor -
mation, Planning, Monitoring, Evaluation and 
Systematization ( Red Colombiana de Sistemas 
de Información, Planeación, Seguimiento, Eva -
luación y Sistematización – SIPSES ) has been 
inactive for the past few years. 
The Colombian Network of M&E (a chapter of 
the Latin American Network of M&E), works 
towards strengthening the results-based manage-
ment culture in Colombia through cooperation 
with government, academia and civil society for 
knowledge sharing. (IOCE, 2012)
Budgets for evaluation (C16):  The government 
units responsible for evaluation have their own 
budgets to conduct evaluation. (2015) 
5.4.2  National government’s capacity 
for independent evaluations 
(Independence of Evaluation)
Independent evaluators (C17):  External con -
sulting firms conduct evaluations in Colombia. 
(2015)
Stakeholders’ involvement/access to informa -
tion (C10): The DEPP disseminates information 
about evaluation results and monitoring activi -
ties to the public and interested sectors as a feed-
back mechanism for accountability. Stakeholder 
involvement is a principle for the Colombian 
evaluation system, as it is believed to facilitate and 
legitimize the evaluation results along with the 
involvement of the public programme manager, 
considered important to enable continuous feed -
back even before the official final report. (National 
Planning Department Colombia, 2015)
<<<PAGE=77>>>
59
COUNTRY PROFILES
105 sinergia.dnp.gov.co/Sinergia/Archivos/1d0d1a57-4548-4cad-b648-920d838b43e4/UNDP_SUDAFRICA.pdf
106 dane.gov.co
107 sinergia.dnp.gov.co/Sinergia/Archivos/52077da3-5b2b-4376-aaeb-c514f68bd4ac/Agenda%20Evaluaciones  
%202015.pdf
108 See limitations regarding generalizations about certain commitments such as budgets (C16), independent evaluators 
(C17), stakeholders’ involvement (C10), peer-to-peer systems (C5) gender (C18) and ethnic and cultural issues (C8). 
SINERGIA uses different communication chan-
nels for sharing information about the meetings, 
with the goals of reaching the highest number 
of stakeholders and providing clear and concise 
messages on evaluation issues. As the next step, 
plans include developing an open data system. 105 
The website has more than 170 evaluation reports 
posted and available for download. It also presents 
a list of completed evaluations and its evaluation 
agenda. (National Planning Department, 2015)
Implementation of evaluation recommenda -
tions (C3): The DEPP evaluation process begins 
with identifying and selecting evaluations and 
ends with monitoring the recommendation’s 
implementation. The system includes the devel -
opment of an agreement with the evaluated 
executing agency in order to ensure that the rec -
ommendations are implemented and that the 
evaluation contributes to improved interventions. 
(Dorado, 2011)
5.4.3  National government’s capacity to 
ensure credible evaluations  
(Credibility of Evaluation)
National data systems (C2): The National 
Administrative Department of Statistics (Depar-
tamento Administrativo National de Estadís -
tica – DANE) is the central government agency 
responsible for collecting and analysing national 
data (e.g. demographics, economics).106
Integrated public registries (C11):  SINERGIA 
relies on online public repositories of data that 
support M&E of government plans and progress 
towards the national development plan. The Sys-
tem of Management and Monitoring of Govern-
ment Goals (Sistema de Gestión y Seguimiento a 
las Metas del Gobierno – SIGOB) contains data 
on indicators for various sectors, and the National 
System of Evaluations (Sistema Nacional de 
Evaluaciones – SISDEVAL) has information on 
the evaluations agenda, evaluation results, reports 
of evaluations conducted and monitoring infor -
mation. (National Planning Department, 2015)
Methodologies (C9): The evaluation scope and 
methodology are defined during the design phase 
and include the theory of change behind the 
public policy. (Dorado, 2011) Documents avail -
able in the DEPP include descriptions of internal 
processes and guidelines to evaluation steps and 
procedures. A manual for users of the National 
Evaluation System is also posted on the web -
site.107 (National Planning Department, 2015)
Peer-to-peer systems (C5): Peer-to-peer systems 
are not used in Colombia. (2015)
Gender (C18): Evaluations take gender into 
their consideration and analysis of programme 
impacts; evaluation data are disaggregated by sex. 
(2015)
Ethnic and cultural dimensions (C8):  Eval -
uations take ethnic and cultural issues into 
their considerations and analyses of programme 
impact; evaluation data is disaggregated by ethnic 
and cultural background. (2015) 
5.5 COSTA RICA
5.5.1  National government’s capacity to use 
evaluations (Use of Evaluation) 108
Institutional set up (C4): Costa Rica has national 
evaluation legislation. It also has universities and 
professional evaluation networks that are cur -
rently pushing for the development of national 
policies, structures and frameworks. Evaluations 
are used to assess the impacts of government pro-
grammes and of specific programmes in certain
<<<PAGE=78>>>
60
COUNTRY PROFILES
109 It is possible that changes have been in place since the source date, however website data does not contradict the source. 
As such, this information was included in the study as an important as a point of departure for future work. 
110 See comment on limitations regarding generalizations about certain commitments. 
sectors in order to provide accountability for gov-
ernment actions, for learning purposes, to adjust 
course and to scale up initiatives. (2015)
Implementing the National Evaluation System 
(Sistema National de Evaluación – SINE) is 
the responsibility of the Ministry of National 
Planning and Economic Policy (Ministerio de 
Planificación Nacional y Política Económica – 
MIDEPLAN),109 with support from the Minis -
try of Finance (Ministerio de Hacienda) and the 
Comptroller General (Contraloría General de la 
República). SINE sets up the government’s legal 
framework under which planning and M&E 
take place. It is organized in a sectoral struc -
ture with a number of coordination and advisory 
mechanisms, which produce the national devel -
opment plan in line with the government’s stra -
tegic priorities. (Vargas, 2011)
The National Evaluation System is made up 
of central government administration and pub -
lic agencies charged with administering public 
resources. MIDEPLAN is responsible for plan -
ning units of more than 100 central and decen -
tralized government institutions. The sectoral 
agencies and ministries, the institutional plan -
ning units and MIDEPLAN’s Evaluation and 
Monitoring Area (in its role as coordinator) par -
ticipate as entities in the National Evaluation 
System. (Vargas, 2011)
The M&E Subsystem (Subsistema de Evaluación 
y Seguimiento) is the unit tasked with identify -
ing progress and quality of the implementation 
of development policies, plans, programmes and 
projects. It works to develop an M&E culture in 
the public sector; to promote the institutional 
monitoring of policies, plans, programmes and 
projects; and to evaluate strategic interventions 
against the goals of the national development 
plan. It also develops M&E guidelines, meth -
odologies and processes; an annual agenda for 
strategic evaluations; proposals for evaluations 
by the institutions managing the programmes; 
and oversees dissemination of information about 
M&E activities. (MIDEPLAN, 2015)
Partnerships to strengthen and promote eval -
uation (C7): Stakeholders (evaluation profes -
sional organizations, universities, private sector 
actors, NGOs), the government and international 
organizations are actively advocating and coor -
dinating efforts to promote evaluation use and 
demand. (2015)
A Central America Evaluation Association 
(Asociación Centroamericana de Evaluación – 
ACE) has existed since 2000. The Association’s 
goals include promoting the practice, research 
and use of evaluation in public and private insti -
tutions in Central America and the Caribbean. 
(IOCE, 2012)
Budgets for evaluation (C16): Policies, pro -
grammes and projects have built into their bud -
get resources for evaluations.  Government units 
responsible for evaluation have their own budgets 
to conduct evaluations.110 (2015)
5.5.2  National government’s capacity 
for independent evaluations 
(Independence of Evaluation)
Independent evaluators (C17):  Evaluations 
are conducted by the internal staff of govern -
ment departments and by independent evaluators 
under contracts. (2015)
Stakeholders’ involvement/access to informa -
tion (C10): Evaluation reports produced by the 
SINE are posted on the MIDEPLAN website.  
(MIDEPLAN, 2015)     
Implementation of evaluation recommenda -
tions (C3): There are systems in place to follow-up 
on the implementation of evaluation recommen-
dations by SINE, MIDEPLAN, the Ministry of 
Finance and the Comptroller General. (2015)
<<<PAGE=79>>>
61
COUNTRY PROFILES
111 inec.go.cr
112 See limitations regarding generalizations about certain commitments such as budgets (C16), independent evaluators 
(C17), stakeholders’ involvement (C10), peer-to-peer systems (C5) gender (C18) and ethnic and cultural issues (C8). 
113 Law 498-6 establishes that the Public Investment Process includes the formulation, prioritization, monitoring and 
evaluation of public-sector investment projects. 
5.5.3  National government’s capacity for 
credible evaluations  
(Credibility of Evaluation)
National data systems (C2): The National Insti-
tute of Statistics and Census (Instituto Nacional 
de Estadística y Censos) is the central gov -
ernment agency responsible for collecting and 
analysing national data (e.g. demographics, eco -
nomics).111
Integrated public registries (C11):  There are 
ongoing efforts to include administrative records 
from all government entities. Several projects 
are in place to improve the quality, relevance and 
standardization of data collected from public 
institutions and entities. (2015)
An integrated public registry exists in MIDE -
PLAN. The System of Indicators of Sustain -
able Development (Sistema de Indicadores sobre 
Desarrollo Sostenible – SIDES) integrates Costa 
Rica’s key information systems, including data 
from the National Institute of Statistics and 
Census, the Central Bank of Costa Rica and the 
Ministries of Finance, Education, Health and 
Social Security. Data is organized around six 
themes: international, social, economic, environ-
mental, citizen security and government perfor -
mance. The system enables easy access to data and 
analysis of the national situation as an important 
tool for studies, programme formulation, policy 
development and programme evaluation. Data 
and a guide to use the system are available on the 
SIDES website. (MIDEPLAN, 2015)
Methodologies (C9):  SINE has manuals and 
guidelines for evaluation work. (2015) There are 
limited resources and staff in the evaluation units. 
The Central America Evaluation Association is 
working towards strengthening the professional 
capacities in evaluation on order to enhance the 
effectiveness of policy, programme and project 
implementation, and is working towards dissem-
inating information on evaluation methodologies 
across the region. 
5.6 DOMINICAN REPUBLIC
5.6.1  National government’s capacity to use 
evaluations (Use of Evaluation) 112
Institutional set up (C4):  There are no legal 
frameworks that require national-level evalua -
tions in the Dominican Republic. Evaluations are 
used to assess the impacts of specific programmes 
in certain government sectors and for learning 
purposes, adjusting course and scaling up initia -
tives. (2015)
Evaluations of investment projects are required 
by law.113 M&E initiatives are also undertaken 
for social programmes and policies supported by 
the Inter-American Development Bank, UNDP 
and the World Bank. 
As the agency responsible for the National Plan-
ning System, the Ministry of Economy, Planning 
and Development (Ministerio de Economia, 
Planificación y Desarrollo – MEPyD) is tasked 
with the responsibility for the formulation, man-
agement and M&E of national policies.
As per the 2010–2030 National Development 
Strategy (Estrategia Nacional de Desarrollo – 
END) the Dominican Republic is currently in 
the process of formulating a proposal to develop 
the National System for M&E. The System 
will enable the production of monitoring and 
progress reports on the implementation of the 
National Plan of Investments of the Public Sec -
tor and Bilateral Cooperation. (Ministério de 
Economia, Planificación y Desarrollo, 2015) 
The Strategic Plan 2013–2016 sets up the devel-
opment of a set of norms and technical regula -
<<<PAGE=80>>>
62
COUNTRY PROFILES
114 For more information, see one.gov.do.
115 For more information, see dl.dropboxusercontent.com/u/4970783/guia-metodologica-2013.pdf.
tions to guide the M&E System and the creation 
of an inter-institutional commission to monitor 
public policies. The Strategic Plan will also guide 
the development of the institutional capacities 
that are to be implemented between 2014 and 
2016. (MEPyD, 2013)
Other sectoral government evaluation institu -
tions exist in the country, such as the Domin -
ican Institute of Evaluation and Research on 
Quality of Education ( Instituto Dominicano de  
Evaluación e Investigación de la Calidad  
Educativa IDEICE), affiliated with the Ministry 
of Education. 
Parliamentarians promoting evaluation use 
(C6): There are no national-level efforts under 
way to promote the need and demand for and use 
of evaluations. (2015)
Partnerships to strengthen and promote evalu -
ation (C7): Stakeholders (professional organiza -
tions, universities, private sector actors, NGOs) 
and international organizations are promoting 
the need and demand for and use of national-  
level evaluations. (2015)
The Network of Evaluators of the Domini -
can Republic ( Red de Evaluadores de la Repú -
blica Dominicana ), created in 2009, is working 
towards the continuous professionalization of 
evaluation in the Dominican Republic. The 
Network aims include enhancing learning, 
improving the quality of development initia -
tives in the country, being a centre for reference 
on good evaluation practices and increas -
ing the use of evaluation in decision-making  
processes. 
Budgets for evaluation (C16) : Budgets are 
not in place for the conduct of evaluations. 
Some policies, programmes and projects have 
resources for evaluations built into their bud -
gets. (2015)
5.6.2  National government’s capacity 
for independent evaluations 
(Independence of Evaluation)
Independent evaluators (C17): The survey indi-
cates that evaluations are conducted by indepen -
dent evaluators under contracts. 
Stakeholders’ involvement/access to infor -
mation (C10): National government evaluation 
reports are not easily available on government 
websites. (2015)
Implementation of evaluation recommenda -
tions (C3): There are no systems in place to 
follow-up on the implementation of evaluation 
recommendations. (2015)
5.6.3  National government’s capacity to 
ensure credible evaluations  
(Credibility of Evaluation)
National data systems (C2): The National 
Agency of Statistics (Oficina National de 
Estadísticas – ONE) is the central government 
agency responsible for collecting and analysing 
national data (e.g. demographics, economics).114
Integrated public registries (C11): In collabora-
tion with the ONE, the MEPyD Strategic Plan 
2013–2016 includes actions to improve public 
registries to improve data quality for M&E pur -
poses. (MEPyD, 2013) 
Methodologies (C9): The Dominican Network 
of Evaluators has organized capacity-building 
events on evaluation topics. (IOCE, 2012) The 
MEPyD launched a Methodological Guide for 
Formulation and Evaluation of Public Invest -
ment Projects for use by the public institutions 
for the development of projects to be included in 
the Public Investment Plan.115 
Peer-to-peer systems (C5): Peer-to-peer systems 
are not used. (2015)
<<<PAGE=81>>>
63
COUNTRY PROFILES
116 See limitations regarding generalizations about certain commitments such as budgets (C16), independent evaluators 
(C17), stakeholders’ involvement (C10), peer-to-peer systems (C5) gender (C18) and ethnic and cultural issues (C8). 
Gender (C18): Evaluation data is disaggregated 
by sex. (2015)
Ethnic and cultural dimensions (C8):  Accord-
ing to the survey results, ethnic and cultural 
issues are not considered in national-level evalu -
ations. (2015)
5.7 EL SALVADOR
5.7.1  National government’s capacity to use 
evaluations (Use of Evaluation) 116
Institutional set up (C4): El Salvador uses eval -
uations to assess impacts of specific programmes 
in certain government sectors (e.g. health, educa-
tion, social assistance). Sectoral policies requiring 
evaluation of specific national programmes exist, 
and there are proposals to institutionalize eval -
uation in the country (these have not yet been 
enacted). (2015)
The National Planning System ( Sistema Natio-
nal de Planificación – SNP ) established the 
Monitoring, Evaluation and Results-Based 
Management (Monitoreo, Evaluación y Gestión 
por Resultados – GPR). GPR and the Budget 
by Results (Presupuesto por Resultados – PPR) 
identify financing in line with established bud -
gets and develop the Annual Evaluation Agenda. 
(Santamaria, 2013) Decentralized units in charge 
of conducting evaluations also exist in several 
other Ministries. (2015)
Evaluation is required in government strategic 
programmes, with a specific emphasis on selected 
social programmes. The goals are to identify 
public policy progress and the results of inter -
ventions on target populations and to develop 
rigorous recommendations for decision makers. 
Evaluation is also used to reassign public funds 
in order to improve programme management, 
policy making and resource allocation. (Organi -
zation of American States, 2015)
Partnerships to strengthen and promote eval -
uation (C7): A group of professionals are push -
ing for the development of national policies, 
structures and frameworks in El Salvador. Inter -
national organizations are also advocating and 
promoting the use of evaluations. (2015) The 
Evaluation Network of El Salvador (Red de Eva-
luación en El Salvador ) was created in 2005 as 
an informal network to exchange information on 
M&E, to enhance M&E culture and to advocate 
for including M&E in the national agenda. It is 
in the process of reactivation and expansion of its 
membership. (IOCE, 2012)
Budgets for evaluation (C16): Some surveys 
indicate that policies, programmes and projects 
have built into their budgets resources for eval -
uations; others indicated that budgets are not in 
place for conducting evaluations. (2015)
5.7.2  National government’s capacity 
for independent evaluations 
(Independence of Evaluation)
Independent evaluators (C17): Evaluations are 
conducted by independent evaluators under con-
tract and by the internal staff of government 
departments, depending on the type of institu -
tion and evaluation scope. (2015)
Stakeholders’ involvement/access to infor -
mation (C10): Once the Annual Evaluation 
Agenda is developed, terms of reference for 
specific evaluations are developed and evalu -
ation committees are established (committees 
are made up of representatives from institutions 
involved with programme implementation). The 
committees are set up as coordinating bodies 
responsible for following up and supervising the 
processes of evaluation. They enable dialogue, 
debate and presentation of proposals for the 
evaluation process. 
The Observatory of Evaluations ( Observato-
rio de Evaluación ) is a government web portal
<<<PAGE=82>>>
64
COUNTRY PROFILES
117 sne.gob.sv/apps/evaluacion
118 CIDE-Centro CLEAR para América Latina 1a. Edición, 2013 Maldonado Trujillo, Claudia Galíndez Hernández, 
Cristina Monitoreo, Evaluación y Gestión por Resultados. Aprendizaje y Cooperación SurSur para la Innovación: 
El Papel de los Actores Subnacionales. clear-la.cide.edu/sites/default/files/Monitoreo_Evaluaci%C3%B3n%20y%20
Gesti%C3%B3n%20por%20Resultados_Maldonado%20y%20Gal%C3%ADndez_0.pdf
119 digestyc.gob.sv
120 See limitations regarding generalizations about certain commitments such as budgets (C16), independent evaluators 
(C17), stakeholders’ involvement (C10), peer-to-peer systems (C5) gender (C18) and ethnic and cultural issues (C8). 
that contains executive summaries of evaluation 
results.117 The Observatory is available for con -
sultation on public policies.118
Implementation of evaluation recommenda -
tions (C3): There are no systems in place to 
follow up on the implementation of evaluation 
recommendations. (2015)
5.7.3  National government’s capacity to 
ensure credible evaluations  
(Credibility of Evaluation)
National data systems (C2): The General Direc-
tion of Statistics and Census ( Dirección General 
de Estadísticas y Censos – DIGESTYC ) is the 
central government agency responsible for col -
lecting and analysing national data (e.g. demo -
graphics, economics).119
Another SNP initiative is the implementation of 
the System of Management and Monitoring of 
Government Goals (Sistema de Gestión y Segui-
miento a las Metas del Gobierno – SIGOB ). 
(Organization of American States, 2015)
Integrated public registries (C11):  Public reg -
istries and administrative records are not inte -
grated. (2015) Developing tools and strategies 
for better data quality is key, as there is usually a 
lack of data (or if available, the data lacks quality). 
(Maldonado Trujillo, 2013 ) 
Methodologies (C9):  The Evaluation Network 
has organized training events on evaluation top -
ics in the past. (IOCE, 2012) There are technical 
courses and manuals available to guide evaluation 
work through the Inter-American Development 
Bank, EvalPartners, ReLAC and others. (2015)
Peer-to-peer systems (C5): Peer-to-peer systems 
are not used, but there are efforts to promote such 
a practice. (2015)
Gender (C18): Evaluation data is disaggregated 
by sex; evaluation reports discuss how gender 
equality is addressed in projects and programmes. 
(2015)
Ethnic and cultural dimensions (C8): National- 
level evaluations do not consider ethnic and cul -
tural issues. (2015) 
5.8 GUATEMALA
5.8.1  National government’s capacity to use 
evaluations (Use of Evaluation) 120
Institutional set up (C4):  Guatemala does not 
yet have a national evaluation policy. The coun -
try is making efforts to establish an institution 
to perform M&E functions. (Organization of 
American States, 2015) There is a proposal in 
the Congress for a legislation introducing results-
based management and evaluation into public 
administration. (2015)
There are no national-level evaluations in the 
country. Evaluations are developed through 
international cooperation for specific govern -
ment programmes and specific issues (e.g. edu -
cation, rule of law, social policy). Evaluations are 
used to assess the impacts of specific programmes 
in certain government sectors. (2015)
The Monitoring and Evaluation Directorate 
(Dirección de Monitoreo y Evaluación ) of the 
Sub-secretariat of Public Policies (Subsecretaria 
de Políticas Píblicas) is responsible for the for -
mulation of, monitoring and evaluation of public 
policies for development in relation to goals and
<<<PAGE=83>>>
65
COUNTRY PROFILES
121 For more information see preventionweb.net/files/27701_leyconcejosdesarrolloguatemala.pdf
122 ine.gob.gt
targets identified for each government department. 
The Sub-secretariat is one of the departments of 
the Secretariat of Planning and Budgeting of the 
Presidency (Secretaría de Planificación y Pro -
gramación de la Presidencia – SEGEPLAN) 
tasked with planning and developing global and 
sectoral programmes and monitoring and evaluat-
ing their impacts. SEGEPLAN works to integrate 
social and territorial interventions, public invest -
ments and international cooperation through a 
national planning system. The Sub-secretariat is 
involved in activities related to the M&E of the 
Millennium Development Goals. (Gobierno de 
Guatemala SEGEPLAN, 2015) 
Partnerships to strengthen and promote eval -
uation (C7): There are no national-level efforts 
under way to promote the need and demand 
for and use of evaluations. (2015) Founded in 
2010, the Guatemala Evaluation Network ( Red 
de Evaluación Guatemala ) is an informal net -
work of evaluation professionals that is dedicated 
to professionalizing evaluation and develop -
ing organizational capacities in M&E through 
capacity-building and knowledge management. 
The Network works to exchange technical infor-
mation on the topics and to disseminate infor -
mation about technical events and conferences. 
(IOCE, 2012)
Budgets for evaluation (C16): Budgets are not 
in place for the conduct of evaluations. (2015)
5.8.2  National government’s capacity 
for independent evaluations 
(Independence of Evaluation)
Stakeholders’ involvement/access to informa -
tion (C10): Development Councils (Consejos de 
Desarrollo) serve as a vehicle for public partici -
pation exists in Guatemala. The Councils’ man -
date includes monitoring “the implementation of 
national development policies, plans, programmes 
and projects and evaluate their implementa -
tion.”  The Councils are the mechanisms used by 
SEGEPLAN.121 Evaluation reports are not made 
public and are not available on government web-
sites. (2015)
Implementation of evaluation recommenda -
tions (C3): There are no systems in place to 
follow up on the implementation of evaluation 
recommendations. (2015)
5.8.3  National government’s capacity to 
ensure credible evaluations  
(Credibility of Evaluation)
National data systems (C2): The National Sta -
tistics Institute (Instituto Nacional de Estadística 
– INE) is the central government agency respon-
sible for collecting and analysing national data 
(e.g. demographics, economics).122
Methodologies (C9): SEGEPLAN’s guide for 
policy formulation presents the need to incor -
porate evaluation into cycle public policy cycles, 
presenting it as a key element of the process. The 
guide also provides a brief explanation of possi -
ble types of evaluation (e.g. design, impact, effi -
ciency). (Gobierno de Guatemala SEGEPLAN, 
2015)
Peer-to-peer systems (C5): Peer-to-peer systems 
are not used. (2015)
Gender (C18):  The responsibilities of the 
Sub-secretariat of Public Policies including guid-
ing gender integration into planning processes 
and into public sector plans, programmes, proj -
ects and investments. ( Gobierno de Guatemala 
SEGEPLAN, 2015) 
Ethnic and cultural dimensions (C8):  Similar 
to Gender (C18), the Sub-secretariat of Public 
Policies has responsibilities towards providing 
guidance for including ethnic and cultural aspects 
in public-sector planning processes, programmes, 
projects and investments. ( Gobierno de Guate -
mala SEGEPLAN, 2015)
<<<PAGE=84>>>
66
COUNTRY PROFILES
123 See limitations regarding generalizations about certain commitments such as budgets (C16), independent evaluators 
(C17), stakeholders’ involvement (C10), peer-to-peer systems (C5) gender (C18) and ethnic and cultural issues (C8). 
124 ine.gob.hn
5.9 HONDURAS
5.9.1  National government’s capacity to use 
evaluations (Use of Evaluation) 123
Institutional set up (C4):  Honduras does not 
have a national evaluation policy. The Unique 
System for Public Policy Evaluation ( Sistema 
Único de Evaluación de las Políticas Públicas – 
SUEPPS) was approved by the National Con -
gress and will be implemented by the Secretariat 
of Social Development ( Secretaria de Desarrollo 
Social e Inclusión Social ). The central govern -
ment conducts evaluations on select social pro -
grammes as part of the mandate of the Secretariat 
of Development and Social Inclusion ( Secretaria 
de Desarrollo e Inclusión Social). (2015)
The General Directorate of Analysis and Eval -
uation of Social Policies ( Dirección General 
de Analysis y Evaluación de Políticas Sociales 
– DIGEP) is tasked with designing and imple -
menting M&E tools to measure progress in 
implementing priority social policies. The Divi -
sion of Planning and Evaluation of Manage -
ment ( Unidad de Planeamiento y Evaluación 
de Gestión ) has the responsibility for design -
ing and analysing public policies, programmes 
and projects; preparing annual operational plans; 
evaluating plan implementation; and defining 
indicators to measure efficiency and effectiveness. 
(Gobierno de Honduras SEDIS, 2015)
Partnerships to strengthen and promote evalu -
ation (C7): International organizations are advo-
cating and promoting the use of evaluations. 
(2015) The Honduran Network of Professionals 
of Planning, M&E and Systematization ( Red 
Hondureña de Profesionales de Planificación, 
Evaluación, Seguimiento y Sistematización – 
REDHPRESS)  has been in place since 2005. 
Network members participated in formulating 
the Unique System for Public Policy Evaluation 
(Sistema Único de Evaluación de las Políticas 
Públicas – SUEPPS). (IOCE, 2012)
5.9.2  National government’s capacity 
for independent evaluations 
(Independence of Evaluation)
Independent evaluators (C17):  Independent 
evaluators conduct evaluations in Honduras. 
(2015)     
Stakeholders’ involvement/access to informa -
tion (C10): Evaluation reports are not made 
public and are not easily available on government 
websites. (2015)
Implementation of evaluation recommenda -
tions (C3):  There are no systems in place to 
follow up on the implementation of evaluation 
recommendations. (2015)
5.9.3  National government’s capacity to 
ensure credible evaluations  
(Credibility of Evaluation)
National data systems (C2): The National Insti-
tute of Statistics ( Instituto Nacional de Estadís -
tica) is the central government agency responsible 
for collecting and analysing national data (e.g. 
demographics, economics).124
Integrated public registries (C11):  SUEPPS 
is an integrated information system, a tool for 
measuring, monitoring and evaluating social pro-
grammes and projects. It is in the process of 
implementation and will eventually have data -
bases with social indicators to inform public man-
agement. (Gobierno de Honduras SEDIS, 2015)
Methodologies (C9): REDHPRES is interested 
in working with local universities for the creation 
of a university course on planning and M&E for 
development projects and programmes. The gov-
ernment has not produced technical manuals to 
guide evaluation work. (2015)
Peer-to-peer systems (C5): Peer-to-peer systems 
are not used. (2015)
<<<PAGE=85>>>
67
COUNTRY PROFILES
125 See limitations regarding generalizations about certain commitments such as budgets (C16), independent evaluators 
(C17), stakeholders’ involvement (C10), peer-to-peer systems (C5) gender (C18) and ethnic and cultural issues (C8). 
126 cabinet.gov.jm/performance_management
127 It is possible that changes have been in place since the source date, however website data does not contradict the source. 
As such, this information was included in the study as an important as a point of departure for future work. 
Gender (C18): Evaluation data is disaggregated 
by sex. (2015)
Ethnic and cultural dimensions (C8):  Evalua -
tion data is disaggregated by ethnic and cultural 
background. (2015)
5.10 JAMAICA
5.10.1  National government’s capacity to use 
evaluations (Use of Evaluation) 125
Institutional set up (C4): Jamaica does not have 
a national evaluation policy. Evaluations are used 
to assess the impacts of all government pro -
grammes, for learning purposes, to adjust course 
and to scale up initiatives. A national results-  
oriented system is currently being implemented 
to promote development effectiveness through 
monitoring and evaluating national development 
projects, programmes and policies. 
With support from the Inter-American Devel -
opment Bank PRODEV II Programme, the 
government is implementing a system (the Inte -
grated Managing for Results Programme) to 
measure targets and monitor government pro -
grammes for improved efficiency and effective -
ness. (IDB, 2015) 
On its website, the government presents results-
based management as an ongoing approach 
to improving and delivering results through 
evidence-based decision-making. The focus is 
on: accountability for performance through the 
establishment of performance objectives for the 
entire government; the formulation of budgets 
specified in planned priorities; and measuring 
and evaluating performance by collecting, analys-
ing and reporting performance data at all levels. 
(Government of Jamaica, 2015)
Created as part of the Integrated Managing for 
Results Programme, the Performance Manage -
ment and Evaluation Unit (PMEU) in the Office 
of the Cabinet is tasked with evaluation responsi-
bilities. Since 2010, PMEU is leading the imple-
mentation a government-wide Performance 
M&E System (PMES), a comprehensive M&E 
framework that include an inventory of activities, 
resources, results, performance measurement and 
governance information. The goals are to exam -
ine programme and policy outcomes and impacts 
and to improve governance results. In addition, 
PMES aims at supporting the government’s 
broad strategic priorities by developing perfor -
mance indicators and a more integrated approach 
to strategic planning, performance monitoring, 
evaluation and reporting. (Grey, 2012) 
Partnerships to strengthen and promote evalu -
ation (C7): International organizations are advo-
cating and promoting the use of evaluations. 
(2015)
Budgets for evaluation (C16): The programmes 
and project that are funded by international 
development partners have resources for evalua -
tions built into their budgets. (2015)
5.10.2  National government’s capacity 
for independent evaluations 
(Independence of Evaluation)
Independent evaluators (C17): Evaluations are 
conducted by the internal staff of government 
departments and by independent evaluators 
under contracts. (2015)
Stakeholders’ involvement/access to informa -
tion (C10): There is information about the 
Institutional Performance M&E System pilot 
programme is on the Government of Jamaica 
website;126 M&E information is not divulged.  
(Lopez, 2011)127 Evaluation reports are not made
<<<PAGE=86>>>
68
COUNTRY PROFILES
128 statinja.gov.jm
129 See limitations regarding generalizations about certain commitments such as budgets (C16), independent evaluators 
(C17), stakeholders’ involvement (C10), peer-to-peer systems (C5) gender (C18) and ethnic and cultural issues (C8). 
public and are not easily available on government 
websites. (2015)
Implementation of evaluation recommenda -
tions (C3): Ministries responsible for the pro -
grammes being evaluated are required to ensure 
that evaluation recommendations are implemented 
and future programmes are redesigned. (2015)
5.10.3  National government’s capacity to 
ensure credible evaluations  
(Credibility of Evaluation)
National data systems (C2):  The Statistical 
Institute of Jamaica is the central government 
agency responsible for collecting and analysing 
national data (e.g. demographics, economics).128
Integrated public registries (C11): The national 
development plan identifies information and 
communication technologies as key areas of 
intervention and recognizes the need for auto -
mated public services. Many government depart-
ments are operating as ‘quasi-independent silos’ 
with difficulties in harmonization among them. 
(Government of Jamaica, 2015)
Methodologies (C9):  The templates for pre -
paring ministries’ strategic business plans are 
available on the government website and con -
tain instructions for the development of M&E 
plans. The development of an M&E plan is 
also included in government departments and 
agencies’ Minimum Standards and Guidelines 
for Business Plans.  (Government of Jamaica,  
2015)
Peer-to-peer systems (C5): Peer-to-peer systems 
are not used. (2015)
5.11 MEXICO
5.11.1  National government’s capacity to use 
evaluations (Use of Evaluation) 129
Institutional set up (C4):  Mexico has well-es -
tablished national evaluation policies. (Rosen -
stein, 2015) These policies have steadily 
institutionalized over the past decade into a 
set of organizations and procedures that evalu -
ate hundreds of programmes each year. (Perez-  
Yarahuan, 2014) 
Evaluations are used to assess the impacts of all 
government programmes and to provide account-
ability for government actions. They are also used 
for learning purposes in order to adjust course 
and to scale up initiatives. (2015)
Evaluation of public policies in Mexico is a 
responsibility of federal government departments 
and sectoral institutions that report to the Presi -
dent. The President annually reports to the Con-
gress on progress made towards implementing 
the national development plan. 
The Division of Evaluation of Management and 
Government Performance ( Unidad de Evalua -
ción de la Gestión y el Desempeño Guberna -
mental – UEGDG ) in the Sub-secretariat of 
Public Function ( Subsecretaria de la Función 
Pública – SFP) is responsible for establishing the 
criteria, tools and methodologies to enable the 
assessment of performance and management in 
the federal public administration. Among other 
goals, the Division aims at identifying the results 
of public investments and the social impacts of 
programmes and projects as well as their effec -
tiveness, efficiencies and quality. (Gobierno de 
Mexico SFP , 2015)
The National Council for Evaluation of Social 
Development Policies ( Consejo Nacional de 
Evaluación de las Políticas de Desarrollo Social – 
CONEVAL) is a decentralized unit of the federal 
government. CONEVAL has the autonomy and 
technical capacity to measure poverty and to con-
duct objective assessments on the country’s social
<<<PAGE=87>>>
69
COUNTRY PROFILES
policy situation. The work focuses on improving 
evaluation and decision-making related to social 
programmes. (Gobierno de Mexico CONEVAL, 
2015) In addition, all ministries in Mexico have 
evaluation units. (2015)
In 2007, SFP and CONEVAL developed the 
Framework for the Evaluation of Federal Pro -
grammes in the Federal Public Administra -
tion (Lineamentos Generales para la Evaluación 
de los Programas Federales de la Administra -
ción Pública Federal ), which introduced results-
based management and evaluation of federal 
programmes. In coordination with CONEVAL 
and the Secretariat of Finance and Public Credit 
(Secretaria de Hacienda y Crédito Público – 
SHCP), SFP prepares an Annual Evaluation 
Programme ( Programa Annual de Evaluación 
– PAE ) to identify evaluations of programme 
design, process or of results to be undertaken. 
(Organization of American States, 2015)
Parliamentarians promoting evaluation use 
(C6): Parliamentarians are actively advocating 
and promoting the use and conduct of evalua -
tions. (2015)
Partnerships to strengthen and promote eval -
uation (C7):  Local stakeholders (professional 
organizations, universities, private sector actors, 
NGOs) and international organizations are col -
laborating and jointly advocating and promoting 
the need and demand for and use of national-  
level evaluations. (2015)
There are two associations of professional eval -
uators in Mexico, the Mexican Association of 
Evaluation Professionals ( Asociación Mexicana 
de Profesionales en Evaluación – AMPE ) and 
the National Academy of Mexican Evaluators 
(Academia Nacional de Evaluadores de México 
– ACEVAL). AMPE aims at contributing to 
the methodological theoretical development of 
evaluation in Mexico and at its dissemination 
to—and application in—academic and research 
institutions and the public and private sectors. 
ACEVAL works towards improving practices 
and ethics for independent and objective eval -
uations through development of quality meth -
odologies. The Mexican Network of M&E is 
a chapter of the Latin American Network of 
M&E. (IOCE, 2012)
Budgets for evaluation (C16): Evaluations can 
be funded and subcontracted out by ministries 
or by CONEVAL. Ministries have evaluation 
budgets. Policies allocate budgets for evaluations 
within programme budgets and make them avail-
able. (2015)
5.11.2  National government’s capacity 
for independent evaluations 
(Independence of Evaluation)
Independent evaluators (C17):  CONEVAL 
and ministries use independent evaluators. In 
cases when ministries use independent evalua -
tors, CONEVAL oversees their evaluation plans, 
terms of reference documents, evaluation pro -
cesses and participates in progress meetings to 
ensure the independence of assessments. To fur -
ther preserve independence, meetings between 
consultants and federal agencies take place in 
the presence of a CONEVAL representative. 
(Perez-Yarahuan, 2014) 
Stakeholders’ involvement/access to informa -
tion (C10):  The CONEVAL website contains 
evaluation reports and evaluation information 
on social programmes since 2008. The web -
site also enables access to databases, syntheses 
of documents and recommendations made by  
CONEVAL. The Annual Evaluation Programme 
is available on the SFP website. (Gobierno de 
Mexico SFP , 2015)
Implementation of evaluation recommenda -
tions (C3):  Since 2008, Mexico has had a for -
mal mechanism for federal programmes and 
their corresponding agencies to follow up on 
evaluation findings. The main evaluation stake -
holders have opportunities to comment on eval -
uation reports and findings. Stakeholders can 
also propose enhancements and specific actions 
to improve programmes. Documents are pub -
lished on federal agencies’ Internet pages, and 
CONEVAL publishes an annual report online on
<<<PAGE=88>>>
70
COUNTRY PROFILES
130 inegi.org.mx
131 See comment on limitations regarding depth and explanations about the use of systems and tools provided.
132 See limitations regarding generalizations about certain commitments such as budgets (C16), independent evaluators 
(C17), stakeholders’ involvement (C10), peer-to-peer systems (C5) gender (C18) and ethnic and cultural issues (C8). 
progress made by the programmes on improve -
ment actions. These are reviewed by the Inter-  
secretarial Commission for Social Development. 
(Perez-Yarahuan, 2014) 
5.11.3  National government’s capacity  
to ensure credible evaluations  
(Credibility of Evaluation)
National data systems (C2): The National Insti-
tute of Statistics and Geography ( Instituto de 
Nacional de Estadística y Geografia – INEGI ) 
is the central government agency responsible 
for collecting and analysing national data (e.g. 
demographics, economics) in Mexico.130 
Integrated public registries (C11): An inventory 
of the Federal Social Development Programmes 
is available on the CONEVAL Website. It inte-
grates information about all social programmes 
and produces data for analysis and decision-  
making. However, public registries and adminis-
trative records are not integrated. (2015)
Methodologies (C9): CONEVAL has provided 
multiple courses and technical consulting on how 
to improve staff capacities. It has also established 
a process for approval of indicators, through 
which CONEVAL staff assesses the appropriate-
ness of indicators used in logic models prepared 
for government programmes. It has also provides 
model of terms of reference, methodological 
guides and minimal requirements for developing 
various evaluation steps. (Gobierno de Mexico 
CONEVAL, 2015)
Peer-to-peer systems (C5): Peer-to-peer systems 
are used in Mexico.131 (2015)
Gender (C18): The CONEVAL evaluation team 
has gender analysis expertise.  Not all evaluations 
take gender into account. However, CONEVAL 
has done extensive work on gender by producing 
specific evaluations and by creating poverty indi-
cators with gender elements. (2015)
Ethnic and cultural dimensions (C8):  Not all 
evaluations take ethnic elements into account. 
However, CONEVAL has done extensive work 
on ethnic groups, specifically within the poverty 
analyses that it regularly produces. (2015)
5.12 PANAMA
5.12.1  National government’s capacity to use 
evaluations (Use of Evaluation) 132
Institutional set up (C4):  There are no legal 
frameworks that demand national- or local-level 
evaluations in Panama. According to the survey, 
the government uses evaluations in order to pro -
vide accountability for their actions, for learning 
purposes, to adjust course and to scale up initia -
tives. (2015)
The Department of Budgetary Programme 
Monitoring and Evaluation ( Departamento de 
Monitoreo y Evaluación de Programas Presu -
puestarios) under the Direction of National Bud-
get (Dirección de Pressupuesto de la Nación ) is 
the government unit charged with improving 
transparency and efficiency in budgeting through 
the creation of mechanisms to monitor and eval-
uate various budgetary programmes. (Gobierno 
de Panama MEF, 2015) 
The Department works towards identifying 
impacts and results of budgetary programmes 
for decision-making related to the development 
of strategic plans. The Department is responsible 
for undertaking evaluation of government pro -
gramme performance in order to identify results 
in line with strategic plans goals and activities. 
The Department is also responsible for prepar -
ing evaluation reports, developing evaluation 
processes and devising regulations and specific
<<<PAGE=89>>>
71
COUNTRY PROFILES
133 contraloria.gob.pa/inec
methodologies for quantitative and qualitative 
indicators. 
The Technical Secretariat of the Social Cabinet 
(Secretaría Técnica del Gabinete Social – STGS) 
of the Ministry of Social Development ( Minis-
terio de Desarrollo Social – MIDES) has among 
its responsibilities the evaluation of policies and 
strategies for social development. ( Gobierno de 
Panama MIDES) The Technical Directorate of 
International Cooperation ( Dirección de Coo -
peración Técnica Internacional) also has respon -
sibilities related to evaluation; it is tasked with 
evaluating technical cooperation programmes. 
(Gobierno de Panama MEF, 2015) 
Partnerships to strengthen and promote evalu -
ation (C7): International organizations are advo-
cating and promoting the use of evaluations. 
(2015)
Budgets for evaluation (C16): Budgets are not 
in place for the conduct of evaluations. (2015)
5.12.2  National government’s capacity 
for independent evaluations 
(Independence of Evaluation)
Stakeholders’ involvement/access to informa -
tion (C10): Evaluation reports are not made 
public and are not easily available on government 
websites. (2015)
Implementation of evaluation recommenda -
tions (C3):  There are no systems in place to 
follow up on the implementation of evaluation 
recommendations. (2015)
5.12.3  National government’s capacity to 
ensure credible evaluations  
(Credibility of Evaluation)
National data systems (C2): The National Insti-
tute of Statistics and Census (Instituto Nacional 
de Estadística y Censo )133 is the central gov -
ernment agency responsible for collecting and 
analysing national data (e.g. demographics, eco -
nomics). 
Integrated public registries (C11):  Public reg -
istries and administrative records are not inte -
grated. (2015)
Methodologies (C9):  Technical courses and 
manuals are not widely available to guide evalu -
ation work. (2015) There are, however, examples 
of collaboration between government and vol -
untary organizations for professional evaluation 
for workshops and technical courses. ( Gobierno 
de Panama MEF, 2015 ) Panama’s Technologic 
University has a Master’s Programme in Project 
Management with a specialization in Evaluation. 
In conjunction with the World Bank, the Minis-
try of Social Development organized workshops 
on the use of impact evaluations to improve pub-
lic policies in Panama ( July 2014). (Gobierno de 
Panama MIDES)
Peer-to-peer systems (C5): Peer-to-peer systems 
are not widely used. (2015)
5.13 SAINT LUCIA
5.13.1  National government’s capacity to use 
evaluations (Use of Evaluation)
Institutional set up (C4):  There is no national 
evaluation policy in Saint Lucia. There are no ref-
erences to evaluation or monitoring and account-
ability on government websites. (Government of 
Saint Lucia, 2015)
As the Caribbean Development Bank Coun -
try Strategy Paper 2013–2016 notes, the “gov -
ernment has [also] reaffirmed its commitment 
to improving key governance components such 
as: accountability, transparency … and improve -
ments in the delivery of Government services,” 
which include regular M&E of the ministries’ 
performance. (Caribbean Development Bank, 
2014, p. 14) However, there is no information 
about current projects by the Caribbean Devel -
<<<PAGE=90>>>
72
COUNTRY PROFILES
134 http://204.188.173.139:9090/stats
135 See limitations regarding generalizations about certain commitments such as budgets (C16), independent evaluators 
(C17), stakeholders’ involvement (C10), peer-to-peer systems (C5) gender (C18) and ethnic and cultural issues (C8). 
136 statistics-suriname.org
opment Bank, the Inter-American Development 
Bank or the World Bank on modernization of 
the state of evaluation in the country. 
5.13.3  National government’s capacity to 
ensure credible evaluations  
(Credibility of Evaluation)
National data systems (C2): The Central Sta -
tistics Office is the central government agency 
responsible for collecting and analysing national 
data (e.g. demographics, economics).134
5.14 SURINAME
5.14.1  National government’s capacity to use 
evaluations (Use of Evaluation) 135
Institutional set up (C4):  There is no national 
evaluation policy or legal frameworks demand -
ing evaluation in Suriname. At the national level, 
there are no efforts in place to develop national 
policies, structures or frameworks requiring eval-
uations or to promote the need and demand for 
and use of evaluations. (2015)
Evaluations are used to assess the impact of 
specific programmes in certain government 
sectors and for learning purposes, to adjust 
course and to scale up initiatives. There are no 
national-level evaluations in the country (2015). 
There are no measurable indicators or an exe -
cution plan to enable evaluations related to the 
national development plan. There is no central 
government unit in charge of conducting eval -
uations or any decentralized government units 
or departments charged with conducting evalu -
ations. Budgets are not in place for the conduct 
of evaluations.
There are no references to evaluation or monitor-
ing and accountability on government websites. 
(Government of Suriname, 2015)
5.14. 2  National government’s capacity 
for independent evaluations 
(Independence of Evaluation)
Independent evaluators (C17):  Independent 
evaluators are used under contracts on an  ad hoc  
basis. (2015)
Stakeholders’ involvement/access to informa -
tion (C10): Evaluation reports are not made 
public and are not easily available on government 
website. (2015)
Implementation of evaluation recommenda -
tions (C3):  There are no systems in place to 
follow up on the implementation of evaluation 
recommendations. (2015)
5.14.3  National government’s capacity to 
ensure credible evaluations  
(Credibility of Evaluation)
National data systems (C2): The General Bureau 
of Statistics is the central government agency 
responsible for collecting and analysing national 
data (e.g. demographics, economics). 136 It is a 
semi-autonomous organization that gathers and 
centralizes social and economic information.      
Methodologies (C9):  There are no technical 
manuals to guide evaluation work. (2015)
Peer-to-peer systems (C5): Peer-to-peer systems 
are not used in Suriname. (2015) 
Gender (C18):  Ad hoc  evaluation reports dis -
cuss how gender is addressed in projects or pro -
grammes. (2015)
Ethnic and cultural dimensions (C8):  Ad hoc  
evaluation reports discuss how ethnic and cul -
tural issues are addressed in projects or pro -
grammes. (2015)
<<<PAGE=91>>>
73
COUNTRY PROFILES
137 See limitations regarding generalizations about certain commitments such as budgets (C16), independent evaluators 
(C17), stakeholders’ involvement (C10), peer-to-peer systems (C5) gender (C18) and ethnic and cultural issues (C8). 
138 See comment on limitations regarding depth.
139 ine.gub.uy
5.15 URUGUA Y
5.15.1  National government’s capacity to use 
evaluations (Use of Evaluation) 137
Institutional set up (C4):  A national evaluation 
policy exists in Uruguay. Evaluations are used for 
learning purposes, to adjust course and to scale 
up initiatives. The government uses evaluations 
to assess the impacts of social programmes. 
Evaluations are also used for accountability pur -
poses and to formulate national development 
plans and programmes and inform the prepara -
tion of multi-year plan budgets (which are then 
monitored and evaluated on an ongoing basis). 
(2015)
The Directorate of Management and Evaluation 
(Dirección de Gestión y Evaluación – AGEV) of 
the Office of Planning and Budget of the Pres -
ident (Oficina de Planeamiento y Presupuesto – 
OPP) is the government department in charge 
of conducting evaluations. AGEV is undertak -
ing performance evaluation of public policies, 
with design, implementation and performance 
methodologies. The Directorate is structured 
around four divisions: Strategic Management 
and Budget ( Gestión Estratégica y Formulación 
Presupuestal); Information for Management and 
Open Government (Información para Ges -
tión y Gobierno Abierto) ; Project Operational 
Management (Gestión Operativa de Proyectos); 
and Analysis and Evaluation of Public Policies 
(Analisis y Evaluación de Politicas Públicas ). 
Evaluations are incorporated into the Five-Year 
Budgetary Plan. 
The Division of Analysis and Evaluation of Pub-
lic Policies in the Directorate has staff dedicated 
to fostering organizational learning, promoting 
actions towards the improvement of govern -
ment services and supporting decision-making 
processes. It is tasked with evaluating the effec -
tiveness, efficiency and impacts of projects and 
programmes of the national budget. The Division 
produces impact evaluations and design, imple -
mentation and performance evaluations of pro -
grammes. Other M&E directorates exist within 
line ministries. 
Partnerships to strengthen and promote evalu -
ation (C7): International organizations and other 
stakeholders (evaluation professional organiza -
tions, universities, private sector actors, NGOs) 
are actively advocating and promoting the use 
and conduct of evaluations. (2015) The Uruguay 
Network of Evaluators ( Red Uruguaya de Eva -
luadores) is an informal network. (IOCE, 2012)
Budgets for evaluation (C16): Government units 
responsible for evaluation have their own budgets 
to conduct evaluation. Policies allocate budgets 
for evaluations in their programme. (2015)
5.15.2  National government’s capacity 
for independent evaluations 
(Independence of Evaluation)
Independent evaluators (C17): Evaluations are 
conducted by the internal staff of government 
departments and by independent evaluators 
under contracts. (2015)
Stakeholders’ involvement/access to informa -
tion (C10): The AGEV website disseminates 
information on evaluation and contains some 
evaluation documents.138
5.15.3  National government’s capacity to 
ensure credible evaluations  
(Credibility of Evaluation)
National data systems (C2): The National Insti-
tute of Statistics ( Instituto Nacional de Estadís -
tica y Censo – INE )139 is the central government 
agency responsible for collecting and analysing 
national data (e.g. demographics, economics).
<<<PAGE=92>>>
74
COUNTRY PROFILES
140 datos.gub.uy
141 These were not covered under this study as they were carried out by the NEC management unit (IPC-IG and the In de-
pendent Evaluation Office of UNDP) during 2014 and 2015. For further information, please visit unteamworks.org/NEC.
142 unteamworks.org/node/441787
Integrated public registries (C11): The govern-
ment has a data portal 140 that provides access to 
national data catalogues and information systems 
in a wide range of areas, such as health, environ -
ment, economy, census (meta- and micro-data 
from the National Institute of Statistics), educa -
tion, World Bank indicators on development, proj-
ects, tourism and transportation. The portal of the 
Uruguay Observatory of Public Policy contains 
indicators on Uruguay development, which enable 
their contextualization on the design of public pol-
icies and the monitoring of its longer term effects. 
It also contains thematically organized indicators 
on the context and the results of budgetary pro -
grammes included in the 2010–2014 Strategic 
Plan and National Budget. The Observatory also 
provides easy access to statistics and data on pub-
lic policies produced by national and international 
organizations, to budgetary data and to documents 
that diagnose and analyse social problems (e.g. 
evaluations of policies and public interventions).
Methodologies (C9): The government supports 
or is involved in the development of work -
shops to promote the development of techniques 
and methodology capacities in evaluation-related 
areas. (Gobierno de Uruguay, 2015) For example, 
the ‘Workshop on Challenges to Results-based 
Management, Uruguay 2015–2050’ recently took 
place ( June 2015) with the participation of 
government staff, NGOs and universities. The 
Workshop focused on issues related planning, 
evaluation and information systems and chal -
lenges for integration. The AGEV website also 
contains brief descriptions of the evaluations of 
design, implementation and performance. The 
survey indicates that a Manual of Evaluations is 
available to guide evaluation work.
Peer-to-peer systems (C5):  Peer-to-peer sys -
tems are not used. (2015)
Gender (C18): Gender is not considered in 
national-level evaluations. (2015)
Ethnic and cultural dimensions (C8):  Ethnic 
and cultural issues are not considered in national- 
level evaluations. (2015)
Coordination practices (C14):  the AGEV is 
interested in creating a national registry of eval -
uations and a network of M&E government 
offices. (Mottola, 2015) 
6.  OTHER GLOBAL AND UNDP 
COMMITMENTS141 
C1. Develop and implement transparent results 
based monitoring and evaluation framework to 
track the efforts and results of the implemented 
commitments proposed in this conference.
 IPC-IG and IEO initiated a COP using 
the unteamworks.org/NEC to promote the 
knowledge shared among countries and the 
baseline study is part of this effort. How -
ever, a more appropriate results-based M&E 
framework has yet to be developed to track 
the efforts and results of commitments.
C12. Have an online platform (NEC COP) 
to present/exchange experiences, keep NEC 
participants connected and follow up on 
commitments.
The following COP e-discussions were promot -
ed and managed by IPC-IG in collaboration 
with EvalPartners, Parliamentarians Forum, UN 
Women,  UNDP , VOPES and government rep-
resentatives.:
 “How to engage parliamentarians in evalu -
ation” among countries regarding commit -
ments C4,C6 and C9 (Parliamentarians and 
Evaluation) with EvalPartners participation 
(Asela – EvalPartners and Parliamentarian 
Forum was the COP moderator);142
 “The role of public registries, administrative 
data and national statistics in the monitoring
<<<PAGE=93>>>
75
COUNTRY PROFILES
143 unteamworks.org/node/456813
144 unteamworks.org/node/466629
145 unteamworks.org/node/489730
146 English: ipc-undp.org/pub/eng/OP283_Challenges_to_integrating_gender_equality_approaches_into_evaluation.pd
 Portuguese: ipc-undp.org/pub/port/OP283PT_Desafios_referentes_a_integracao_de_um_enfoque_de_genero_em_
avaliacoes.pdf
147 English: ipc-undp.org/pub/eng/OP299_NEC_conference_enhancing_national_evaluation_capacities_and_achieving_
the_Sustainable_Development_Goals.pdf
 French: ipc-undp.org/pub/fra/OP299FR_Capacites_nationales_d_evaluation_CNE_arenforcer_les_capacites_
nationales_d_evaluation_et_atteindre_les_Objectifs_de_developpement_durable.pdf
 Portuguese: ipc-undp.org/pub/port/OP299PT_Conferencia_NEC_2015_Fortalecendo_as_Capacidades_Nacionais_
de_Avaliacao_e_Alcan%C3%A7ando_os_Objetivos_de_Desenvolvimento_Sustentavel.pdf
 Spanish: ipc-undp.org/pub/esp/OP299SP_Conferencia_Capacidades_Nacionales_de_Evaluacion_Bangkok_la_
mejora_de_las_capacidades_y_el_cumplimiento_de_los_Objetivos_de_Desarrollo_Sostenible.pdf
and evaluating public policies” among coun -
tries regarding commitments C2 and C11;143
 “How to incorporate gender perspectives in 
the Monitoring and Evaluation National 
Systems”144 among countries regarding com -
mitment C18 (Marco Segone – Eval Part -
ners, United Nations Evaluation Group and 
UN Women has written the paper that starts 
the discussion); and
 “How the 2015 NEC Conference in Bang -
kok ‘Blending Evaluation Principles with 
Development Practices’ can enhance national 
evaluation capacities and help to develop and 
achieve the Sustainable Development Goals” 
among countries regarding SDG and Eval -
uation,145 moderated by UNDP IEO and -
UNDP Brazil.
C13. Translate material on evaluation into dif -
ferent languages.
Several materials on evaluation were translated 
by Partners into different languages and the fol -
lowing was produced by UNDP:
 Publication – One Pager 261: How to 
Engage Parliamentarians in Evaluation 
regarding NEC commitments C4, C6, and 
C9 (summarizing the COP e-discussion 
on Parliamentarians and Evaluation) was 
published in English and Portuguese 
(September 2014);
 Publication – One Pager 272: The Use of 
Data in the Monitoring and Evaluation 
of Public Policies regarding NEC com -
mitments C2 and C11 (summarizing the 
COP e-discussion on Evaluation and public 
registries, administrative data and national 
statistics) was published in English and Por -
tuguese (December 2014);
 Publication – One Pager No 283: Challenges 
to Integrating Gender Equality Approaches into 
Evaluation146 regarding NEC commitment 
C18 (summarizing the COP e-discussion 
on Gender and Evaluation) was published in 
English and Portuguese (April 2015);
 Publication – One Pager Series on SDG 
and National Evaluation Capacities (sum -
marizing the COP e-discussion on “How the 
2015 NEC Conference in Bangkok ‘Blending 
Evaluation Principles with Development Prac-
tices’ can enhance national evaluation capacities 
and help to develop and achieve the Sustainable 
Development Goals” COP e-discussion ):
 First publication One Pager No 299 — 
The 2015 NEC Conference in Bangkok: 
Enhancing National Evaluation Capac -
ities and Achieving the Sustainable 
Development Goals,147 was published on 
August 2015 in English, French, Portu -
guese and Spanish;
 Second One Pager No 304 — Supporting 
the Sustainable Development Goals: Pri-
<<<PAGE=94>>>
76
COUNTRY PROFILES
148 http://www.ipc-undp.org/search_publications?combine=306&field_author_value=&field_type_value=All&field_
language_value=All&field_subject_value=All&field_datepub_value%5Bvalue%5D%5Byear%5D=2015
149 English: ipc-undp.org/pub/eng/OP304_Supporting_the_Sustainable_Development_Goals_Priorities_for_a_Global_
Evaluation_Agenda.pdf
 French: ipc-undp.org/pub/fra/OP304FR_Vers_les_Objectifs_du_developpement_durable_definir_les_priorites_d_
un_Programme_mondial_pour_l_evaluation.pdf
 Portuguese: ipc-undp.org/pub/port/OP304PT_Apoiando_os_Objetivos_de_Desenvolvimento_Sustentavel_
Prioridades_para_uma_Agenda_Global_de_Avaliacao.pdf
 Spanish: ipc-undp.org/pub/esp/OP304SP_Promocion_de_los_Objetivos_de_Desarrollo_Sostenible_prioridades_
para_un_Programa_Global_de_Evaluacion.pdf
150 ipc-undp.org/pub/port/html/relatorio_nec
151 youtube.com/watch?v=3NG94CAugUo&index=1&list=PL4q22k-_D2259nTO54AHR-9m32_lDk4L9
orities for a Global Evaluation Agenda,148 
was published on September 2015 in 
English, French, Portuguese and Spanish;
 Third One Pager no. 306 - Strengthen -
ing National Evaluation Capacities to 
Evaluate Sustainable Human Develop -
ment, was published on October 2015 
in English, Spanish, French and Portu -
guese.149
 Translated the III NEC Conference proceed-
ings to Portuguese;150 Produced a video “Inter-
national workshop: South-South Learning on 
National Evaluation Capacities.”151
 The francophone network, led by Réseau 
Francophone d’évaluation (RFE) has been 
proactive in not only translating materials 
from English to French, but also collecting 
and developing original resources in French.
 The Spanish network, led by ReLAC, has 
done similar extensive work.
 The EvalYear logo was translated into 32 lan-
guages.
 IOCE’s VOPE Institutional Capacity Tool-
kit is now available in English and French, 
and soon in Spanish as well.
C15. Support joint regional/national events to 
take stock of developments in these commit -
ments (In 2014) including the sharing/learning 
good practices of validating data from multiple 
sources, managing sensitive data, disseminat -
ing evaluation results.
The following events have been promoted since 
2013:
Event Dates Location Organizer
1.   IX Conferencia Anual de la 
REDLACME (Red Latino americana 
de Monitoreo y Evaluación)
December 2013 Peru REDLACME
2.   7thAfrEA (African Evaluation 
Association) CONFERENCE 
“Evaluation for Development: 
From Analysis to Impact” 
March 2014 Yaounde, 
Cameroun
AFREA
3.   “South Asia Regional Consultation 
on National Evaluation Policies”
September 2014 Colombo, Sri Lanka Parliamentarian Forum
4.   EES “Towards a Global 
Parliamentarians Forum for 
Development Evaluation” 
October 2014 Dublin, Ireland  EES 
5.   “The role of public registries, 
administrative data and national 
statistics in the Monitoring and 
evaluating public policies” 
3–5 November 
2014
Rio de Janeiro, 
Brazil
IEO and IPC-IG/UNDP ,  
MDS Brazil and IPEA Brazil
<<<PAGE=95>>>
77
COUNTRY PROFILES
Event Dates Location Organizer
6.   Celebration for official adoption of 
the UN resolution on evaluation
17 December 
2014
UN building,  
New York
United Nations Evaluation 
Group
7.   India Evaluation Week 19–23 January 
2015
Delhi, India IAMR and Planning 
Commission of India
8.   IDRC– Series of EvalYear speaker/ 
panel events: Evaluating the 
Impact of Climate change; Lessons 
from Gender Evaluation; Impact 
Evaluation; Evaluation field-
building in the South; Evaluating 
Rule of Law
6 February to 30 
November 2015
Ottawa and 
Montreal Canada
International Development 
Research Centre
9.   1 ERE Journées Ivoiriennes de 
l’Evaluation (JiE 2015)
09-10 to 11 
February 2015
Abidjan, Côte d’ 
Ivoire
Réseau Ivoirien de Suivi et 
d’Evaluation (RISE)
10.   EvalMENA General Assembly 23–26 February 
2015
Cairo, Egypt EvalMENA Network
11.   IAPE 13th Annual Conference on 
Advocacy for Evaluation
2 March 2015 Mandel Institute 
for Leadership in 
Be’er Sheva Israel
The Israeli Association for 
Program Evaluation (IAPE)
12.   ReLAC 4th International 
Conference
9–13 March 2015 Lima, Peru Latin-American and Caribbean 
Monitoring, Evaluation and 
Systematization Network 
(RELAC)
13.   Uganda Evaluation Week 10–13 March 
2015
Uganda The Government of Uganda 
represented by the Office of 
the Prime Minister and the 
Uganda Parliamentary Forum 
on Evaluation in partnership 
with the Uganda Evaluation 
Association
14.   United Nations Evaluation Group 
Evaluation Week
9–13 March 2015 New York, USA United Nations Evaluation 
Group 
15.   New Zealand’s government-led 
initiative for the International 
Year of Evaluation
18 March 2015 Wellington,  
New Zealand
Organizational Evaluation 
team of the Ministry of 
Business, Innovation and 
Employment. Department of 
Prime Minister and Cabinet 
(the NZ Prime Minister’s Office) 
is co-sponsoring.
16.   SAMEA, WSG & CLEAR AA offi-
cially launch the International 
Year of Evaluation in South Africa
19 March 2015 University of 
Witwatersrand 
(Wits) in 
Johannesburg
South African Monitoring 
and Evaluation Association 
(SAMEA), WSG & CLEAR AA
17.   Conference on taking responsi-
bility in M&E for systemic change
19–20 March 
2015
Wageningen,  
The Netherlands
Centre for Development 
Innovation, Wageningen 
University and Research centre
18.   The launch of EvalYear in 
Mauritania
31 March 2015 Nouakchott, 
Mauritania
Association Mauritanienne de 
Suivi-Evaluation (Mauritania 
Evaluation Network)
19.   Webinar – Future opportunities 
and challenges for evaluation at 
UNDP
1 April 2015 Virtual Independent Evaluation Office 
of UNDP and the Fletcher 
School
(continued)
<<<PAGE=96>>>
78
COUNTRY PROFILES
Event Dates Location Organizer
20.   Webinar – Emerging challenges 
for equity focused and gender 
responsive evaluation
8 April 2015 Virtual Independent Evaluation Office 
of UN Women and the Fletcher 
School
21.   Launch of the International Year 
for Evaluation in Madagascar
17 April 2015 Antananarivo, 
Madagascar
Madagascar Evaluation Society 
(MASSE)
22.   Italian Evaluation Association 
annual conference
17–18 April 2015 Genoa, Italy Italian Evaluation Association 
(AIV)
23.   A high level panel discussion 
and reception to promote 
EvalYear 2015
21 April 2015 Vienna, Austria Vienna based UN agencies 
together with the Austrian 
Ministry of Foreign Affairs
24.   Danish Government EvalYear 
event: “Policy and Practice of 
Danida Evaluation”
11 May 2015 Copenhagen, 
Denmark
Danish Ministry of Foreign 
Affairs
25.   UK Evaluation Society 
Conference
13–14 May 2015 London, UK UK Evaluation Society
26.   Nirun Sahingiray International 
Forum on Measurement 
and Evaluation in Non-profit 
Organizations
14 May 2015 Istanbul, Turkey Educational Volunteers 
Foundation of Turkey with 
cooperation of Harvard 
University
27.   “Sistemas de Protección e 
Inclusión Social en América 
Latina”
21 May Buenos Aires, 
Argentina
la Administración Nacional de 
la Seguridad Social conjun-
tamente con el Ministerio de 
Trabajo, Empleo y Seguridad 
Social, la Organización 
Iberoamericana de Seguridad 
Social y la Universidad Tres de 
Febrero
28.   Development Evaluation 
National Forum
22–23 May 2015 Rabat, Morocco Moroccan Evaluation 
Association
29.   Canadian Evaluation Society 
(CES) conference
24–27 May 2015 Montreal, Canada Canadian Evaluation Society 
(CES)
30.   The Jordan Evaluation Days 26–28 May 2015 Amman, Jordan EvalJordan
31.   African Development Bank – 
IDEV event titled “Development 
Evaluation – Development 
Effectiveness.”
28 May 2015 Abidjan, Côte 
d’Ivoire  
Independent Development 
Evaluation (IDEV) - African 
Development Bank
32.   Convención Anual de la 
Sociedad Puertorriqueña de 
Evaluación
30 May 2015 San Juan, Puerto 
Rico
La Sociedad Puertorriqueña de 
Evaluación
33.   Seminario de Introducción a la 
Evaluación de Políticas Púbicas
1 June 2015 Universidad 
Interamericana de 
Puerto Rico
La Sociedad Puertorriqueña de 
Evaluación
34.   Czech Evaluation Society Annual 
Conference
9 June 2015 Prague, Czech 
Republic
Czech Evaluation Society
35.   Conference on Evidence to 
practice – How NGOs can benefit 
from impact studies
9 June 2015 Bern, Switzerland Swiss Agency for Development 
and Cooperation SDC
36.   Conference: The future of 
training and further education  
in evaluation
11–12 June 2015 Saarbrücken, 
Germany
Master of Evaluation (MEval), 
Saarland University and 
University of Applied Sciences, 
Saarbrücken
(continued)
<<<PAGE=97>>>
79
COUNTRY PROFILES
Event Dates Location Organizer
37.   Congreso Internacional 
“Evaluación y Rendición de 
Cuentas para la Transparencia 
Democrática” & IX Conferencia 
Bienal Internacional de la SEE
11–12 June 2015 Sevilla, España Sociedad Española de 
Evaluación de Políticas 
Públicas
38.   DAC Evaluation Network 
meeting
15–16 June Paris, France DAC Network on Development 
Evaluation, OECD
39.   Mexico Evaluation Week 15–19 June 2015 Mexico City, Mexico The CLEAR Center; The 
Mexican Agency for 
International Development; 
National Academy of 
Evaluators, The National 
Council for the Evaluation of 
Social Development Policy.
40.   Journées Françaises de 
l’Evaluation
18–19 June 2015 Montpellier, France Société Française de 
l’Evaluation
41.   UK Department for International 
Development´s first 2015 Year of 
Evaluation event
18 June 2015 London, UK Department for International 
Development, UK
42.   Speakers Lunch, Celebration 
of EvalYear at the International 
Program for Development 
Evaluation Training
24 June 2015 Carleton University, 
Ottawa, Canada
International Program for 
Development Evaluation 
Training 
43.   Media Dialogue in EvalYear in 
Ghana
25 June 2015 Ghana Ghana M&E Forum (GMEF) 
with UNICEF – Ghana
44.   Symposium: Evaluation as 
a strategic element for the 
effectiveness of public policies, 
programmes and projects
26 June 2015 Managua, 
Nicaragua
Nicaraguan Network in 
Monitoring and Evaluation 
(ReNicSE) and Institute of 
Administration and Public 
Policies /UNI
45.   National launch of EvalYear in 
Ghana followed by regional 
forums on EvalYear in three 
regions and a policy dialogue
2 July 2015 Ghana Ghana M&E Forum (GMEF) 
with UNICEF – Ghana
46.   Colloquium of state and the 
evaluation community
2 July 2015 Santiago, Chile Red de Seguimiento, 
Evaluación y Sistematización 
de Latinoamerica y el Caribe, in 
Chili. (RELAC_Ch)
47.   The Aotearoa New Zealand 
Evaluation Association 
Conference
6–9 July 2015 Auckland, New 
Zealand
The Aotearoa New Zealand 
Evaluation Association
48.   Regional Colloquium on the 
evaluation of public policies 
Theme : “Building together the 
evaluation of tomorrow”
7–9 July 2015 Cotonou, Republic 
of Benin
Ministry of Evaluation of 
Public Policies, Promotion of 
Good Governance and Social 
Dialogue in partnership with 
UNDP , CLEAR AFRICA, UNICEF 
and 3IE
49.   Seminario Internacional: La 
Contribución de la Evaluación 
al Desarrollo en América 
Latina, Diálogo entre Política y 
Evaluación
15–17 July 2015 Centro de 
Investigación y 
Capacitación en 
Administración 
Pública (CICAP), San 
José, Costa Rica
Universidad de Costa Rica 
(UCR), Universidad del Sarre, 
Alemania (UdS)
(continued)
<<<PAGE=98>>>
80
COUNTRY PROFILES
Event Dates Location Organizer
50.   Wilton Park event on New 
Frontiers for Evaluation in an era 
of market oriented development
20–22 July 2015 Wilton Park 
Conference Centre, 
West-Sussex, UK
Wilton Park and the Centre for 
Development Impact
51.   EvalYear celebrations at the 
Annual General Meeting of the 
APNODE
23–24 July 2015 Abidjan, Côte 
d’Ivoire
African Parliamentarians’ 
Network on Development 
Evaluation (APNODE)
52.   Evaluation day – “EvalCafé” 1 August 2015 Yaounde, 
Cameroon
Cameroonian Community of 
Evaluators
53.   Consultation with East 
Asian Parliamentarians in 
Strengthening Evaluation 
Function in National 
Development Agenda
10–11 August 
2015
Bangkok, Thailand PFDE, UNICEF , UN Women, 
EvalPartners
54.   10th Conference of the Latin-
American and the Caribbean 
Network on Monitoring and 
Evaluation (REDLACME)
2–4 September 
2015
Panama City, 
Panama
REDLACME, The Inter-American 
Development Bank; the World 
Bank; and the CLEAR Center 
for Spanish-speaking Latin 
America
55.   Swiss Evaluation Society (SEVAL) 
and Geneva Evaluation Network 
(GEN) conference
3–4 September 
2015
University of 
Geneva, Geneva, 
Switzerland
Swiss Evaluation Society 
(SEVAL) and Geneva Evaluation 
Network (GEN)
56.   Australasian Evaluation Society 
(AES) conference
5–9 September 
2015
Melbourne, 
Australia
Australasian Evaluation Society
57.   Ethiopian Monitoring and 
Evaluation Association 2nd 
General Assembly
6–7 September 
2015
Addis Ababa, 
Ethiopia
Ethiopian Monitoring and 
Evaluation Association
58.   ZEA Regional Conference and 
Workshops
14–18 September 
2015
Harare, Zimbabwe Zimbabwe Evaluation 
Association
59.   ADB learning event enti-
tled “ Think Sustainable, Act 
Responsible”
15–16 September 
2015
Manila, Philippines Asian Development Bank
60.   SLEvA International Conference 
2015
15–18 September 
2015
Colombo, Sri Lanka Sri Lanka Evaluation 
Association
61.   Consultation with Latin 
American Parliamentarians 
in Strengthening Evaluation 
Function in Post Development 
Agenda
17–18 September 
2015
Parlatino, Panama 
City, Panama
PFDE, UNICEF , CLEAR, UN 
Women, IPC-IG/UNDP , UNFPA 
and EvalPartners
62.   International Programme 
Evaluation Network  conference
23–25 September 
2015
Kiev, Ukraine International Programme 
Evaluation Network
63.   Conference entitled “Evaluating 
for Growth: Introducing the 
Hellenic Evaluation Society’’
24 September 
2015
Athens, Greece Hellenic Evaluation Society
64.   Polish Evaluation Society 
Conference
27–29 September 
2015
Krakow, Poland Polish Evaluation Society 
with the Polish Ministry of 
Regional Development and the 
Polish Agency for Enterprise 
Development
65.   Joint conference: Making effec-
tive use of evaluations in an 
increasingly complex world
30 September 
2015
Paris, France UNESCO, OECD, French 
Evaluation Society, European 
Evaluation Society
(continued)
<<<PAGE=99>>>
81
COUNTRY PROFILES
Event Dates Location Organizer
66.   5th Annual Development 
Evaluation Forum
September 2015 
(dates to be 
confirmed)
Trinidad and 
Tobago
Ministry of Planning and 
Sustainable Development 
Trinidad and Tobago
67.   Encuentro Iberoamericano 
Sobre Institucionalizacion De La 
Evaluacion
30 September –  
2 October 2015
Cartagena de 
Indias, Colombia
Secretaría General de 
Cooperación Internacional 
para el Desarrollo División de 
Evaluación de Políticas para 
el Desarrollo y Gestión del 
Conocimiento
68.   International Conference on 
institutionalizing the evaluation 
in public policies
5–6 October 2015 Rabat, (Morocco) National Observatory of 
Human Development, in 
partnership with the United 
Nations in Morocco
69.   Moroccan Evaluation Week 7–10 October 
2015
Rabat (Morocco) Moroccan Evaluation 
Association
70.   SAMEA’s 5th Biennial Conference 12–16 October 
2015
Hilton Hotel 
in Sandton, 
Johannesburg
South African Monitoring 
and Evaluation Association 
(SAMEA)
71.   CEI EvalYear Conference 2015 14–15 October 
2015
Montego Bay, 
Jamaica
Caribbean Evaluators 
International
72.   Training programme on National 
Evaluation societies
19–31 October 
2015
Antwerp, Belgium The Institute of Development 
Policy and Management, 
University of Antwerp
73.   National Evaluation Capacities 
(NEC) conference
26–30 October 
2015
Bangkok, Thailand UNDP in partnership with 
United Nations Evaluation 
Group and EvalPartners
74.   IDEAS Global Assembly 26–30 October 
2015
Bangkok, Thailand IDEAS
75.   First Regional Conference of 
Evaluators of Western Balkan
28–29 October 
2015
Sarajevo, Bosnia & 
Herzegovina
Western Balkan Evaluation 
Network and Evaluation 
Society of Bosnia & 
Herzegovina
76.   RASPPE Annual Conference 29–31 October 
2015
Moscow, Russia Russian Association of 
Specialists in Program and 
Policy Evaluation
77.   International conference on 
Education Evaluation: to ensure 
quality and development
4–5 November 
2015
Riyadh, Saudi 
Arabia
Public Education Evaluation 
Commission (PEEC)
78.   African Development Bank 
Development Evaluation Week
6 and 9–11 
November
Abidjan, Cote 
d’Ivoire
Independent Development 
Evaluation (IDEV) – African 
Development Bank
79.   American Evaluation Association 
(AEA) conference
9–14 November 
2015
Chicago, USA American Evaluation 
Association
80.   Celebrating EvalYear during the 
Evaluation Week with the end of 
year session of the Parliament 
and the Senate of Cameroon
9–13 November 
2015
Yaoundé 
Conference Center
Cameroon Development 
Evaluation Association (CaDEA)
81.   1st international conference of 
NAE
16–17 November 
2015
Abuja, Nigeria Nigerian Association of 
Evaluators
(continued)
<<<PAGE=100>>>
82
COUNTRY PROFILES
Event Dates Location Organizer
82.   Two-day technical seminar on 
“Enhancing the evaluability of 
Sustainable Development  
Goal 2”
17–18 November 
2015
IFAD in Rome, Italy Evaluation Offices of FAO, IFAD, 
WFP and CGIAR
83.   Community of Evaluators 
South Asia (CoE-SA) Evaluation 
Conclave (in the context of 
Global EvalYear event)
23–27 November 
2015
Kathmandu, Nepal Community of Evaluators 
South Asia (CoE-SA)
84.   Global EvalYear Event which 
includes EvalPartners 2nd  
Global Forum
23–27 November 
2015
Kathmandu, Nepal EvalPartners, IOCE, UN Women, 
CoE-SA, PFDE, CoE Nepal, 
Parliament of Nepal, National 
Planning Commission of Nepal, 
United Nations Evaluation 
Group
85.   2015 Brazilian Monitoring and 
Evaluation Network Seminar
25–27 November 
2015
Belo Horizonte-MG, 
Brazil
Brazilian Monitoring and 
Evaluation Network and 
Fundação João Pinheiro
86.   Evaluation Forum at US 
Department of State
2 December 2015 George C. Marshall 
Conference Center, 
Washington, DC
U.S. Department of State
87.   The 13th Official Donor 
Assistance Evaluation Workshop
9–10 December 
2015
Tokyo, Japan Ministry of Foreign Affairs of 
Japan
7. FINAL REMARKS 
This study provides an overview of the status of 
National Evaluation Capacities in the 43 UNDP 
programme countries that indicated interest in 
the 18 NEC commitment of the 2013 NEC 
Conference—to use evaluations and to ensure 
the evaluations they produce are credible and 
independent. 
It describes a variety of institutional settings and 
legal frameworks that exist among the countries 
analysed and reveals that worldwide, evaluation is 
a highly dynamic process. Many different combi-
nations are in place, reflecting a variety of govern-
ment’s interests, political contexts and countries’ 
developmental stage. Evaluation is constantly 
being reviewed and concepts are being refined 
as interests and actions oriented towards better 
evaluation and better processes evolve. These, in 
turn, are also a function of the progressive imple-
mentation and use of evaluations—with their 
implementation and use, such processes can be 
reviewed and refined. 
Regarding the existence of a legal framework  
or national evaluation policy, variations exist 
with some countries having a national evaluation 
policy, others having national evaluation legisla -
tion but not a policy, and many countries having 
some kind of legal framework in place, either 
formalized or semi-formalized. Some countries 
that do not yet have a national evaluation policy 
have proposals or draft national evaluation pol -
icy waiting for legislation. Many countries have 
sectoral policies requiring evaluations of national 
programmes as opposed to national policies. 
The ways in which national evaluation policies 
are used also varies. Many governments pursue 
national evaluation policies as a way to ensure 
evaluations are used. Other countries are looking 
at legal frameworks as a way to ensure that there 
are minimal standards and that quality guidelines 
are in place. 
Regarding the current institutional setting  at 
the national government level, there is a diversity 
of models. In almost all countries, international 
(continued)
<<<PAGE=101>>>
83
COUNTRY PROFILES
donor pressure for evaluations has facilitated 
the creation of a minimum structure to fulfil 
donor needs; national governments often have a 
unit or division tasked with monitoring donor’s 
work. Some national governments have sophis -
ticated structures and policies with mechanisms 
to ensure that evaluations are produced credibly 
and independently. Their evaluation results are 
useful and used for decision-making and assess 
the performance, impact and effectiveness of 
their programmes. 
In many countries, the Ministry of Planning has 
an evaluation unit and is monitoring and evaluat-
ing the implementation of national plans. There 
are many cases in which decentralized evaluation 
units exist across the line ministries to facilitate 
that work, such in the Ministries of Social Devel-
opment, Education and Health. 
In any case, a central evaluation unit is not neces-
sarily the only possible institutional arrangement, 
as these are usually a function of the size of gov -
ernments’ structures and their specific arrange -
ments in each case. Since complexities exist in 
the formulation of each institutional setting, in 
certain cases arrangements around a central unit 
seem to work well. In other cases, decentralized 
evaluation units enable a variety of perspectives 
on evaluation work and research undertaken. 
Regarding the use of evaluations,  the lack of 
a national policy is not an indication that eval -
uations are not used.  Many countries that do 
not have a national evaluation policy use eval -
uations on an ongoing basis. The survey results 
demonstrate that many countries do not have 
national-level evaluations undertake sectoral 
evaluations of national programmes and evalua -
tions of projects of national development plans to 
assess progress towards the plan’s goals and tar -
gets. In many cases, these are also to be perceived 
as national-level evaluations. Many countries 
also referred to evaluations done by international 
donor agencies on national governments pro -
grammes as national-level evaluations. As such, 
the concept of national-level evaluations has yet 
to be clearly articulated. The term is sometimes 
used in reference to ‘nationwide’ evaluations, 
sometimes used in reference to sectoral evalu -
ations done by government of certain national 
programmes and performed by the donor com -
munity on national level interventions. 
The concept is also used to describe macro- 
level evaluations (related to assessments of the 
national development plan, government plan 
targets and policy impact), meso-level evaluations 
(tracking performance of government agencies, 
their plans and programmes) and micro-level 
evaluations (assessments of individual perfor -
mances).152 Monitoring and evaluation work 
done by a variety of national-level institutions, 
including the legislative, executive and judiciary 
levels (such as the work performed by auditor 
generals in certain countries), is also referred to 
as national-level evaluations. 
Evaluations are used widely. There are a few 
cases in which M&E systems are in place but 
the focus of the work is on monitoring and little 
is done on evaluation; situations where adminis -
trative reforms are pushing for modern manage -
ment techniques that incorporate evaluation; and 
examples where governments show little interest 
in evaluation.
The study also found that the concept of ‘pro -
gramme evaluation’ may be understood differ -
ently in each case. Some understand it widely 
as a tool to measure programme relevance and 
impact. Others describe it in relation to monitor-
ing activities tracking project implementation or 
budgetary expenditures. 
In almost all countries, there are efforts in place 
to promote the use of evaluations either by par -
liamentarians or voluntary organizations for pro-
fessional evaluation, universities, international 
donors and other stakeholders.  Numerous coun-
152 The concepts of macro-, meso- and micro-level evaluations are well described in Aquilino, 2015.
<<<PAGE=102>>>
84
COUNTRY PROFILES
tries have a national evaluation society and some 
have more than one.
Several issues have been identified as limita -
tions for the use of evaluations. At times, some 
national governments use evaluations more as 
a political mechanism or a marketing tool to 
assess the performance of certain programmes 
that are considered political priorities. Use of 
evaluation is also sometimes hampered by dif -
ficulties to align the timing, scope and focus of 
the evaluations with the timing, scope and focus 
of national planning and budgeting processes. 
Even in countries with comprehensive evalua -
tion practices, there is evidence of coordination 
challenges regarding timing and design of tar -
gets and indicators. 
A key issue identified by the Study is the lack of 
a process to follow up on evaluation recommen -
dations. Even if those processes are in place, there 
are cases where recommendations are too diffi -
cult and complex to implement or require joint 
follow-up by different levels of government. 
Every country has a central agency responsible 
for collection and analysis of national data,  but 
most countries don’t have integrated public reg -
istries. There are many examples of investments 
being made in development of web portals and 
integrated systems, which could become import -
ant sources of data for evaluation. 
The existence of technical evaluation capacities is 
key for many governments. Many of them have 
invested in developing M&E capacities, guides 
and methodologies for the implementation of a 
variety of such ‘evaluation’ processes. Some evalu-
ation units have managed to gain full respect for 
the quality of their work due to the level of staff 
expertise. In other cases, even if evaluations are 
required, national capacities are scarce to ensure 
measurable indicators are developed or that plans 
exist to produce evaluations. 
Regarding stakeholders’ involvement and 
access to information , many governments have 
policies and procedures enabling the involve -
ment of representatives of the programmes 
being evaluated. A few have structures in place 
for participation of the beneficiaries of such 
programmes in the evaluation processes. Some 
countries restrict public access to evaluation 
information. Many countries post their evalua -
tion reports on the web, but in some cases the 
large volume and the technical nature of the 
reports restrict citizens’ access to information 
and limit engagement. 
Budgets can also be a limitation to undertaking 
evaluations. However, the study found that it is 
difficult to generalize and map the extent to which 
budgets are or are not available and whether they 
are or are not a constraint. There are many cases 
in which policies and evaluation agendas demand 
evaluations, but their execution is subjected to the 
existence of financial resources. There are also sit-
uations in which budgets are in place but are not 
sufficient to conduct all the needed work. Often, 
many government units responsible for evaluation 
have their own budgets to conduct evaluation—
but that does not mean these resources are in fact 
available. Ultimately, budgets are highly influ -
enced by government politics. 
Similarly, regarding gender and ethnic and cul -
tural issues, these are specific to each evaluation 
study and difficult to generalize. In many cases, 
evaluations disaggregate data by sex, but that is 
as far as they go. In other circumstances, gender 
issues are better considered in evaluation and 
reporting. With a few exceptions, ethnic and 
cultural issues  are seldom considered in evalua -
tion work, unless it is the main focus of analysis. 
Both aspects are heavily dependent on the object 
of evaluation. 
Similarly, it is important to understand that the 
fabrics that countries and national governments 
are made of is not uniform. Several shades exist 
and there is need to think about granularity. Even 
within the countries themselves, issues resist gen-
eralization. For example, even within the same 
national government for the MDGs alone, there
<<<PAGE=103>>>
85
COUNTRY PROFILES
are sectors (housing, health, education) in which 
budgets exist for evaluations and others that will 
not be priorities for governments. 
As a governance tool, evaluations are often pro -
duced as demanded by decision makers and 
managers who need accurate, updated and timely 
produced information for policymaking; by civil 
society in need of tools to assess government 
interventions and sector needs; and by the media 
and the public for accountability of the use of 
public resources. 
Donors had an impact on the success of the gov-
ernment’s M&E system in some countries. In 
addition to the establishment of new or stand-
alone M&E units in government, international 
donors have also been pushing for broader 
public sector and administrative reforms or 
governance activities in support of improved 
transparency, accountability or simply good 
management as part of their democratic gover -
nance programmes. 
All of these granular aspects of national evalu -
ation capacities need to be taken into consider -
ation for the  formulation of a future evaluation 
agenda and should be incorporated into the 
broader development agenda, as these are com -
plex and intrinsically linked to each country’s 
development agenda. It is clear from this Study 
that strong correlations exist between the stage of 
democratic governance in the countries surveyed 
and the capacity of their governments to conduct 
evaluations and ensure the independence, credi -
bility and use of evaluation results.
<<<PAGE=104>>>

<<<PAGE=105>>>
87
WORKS CITED
WORKS CITED 
Abdelhamid, D. (2014). Egypt – Institution-
alizing and Streamlining Development 
Monitoring and Evaluation in Pre- and 
Post-Revolutionary Egypt. Proceedings 
from the Third International Conference on 
National Evaluation Capacities. 30 September 
– 2 October 2013 São Paulo, pp. 232-237.
African Development Bank. (2011, October). 
Burundi Country Strategy Paper 2012-
2016. From afdb.org/fileadmin/uploads/
afdb/Documents/Project-and-Operations/
Burundi%20-%20CSP%202012-16.pdf.
Ahmad, S. B. (2011). Malaysia: Programme/
Project Evaluation – the Malaysian 
Experience. roceeding from the Second 
International Conference on National 
Evaluation Capacities 12-14 September 2011 
Johannesburg.
AIM. (2015). Africa Impact Evaluation Initiative .  
From World Bank: http://web.
worldbank.org/WBSITE/EXTERNAL/
COUNTRIES/AFRICAEXT/
EXTIMPEVA/0,, menuPK:2620040~ 
pagePK:64168427~piK:64168435 
~theSitePK:2620018,00.html.
Alemu, G. T . (2011). Ethiopia: Evaluation in 
Ethiopia: Institutional Setting, Experiences, 
Challenges and Prospects. Proceedings from 
the International Conference on National 
Evaluation Capacities, 15-17 December 2009 
Casablanca, pp. 62-67.
Aquilino, N. (2015 Agosto). Hacia una política 
nacional de evaluación. Documento de 
Politicas Publicas. Area de Instituciones y 
Gestiòn Pùblica. Recomendaciòn 151.
Asian Development Bank. (2014). Nepal: The 
National Monitoring & Evaluation System 
and the SREP Investment Plan.  
The Phillipines.
Brazilian M&E Network. (2015). From 
redebrasileirademea.ning.com/.
Byamugisha, A. &. (2011). Uganda: Giving 
National Director Through Evaluation: 
Uganda’s Evaluation of its Poverty 
Eradication Action Plan (1997-2007). 
Proceeding from the Second International 
Conference on National Evaluation Capacities 
12-14 September 2011 Johannesburg.
Caribbean Development Bank. (2014). Country 
Strategy Paper 2013-2016 Saint Lucia. From 
caribank.org/uploads/2014/12/BD123_12_
CSP_STL_FINAL.pdf.
Chafiki, M. (2011). The Evaluation of Public 
Policies – the Case of Gender-Responsive 
Budgeting. Proceeding from the Second 
International Conference on National 
Evaluation Capacities 12-14 September 2011 
Johannesburg.
CLEAR. (2012, March). Workshop Report: 
African Monitoring and Evaluation Systems. 
Collaborative Reflection and Leaning 
amongst Peers. From egional Centers for 
Learning on Evaluation and Results (Clear): 
theclearinitiative.org/african_M&E_
workshop.pdf.
Community of Evaluators Pakistan. (2015). 
From coepakistan.org/coe/.
Dery, B. B. (2014). Ghana – Bulding M&E 
Capacities to Enhance the National M&E 
System in Ghana: The Way Forward. 
Proceedings from the Third International 
Conference on National Evaluation Capacities. 
30 September – 2 October 2013 São Paulo, pp. 
203-210.
Development Evaluation Society of India. (2015). 
From desiindia.org.
<<<PAGE=106>>>
88
WORKS CITED
Dhakal, T . (2014). Nepal – Institutionalization 
and Use of Evaluations in the Public 
Sector in Nepal. Proceedings from the 
Third International Conference on National 
Evaluation Capacities. 30 September –  
2 October 2013 São Paulo, pp. 137-142.
Djidjoho, A. N. (2014). Benin – The Process 
of Institutionalizing Evaluation in Benin: 
Progress on Questions of Usage and 
Indepencence. Proceedings from the Third 
International Conference on National 
Evaluation Capacities. 30 September –  
2 October 2013 São Paulo, pp. 196-202.
Djidjoho, A. N. (2011, December). Benin: 
Capacities on Evaluation of National Public 
Policies. Proceedings from the International 
Conference on National Evaluation Capacities 
15-17 December 2009 Casablanca, p. 20.
Dorado, D. (2011). Proceedings from the 
International Conference on National 
Evaluation Capacities, 15-17 December 2009 
Casablanca, pp. 48-53.
Dorado, D. (2011). Colombia: SINERGIA 
– Colombia’s System of Monitoring and 
Evaluation. Proceedings from the International 
Conference on National Evaluation Capacities, 
15-17 December 2009 Casablanca.
Evaluation Association of Bhutan. (2015). From 
evalbhutan.org/.
Evaluation Office at the UNDP . (2011). 
Proceeding from the Second International 
Conference on National Evaluation 
Capacities 12-14 September 2011 
Johannesburg. Use of Evaluation in Decision-
making for Public Policy and Programmes. New 
York: UNDP .
Ghana National Development Planning 
Commission. (2015). From ndpc.gov.gh/
divisions/.
Goldman, I. S. (2014). South Africa – 
Reflections on the South African 
Experience with Evaluation and the Use 
of Evaluative Evidence to Orient Public 
Policy Formulation. Proceedings from the 
Third International Conference on National 
Evaluation Capacities. 30 September –  
2 October 2013 São Paulo, pp. 227-231.
Government of Afghanistan Ministry of 
Finance. (2014). General Plan and Results 
Based Monitoring. Assessment of M&E 
Systems in Ministries and Agencies. August 
2014. Ministry of Finance Directorate 
General Budget & Ministry of Economy.
Government of Afghanistan. (2015, March). 
From Assessment of M&E Systems in 
Ministries and Agencies: budgetmof.gov.
af/images/stories/DGB/BPRD/PERU/
Full%20Diagnostic%20Report%20Final%20
(3March2015).pdf.
Government of Argentina. (2015). From 
jefatura.gob.ar/archivos/politicas-publicas/
Lineamientos_2013-2015.pdf.
Government of Benin. (2012). National 
Evaluation Policy. From gazelletouch.
lagence.de.com/newbepp/
wp-content/uploads/2013/10/
SYNTHESE-DU-DOCUMENT-
DE-POLITIQUE-NATIONALE-
D%E2%80%99EVALUATION-
2012-%E2%80%93-2021-05012012.pdf.
Government of Benin. (2015). From evaluation-
gouv.bj.
Government of Bhutan. (2015). From gnhc.gov.
bt/.
Government of Burundi. (2011). Vision Burundi 
2025. From presidence.gov.bi/IMG/pdf/
Vision_Burundi_2025_complete_FR.pdf.
Government of Ethiopia. (2015). From 
ethiopians.com/Ethiopia_GTP_2015.pdf.
Government of Guatemala SEGEPLAN. 
(2015). From Guía para formulación 
de políticas públicas: segeplan.gob.gt/
downloads/2015/Politicas_Publicas/GpFPP .
pdf.
Government of Honduras SEDIS. (2015). 
Secretariat of Development and Social 
Inclusion. From sedis.gob.hn/portal/
atribuciones.
<<<PAGE=107>>>
89
WORKS CITED
Government of India Independent Evaluation 
Office. (2015). From ieo.gov.in/.
Government of India National Planning 
Commission. (2015). From 
planningcommission.nic.in.
Government of India. (2015). From 
performance.gov.in/sites/all/document/files/
pmes/pmes.pdf.
Government of Indonesia. (2015). From 
indonesia.go.id/en/ministries/ministers/
state-minister-for-chairperson-of-
the-national-development-planning-
agency/1646-profile/277-kementerian-
perencanaan-pembangunan-nasional.html.
Government of Jamaica. (2015). From cabinet.
gov.jm/performance_management.
Government of Kenya. (2015). From 
devolutionplanning.go.ke/wp-content/
uploads/2014/08/Min-of-Planning-
Brochure.pdf.
Government of Malawi. (2015). From 
malawi.gov.mw/index.php?option=com_
content&view=article&id=30&Itemid=8.
Government of Malawi. (2015). From 
Ministry of Finance: finance.
gov.mw/index.php?option=com_
content&view=article&id=113&Itemid=117.
Government of Malaysia Economic Planning 
Unit. (2015). From epu.gov.my/en/functions.
Government of Malaysia Economic 
Planning Unit. (2010). 10th Malaysia 
Plan 2011-2015. From epu.gov.my/en/
tenth-malaysia-plan-10th-mp-.
Government of Malaysia ICU. (2015). 
From icu.gov.my/pg/mobile2.
php?pg=info_k&type=profil.
Government of Malaysia. (2015). 11th Malaysia 
Plan 2016-2020: Anchoring Growth on 
People. From rmk11.epu.gov.my/book/eng/
Elevent-Malaysia-Plan/RMKe-11%20
Book.pdf.
Government of Malaysia. (n.d.). 10th 
National Development Plan. From epu.
gov.my/en/tenth-malaysia-plan-10th-
mp-?p_p_auth=RczBnru8&p_p_
id=77&p_p_lifecycle=0&p_p_
state=maximized&p_p_mode=view&_77_
struts_action=%2Fjournal_content_
search%2Fsearch.
Government of Mexico CONEVAL. (2015). 
Consejo National de Evaluacion de las Politicas 
de Desarrollo Social. From www.coneval.gob.
mx.
Government of Mexico SFP . (2015). 
Subsecretaria de la Funcion Publica SFP- 
Unidad de Evaluación de la Gestión y 
el Desempeño Gubernamental. From 
funcionpublica.gob.mx.
Government of Mongolia. (2014). Mongolia 
– Institutional Strenghtening for Donor 
Assistance Management Project. From mof.
gov.mn/wp-content/uploads/2014/12/
TOR-for-ME-Manual-and-Training_
approved-20141225.pdf.
Government of Nepal National Planning 
Commission. (2013). National Monitoring 
and Evaluation Guidelines. Kathmandu.
Government of Niger. (2015). From niger-gouv.
org/ministeres.html.
Government of Niger. (2012). Synthese PDES 
Niger 2012-2015. From mpatdc.gouv.
ne/images/stories/rapport/synthese%20
PDESNiger2012-2015Fr.pdf.
Government of Nigeria. (2011). The 
Transformation Agenda 2011-2015: Summary 
of Federal Government’s Key Priority 
Policies, Programmes and Project. From 
nationalplanning.gov.ng/images/docs/
Transformation.pdf.
Government of Nigeria. (2012). From Mid-
term Report of the Transformation 
Agenda (May 2011- May 2013): Taking 
Stock Moving Forward: nationalplanning.
gov.ng/images/docs/downloadcenter/
midtermreportofthetransformationagenda.
pdf.
<<<PAGE=108>>>
90
WORKS CITED
Government of Pakistan Planning Commission. 
(2015). From pc.gov.pk/organization/
sections/ppmi.pdf.
Government of Pakistan. (2015). Pakistan 
2025. One Nation – One Vision. Executive 
Summary. From pc.gov.pk/wp-content/
uploads/2015/05/Vision-2025-Executive-
Summary.pdf.
Government of Panama MEF. (2015). 
Ministerio de Economia y Finanzas. 
From mef.gob.pa/es/direcciones/
presupuestoNacion/Paginas/ue_
monitoreoyevaluacion.aspx.
Government of Panama MIDES. (n.d.). 
MInisterio de Desarrollo Social. From mides.
gob.pa/?page_id=164.
Government of Saint Lucia. (2015). From govt.
lc/.
Government of South Africa DPME. (2015). 
National Evaluation Policy Framework. From 
thepresidency.gov.za/MediaLib/Downloads/
Home/Ministries/National_Evaluation_
Policy_Framework.pdf.
Government of South Africa. (2015). From 
thepresidency-dpme.gov.za/keyfocusareas/
evaluationsSite/Pages/default.aspx.
Government of Suriname. (2015). From gov.sr/.
Government of Tanzania MCDGC. (2015). 
MInistry of Community Development Gender 
and Children. From mcdgc.go.tz/index.php/
departments/category/policy_and_planning/.
Government of Tanzania MOF. (2015). 
Ministry of Finance. From mof.go.tz/index.
php?option=com_content&view=articl
e&id=729:monitoring-evaluation-and-
performance-reporting&catid=51:planning
&Itemid=251.
Government of Tanzania Planning 
Commission. (2015). President’s Office 
Planning Commission. From mipango.
go.tz/index.php?option=com_
content&view=article&id=39&Itemid=106.
Government of Tanzania PO-PSM. 
(2015). President’s Office Public 
Service Management. From utumishi.
go.tz/index.php/organistation-
structure/divisions/planning-division/
monitoring-and-evaluation-section.
Government of Thailand NESDB. (2015). 
National Economic and Social Development 
Board. (Office of the Prime Minister, 
Government of Thailand) From eng.nesdb.
go.th/Default.aspx?tabid=72.
Government of Thailand. (2012). Summary of 
the Eleventh National Economic and Social 
Development Plan (2012-2016). From eng.
nesdb.go.th/Default.aspx?tabid=72.
Government of Uganda OPM. (2015). Office of 
the Prime Minister. From opm.go.ug/opm/
mandate.html.
Government of Uruguay. (2015). From agev.opp.
gub.uy/.
Grey, S. (2012). Performance Monitoring & 
Evaluation Partnering with the Audit 
Committees. From mof.gov.jm/documents/
documents-publications/document-centre/
file/395.html.
Gross National Happiness Commission. (2011). 
Gender Pilot Study: Bhutan. From gnhc.gov.
bt/wp-content/uploads/2011/05/rep_gpsr.
pdf.
Hashim, K. &. (2014). South Asia: Why 
National Evaluation Policies Matter in 
South Asia. Proceedings from the Third 
International Conference on National 
Evaluation Capacities. 30 September –  
2 October 2013 São Paulo.
Hayana, A. (2014). Indonesia – Monitoring 
and Evaluation System. Proceedings from the 
Third International Conference on National 
Evaluation Capacities. 30 September –  
2 October 2013 São Paulo, pp. 114-118.
High Planning Commission Morocco. 
(2015). From hcp.ma/Centre-National-d-
Evaluation-des-Programmes_a734.html.
<<<PAGE=109>>>
91
WORKS CITED
IDB. (2015). Inter-American Development Bank. 
From Jamaica Project Profile: PRODEV 
II: idbdocs.iadb.org/wsdocs/getdocument.
aspx?docnum=1532734.
IOCE. (2012). 2012 Survey National Evaluation 
Organizations. From ioce.net/en/
nationalOrganizations.php.
IOCE. (2014). 2014 Survey National Evaluation 
Organizations. From International 
Organization for Cooperation in Evaluation: 
ioce.net/en/PDFs/national/2014/Russia%20
-%20Association%20of%20Specialists%20
in%20Program%20and%20Policy%20
Evaluation%20ASPPE.pdf.
IOCE. (2015). 2015 Survey National Evaluation 
Organizations.
IOCE. (2012). Case Study Organizations 2012. 
From International Organziation for 
Cooperation in Evaluation: ioce.net/en/
nationalOrganizations.php.
IPEN. (2014). International Program Evaluation 
Network. (Conference Program) From 
eval-net.org/conference/2014/IPEN_2014_
Conference_Program_21_09_ENG.pdf.
Joppert, M. P . (2012, December). Strengthening 
VOPEs’ capacities to enhance evaluators’ skills. 
Thailand.
Khattak, F. H. (2012). From Role of Monitoring 
in Social Sector Development: pc.gov.pk/
wp-content/uploads/2013/12/Article-on-
Role-of-Monitoring-and-Evaluation-on-
social-sector-deveopment.pdf.
Khattak, F. H. (2014). Projects Evaluation in 
Pakistan. From Government of Pakistan 
Planning, Development & Reform 
Division.: pc.gov.pk/?page_id=950.
Kuzmin, A. &. (2014 ). The Emerging Field 
of Evaluation and the Growth of the 
Evaluation Profession: The Russian 
Experience. The Canadian Journal of 
Program Evaluation, Vol. 28 (No. 3), Pages 
87–102.
Lopez, R. G. (2011). Managing for Development 
Results: Progress and Challenges in 
Latin America and the Caribbean. From 
idbdocs.iadb.org/wsdocs/getdocument.
aspx?docnum=37544980.
Lull, F. &. (2014). Albania: Challenges of a 
New Evaluation Society. Proceedings from the 
Third International Conference on National 
Evaluation Capacities. 30 September –  
2 October 2013 São Paulo.
Machuka, S. M. (2014). Kenia – Credibility of 
Evaluation: The Kenyan Case. Proceedings 
from the Third International Conference on 
National Evaluation Capacities. 30 September 
– 2 October 2013 São Paulo, pp. 211-215.
Magembe, E. &. (2011). Tanzania: The 
importance of Monitoring and Evaluation 
in Achieving National Development Policies 
and Programmes’ Targets. roceeding from the 
Second International Conference on National 
Evaluation Capacities 12-14 September 2011 
Johannesburg.
Majid, M. K. (2014). Malaysia – An Evaluation 
of Public Perception towards Government 
Projects: A case study of Constitution NYZ. 
Proceedings from the Third International 
Conference on National Evaluation Capacities. 
30 September – 2 October 2013 São Paulo, pp. 
132-136.
Malaysia Administrative Modernization and 
Management Planning Unit. (2015). 
Government of Malaysia. From mampu.gov.
my/web/en/star-rating.
Maldonado Trujillo, C. G. (2013 ). Monitoreo, 
Evaluación y Gestión por Resultados. 
Aprendizaje y Cooperación SurSur para 
la Innovación: El Papel de los Actores 
Subnacionales. (1. Edición, Ed.) From 
CIDE-Centro CLEAR para América 
Latina: clear-la.cide.edu/sites/default/files/
Monitoreo_Evaluaci%C3%B3n%20y%20
Gesti%C3%B3n%20por%20Resultados_
Maldonado%20y%20Gal%C3%ADndez_0.
pdf.
<<<PAGE=110>>>
92
WORKS CITED
Mattalini. (2013, Julio 30-21). Estructuras 
evaluativas y seguimiento de programas en 
Argentina. (P . d. Ministros, Producer) From 
jefatura.gob.ar/archivos/politicas-publicas/
Estructuras_evaluativas_y_seguimiento_de_
programas_Argentina-Matias_Mattalino.
pdf.
Mattalini, M. (2013). Estructuras evaluativas y 
seguimiento de programas en Argentina. From 
jefatura.gob.ar/archivos/politicas-publicas/
Estructuras_evaluativas_y_seguimiento_de_
programas_Argentina-Matias_Mattalino.pdf.
Medagangoda-Labe, A. (2015 5-September). 
Deputy Resident Representative UNDP 
Morocco. Note to Ana Rosa Monteiro Soares.
MIDEPLAN. (2015). Sistema Nacional 
de Planificacion . From mideplan.
go.cr/2014-05-20-21-27-18?id=337.
Ministere a la Presidence Charge de la Bonne 
Gouvernance et de la Privatisation. (2011). 
Strategie Nationale de Bonne Gouvernance et 
de Lutte contre la Corruption.  From finances.
gov.bi/images/download/publications/
strategie_bne_gouvernance_lutte_contre_
corruption.pdf afdb.org/fileadmin/uploads/
afdb/Documents/Project-and-Operations/
Burundi%20-%20CSP%202012-16.pdf.
Ministere du Plan Niger. (2015). Ministre 
d’Etat, Ministre du Plan, de l’Aménagement 
du Territoire et du Développement 
Communautaire. From mpatdc.
gouv.ne/index.php?option=com_
content&view=article&id=111&Itemid=106.
Ministerio de Desenvolvimento Social. (2015). 
From aplicacoes.mds.gov.br/sagirmps/
ferramentas/TemplateHTML/EG_
FOLDER_SAGI.pdf.
Ministerio de Economía, Planificación y 
Desarrollo (MEPyD). (2013). From PLAN 
ESTRATÉGICO INSTITUCIONAL 
2013-2016: economia.gob.do/mepyd/
wp-content/uploads/archivos/transparencia/
plan-estrategico/plan-estrategico-
institucional-mepyd-2013-2016.pdf.
Ministério de Economia, Planificación y 
Desarrollo. (2015). From Ministério de 
Economia, Planificación y Desarrollo – 
MEPyD: economia.gob.do/mepyd/.
Ministry of Finance. (2015). Ministry of Finance 
and Economic Affairs. From economicaffairs.
gov.bb/agency-research-and-planning-unit.
php.
Morales Rojasand, C. &. (2011). Costa Rica: 
Monitoring, Follow-up and Evaluation 
of Strategic Actions. Proceedings from 
the International Conference on National 
Evaluation Capacities, 15-17 December 2009 
Casablanca., pp. 54-61.
Mottola, J. P . (2015). Dirección de Gestión y 
Evaluación (AGEV), Office of Planning 
and Budget of the President (Oficina de 
Planeamiento y Presupuesto – OPP). From 
agev.opp.gub.uy/documentos/juan_pablo_
mottola.pdf.
Mouime, M. &. (2011). Morocco: Information 
System and National Observatory of 
Human Development Household Panel 
for Evaluation of Public Policy on Human 
Developement. Proceeding from the Second 
International Conference on National 
Evaluation Capacities 12-14 September 2011 
Johannesburg.
National Council for Sustainable Development 
of the Kyrgyz Republic. (2013). 2013-2017 
National Sustainable Development Strategy. 
From https://eiti.org/files/Kyrgyz_NSSD-
final-version-eng-Feb4.pdf.
National Planning Commission. (2015). 
Government of Nigeria. From 
nationalplanning.gov.ng/index.
php/78-featured/106-article-e.
National Planning Commission. (2015). Nepal. 
From npc.gov.np/web/ui/index.php/home/
pdna.
National Planning Department Colombia. 
(2015). From dnp.gov.co/Paginas/inicio.
aspx.
<<<PAGE=111>>>
93
WORKS CITED
National Planning Department. (2015). Sinergia. 
From https://sinergia.dnp.gov.co/Sinergia/
Archivos/52077da3-5b2b-4376-aaeb-
c514f68bd4ac/Agenda%20Evaluaciones%20
2015.pdf.
Niger Diaspora. (2015). Institutionnalisation de 
l’évaluation des politiques publiques au Niger : 
Poser les bases d’une plus grande efficacité des 
politiques et programmes de développement. 
From nigerdiaspora.net/les-infos-du-pays/
economie/item/69568-institutionnalisation-
de-l-evaluation-des-politiques-publiques-
au-niger-poser-les-bases-d-une-plus-
grande-efficacite-des-politiques-et-
-programmes-de-developpement.
Nogoibaeva, C. (2014). Policy Making in the 
Executive Branch of the Government of Kyrgyz 
Republic. Working Paper No. 29, University 
of Central Asia, Institute of Public Policy 
and Administration.
Nyasuly, W. (2014). Malawi – Monitoring 
and Evaluation of the National Budget 
in Malawi. Proceedings from the Third 
International Conference on National 
Evaluation Capacities. 30 September – 2 
October 2013 São Paulo, pp. 216-221.
Office of the Minister of State for 
Administrative Reform. (2011). Strategy 
for the Reform and Development of Public 
Administration in Lebanon. From omsar.gov.
lb/SiteCollectionDocuments/www.omsar.
gov.lb/PDF%20Files/ICT%20Strategies%20
and%20Master%20Plans/strategy%20in_
english.pdf.
Organization of American States. (2015). From 
oas.org/es/sap/dgpe/gemgpe/Colombia/
evaluacion.asp.
Pelishi, N. (2014). World Bank Conference 
“Monitoring and Evaluation Capacity 
Development in the Western Balkans and 
Turkey. From worldbank.org/content/
dam/Worldbank/Event/ECA/capacity-
development-conference-summary.pdf.
Perez-Yarahuan, G. (2014). Mexico: Evaluation 
Use and its Institutionalization in the 
Federal System in Mexico. Proceedings 
from the Third International Conference on 
National Evaluation Capacities. 30 September 
– 2 October 2013 São Paulo.
Perotti, N. (2014). Argentina – Policy 
Evaluations of National Public 
Administration: Overview. Proceedings 
from the Third International Conference on 
National Evaluation Capacities. 30 September 
– 2 October 2013 São Paulo, pp. 143-146.
Reeves, J. (2014). Daniel K. Inouye Asia-
Pacific Center for Security Studies . From 
Development Planning in Mongolia: Failure 
and Potential: apcss.org/development-
planning-in-mongolia-failure-and-
potential/.
Rosenstein, B. (2013). Mapping the Status 
of National Evaluation Policies. Paper 
Commissioned by Parliamentarians Forum 
on Development Evaluation in South Asia 
jointly with EvalPartners.
Rosenstein, B. (2015). Status of National 
Evaluation Policies. Global Mapping 
Report. 2nd Edition, Implemented by 
Parliamentarians Forum on Development 
Evaluation in South Asia jointly with 
EvalPartners.
Royal Government of Bhutan. (2015). 
Evaluation Policy 2014 (Second Draft). From 
gnhc.gov.bt/wp-content/uploads/2015/01/
Evaluation-Policy-27-January-2015.pdf.
Royal Government of Bhutan. (2011). Tenth 
Five Year Plan. Mid Term Review Report. 
Gross National Happiness Commission.
Santamaria, C. (2013, November). Evaluación 
de Politicas y Programas Públicos: Experiencia 
de El Salvador. Presentation at CLEAR. 
Mexico. From CLEAR: clear-la.cide.edu/
sites/default/files/Day%201_The%20
Challenges%20of%20Emerging%20
Systems_El%20Salvador_0.pptx.
<<<PAGE=112>>>
94
WORKS CITED
Sarwary, M. H. (2014, June). Use of Evaluation: 
Local Governance M&E System in 
Afghanistan. Solutions Related to Challenges 
of Independence, Credibility and Use of 
Evaluation. Proceedings from the Third 
International Conference on National 
Evaluation Capacities.
Serpa, S. M. (2014). Brazil – A Model to 
Evaluate the Maturity of the Brazilian 
Public Administration’s Evaluation Systems. 
Proceedings from the Third International 
Conference on National Evaluation Capacities. 
30 September – 2 October 2013 São Paulo, pp. 
147-155.
Sivagnanasothy, V. &. (2014). Sri Lanka – 
Country-led National Evaluation System: 
Indpendence, Credibility and Use of 
Evlautions; Challenges and Solutions. 
Proceedings from the Third International 
Conference on National Evaluation Capacities. 
30 September – 2 October 2013 São Paulo, pp. 
124-131.
Sivagnanasothy, V. &. (2014). Sri Lanka 
Country-led National Evaluation System: 
Independence, Credibility and Use of 
Evaluation Challenges and Solutions. 
Proceedings from the Third International 
Conference on National Evaluation Capacities. 
30 September – 2 October 2013 São Paulo.
Sivagnanasothy, V. (2011). Sri Lanka: National 
Monitoring and Evaluation System: 
Experiences, Challenges and the Way 
Forward. Proceedings from the International 
Conference on National Evaluation Capacities, 
15-17 December 2009 Casablanca., pp. 74-90.
Sivagnanasothy, V. (2015). UNDP International 
Conferences on National Evaluation Capacities 
significantly influenced the Evaluation 
Culture in Sri Lanka. Secretary, Ministry 
of Plantation Infrastructure Development, 
Government of Sri Lanka.
Tesfaye, H. (2015, August 18). Note to IPDET 
LIst Serv. IPDET@LISTSERV .IPDET.ORG.
Thailand Evaluation Network. (2015). From 
tenthailand.net/.
The Federal Democratic Republic of 
Ethiopia. (2010, September). Growth and 
Transformation Plan (GTP) 2010/11-
2014/15. From ethiopians.com/Ethiopia_
GTP_2015.pdf.
The Global Network of National Councils for 
Sustainable Development and Similar Bodies. 
(2015). From [Office of ] the National 
Economic and Social Development Board 
(NESDB): ncsds.org/index.php/homepage/
background/85-country-profiles/158-
thailand.
The World Bank. (2011, January). Final Report. 
Results Based Management in Thailand. 
Country Development Partnership on Gover-
nance and Public Sector Reform. Implementing 
Results Based Management in Thailand. From 
www-wds.worldbank.org/external/default/
WDSContentServer/WDSP/IB/2011/12/1
9/000333037_20111219235215/Rendered/
PDF/660670WP0P12260ed0Manage-
ment0Report.pdf.
Trivedi, P . (2011). India: India Experience with 
the Performance Monitoring and Evaluation 
System for Government Departments. 
Proceeding from the Second International 
Conference on National Evaluation Capacities 
12-14 September 2011 Johannesburg.
UNDP. (2015). From undp.org/
content/dam/mongolia/JobTORs/
VacancyAnnouncements/VA2013/MED/
TOR%236_National%20Consultant_
Evaluation%20of%20M%26E%20system_
ENG.pdf.
UNDP IEO. (2015). Concept Paper National 
Evaluation Capacities Conference Bangkok.
UNDP IEO. (2014). Proceedings from the 
Third International Conference on National 
Evaluation Capacities. 30 September –  
2 October 2013 São Paulo. Solutions Related 
to Challenges of Independence, Credibility 
and Use of Evaluation. New York: UNDP 
Independent Evaluation Office.
<<<PAGE=113>>>
95
WORKS CITED
UNDP NEC. (2015). NEC Team Works. From 
unteamworks.org/NEC.
UNDP . (2011). Proceedings from the 
International Conference on National 
Evaluation Capacities, 15-17 December 
2009 Casablanca. National Evaluation 
Capacities. New York.
United Nations Economic Social Council. 
(2015). Development Strategies That Work. 
(Country experiences presented at the 
ECOSOC Annual Ministerial Review) 
From Mongolia Comprehensive National 
Development Strategy: webapps01.un.org/
nvp/indpolicy.action?id=2966.
Vaitsman, J. a.-S. (2011). Avaliaçao de 
programas e profissionalizacao da gestao 
publica. Revista Brasileira de Monitoramento 
e Avaliacao, Numero 01.
Van Hoot, C. (2012.). Supporting good practice 
in monitoring and evaluation in partner 
countries: Lessons learned from Uganda.  
From DEVPOLICYBLOG from the 
Development Policy Centre: devpolicy.org/
supporting-good-practice-in-monitoring-
and-evaluation-in-partner-countries-
lessons-from-uganda/.
Vargas, M. N. (2011). Costa Rica: Using 
Evaluation in the Public Sector – Current 
Situation and Challenges. Proceeding 
from the Second International Conference 
on National Evaluation Capacities 12-14 
September 2011 Johannesburg.
World Bank. (2015). From MN-Institutional 
Strengthening for Donor Assistance 
Management Project: www-wds.
worldbank.org/external/default/
WDSContentServer/WDSP/
EAP/2015/02/23/090224b082b3ae27/1_0/
Rendered/PDF/Mongolia000MN00Report 
000Sequence003.pdf.
World Bank. (2015). Mongolia – Institutional 
Strenghtening for Donor Assistance 
Management Project. From mof.gov.
mn/wp-content/uploads/2014/12/
TOR-for-ME-Manual-and-Training_
approved-20141225.pdf.
Yantio, D. Y. ( 2013, March). The Program 
Evaluation in Cameroon: An Overview by a 
Practicioner. eV ALUation Matters.
<<<PAGE=114>>>

<<<PAGE=115>>>
97
ANNEX 1. 43 UNDP COUNTRIES AND THEIR COMMITMENTS
153 As explained in Section 1, these are not official commitments signed by official government representatives, but represent key areas 
of interest for government representatives, policy makers or practitioners from these countries expressed during the Third NEC 
Conference in São Paulo.
Annex 1
43 UNDP COUNTRIES AND  
THEIR COMMITMENTS
153
 
Country C1 C2 C3 C4 C5 C6 C7 C8 C9 C10 C11 C12 C13 C14 C15 C16 C17 C18
Benin n y n n n n n n n n n n n n n n n n
Burundi y n n n n n y n n n n n n n n n n n
Cameroon n n n n n y y y y y n y y n n n n n
Ethiopia n n n n n n n y n n n n n n y n n n
Ghana n y n n n y y  n n n n n n y y n n
Kenya y y y n y y y y n n n y n n n n n n
Malawi y y n n n n n n n n n n n n n n n n
Niger n n n n n n y y n n n n n y n n n n
Nigeria n n n y  y y n n n n n n n n n n n
South Africa n y y n y n y y y y y y n n n n n n
Tanzania n y y y y n y n y n y n n n n n n n
Uganda y n y n y n y n y n y y n y y n n n
Egypt n n y y y n y y y n n n y y y n n n
Lebanon y n n n y n n y n n n y n n n n n n
Morocco n y n n n n y n y y y y n y y n n n
Afghanistan n n y n n n y y n n n n n n y n n n
Bhutan n n n y y y y n y y n y n n n n n n
India y n n n n n n n n n n n n n n n n n
Indonesia y y n n n n n n n n n n n n n n n n
Malaysia n n y n n n n y n n n n n n n n n n
Mongolia y y n y n n y n y n y n n n n n n n
Nepal y n n n n n y n n n n n n n n n n n
Pakistan n n n n n y y n n n n n n n n n n n
Sri Lanka y n y y y y y n y y n y n y y n n n
Thailand n n n n n n y n n n n n n n n n n n
Albania n n y n y n y n n n n n y n y n n n
<<<PAGE=116>>>
98
ANNEX 1. 43 UNDP COUNTRIES AND THEIR COMMITMENTS
Country C1 C2 C3 C4 C5 C6 C7 C8 C9 C10 C11 C12 C13 C14 C15 C16 C17 C18
Kyrgyzstan n n n n n n n n n n n n n n y n n n
Russia n n n n y n y n n n n n n n n n n n
Argentina n n n n n n y y y y n y y y y n n n
Barbados y y n y y y y n n y n n n n n y n n
Brazil n y y y y y y y y y y n y y n n n n
Colombia n n n n n n n y n n n n n n n n n n
Costa Rica n n n y n n y n n n n n n n n n n n
Dominican 
Republic y n y n y n y n n y y n n n y n n n
El Salvador n y n y n n n n n n y n n n n n n n
Guatemala n n n n n n n n n n n n n y y n n n
Honduras n n n y n n n y n y y n n n n n n n
Jamaica n y n y n n n n n n n n n n n n n n
Mexico n n y n n n n n n n n n n n n n n n
Panama n n n n n n y n n n n n n n n n n n
Saint Lucia n n n y n n y n n n n n n n n n n n
Suriname y y n n n y y y y n y n n n n n n n
Uruguay n n n n n n y n n n n n n y n n n n
<<<PAGE=117>>>
99
ANNEX 2. STUDY FRAMEWORK
154 The existence of references does not mean budgets exist.
155 This commitment also links central and local levels of government, which this study will not likely to be able to document. 
Annex 2
STUDY FRAMEWORK 
Commitments Issues/Area of 
Commitment
Reporting 
Questions Survey-questions/Respondent
Data Col-
lection 
Methods
1. National government’s capacity to use evaluations (Use of Evaluation)
C4. Study the alternatives, 
assessing the pro and cons, 
of different options of 
institutional set-ups, such 
as national evaluation 
legislation and policies, 
where appropriate, taking 
the country/cultural 
context into account 
and establishing a set of 
minimum requirements 
based on lessons learned.
Institutional 
set-ups/Legal 
frameworks for 
evaluation
Does the country 
have institutional 
set-ups, such as 
national evalua-
tion legislation or 
policies formally 
requiring the 
conduct of evalu-
ations for national 
programmes and 
policies?
UNDP/NG/VOPEs (either or all): Does 
the country have requirements for eval-
uation in the form of national evaluation 
legislation, national evaluation policy, 
or policies requiring evaluations for 
national programmes and policies?
UNDP/NG/VOPEs (either or all): Are 
there specific efforts by the government 
and civil society (professional networks, 
universities) to develop/set up National 
level policies/structures/frameworks? 
What are those?
UNDP/NG/VOPEs (either or all): Are 
evaluations used in specific government 
sectors (i.e. health, education, social 
assistance)? How?
Desk 
review and 
Survey
C16. Assign budgets or 
percentages of initiatives 
to evaluations when 
designing/approving proj-
ects/programmes/policies 
or assign a percentage of 
the initiative cost. 
Budget for 
evaluations
UNDP/NG/VOPEs (either or all): Do 
policies and frameworks refer to the 
need of budgets in place to conduct the 
work?154
Survey
C14. Map and analyse 
effectiveness of coor-
dination mechanisms 
and practices between 
central evaluation units 
and sector ministry units 
and local government 
evaluation.155
Evaluation 
Management 
-Central/ 
decentralized 
Administrative 
Systems
What are the 
administrative/
management 
structure(s) at the 
national level to 
implement eval-
uation policies 
(and plan, con-
duct, administer 
and follow up on 
evaluations)?
UNDP/NG/VOPEs (either or all): Does 
the National government have a central 
evaluation unit?
UNDP/NG/VOPEs (either or all): Are 
there evaluation units in specific gov-
ernment sectors (i.e. health, education, 
social assistance)?
NG/VOPEs (UNDP unlikely?): Is there 
communication, collaboration, and coop-
eration among evaluation units of vari-
ous national government departments?
NG/VOPEs (UNDP unlikely?): Is there 
communication, collaboration, and 
cooperation among evaluation units of 
between national and other levels of 
government?
Desk 
review and 
Survey
Survey
Survey
<<<PAGE=118>>>
100
ANNEX 2. STUDY FRAMEWORK
Commitments Issues/Area of 
Commitment
Reporting 
Questions Survey-questions/Respondent
Data Col-
lection 
Methods
C6. Create/strengthen 
Parliamentarians’ 
forum for development 
evaluation in different 
regions to advocate for use 
and conduct of evaluations.
C7. Facilitate partnership 
/ cooperation between 
government, voluntary 
organizations for 
professional evaluation 
(VOPEs), parliament 
and the private sector 
to strengthen the 
understanding about what 
evaluation is and how it 
can be useful for different 
actions.
Evaluation 
culture/ 
Promotion of 
evaluation and 
its demand/
use
Are there external 
efforts to promote 
evaluation and its 
use?
Does your country 
have a parlia-
mentarian forum 
for evaluation, 
does your coun-
try engage in a 
regional one?
Do parliamentar-
ians demand and 
make use of eval-
uations? How? If 
they demand, how 
is this processed?
UNDP/NG/VOPEs (either or all): 
What are the main institutions actively 
advocating for the use and conduct 
of evaluations (i.e. VOPEs, Parliament, 
National Government units, Private 
Sector)?
UNDP/NG/VOPEs (either or all): 
What efforts are underway by these 
institutions to promote the need and 
demand for and use of evaluations of 
national-level government programmes?
UNDP/NG/VOPEs (either or all): Is 
there cooperation between Government, 
VOPEs, Parliament and Private Sector in 
theses efforts?
UNDP/NG/VOPEs (either or all): Is 
there a parliamentarian forum for 
evaluation at the national level in the 
country? Is there a parliamentary forum 
at a regional level? Does the National 
Government participate in any or both 
of them?
UNDP/NG/VOPEs (either or all): Do 
parliamentarians demand and make use 
of evaluations? How? If they demand, 
how is this processed?
Desk 
review and 
Survey
Survey
Desk 
review and 
Survey
Survey
2. National government’s capacity for independent evaluations (Independence of Evaluation)
C3. Develop systems to 
promote the transparent 
follow-up of evaluations, 
such as management 
response tracking sys-
tems and citizen’s com-
mission that allow for 
effective monitoring of the 
implementation of evalua-
tion recommendations.
C10. Develop standards, 
based on lessons learned 
to ensure stakeholders 
involvement while still 
guaranteeing indepen-
dence of the evaluation.
Stakeholder 
Involvement/
management 
response
Are there specific 
efforts to promote 
the independence 
of evaluations 
(i.e. stakeholder 
involvement, 
system for man-
agement response 
transparency and 
accountability 
mechanisms)? 
Are there references to transparency, 
accountability and external stakeholder 
involvements in evaluation in govern-
ment websites and documents?
UNDP/NG/VOPEs (either or all): Are 
VOPEs, Parliament, Private Sector and 
others advocating for transparency, 
accountability and stakeholder involve-
ment in National evaluation processes?
NG/VOPEs (UNDP unlikely?): Are 
there specific efforts to promote the 
independence of evaluations (i.e. 
stakeholder involvement, system for 
management response, transparency 
and accountability mechanisms)?
Desk 
Review
Desk 
Review and 
Survey
<<<PAGE=119>>>
101
ANNEX 2. STUDY FRAMEWORK
Commitments Issues/Area of 
Commitment
Reporting 
Questions Survey-questions/Respondent
Data Col-
lection 
Methods
3. National government’s capacity to ensure credible evaluations (Credibility of Evaluation)
C2. Collaborate to build 
and strengthen credible 
national data systems to 
improve the integrity of 
such systems, in order to 
better link performance of 
policies and programmes.
C11. Develop/connect 
national registries/
national statistical sys-
tems to M&E systems with 
increased frequency of 
data collection to support 
decision-making.
Data Systems Are there National 
data systems in 
place? 
Is there a central government agency 
responsible for collecting and analysing 
national data (e.g demographics, 
economics)?
Are there any integrated public 
registries, administrative records, 
national statistics, M&E system used for 
evaluations?
 
Desk 
review 
C9. Develop standards, 
based on lessons learned, 
to ensure proper triangu-
lation of evidence, checks 
and balances and qualita-
tive data use to not be just 
perception-based.
C5. Develop /strengthen/ 
support / expand joint 
peer-to-peer systems and 
mentoring programmes 
among professional associ-
ation of evaluators and gov-
ernment evaluation units.
C17. Use Independent 
evaluators to facilitate/
moderate self-assessments 
and reviews.
Evalua-
tion Tech-
niques and 
Methodologies
Are there specific 
guides/courses on 
evaluation tech-
niques, manuals 
and methodologies 
to assist evaluation 
practitioners?
UNDP/NG/VOPEs (either or all): Are 
courses/guides on evaluation practice 
available by Universities, VOPEs, Govern-
ment, other education institutions?
UNDP/NG/VOPEs (either or all): Are 
the professional evaluation associations 
in the country playing a role to advance 
evaluation techniques in general?
 
Desk 
Review and 
Survey
C8. Develop approaches 
based on lessons learned, 
on how to incorporate cul-
tural dimensions into eval-
uation in different regional 
and national contexts.
C18. Incorporate gender 
capacities/perspectives in 
M&E national Systems
Gender and 
cultural 
evaluation 
capacities/
perspectives
Are guides/meth-
odologies for the 
incorporation of 
cultural/gender 
issues in evaluation 
processes available 
in the country? Are 
they used?
UNDP/NG/VOPEs (either or all): Are 
there courses/guides on incorporation 
of cultural dimensions and gender 
capacities in the evaluation processes 
available in the country?
UNDP/NG/VOPEs (either or all): Are 
gender issues incorporated in national 
government evaluation processes?
UNDP/NG/VOPEs (either or all): Are 
cultural issues incorporated in national 
government evaluation processes?
UNDP/NG/VOPEs (either or all): Are 
the professional evaluations and others 
advocating for the incorporation of cul-
tural dimensions, gender capacities in 
the evaluation processes?
Desk 
Review and 
survey
Survey
Survey
Desk 
Review and 
survey
<<<PAGE=120>>>

<<<PAGE=121>>>

<<<PAGE=122>>>
United Nations Development Programme 
Independent Evaluation Office
220 East 42nd Street, New York, NY 10017, USA
Tel. +1 (646) 781 4200, Fax  +1 (646) 781 4213
Web: www.undp.org/evaluation
Empowered lives. 
Resilient nations. 
             ⁄ UNDP_Evaluation
            ⁄ ieoundp
            ⁄evaluationoffice