<<<PAGE=1>>>
Republic of Kenya 
 
 
 
Baseline Study on the 
Performance Monitoring and 
Evaluation Culture  
in the Public Sector in  
Kenya 
 
October 2019 
 
(Final Report)
<<<PAGE=2>>>
Baseline on Performance M&E Culture in the Public Sector in Kenya  October 2019 
 
ii 
 
 Table of Contents  
 
Acronyms ................................................................................................................................ iii 
Executive Summary ................................................................................................................. iv 
1. Introduction .......................................................................................................................... 1 
1.1 Background of the Study ................................................................................................. 1 
1.2 Efforts to Establish a Monitoring and Evaluation System in Kenya .................................2 
2.Theoretical Framework ......................................................................................................... 2 
3. Study Objective ................................................................................................................... 4 
4. Study Methodology .............................................................................................................. 5 
5. Study Findings ..................................................................................................................... 6 
5.1 Introduction .....................................................................................................................6  
5.2 Response Rate................................................................................................................7  
5.3 The Supply Side of M&E ................................................................................................. 8 
5.4 The Demand Side of M&E ............................................................................................. 15 
5.5 Barriers to the Use and Supply of Evaluation Evidence ................................................ 20 
6. Conclusions and Recommendations ................................................................................. 24 
6.1 Conclusions ................................................................................................................... 24 
6.2 Recommendations ........................................................................................................ 27 
Appendix 1: References ...................................................................................................... 28
<<<PAGE=3>>>
Baseline on Performance M&E Culture in the Public Sector in Kenya  October 2019 
 
iii 
 
Acronyms  
AfDB   African Development Bank  
CLEAR-AA   Evaluation and Results Anglophone Africa  
CIDP   County Integrated Development Plans  
CIMES  County Integrated Monitoring and Evaluation System  
CPPMUs  Central Projects and Planning Management Units  
CVF    Competing Values Framework 
GOK   Government of Kenya  
IMS   Information Management System 
NIMES  National Integrated Monitoring and Evaluation System  
NGOs   Non-Governmental Organisations 
OCAI    Organisational Culture Assessment Instrument 
SAGAs   Autonomous Government Agencies 
TWENDE MBELE   Twende Mbele Programme  
TOR   The Terms of Reference
<<<PAGE=4>>>
Baseline on Performance M&E Culture in the Public Sector in Kenya  October 2019 
 
iv 
 
Executive Summary 
 
This baseline survey is an initiative of the Government of Kenya through the State Department 
of Planning with support from the Twende Mbele Programme. The Twende Mbele Programme 
is a partnership between governments, the African Development Bank and the Centre for 
Learning on Evaluation and Results -Anglophone Africa , to strengthen monitoring and 
evaluation systems in the public sector. The Kenyan baseline survey was carried out in August 
and September 2019, targeting state departments, state corporations and county governments.  
 
The ob jective of th e survey was to establish baseline information on the monitoring and 
evaluation (M&E) culture that exists within the public sector by identifying the current conditions 
against which future changes in the country’s National Integrated Monitoring and Evaluation 
System and culture could be tracked to increase the adaptation of monitoring and evaluation 
and performance management as part of public sector reform. The working hypothesis of the 
survey was that an M&E culture that looks positively at change, adaptation and learning leads 
to improved and operational performance systems. To test this hypothesis, the survey sought 
to answer four questions , namely: Is there an endogenous demand for M&E in the public 
sector? Is there an adequate supply of M&E evidence to meet demand? What are the barriers 
to the use and supply of M&E evidence in the public sector? What is the dominant performance 
M&E culture in the Kenyan Public Sector? 
 
A standard questionnaire was used to conduct the survey , in order to make the findings 
comparable to those of other countries where the survey had already been done. Using a cross-
sectional survey design, a total of thirty-six (36) in-depth interviews and thirty-seven (37) online 
surveys were conducted, cutting across the state departments, state corporations and county 
governments. Quantitative data were analys ed descriptively , while qualitative data were 
analysed using content analysis, patterning, theming and scenario mapping.  
 
The study showed that endogenous demand for M&E within the public sector is driven by 
several articles in the Constitution of Kenya 2010, which imply the need for a structured way of 
monitoring policies, programmes and projects. Further, the County Governments Act, 2012 , 
and the Public Finance Management Act, 2012, require clear county planning and monitoring 
systems. Within the public sector, the Monitoring and Evaluation Directorate works to 
strengthen evidence-based policy formulation and improve the  tracking of results.
 To achieve 
this, the Directorate works with  various Central Projects and Planning Management Units 
(CPPMUs) at both levels of government. Almost all institutions surveyed had a unit dedicated 
to M&E. Most of these units were headed by officers at senior management level within the 
government. This is an important condition in ensuring endogenous demand, as it guarantees 
that it will be championed high up in the organis ation structure. However, in the public sector, 
accountability for performance,  and resource allocation decisions , are vested in the office of 
either the Principal or Cabinet Secretaries, a good proportion of whom were reported to be not
<<<PAGE=5>>>
Baseline on Performance M&E Culture in the Public Sector in Kenya  October 2019 
 
v 
 
ensuring consistent demand for evaluation. As a result, too few resources were allocated to 
evaluation.  
Further, erratic changes in government policy and political dynamic s increased the time 
pressure on responsible officers who had to take decisions without proper diagnosis of the 
problem. The championing of M&E was also hampered by the current practice of focusing on 
activities and outputs rather than on outcomes. Another factor that hindered the championing 
of M&E is the fact that a majority of the institutions surveyed saw M&E as a form of policing 
and a way of controlling staff, and as the job of the M&E unit and not of all managers.  
Generally, strategic plans contained implementation frameworks with indicators and targets. 
Further, indicators and targets were integrated into annual performance plans to measure and 
monitor performance. However, overachievement of those targets was rare as a result of 
persistent budget cuts from the government that consistently led to the downward revision of 
annual targets. On the question of “incentives” in circumstances where performance was either 
above or below expectation, the study did not establish a conclusive practice across the public 
sector. Even though several “reward and punishment” mechanisms were mentioned as being 
used by the institutions s urveyed, there was no clear approach to administering those 
mechanisms.  
A majority of the institutions surveyed used evaluation evidence, with most of them using it 
throughout the programme life cycle. Internally-generated evaluation evidence was used more 
to improve the understanding of interventions and to enhance the value derived from the 
participation of stakeholders in the planning and implementation of evaluation, than to make 
changes to policies. The results of the study showed that more institutions used evaluation 
recommendations from other departments or stakeholders than from internal sources. A 
striking result was that, irrespective of whether evaluation recommendations were from internal 
or external sources, most institutions reported using it  either often or always to improve their 
understanding of interventions. Further, the results showed that in either case, fewer 
institutions would often or always use the evidence for making changes to policies. This finding 
may point towards a weak link between evaluation evidence and policy change.  
A majority of the surveyed institutions had units in their structures that were dedicated to M&E. 
Most of these units had fewer than seven posts, with over 70% of the institutions indicating a 
number of vacancies in their M&E units. On another front, over 50% of the institutions surveyed 
indicated that their performance information management systems either rarely or never 
integrated most informati on needed by managers. This practice implies that the output from 
the system is not what managers require to make decisions, or that the decisions made using 
such information are not fully supported. 
 
Generally, whenever performance was below expectation, most institutions surveyed would 
either rarely or never sanction the responsible official. The argument advanced for this practice 
was that targets are usually set at a departmental level, and attributing non-achievement to an 
individual may be difficult. On the other hand, fewer than one-third of the institutions surveyed
<<<PAGE=6>>>
Baseline on Performance M&E Culture in the Public Sector in Kenya  October 2019 
 
vi 
 
would either reward or regard highly staff members who were responsible for performance that 
was above expectation. This is compounded by  the fact that in over 40% of the institutions, 
senior managers took personal credit without acknowledging their team whenever performance 
was above expectation. In over 30% of the institutions that performed above expectation, 
learning was either rarely or never documented and shared internally and exter nally. This 
practice denies follow-on programmes the opportunity to innovate based on past lessons.  
 
The main methods used to disseminate M&E information were community meetings and 
websites, while the least commonly used methods were academic journals and conference 
papers. Dissemination of evidence using a cademic journals and c onference papers is more 
targeted and interactive,  since these are generally subjected to rigorous peer review 
mechanisms, and benefit from well -structured and scientific feedback process es. Thus, they 
provide a robust channel for disseminating scientific information which can inform decision-
making. 
 
On average, the results indicated a relatively weak supply  side. As a result, most institutions 
did not undertake evaluation as a systematic research process. In addition, most institutions 
had weak internal capacity to conduct evaluations, so that evaluations were often conducted 
by external consultants. Furthermore, most institutions focused on activities and outputs rather 
than outcomes and impact. This implies the following: that most institutions carried out more of 
a monitoring and process form of evaluation , as opposed to an outcome and impact form of 
evaluation; that most institutions had too few financial resources allocated to evaluation; and  
that more than one-third of the institutions did not see problems as an opportunity for learning 
and improvement.  
 
Barriers to the use and supply of evaluation evidence were assessed and analysed in two 
categories, namely value- related and system -related barriers. The results showed that the 
supply and use of M&E evidence was  weighed down more by systemic than value- related 
barriers. Most institutions cited the following as being critical barriers : too few financial 
resources being allocated to evaluation;  weak capacity for  conducting evaluations within the 
department; a focus on activities and outputs rather than on outcomes and impact; M&E being 
seen as a form of policing and a way of controlli ng staff; time pressure making it difficult or 
impossible to make decisions; and evaluation not being undertaken as a systematic process. 
 
Overall, the current performance of M&E culture was marked by a combination of doing things 
together (collaborative/clan culture), doing new things (adhocratic/creating culture) , doing 
things fast (competition culture), and doing things right  (control/hierarchy culture). However, 
the working hypothesis envisioned a greater focus on doing new things  (adhocracy) blended 
with doing things right. As such, the working hypothesis was not fully supported. Consequently, 
to achieve the envisioned culture, the study makes two broad structural and organis ational 
recommendations, namely: creating and enhancing strong support ('championship') as a key
<<<PAGE=7>>>
Baseline on Performance M&E Culture in the Public Sector in Kenya  October 2019 
 
vii 
 
driver for endogenous demand for M&E ; and increasing the understanding, acceptance, 
standardisation and performance of the M&E function in the public sector through the 
implementation of a deliberate policy framework that promotes incentives for the supply and 
use of M&E evidence, M&E capacity strengthening, mainstreaming, and institutionalisation.
<<<PAGE=8>>>
Baseline on Performance M&E Culture in the Public Sector in Kenya  October 2019 
 
1 
 
1. Introduction 
1.1 Background of the Study 
 
This report presents the findings of a baseline study on m onitoring and e valuation (M&E) 
culture in the National Integrated M&E System (NIMES) in Kenya as part of a wider programme 
in Kenya and Ghana, building on the knowledge gained from similar studies previously carried 
out in Benin, Uganda and South Africa in 2017. The study is an initiative of the Government of 
Kenya (GOK), in collaboration with the Twende Mbele programme, to strengthen performance 
M&E in Africa.  
 
Twende Mbele is a peer learning partnership, started by Uganda, South Africa and Benin, who 
have been working together with the Centre for Learning on Evaluation and Results (CLEAR) 
Anglophone Africa and IDEV since 2012 to share experiences related to M&E. The goal of 
Twende Mbele is to support the widespread implementation and sustainability of M&E systems 
through partnerships and collaboration across Africa. Through Twende, it is hoped that M&E 
systems in partner countries will be improved and used more widely . Specif ically, Twende 
initiatives are intended to improve governance throughout Africa in a number of  ways: they 
hope to stimulate the demand for, and the use of, M&E tools within partner countries and by 
other governments ; they aim to improve the understanding of M&E and encourage greater 
knowledge about its use; and they promote the sharing throughout Africa of information and 
learning about how M&E has been successfully  used. In addition, the Programme supports 
collaboratively developed M&E practices, policies , tools and procedures , as well as effective 
and collaborative programme management. 
 
As a step towards directing the type of interventions to be undertaken in the country’s NIMES, 
the State Department of Planning , in collaboration with Twende Mbele, commissioned a 
baseline survey of the performance M&E culture in the public sector in Kenya. The study aims 
to establish baseline information on the M&E culture that exists within the public sector  by 
identifying the current conditions against which future changes in the country’s NIMES and 
M&P culture can be tracked. Specifically, the study is meant to assess the state of M&E culture 
in the government by delineating how various M&E systems interact with each other to improve 
performance and accountability , with a specific focus on policy, approach, concept ual, 
framework and organisational arrangements in the public sector. The long-term value of this 
study would be to increase the ad aptation of M&E and performance management as part of 
public sector reform.
<<<PAGE=9>>>
Baseline on Performance M&E Culture in the Public Sector in Kenya  October 2019 
 
2 
 
1.2 Efforts to Establish a Monitoring and Evaluation System in Kenya 
Development of an integrated M&E system in Kenya began in 2000 with the Interim Poverty 
Reduction Strategy Paper (2000-2003). This was followed by the development of the National 
Integrated Monitoring and Evaluation System (NIMES) in 2004. NIMES was used to track the 
performance of the Economic Recovery Strategy 2003- 2007, and is currently being used to 
track performance progress for the medium-term plans (MTPs) of Kenya Vision 2030, which is 
the country’s development blueprint. The creation of the Monitoring and Evaluation Directorate 
(MED) in the then Ministry of Planning and National Development gave M&E a home within the 
government sector.  
 
For devolution and c ounty governments, the n ational government developed the County 
Integrated Monitoring and Evaluation System (CIMES) Guidelines for the county governments 
to monitor and report on the implementation of County Integrated Development Plans (CIDP). 
Both Kenya Vision 2030 and the CIDPs have M&E frameworks to act as a guide in tracking 
their performance. 
 
The Constitution of Kenya 2010, in articles 10, 35, 56, 174, 185, 201, 203, 225, 220, 226 and 
227, implies that there is a need for a structured way of monitoring policies, programmes and 
projects. In addition, the County Governments Act, 2012 (Sections 47 & 108) , and the Public 
Finance Management Act, 2012 (Section 126) , require clear county planning and monitoring 
systems. This means that both levels of governments should provide collaborative and 
evidence-based sustainable solutions for growth and development. In practice, this should be 
backed by evidence from quality and timely M&E data regarding the implementation of 
development projects, programmes and policies. 
 
2.Theoretical Framework 
 
M&E culture i s an organisational culture that deliberately seeks information about  its 
performance to learn how to better manage and deliver its program mes and services, and 
thereby to improve its performance (Mayne, 2008). Organisations that have this culture value 
empirical evidence about  the results they are aiming to achieve.  This definition corresponds 
with the World Bank definition that M&E culture comprises a shared set of values, conventions, 
or social practices; with a positive M&E culture denoting a situation where M& E is accepted, 
welcomed, encouraged and valued by all members of the team as an essential part of 
successfully implementing projects (World Bank, 2009). 
 
These definitions indicate situations where there may be a demand for, and provision of, M&E. 
As CLEAR (2012) has observed, when decision- makers wish to use evidence from M&E 
systems to make choices, demand for M&E is generated. An important component of demand
<<<PAGE=10>>>
Baseline on Performance M&E Culture in the Public Sector in Kenya  October 2019 
 
3 
 
is that it should be endogenous to the system in which it is operating (Bemelmans-Videc, Rist, 
& Vedung, 2003). Literature suggests that endogenous demand for M&E systems exists when 
the following elements are present : there are well-positioned individual and institutional 
champions across the system; there are incentives that  link performance data, monitoring 
information and evaluation recommendations to resource allocation that  is results-orientated; 
and appropriate evaluations that promote the use of their recommendations are commissioned 
(Kusek & Rist, 2004; Mackay, 2007; Plaatjies & Porter, 2011).  
 
Inevitably, a demand for M&E calls for the supply of M&E to keep the system in equilibrium. 
Any disturbance to this equilibrium affects the functioning of the system. If, for instance, the 
capacity for supplying M&E information is  high, but the demand for quality evidence from 
decision makers is low, supply and demand will be mismatched. According to Porter (2013), 
even though there is an apparent demand for evaluation in Africa, the main response remains 
the use of monitoring systems. Porter further argues that, though ‘M&E Units’ have been set 
up by governments in Africa that apparently set incentives for evaluations to be carried out, in 
reality most of them are units that collate monitoring information and conduct some analys is 
based on that information. 
 
A recent diagnostic study of  the supply of, and demand for, evaluators in South Africa found 
that problems with the quality of demand are often the cause of problems with the quality and 
quantity of sup ply (Philips, 2018) . This finding corroborates that of the World Bank (2014). 
Philips (2018) recommends that, in order to reduce the risk of a shortage in supply of M&E 
evidence, the primary focus should be on improving the quality of government demand. The 
implication here is that the performance of M&E systems depends largely on the relationship 
between demand for evidence- based decisions and the supply of evidence to support those 
decisions. The strength of this relationship is further dependent upon the organisational M&E 
culture, thus providing a direct link between organisational culture, performance and M&E  
(Berrio, 2003; Kotter & Heskett,  1992; Wagner & Spencer , 1996) . Conceptually, this 
relationship can be depicted as shown in Figure 1.
<<<PAGE=11>>>
Baseline on Performance M&E Culture in the Public Sector in Kenya  October 2019 
 
4 
 
Figure 1: Conceptual Framework 
 
This conceptual relationship implies that demand for evidence-based decisions and the supply 
of evidence for decision-making are interrelated. These two sides of M&E are influenced by the 
organisational M&E culture as well as barriers to the use of M&E evidence. Depending on how 
these factors  interplay, there is either a strong ly or weak ly performing M&E system  in an 
organisation.  
 
Indicators of organis ational culture are more developed in the broader field of organisation 
theory. Specifically, the Competing Values Framework  (CVF) developed by Quinn and 
Rohrbaugh (1981) and refined by Cameron and Quinn (1999) provides a robust model for 
diagnosing organisational culture. This framework has two underlying dimensions: whether an 
organisation has a predominantly internal or external focus, and whether it strives for flexibility 
and individuality or stability and control. The framework is also based on six organis ational 
culture dimensions and four dominant culture types (ie, clan, adhocracy, market, and 
hierarchy). This framework is validated by a lot of research (Denison, 1990; Deshpande & 
Farley, 2004), and is aligned with other dimensions that describe how people behave when 
organising (Linnenluecke, 2010; Cameron & Quinn, 2006).  
 
3. Study Objective 
 
The objective of the study was to establish baseline information on the M&E culture that exists 
within the public sector by identifying the current conditions against which future changes in 
the country’s NIMES and culture could be tracked. Accordingly, the working hypothesis of this 
study was that a culture which has a positive attitude towards change, adaptation and learning 
will develop improved performance M&E systems  which are fully operational . To test this 
hypothesis, the study sought to answer the following four questions:  
Demand for 
Evidence-Based 
Decisions 
Organizational M&E Culture 
Performance of 
M&E System 
Supply of 
Evidence for 
Decision-Making 
Barriers to Use of 
M&E Evidence
<<<PAGE=12>>>
Baseline on Performance M&E Culture in the Public Sector in Kenya  October 2019 
 
5 
 
 
i) Is there endogenous demand for M&E in the Kenyan public sector? 
ii) Is there a sufficient supply of M&E evidence to sustain demand in the Kenyan public 
sector?  
iii) What are the incentives and barriers to the use of M&E evidence in the Kenyan public 
sector? 
iv) What is the dominant performance M&E culture in the Kenyan public sector? 
 
4. Study Methodology 
 
This study was designed as mixed-method research combining both quantitative and 
qualitative strategies. To obtain data, face-to-face interviews and on- line surveys using a 
questionnaire were adopted. The study targeted all public sector organisations: 22 government 
ministries and 47 county governments , as well as sampling from state departments , state 
corporations and county government depart ments. Sampling of respondents was guided by 
the terms of reference (ToR), which required that the study conduct (i) 25 in-depth interviews 
with senior government officials drawn from government ministries, and (ii) 120 online surveys 
with senior government officials drawn from ministries, state departments, or counties that did 
not participate in the in- depth face to face interviews. Selection of the required sample was 
done purposively, taking into consideration the level of implementation of NIMES/CIMES.  
 
A pre-designed instrument was provided by TWENDE MBELE  in collaboration with the M&E 
Directorate (MED) of the State Department of Planning . The instrument comprised a 
questionnaire utilizing a Likert -type scale with 13 sections. The first section focused on basic 
data about the respondents and their organis ation. The last three sections were focused on 
understanding the respondents’ prior knowledge of TWENDE MBELE, their feedback regarding 
the interview and their comments on the interview. The remaining 8 sections addressed the 
core of the study , which centred around the following elements: the M&E institutional 
environment; performance management incentives ; the use of evaluation evidence;  the 
evaluation culture;  value-related barriers ; evaluation system barriers to evaluation use ; the 
information management  system; indicators and targets ; evaluation report sharing ; and 
methods of sharing evaluation reports. The units of observation were the key informants from 
each of the sampled units, who in most cases turned out to be the heads of those units or their 
designees.  
 
Raw data were cleaned up by triangulating responses across the entire questionnaire to rid it 
of any inconsistent responses. This was also done by making cross -references to the 
documents provided as evidence during the interview. Cleaned data were then entered into a
<<<PAGE=13>>>
Baseline on Performance M&E Culture in the Public Sector in Kenya  October 2019 
 
6 
 
database created in CSpro, and  exported to SPSS version 20 for analysis. Quantitative data 
was analysed descriptively using percentages and measures of central tendency, specifically 
mean and mode. Analysed data was presented in tabl es and charts, and was disaggregated 
into three categories representing the units of analysis for this study, namely state departments, 
state corporations, and county governments. Qualitative data w ere analysed by scenario and 
inductive mapping , particularly to determine the prevailing culture within the public sector , 
where responses were mapped onto the dimensions of the CVF. A simple grounded theory 
approach (inductive qualitative analysis) involving content analysis, patterning , and thematic 
analysis was applied to identify common barriers to positive performance M&E within the public 
sector.  
 
The major limitation of this study was the mobilisation of respondents. While the researchers 
managed to conduct 36 in-depth interviews, the online survey yielded only 37 responses after 
persistent follow-up and reminders from the MED. The l iterature review shows that online 
surveys normally have low response rates. For example,  a study by Nulty (2008) 1 compared 
the response rates of  paper-based and online surveys for nine surveys and found that, on 
average, the online survey response rate was 33%, which was 23 points lower than the paper-
based survey. Nigel Lindemann (August 2019), in his study T he accumulated data into one 
number, found that the average survey response rate was 33%. Fluidsurveys.com says that 
the average response rate for email surveys is 24.8%2. In this study, the face-to-face interview 
response rate was 144% (36/25), while the online survey response rate wa s 30.8% (37/120). 
This is generally within established on-line survey study response rates , and therefore the 
observed online response rate of this study was considered acceptable.  
 
5. Study Findings 
5.1 Introduction 
 
The findings are organised into two main areas: supply-side and demand-side, as established 
by the study instrument , and which is similar to a comparable study by CLEAR  (2013). The 
supply-side findings are divided into the following elements: M&E units and  staff; the M&E 
institutional environment ; the information management system ; indicators and targets ; 
evaluation report sharing ; and methods of s haring evaluation reports. The demand side 
focuses on M&E championship in the public sector , and the use of evaluation evidence.  
Barriers to both the supply of and demand for evaluation evidence are dealt with separately. 
                                                           
1 The adequacy of response rates to online and paper surveys: what can be done? Vol. 33, No. 3, 
June 2008, 301–314. 
2 (http://fluidsurveys.com/university/response-rate-statistics-online-surveys-aiming/).
<<<PAGE=14>>>
Baseline on Performance M&E Culture in the Public Sector in Kenya  October 2019 
 
7 
 
Based on these barriers, and the analysis of demand and supply, an organisation’s M&E culture 
is diagnosed.  
 
5.2 Response Rate 
 
This report is based on the findings from in-depth interviews and online surveys conducted with 
a total of 73 respondents drawn from 30 state departments, 6 state corporations, and 37 county 
departments. This represents a response rate of 50.3 % of the total senior  management 
populaton, of whom 51 (69.9%) were male and 22 (30.1%) were female. Of the total 
respondents, 22 (30.1%) had worked in the public sector for over 20 years, 27 (37.0%) for 
between 10 and 19 years, and 24 (32.9%) had worked for a period of fewer than nine years. A 
total of 61 respondents (83.56%) had been in their current posts for a period of  six years or 
less, with 32 (52.5%) of them having been in their current position for three years or less.  
 
In terms of education levels, 67 (91.8%) of the respondents had a master’s level of education 
and above, while six (8.2%) had either an undergraduate degree or a professional qualification. 
With regard to the respondents’ current job levels, 46 (63%) were drawn from senior 
management, with the remaining 27 (37%) coming from mid- level management. Only 14 
(19.2%) of the respondents had heard of the Twende Mbele Project.
<<<PAGE=15>>>
Baseline on Performance M&E Culture in the Public Sector in Kenya  October 2019 
 
8 
 
5.3 The Supply Side of M&E  
5.3.1 The M&E Institutional Environment 
 
In considering the institutional environment for M&E, attention was paid to the existence of 
established M&E units within the public sector, and the organisational commitment to M&E, by 
looking at the position of M&E in the organisational structure, the number of M&E posts in that 
structure, and how many of those posts had been filled. A total of 68 (93.2%) respondents had 
a unit dedicated to M&E. Chart 1 shows that, although 93.2% of the institutions had M&E units, 
the majority (51.5%) of them had fewer than four posts, 30.9% had between four and six posts, 
while 17.6% had been established with seven or more posts in their structure. Of the five 
institutions that had no unit dedicated to M&E , four were county departments. On the other 
hand, four (5.5%) of the surveyed institutions did not have a formal structure for M&E units.  
 
 
Chart 1: Percentage of Institutions with M&E Units, and their Staffing Levels 
 
Chart 2 presents a summary of the vacant pos ts in M&E structure s for the entire number of 
surveyed institutions. As shown in the chart, 17 (23.3%) of the institutions r eported having no 
vacant posts in their M&E units, while 56 (76.7%) had  one or more vacant posts. Of the 30 
state departments surveyed, five (16.7%) had all posts filled, nine (30%) had between one and 
three vacant positions, while 16 (53.3%) had four or more unfilled positions in their M&E units. 
Of the six autonomous government agencies (SAGAs) that were surveyed, one had no vacant 
posts in its M&E unit , four (66.7%) had between one and three vacant posts, while one had 
seven vacant posts. Eleven county gover nment departments , representing 29.7% of the 
surveyed county departments, had all posts filled in their M&E structures,  while 12 (32.4%) of 
the county departments reported having between one and three vacant posts. Fourteen county 
departments, representing 37.8% of the county departments surveyed, reported having four or 
more vacant positions. 
 
Regarding responsibility levels for M&E, 43 (58.9%) of the surveyed institutions reported that 
their M&E units were headed by officers at director level, while the remaining 30 (41.1%) were
<<<PAGE=16>>>
Baseline on Performance M&E Culture in the Public Sector in Kenya  October 2019 
 
9 
 
headed by an official below director level. Of the institutions whose M&E units were headed by 
a director-level officer, 20 (46.5%) were state departments, four (9.3%) were SAGAs, and 19 
(44.2%) were county departments. Of the 30 organisations whose M&E units were headed by 
an officer below the level of director, 10 (33.3%) were state departments, two  (6.67%) were 
SAGAs, and 18 (60%) were county departments.  
 
 
 
Chart 2: Number of Institutions with M&E Vacant Posts 
 
5.3.2 Information Management System  
 
The assessment of the i nformation management system (IMS) capacity of public -sector 
institutions was based on  three dimensions , namely: whether the system integrated all the 
information needed by managers; whether the system considered and integrated the 
information needs of different stakeholders; and, whether the system took into account the 
quality of consultation processes tha t were needed to ensure that the information needs of 
different users were taken into consideration. The study established that the information 
management system integrated most information needed by managers in 32 (43.8%)  of the 
institutions, while in ano ther 32 (43.8%), there was limited integration. Nine  (12.4%) of the 
institutions surveyed reported that their information management systems did not integrate the 
information needed by managers at all. Chart 3 provides a summary of this data.
<<<PAGE=17>>>
Baseline on Performance M&E Culture in the Public Sector in Kenya  October 2019 
 
10 
 
 
Chart 3: Integration of Managers’ Information Needs 
 
On the question of whether the IMS considered and integrated all the information needs of the 
different stakeholders; six (8.2%) of the surveyed institutions reported that this did not happen 
at all ; 29 (39.7%) reported that this practice happened,  but on a limited basis ; another 29 
(39.7%) of the surveyed institutions confirmed that this practice was mostly in place, while 9 
(12.3%) of the institutions reported that this practice was well in place. T able 1 summarises 
these data. 
 
Table 1: Integration of Information Needs of Stakeholders 
 
 
 
As to whether the system took into account the quality of the consultation processes needed 
to ensure that the information needs of different users were taken into consideration, five (6.8%) 
of the surveyed institutions reported that this was not done  at all, while 25 (34.2%) reported 
that this was done to a limited extent. However, this practice was mostly in place in 35 (47.9%) 
of the institutions surveyed, and well in place in seven (9.6%) of them. Table 2 summarises 
these data. 
 
No. % No. % No. % No. %
Not at all 3 10.0 0 0.0 3 8.1 6 8.2
Limited 7 23.3 3 50.0 19 51.4 29 39.7
Mostly in place 16 53.3 2 33.3 11 29.7 29 39.7
Well in place 4 13.3 1 16.7 4 10.8 9 12.3
Don’t Know 0 0.0 0 0.0 0 0.0 0 0.0
Total 30 100.0 6 100.0 37 100.0 73 100.0
State Departments SAGAs County Department Total
Does IMS integrate information needs of different stakeholders?
Response
<<<PAGE=18>>>
Baseline on Performance M&E Culture in the Public Sector in Kenya  October 2019 
 
11 
 
Table 2: System Consideration of Quality of Consultation Processes 
 
 
 
5.3.3 The Practice When Departmental Performance is Below Expectation   
 
The survey established that 66 (90.4%) of the institutions surveyed had their performance 
expectations and individual performance agreements linked. However, this was not the practice 
in three of the state departments and four  of the county departments surveyed. In 
circumstances where either individual or departmental performance was below expectation, 
five (6.8%) of the institutions surveyed indicated that their reports were structured to hide 
information, while 38 (52.1%) of the institutions indicated that reports were rarely structured to 
conceal poor performance (with 34.2% also reporting, 'never') . Interestingly, in five  (6.8%) of 
the institutions surveyed, respondents did not know whether reports were structured to hide 
information on performance that was below expectation. Their argument was that M&E reports 
were escalated upwards within the institutional hierarchy and they could not tell whether senior 
officials further up the ladder actually reported in accordance with this information. These data 
are summarised in Table 3. 
 
No. % No. % No. % No. %
Not at all 2 6.7 0 0.0 3 8.1 5 6.8
Limited 10 33.3 1 16.7 14 37.8 25 34.2
Mostly in place 15 50.0 4 66.7 16 43.2 35 47.9
Well in place 3 10.0 1 16.7 3 8.1 7 9.6
Don’t Know 0 0.0 0 0.0 1 2.7 1 1.4
Total 30 100.0 6 100.0 37 100.0 73 100.0
Response
State Departments SAGAs County Department Total
Does IMS consider quality of consultation processes needed to ensure that information 
needs of different users are taken into consideration?
<<<PAGE=19>>>
Baseline on Performance M&E Culture in the Public Sector in Kenya  October 2019 
 
12 
 
Table 3: Structuring Reports in Situations of Underperformance 
 
 
 
In 27 (37%) of the institutions surveyed, results would never be ignored when departmental 
performance was below expectation. However, in 35 (47.9%) of the institutions surveyed, such 
practices happened, though rarely. Eight (11%) of the institutions surveyed reported that this 
practice often happened, while two  institutions reported that this practice always happened. 
Table 4 summaris es these data. Other practices identified when performance was below 
expectation are summaris ed in Chart 4. Generally, whenever performance was below 
expectation, most institutions surveyed would either rarely or never sanction the responsible 
officials, and managers would also rarely or never reject the accuracy of poor results. In most 
cases, learning and changes would be documented and used to improve future results. 
Furthermore, in most institutions, the responsible officials would be required to expl ain and 
identify how results could be improved. 
 
Table 4: Responses to Whether Below-Expectation Performance was Ignored 
 
 
 
Number Percent Number Percent Number Percent Number Percent
Never 12 40.0 4 66.7 9 24.3 25 34.2
Rarely 15 50.0 2 33.3 21 56.8 38 52.1
Often 1 3.3 0 0.0 4 10.8 5 6.8
Always 0 0.0 0 0.0 0 0.0 0 0.0
Don’t Know 2 6.7 0 0.0 3 8.1 5 6.8
Total 30 100.0 6 100.0 37 100.0 73 100.0
   Reports structured to hide the information
State Departments SAG As County Department TotalResponse
Number Percent Number Percent Number Percent Number Percent
Never 15 50.0 4 66.7 8 21.6 27 37.0
Rarely 12 40.0 2 33.3 21 56.8 35 47.9
Often 2 6.7 0 0.0 6 16.2 8 11.0
Always 1 3.3 0 0.0 1 2.7 2 2.7
Don’t Know 0 0.0 0 0.0 1 2.7 1 1.4
Total 30 100.0 6 100.0 37 100.0 73 100.0
Response State Departments SAG As County Department Total
   Results ignored
<<<PAGE=20>>>
Baseline on Performance M&E Culture in the Public Sector in Kenya  October 2019 
 
13 
 
 
Chart 4: Other practices when performance is below expectation  
 
5.3.4 The Practice When Departmental Performance is Above Expectation 
 
In cases w hen the departmental performance was above expectation, the study established 
that learning was either rarely or never documented and shared internally and externally in 25 
(34.2%) of the surveyed institutions  (of which 16 were county departments while nine  were 
state departments). However, in 48 (65.8%) institutions, learning was either often or always 
documented and then shared internally and externally. This practice was reported in 21 (70%) 
state departments, all SAGAs, and 21 (56.8%) county departments. The study also established 
that in 31 (42.5%) institutions, senior managers took personal credit without acknowledging 
their team whenever performance was above expectation. This  practice was reported in 11 
(36.7%) state departments, two (33.3%) SAGAs, and 18 (48.6%) county departments.  
 
Only 24 (32.9%) of the institutions surveyed would reward the official responsible for 
performance that was above expectation. This practice was reported in 8 (26.7%) state 
departments, 4 (66.7%) SAGAs, and 12 (32.4%) county departments. On the other hand , 48 
(65.7%) institutions comprising 22 (73.3%) state departments, 24 (64.9%) county departments, 
and 2 (33.3%) SAGAs, either rarely or never rewarded officers responsible for performance 
that was above expectation.  
 
The study showed that in 50 (68.5%) of the surveyed institutions, lessons learnt with respect 
to performance that was above expectation would be documented. This prac tice was either 
often or always the case in 19 (63.3%) state departments, all SAGAs and 25 (67.6%) county 
departments. However, in 22 (30.1%) of the surveyed institutions, lessons learnt were either 
never or rarely documented, with 10 (33.3%) state departm ents, one (16.7%) SAGA, and 11 
(29.7%) county departments reporting this to be the case.
<<<PAGE=21>>>
Baseline on Performance M&E Culture in the Public Sector in Kenya  October 2019 
 
14 
 
In 42 (57.6%) of the surveyed institutions, officers responsible for performance that was above 
expectation would either rarely or never be highly regarded in the department. Twenty-two 
(73.3%) state departments and 18 (48.6%) county departments reported t his practice. 
However, in 29 (39.7%) of the surveyed institutions representing eight  (26.7%) state 
departments, four (66.7%) SAGAs and 17 (45.9%) county departments, officers responsible 
for performance that was above expectation would either often or always be highly regarded in 
the department.  
 
In 26 (35.6%) surveyed institutions representing eight (26.7%) state departments, two (33.3%) 
SAGAs and 16 (43.2%) county departments, performance results that were above expectation 
would either rarely or never be discussed by the M&E unit to identify the causes. On the other 
hand, those results would often or always be discussed in 46 (63.1%) of the surveyed 
institutions, representing 22 (73.3%)  state departments, four (66.7%) SAGAs, and 20 (54%) 
county departments. Chart 5 summarises these data. 
 
 
Chart 5: Practices when Performance is Above Expectation  
 
5.3.5 Dissemination of Evaluation Reports 
 
Dissemination is critical for the widespread supply of evaluation evidence. As shown in Chart 
6, the most commonly reported method of sharing reports was “community meetings”, with 61 
(83.6%) of the institutions surveyed indicating their use. The proportion of institutions using this 
method appeared to be the same across state departments (83%) , SAGAs (83%) and county 
departments (83%). The second- most commonly used method was “websites”, which 56 
(76.7%) of the institutions indicated they used. Twenty-two (73.3%) state departments, five  
(83.3%) SAGAs and 29 (78.4%) county departments reported th at they used this method to 
disseminate M&E reports. The least commonly used methods were “ academic journals” 
(15.1%) and “conference papers” (34.2%). The results of the study showed that only eight
<<<PAGE=22>>>
Baseline on Performance M&E Culture in the Public Sector in Kenya  October 2019 
 
15 
 
(26.7%) state departments and 3 (50%) SAGAs reported using academic journals, while no 
county department s used them. Fourteen (46.7%) state departments, all SAGAs and five 
(13.5%) county departments reported that they used conference papers to disseminate their 
M&E reports. Chart six summarises the results of how evaluation reporst are shared. 
 
 
Chart 6: Methods of Sharing Evaluation Reports 
 
5.4 The Demand Side of M&E  
5.4.1 Introduction 
 
This section presents the findings of the study on M&E demand along three dimensions  that 
are derived from the survey tool,  namely: M&E championship within the public sector ; 
performance management incentives; and use of M&E evidence.  
 
5.4.2 M&E Championship in the Public Sector 
 
M&E championship determines the ability of M&E units to affect demand for (and therefore, 
supply of) evidence for decision-making, and whether that evidence is used to inform decision-
making. At the national level, an M&E unit is established as a directorate within the National 
Treasury in the State Department of Planning. Within the government line ministries, state
<<<PAGE=23>>>
Baseline on Performance M&E Culture in the Public Sector in Kenya  October 2019 
 
16 
 
corporations and county governments, M&E units are located  in departments of planning and 
mostly headed by economists who are employed at various levels of management. Some work 
at director level, while others are positioned below director level. Generally, the higher in the 
organisational hierarchy, the champion is, the greater their influence on resource allocation for 
evaluations and implementation of evidence-based decisions.  
From the findings of this study, 43 (58.9%) of the surveyed institutions reported that their M&E 
units were headed by officers at director level, while the remaining 30 (41.1%) were headed by 
an official below director level. Of the institutions whose M&E units were headed by a director-
level officer, 20 (46.5%) were state departments, four (9.3%) were SAGAs and  19 (44.2%) 
were county departments. Of the 30 organisations whose M&E units were headed by an officer 
below the level of director, 10 (33.3%) were state departments, two (6.67%) were SAGAs, while 
18 (60%) were county departments.  
 
5.4.3 Performance Management Incentives 
 
All surveyed institutions had strategic plans (even though some  had expired and others were 
in draft form). Generally, strategic plans contained implementation frameworks with indicators 
and annual targets. In 27 (90%) state departments, six (100%) SAGAs, and 35 (94.6%) county 
departments, indicators and targets were integrated into annual performance plans to measure 
and monitor performance. In all the institutions, both departmental and individual work plans 
were present, and were drawn from, and linked to, the strategic plan.  
 
On the question of performance management incentives, this study looked at aspects of 
“reward and punishment ” for achieving results above and below expectation. Most of the 
institutions surveyed reported that over-achievement with regard to targets was rare as a result 
of persistent budget cuts from the government that constantly led to the downward revision of 
annual targets. Some of the “punishment” mechanisms cited as being used by the institutions 
surveyed included warning letters, putting staff on performance improvement plans, and where 
performance still did not improve, separation. “Reward” mechanisms that were cited included 
letters of commendation, promotions, some form of bonus payment for excellent performance, 
annual parties for staff, and departmental recognition events. 
 
The study showed that in circumstances where performance was below expectation, most 
institutions (60.3%) would either never or rarely sanction the officers responsible. This practice 
was reported in 18 (60%) stat e departments, four (66.7%) SAGAs, and 22 (59.5%) county 
departments. However, in 80.8% of the surveyed institutions, officers responsible for 
underperformance would be given an opportunity to explain and identify how results could be 
improved. This practice was reported in 28 (93.3%) state departments, all SAGAs, and 25 
(67.6%) county departments.
<<<PAGE=24>>>
Baseline on Performance M&E Culture in the Public Sector in Kenya  October 2019 
 
17 
 
In cases where performance was above expectation, 31 (42.5%) of the institutions surveyed,  
representing 11 (36.7%) state departments, two  (33.3%) SAGAs, and 18 (48.6%) county 
departments, reported that senior managers either often or always took personal credit without 
acknowledging their team. This could probably explain why 65.7% of the institutions surveyed 
reported that officers responsible for performance above expectation were either never or were 
rarely likely to be rewarded. This was the practice in 22 (73.3%) state departments, two (33.3%) 
SAGAs, and 24 (64.9%) county departments. Further, 57.6% of the institutions surveyed,  
representing 22 (73.3%) state departments, two  (33.3%) SAGAs , and 18 (48.6%) county 
departments, reported that such officers would be either never or rarely highly regarded in the 
department. Interestingly, in both cases of under - or over-performance, a majority (65.8%) of 
the institutions documented and shared lessons internally and externally  through their annual 
reports and in their strategic plans. Chart 7 summarises these practices. 
 
 
Chart 7: Performance Management Incentives 
 
The public sector in Kenya has institutionalised performance contracting, where each institution 
negotiates its annual targets with the government’s performance contracting agency and 
cascades the negotiated targets to its individual departments. Negotiated targets are informed 
by the institutions’ strategic plans, but it is not uncommon for such targets to be varied based 
on ad hoc presidential directives or changing government policy. Thus, the achievement of 
institutional objectives and agreed targets is largely moderated by the performance contracting 
environment and government policy.  
 
5.4.4 Use of Evaluation Evidence 
 
Evidence has been described in the literature as “ what constitutes actual or asserted facts 
planned for use in support of a conclusion”  (Kothari, Boyko, & Campbell-Davison, 2015). In 
Section 2.0, it has been argued that, when decision-makers use evidence from M&E systems 
in making decisions, a demand for M&E is generated. The demand for M&E then calls for the
<<<PAGE=25>>>
Baseline on Performance M&E Culture in the Public Sector in Kenya  October 2019 
 
18 
 
supply of M&E. The focus in evidence-policy-making is to determine the extent to which policies 
are informed by evidence, which in turn is influenced by (i) a demand for evidence by policy -
makers; (ii) a  good supply of quality evidence;  (iii) contextually-relevant research being 
available to policy-makers; and (iii), connections being established between researchers and 
policy-makers. 
 
The baseline survey sought to establish from respondents whether , and when,  evaluation 
evidence is used. A total of 63 (86.3%) institutions reported us ing evaluation evidence:  29 
(96.7%) state departments, six (100%) SAGAs, and 28 (75.7%) county departments. Of the 10 
(13.7%) institutions which reported that they did not use evaluation evidence, one (3.3%) was 
a state department, while nine (24.3%) were county departments. Of the institutions that used 
evaluation evidence, 44 (69.8%) used it throughout the entire programme or project life cycle, 
i.e., throughout the planning, designing and implementation phases. However, 19 (30.2%) of 
the institutions using M&E evidence indicated that they used it only once an evaluation had 
been completed. Table 5 summarises these data. 
 
Table 5: When Evaluation Evidence is Used 
 
 
 
As Chart 8  shows, evaluation evidence was mostly used to improve the understanding of 
interventions, and to enhance the value derived from the participation of stakeholders in the 
planning and implementation of evaluations. A relatively large percentage (30.2%) of the 
institutions that used evaluation evidence indicated tha t they either never or rarely  used it to 
make changes to policies.  
 
Number Percent Number Percent Number Percent Number Percent
Throughout planning designing and 
implementation of programmes and projects 21 72.4 6 100.0 17 60.7 44 69.8
Once evaluation is completed 8 27.6 0 0.0 11 39.3 19 30.2
Total 29 100.0 6 100.0 28 100.0 63 100.0
Those using State Departments SAG As County Department Total
<<<PAGE=26>>>
Baseline on Performance M&E Culture in the Public Sector in Kenya  October 2019 
 
19 
 
 
Chart 8: Actual use of Evaluation Evidence 
 
Interestingly, when a comparison was made between the frequency of use of internal 
evaluation evidence and the use of external evidence from other departments or stakeholders, 
the results of the study showed that more institutions used evaluation recommendations from 
other departments or stakeholders than from internal sources. In other words, the rarity of 
evidence use across all the four stipulated uses decreased with the use of external evaluation 
evidence. What was striking was that irrespective of whether evaluation recommendations 
were from internal or external sources, most institutions reported using it either often or always 
to improve their understanding of interventions. Further, the data showed that in either case, 
fewer institutions would often or always use the data for making changes to  policies. Table 6 
summarises these data. 
 
Table 6: Use of Internal and External Evaluation Recommendations  
 
 
 
Never or Rarely Often or Always Never or Rarely Often or Always
Make changes in the policies 30.20% 71.40% 23.80% 76.20%
Improve understanding of intervention 17.50% 82.50% 15.90% 84.10%
Give legitimacy to a course of action taken 27% 73% 17.50% 82.50%
Enhance value derived from stakeholders' participation 
Use of Evaluation Evidence
19.00%
External Evaluation Recommendations
Percentage of Institutions That Use 
81.00%
 Internal Evaluation Recommendations:
20.60% 79.40%
<<<PAGE=27>>>
Baseline on Performance M&E Culture in the Public Sector in Kenya  October 2019 
 
20 
 
5.5 Barriers to the Use and Supply of Evaluation Evidence 
5.5.1 Introduction 
 
The conceptual model presented in Figure 1 identified barriers to the use of evaluation 
evidence as one of the variables that affect the performance of M&E systems. This section 
describes the major barriers to the effective use of evaluation evidence in decision- making, 
learning and accountability. These barriers are discussed under two categories, namely value-
related and system-related barriers.  
 
5.5.2 Value-Related Barriers 
 
The study assessed value-related barriers to evaluation using a 10-item Likert-type scale that 
sought to establish how frequently public-sector institutions experienced specific barriers. The 
results showed that in the majority (54.8%) of institutions surveyed, M&E was seen as policing 
and a way of controlling staff. This barrier was more likely to be experienced in county and 
state departments than in SAGAs. In 49.3% of the surveyed institutions, M&E was regarded as 
the job of the M&E unit and not of all managers. Again, this barrier was more likely to be 
experienced in county and state departments than in SAGAs. The third most experienced 
value-related barrier was a fear of admitting mistakes or problems, which affected the reporting 
of any performance that was below expectation,  and discouraged innovative ways of solving 
problems. More of the county and state departments experienced this barrier than SAGAs. 
Table 7 summarises these data.
<<<PAGE=28>>>
Baseline on Performance M&E Culture in the Public Sector in Kenya  October 2019 
 
21 
 
Table 7: Value-Related Barriers to the Use of Evaluation Evidence 
 
Major barriers to the effective use of 
evaluation in decision-making, learning 
and accountability  
 
Number of Institutions Experiencing a Barrier Often or Always 
State Departments SAGAs County Departments Total 
Problems are concealed 8 26.7% 1 16.7% 10 27.0% 19 26.0% 
Resistance from senior management to 
transparent decision-making processes 6 20.0% 1 16.7% 8 21.6% 15 20.5% 
Little respect for evidence-based 
decision-making in the department 6 20.0% 1 16.7% 13 35.1% 20 27.4% 
The hierarchy makes it difficult to openly 
and robustly discuss performance 12 40.0% 3 50.0% 9 24.3% 24 32.9% 
Fear of admitting mistakes or problems 14 46.7% 2 33.3% 16 43.2% 32 43.8% 
The M&E unit has little influence in the 
department 10 33.3% 0 0.0% 18 48.6% 28 38.4% 
M&E is seen as policing and a way of 
controlling staff 16 53.3% 3 50.0% 21 56.8% 40 54.8% 
M&E is regarded as the job of the M&E 
unit and not of all managers 12 40.0% 1 16.7% 23 62.2% 36 49.3% 
Senior management do not champion 
M&E and there is no honesty about 
performance 
7 23.3% 1 16.7% 9 24.3% 17 23.3% 
Problems not treated as an opportunity 
for learning and improvement 7 23.3% 1 16.7% 15 40.5% 23 31.5% 
 
5.5.3 System-Related Barriers 
 
Systemic barriers to the use and supply of evaluation evidence were assessed using a 9-item 
Likert-type scale that was designed to establish how often specific system-related barriers were 
experienced within the public sector.  The findings of this study showed that most (79.5%) of 
the institutions surveyed either often or always experienced a barrier occasioned by too few 
financial resources allocated to evaluation. This barrier was experienced by 26 ( 86.7%) state 
departments, five (83.3%) SAGAs, and 27 (73%) county departments. The second most cited 
barrier was weak departmental capacity for conducting evaluations, implying that evaluations 
were conducted by external consultants. At least 66.7%, 83.3% and 48.6%, of state 
departments, SAGAs, and county departments, respectively, experienced this barrier. In 42 
(57.5%) of the institutions surveyed, evaluation was more of a process, focusing on activities 
and outputs rather than outcomes and impact. This barrier was reported by 53.3%, 66.7%, and 
49.6%, of state departments, SAGAs and county departments, respectively.  Table 8 presents 
data on the systemic barriers.
<<<PAGE=29>>>
Baseline on Performance M&E Culture in the Public Sector in Kenya  October 2019 
 
22 
 
Table 8: Systemic Barriers to the Use and Supply of Evaluation Evidence 
 
Description of Barrier 
Number of Institutions Reporting a Barrier Often or Always 
State 
Departments SAGAs County 
Departments Total 
Evaluation is not undertaken as a systematic 
research process 14 (46.7%) 4 (66.7%) 19 (51.4%) 37 (50.7%) 
Time pressure means decisions are often taken 
without proper diagnosis of the problem 16 (53.3%) 3 (50.0%) 20 (54.1%) 39 (53.4%) 
Capacity to conduct evaluation within the 
department is weak and evaluations are 
conducted by external consultants 
20 (66.7%) 5 (83.3%) 18 (48.6%) 43 (58.9%) 
There are inadequate mechanisms for 
implementing evaluation recommendations (for 
example, management improvement plan) 
17 (56.7%) 2 (33.3%) 19 (51.4%) 38 (52.1%) 
Managers do not have the skills to understand 
and use evaluation recommendations 9 (30.0%) 3 (50.0%) 8 (21.6%) 20 (27.4%) 
Focus will stay on activities and outputs rather 
than outcomes and impact 16 (53.3%) 4 (66.7%) 22 (49.6%) 42 (57.5%) 
Concerns about ‘unhelpful’ conclusions about 
policies’ effectiveness 9 (30.0%) 1 (16.7%) 11 (29.7) 21 (27.450 
There is no consistent demand for evaluation 
from ministers and management 10 (33.3%) 0 (0.0%) 18 (48.6%) 28 (38.4%) 
Too few financial resources allocated to 
evaluation 26 (86.7%) 5 (83.3%) 27 (73.0%) 58 (79.5%) 
 
5.5.4 Synthesis of Performance M&E Culture 
 
Performance M&E culture was assessed along the four dimensions of the Competing Values 
Framework. Specific items in the questionnaire were mapped onto the sub- dimensions of the 
CVF, as detailed in the Organis ational Culture Assessm ent Instrument (OCAI) (Cameron & 
Quinn,1999). Scores for each sub- dimension were determined based on the average scores 
assigned by the respondents. Using these scores, the OCAI was filled in online. This process 
was repeated,  based on the desired  ('preferred') scores premised on the study’s theory  of 
change. The results are presented in Table 9 and Chart 9 below. Taking the region shaded in 
pink to represent the current situation,  and the region shaded blue to represent the preferred 
culture, the chart shows that, currently, the performance M&E culture in Kenya has a blend of 
doing things together (collaborative or clan culture), doing new things (adhocratic  or creating 
culture), doing things fast (competition culture), and doing things right  (control or hierarchy 
culture). However, the envisaged theory of change envisions a greater focus on doing new 
things (adhocracy) blended with doing things right . Thus, the existing practice  needs to be 
adjusted to fully support a culture which looks positively  towards change, adaptation and 
learning. In other words, M&E practice requires that there should be a de-emphasising of some
<<<PAGE=30>>>
Baseline on Performance M&E Culture in the Public Sector in Kenya  October 2019 
 
23 
 
aspects of clan and market culture that currently stand in  the way of enhanced adhocracy 
blended with  hierarchy. 
 
Table 9: OCAI Scores 
 
Culture Profile 
Scores 
NOW PREFERRED 
CLAN 24.83 21.67 
ADHOCRACY 30.17 34.17 
MARKET 23.67 21.67 
HIERARCHY 21.33 22.50 
 
 
Chart 9: Current and Preferred Culture
<<<PAGE=31>>>
Baseline on Performance M&E Culture in the Public Sector in Kenya  October 2019 
 
24 
 
6. Conclusions and Recommendations 
6.1 Conclusions  
Is there endogenous demand for M&E in the Kenyan public sector? 
The study showed that endogenous demand for M&E within the public sector is driven by 
several articles in the Constitution of Kenya 2010 which that a structured way of monitoring 
policies, programmes and projects  is needed.  Furthermore, the County Governments Act, 
2012, and the Public Finance Management Act, 2012,  require clear county planning and 
monitoring systems. Within the public sector, the Monitoring and Evaluation Directorate works 
to strengthen evidence-based policy formulation and to improve on the tracking of results. To 
achieve this, the directorate works with various CPPMUs at both levels of government. Almost 
all institutions surveyed had a unit dedicated to M&E. Most of these units were headed by 
officers at senior management level within the government. This is an important condition for 
ensuring endogenous demand, since it guarantees championship high up in the organisational 
structure. However, in the public sector, accountability for performance and resource allocation 
decisions is vested in the offices of either the principal or cabinet secretaries, a good proportion 
of whom were reported to not provide a consistent demand for evaluation. As a result, too few 
resources were allocated to evaluation.  
Furthermore, erratic changes in government policy, and political dynamics, increased the time 
pressures on responsible officers, who had to take decisions without a proper diagnosis of the 
problems being dealt with. M&E championship was also weighed down by the current practice, 
which focuses on activities and outputs rather than on outcomes. Another factor that weighed 
down on the championing of M&E is the fact that the majority of institutions surveyed saw M&E 
as a form of policing and a way of controlling staff, and as the job of the M&E unit and not of 
all managers.  
Generally, strategic plans contained implementation frameworks with indicators and targets. 
Furthermore, indicators and targets were integrated into annual performance plans to measure 
and monitor performance. However, overachievement of those targets was rare as a result of 
persistent budget cuts by the government, which consistently led to the downward re vision of 
annual targets. On the question of “incentives” in circumstances where performance was either 
above or below expectation, the study did not establish a conclusive practice across the public 
sector. Even though a number of “ reward and punishment” mechanisms were cited as being 
used by the institutions surveyed, there was no clear approach to administering those 
mechanisms.  
The majority of the institutions surveyed used evaluation evidence, with most of them using it 
throughout the programme life cycle. Internally-generated evaluation evidence was used more 
to improve the understanding of interventions and to enhance the value derived from 
stakeholders’ participation in the planning and implementation of evaluation, than to make 
changes to policies. The results of the study showed that more institutions used evaluation
<<<PAGE=32>>>
Baseline on Performance M&E Culture in the Public Sector in Kenya  October 2019 
 
25 
 
recommendations from other departments or stakeholders than from internal sources. In other 
words, the number of institutions reporting the use of external evaluation evidence was 
consistently higher than those reporting the use of internal evidence for the same purposes. A 
striking result was that irrespective of whether evaluation recommendations were from internal 
or external sources, most institutions reported using it either often or always to improve their 
understanding of interventions. Further more, the results showed that in either case, fewer 
institutions would often or always use the data for making changes to policies. This finding may 
point towards a weak link between evaluation evidence and policy change.  
Is there a sufficient supply of M&E evidence to sustain demand? 
 
The results of this study sh owed that a majority of the surveyed institutions had units in their 
structures dedicated to M&E. Most of these units had less than seven posts, with over 70% of 
the institutions indicating a number of vacancies in their M&E units. Even though the study did 
not delve into the reasons for vacant posts, inadequate financial allocations to M&E units or a 
shortage of suitable personnel to fill these posts could be probable explanations. On another 
front, over 50% of the institut ions surveyed indicated that their performance information 
management systems either rarely or never integrated most of the information needed by 
managers. Interestingly, the results of this study showed that more institutions had their 
information management systems consider and integrate all the information needs of different 
stakeholders. This practice implies that the output from the system is not what managers 
require to make decisions , or that the decisions made using such information are not fully 
supported. 
 
Although the practice of structuring reports to hide or ignore information when performance is 
below expectation was largely reported as being rare, the fact that it could happen means that 
the affected evaluation reports did not contain accurate information, and therefore decisions 
made based on those reports were bound not to be useful. Generally, whenever performance 
was below expectation, most institutions surveyed would either rarely or never sanction the 
responsible official. The argument  advanced for this practice was that targets are usually 
departmental, and attributing non-achievement to an individual may be difficult. On the other 
hand, fewer than one- third of the institutions surveyed would either reward or regard highly 
those staff members who were responsible for performance that was above expectation. This 
is compounded by the fact that in over 40% of the institutions, senior managers took personal 
credit, without acknowledging their team , whenever performance was above expectation. I n 
over 30% of the institutions that performed above expectation, learning was either rarely or 
never documented and shared internally and externally. This practice denies follow -on 
programmes the opportunity to innovate based on past lessons. 
 
 
The main methods used to disseminate M&E information were community meetings and 
websites, while the least commonly used methods were academic journals and conference
<<<PAGE=33>>>
Baseline on Performance M&E Culture in the Public Sector in Kenya  October 2019 
 
26 
 
papers. The dissemination of evidence using academic journals and conference papers is more 
targeted and interactive, since these mediums are generally subjected to rigorous peer review 
mechanisms and benefit from a well-structured and scientific feedback process. Thus, they 
provide a robust channel for disseminating scientific information that is intended  to inform 
decision-making. 
 
On average, the results indicated a relatively weak supply -side, with the following 
consequences: most institutions did not undertake evaluation as a systematic research 
process; most institutions had weak internal capacity to conduct evaluation, so that evaluations 
were conducted by external consultants ; and, most institutions focused on activities and 
outputs rather than outcomes and impact. This implies that most institutions carried out more 
of a monitoring and process evaluation as opposed to an outcome and impact evaluation . It 
also implies that most institutions had too few financial resources allocated to evaluation, and 
that more than one-third of the institutions did not see problems as an opportunity for learning 
and improvement.  
 
What are the barriers to the use and supply of evaluation evidence in the public sector? 
 
Barriers to the use of evaluation evidence were assessed and analys ed in two categories, 
namely value-related and system-related barriers. The six most cited barriers , in descending 
order of frequency of citation, were: 
 
Barrier Description % 
Too few financial resources allocated to evaluation 79.5% 
Capacity to conduct evaluation within the department is weak, and evaluations are conducted by 
external consultants 
58.9% 
Focus will stay on activities and outputs rather than outcomes and impact 57.5% 
M&E is seen as policing and a way of controlling staff 54.8% 
Time pressure means decisions are often taken without proper diagnosis of the problem 53.4% 
Evaluation is not undertaken as a systematic research process 50.7% 
 
In terms of frequency weighting, the results indicated that the supply and use of evaluation 
evidence was more weighed down by systemic barriers than by value-related barriers.  
 
What is the dominant performance M&E culture in the Kenyan public sector? 
 
The results showed that the current performance M&E culture had a blend of doing things 
together (collaborative or clan culture), doing new things (adhocratic or creating culture), doing 
things fast (competition culture), and doing things right (control or hierarchy culture). However, 
the working hypothesis envisioned a greater focus on doing new things (adhocracy) blended 
with doing things right. As such, the working hypothesis was not fully supported. Going forward,
<<<PAGE=34>>>
Baseline on Performance M&E Culture in the Public Sector in Kenya  October 2019 
 
27 
 
the M&E system in the public sector would need to g reatly de- emphasise the clan or 
collaborative culture, g reatly emphasise the adhocracy or creating culture, s lightly de -
emphasise the market or competing culture, and s lightly emphasise the stability or control 
culture. 
 
6.2 Recommendations 
 
i. Create and enhance s trong championship as a key driver  for endogenous demand for 
M&E through: 
  
 Domiciling the M&E function in the p residency to influence enhanced resource 
allocation and the use of evidence for changing policies. This is in line with practices 
in Benin, Ghana, South Africa and Uganda (CLEAR, 2012). At the state department, 
state corporation and county levels, domicile the M&E function in the offices of  
cabinet secretaries, managing directors, and governors, respectively.  
 
 Transforming MED into an independent a uthority that coordinates the appraisal, 
planning, and execution of monitoring and evaluation across the public sector. In this 
way, ad hoc budget cuts, political influence in resource allocation,  and the 
discretionary use of evaluation evidence could be minimised. 
 
ii. Increase the understanding, acceptance, standardis ation and performance of the M&E 
function in the public sector through the deliberate application of a policy framework that 
promotes incentives for the use of M&E evidence , as well as M&E capacity 
strengthening, mainstreaming , and institutionalisation. This will help to address the 
systemic and value-related barriers that currently adversely affect the use of, supply of, 
and demand for, M&E evidence.
<<<PAGE=35>>>
Baseline on Performance M&E Culture in the Public Sector in Kenya  October 2019 
 
28 
 
Appendix 1: References 
 
Bemelmans-Videc, M.L., Rist, R.C., & Vedung, E. (2003), Carrots, sticks, and sermons: Policy 
 instruments and their evaluation. New Brunswick: Transaction 
Cameron, K., & Quinn, R. (2006). Organizational Culture Assessment Instrument (OCAI). USA: 
 University of Michigan. 
Center for Learning on Evaluation and Results (CLEAR). (2012). African Monitoring and Evaluation 
Systems: Collaborative Reflection and Learning Amongst Peers. Workshop Report. Pretoria, 
South Africa. 
Denison, D.R. (1990). Wiley Series on Organizational Assessment and Change. Corporate 
 Culture and Organizational Effectiveness. Oxford, England: John Wiley & Sons. 
Deshpande, R., & Farley, U.J. (2004). Organizational Culture, Market Orientation, 
 Innovativeness, and Firm Performance: An International Research Odyssey. International 
 Journal of Research in Marketing, 21(1), 3-22. 
Kusek, J.Z., & Rist, R.C. (2004). Ten Steps to a Results-Based Monitoring and Evaluation 
 System., NY: IBRD/World Bank. 
Lindemann, N. (August 8,2019). What is the average Survey response rate? 
 https://surveyanyplace.com/average-survey-response-rate/ 
Linnenluecke, M.K. (2010). Corporate Sustainability and Organizational Culture. Journal of World 
 Business, 45(4),357-366. 
Mackay, K. (2007). How to Build M&E Systems to Support Better Government.  
 Independent Evaluation Group, World Bank, Washington DC. 
 http://www.worldbank.org/ieg/ecd/docs/How_to_build_ME_gov.pdf 
Mayne, J. (2008). Building an Evaluative Culture for Effective Evaluation and Results 
 Management. ILAC Working Paper 8. Rome, Italy: Biodiversity International. 
Nulty, D.D. (2008). The adequacy of response rates to online and paper surveys: what can be 
 done? Vol. 33, No. 3, 301–314. 
Quinn, E.R., & Rohrbaugh, J. (1981). A Competing Values Approach to Organizational 
 Effectiveness. Public Productivity Review, 5(2), 122-140. 
Philips, S. (2018). Diagnostic on the Supply and Demand of evaluators in South Africa: Diagnostic 
 Report. Twende Mbele: Using M&E to improve performance and accountability of African 
 governments. 
Plaatjies, D. and Porter, S. (2011), ‘Delivering on the Promise of Performance Monitoring and 
 Evaluation ‘, in Daniel Plaatjies (ed.), The Future Inheritance: Building State Capacity in 
 Democratic South Africa. Johannesburg: Jacana. 
World Bank (IEG). (2014). The Changing Landscape of Development Evaluation Training: A Rapid 
 Review