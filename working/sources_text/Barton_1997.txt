<<<PAGE=1>>>
CARE - Uganda 
 
 
Guidelines to Monitoring 
and Evaluation 
 
How are we doing? 
 
 
 
By: Tom Barton 
CRC 
 
 
 
Contacts:  
Nick Ritchie, Country Director 
Geoffrey Chege, Assistant Country Director 
CARE International in Uganda
<<<PAGE=2>>>
These guidelines were produced by the  
Monitoring and Evaluation Task Force of 
CARE International in Uganda 
17 Mackinnon Road, Nakasero 
P.O. Box 7280 
Kampala, Uganda 
 
Contacts:  
Nick Ritchie, Country Director 
Geoffrey Chege, Assistant Country Director 
 
 
Written by consultant 
Tom Barton 
Creative Research & Evaluation Centre 
P.O. Box 21175 
Kampala, Uganda 
e-mail < crc@crc.uu.imul.com > 
 
 
January 1997 
 
 
 
 
Reproduced for wider dissemination by  
Jim Rugh, Program Design, Monitoring and Evaluation Coordinator 
Program Assessment and Development (PAD) / Program Division 
CARE-USA 
151 Ellis Street NE 
Atlanta, GA 30303, USA 
e-mail < rugh@care.org >
<<<PAGE=3>>>
CARE M&E Guidelines 1 
Contents 
TABLE OF CONTENTS 
 
Table of Contents ........................................................................................................ 1 
Endorsement ................................................................................................................ 2  
Preface .......................................................................................................................... 3 
Foreword ...................................................................................................................... 4   
Acknowledgements ...................................................................................................... 5 
Introduction ................................................................................................................. 6 
1.  Why is information importan t to projects?  ....................................................... 9 
2.  Who needs information about CARE projects?  ............................................... 12 
      What information is needed and why?  
3.  What are some of the common strengths and weaknesses of information 
gathering, analysis, and use in development projects? ................................ 21  
4.  What key concepts are fundamental  to understanding and planning for 
information management? .................................................................................... 25 
5.  What needs to be included in projec t planning in order to have the desired 
information available at the right time in usable form? .................................... 51   
6.  Indicators - what do we (or the users) specifically want to know about projects? 
..................................................................................................................................57 
7.  Sources - where can we find the information we need? ..................................... 67 
      Sampling - how can we be sure information is representative? 
8.  Methods for gathering information - how to obtain the information desired?  81 
9.  Analysis methods - how to understand and give meaning to raw 
data/information? ............................................................................................95 
10.  And then what? - presentation of findings and ensuring action .....................103 
11.  Issues affecting internal project planning and operations related to M&E ..113 
ANNEXES  
1.  Glossary ........................................................................................................119 
2.  Abbreviations (acronyms) ..........................................................................128 
3.  Components of key documents in M&E system ......................................130 
4.  Methods (tools) ............................................................................................132 
5.  Alternative terminology for Log Frame elements....................................149 
6.  References.....................................................................................................150
<<<PAGE=4>>>
CARE M&E Guidelines 2 
Endorsement 
 
Endorsement 
 
Our goal is for CARE staff around the world do better project design, establish more effective 
monitoring systems and conduct or coordinate better quality evaluations.  In order to achieve 
that goal we seek means of assisting those staff responsible for aspects of design, monitoring 
and evaluation (D+M&E) to continue to learn more about those subjects.  This includes 
providing useful materials to facilitate that learning and provide guidance in practice. 
 
The ideal persons to develop relevant materials on D+M&E are those who are closest to the 
field where CARE projects operate.  Their experiences and perspectives are relevant to their 
colleagues in other countries and projects.  The challenge is to find persons who have sufficient 
expertise to share and sufficient time and energy to articulate their experience in a way which is 
helpful to others. 
 
It is thus a delight to find and share a document as well done as the M&E Guidelines developed 
by CARE-Uganda. 
 
In their efforts to improve their monitoring and evaluation capacity, the staff of CARE-Uganda 
formed a M&E Task Force.  Members include representatives of CARE-Uganda projects and 
sectors, under the leadership of Assistant Country Director Geoffrey Chege and Country 
Director Nick Ritchie.  With the assistance of  consultant Tom Barton, this Task Force 
identified the strengths and weaknesses of the M&E capacities of each project, organised a 
M&E workshop for key staff from all projects, and, building on the lessons learned from that 
workshop, have now prepared these guidelines. 
 
Though the intended audience of these guidelines was initially CARE staff in Uganda, it is 
evident to me that this document deserves to be held up as an excellent guideline for all of 
CARE -- indeed, for staff of any development agency.  There are many manuals on this subject 
available from various sources, but this is the most practical and clearly written I have seen.  
And it is addressed to the specific conditions and needs of CARE projects.   
 
The philosophy, concepts, and terminology in these M&E guidelines are consistent with that of 
other current CARE documents, including the PMTF API framework, the Project Design 
Workshop Trainers’ Guidelines, and the materials being developed as a part of the MER 
initiative. 
 
Thus I endorse this document to serve as M&E guidelines for all of us in CARE. I strongly 
recommend it to anybody who has anything to do with monitoring and evaluating development 
projects. 
. 
Jim Rugh 
 Coordinator of Program Design, Monitoring and Evaluation 
CARE-USA / Atlanta
<<<PAGE=5>>>
CARE M&E Guidelines 3 
Preface 
 
Preface 
 
CARE International is the largest private non-sectarian aid organisation in the world, bringing 
help to those most in need.  Its purpose is to help the developing world’s poor in their efforts to 
achieve long-term social and economic well-being and to offer relief in times of crisis when 
there is acute suffering and life is threatened.  The current programming sectors of CARE are: 
Agriculture and Natural Resources (ANR), Small Economic Activity Development (SEAD), 
Primary Health Care (PHC), Girls’ Education and Literacy, and Population.  In these areas, 
CARE supports processes that create competence and become self-sustaining over time.  In 
addition, CARE advocates for public policies and programmes that support these ends.   
 
Since the signing of CARE International in Uganda’s agreement with the Government of 
Uganda in 1979, CARE has been assisting Uganda to build on its own considerable resources 
to address human needs via projects in agricultural production, environmental protection and 
conservation, reproductive health, water and sanitation, and small economic activity 
development.  As CARE works primarily at the community level, the scope of its work is more 
regional than national.  CARE activities are concentrated in Arua, Nebbi and Moyo districts of 
the West Nile region; Bushenyi, Ntungamo, Kasese, Rukungiri, Kabale, and Kisoro districts in 
the Southwest region, and Mbale, Kapchorwa, Pallisa and Kumi districts in the Eastern region.   
 
CARE Uganda is dedicated to the goal of improving the capacity of Ugandans to manage their 
natural, cash, and human resources in a sustainable manner.  This goal is to be reached 
through programmes of proven quality, which allow for pioneering approaches, women’s 
empowerment, cost-effectiveness, integrated project strategies, manageable expansion, and 
legitimate participation.  In support of this goal, CARE Uganda aims at improved 
collaboration between its partners, more effective monitoring and evaluation, and enhanced 
human resource development in CARE.   
 
To maximise its efficiency and effectiveness, CARE periodically reviews its activities in 
consultation with its government counterparts and collaborators, and introduces modification 
to its programme and geographic focus as necessary.   
From: CARE International in Uganda – Project Briefs, 1996
<<<PAGE=6>>>
CARE M&E Guidelines 4 
Preface 
Foreword 
 
Every CARE Country Office faces the challenge of assessing progress in its projects and 
understanding the ways it is making a difference, beneficial or otherwise, in people’s lives and 
the institutions serving them.  Attaining this, we can use lessons learned to continuously 
improve the design and implementation of our programme. 
 
There is no shortage of literature on the subject of monitoring and evaluation; indeed, it is vast.  
Unfortunately, much of it is very technical and obscure.  Sorting out what is useful and 
necessary to a complex programme of varying sectors, or even an individual project, can be a 
daunting task.  Most CARE programme staff have technical backgrounds, but their academic 
education rarely includes monitoring and evaluation, or the M&E training is seldom oriented to 
the needs of an NGO project.  The common result is that monitoring and evaluation too often 
remains ‘mysterious’, consuming substantial time and resources with little to show for 
considerable effort. 
 
Having examined the M&E issues facing CARE Uganda, we agreed that our prime objectives 
were de-mystifying monitoring and evaluation and putting practical guidelines in the hands of 
those who need them.  We decided to do this exploring and learning together - empowering 
ourselves - and producing guidelines which can be understood and used by just about anyone 
working on a project.  To help us achieve this objective we made some key decisions during 
the early planning:  
• to omit project design issues in this initiative.  While a project design has a significant 
effect on the type of M&E system required, we decided M&E issues were a sufficient 
challenge without simultaneously tackling those issues. 
• to focus our initial effort principally on the effects (intermediate goal level) and to more 
substantively address impacts (and final goals) in a second phase.  (Exploring impacts, 
and how to assess them in practical ways is our next task.) 
• to create an M&E task force as a “brain trust” within CARE to work collectively on this 
and subsequent phases.  (Gathering talent from across the organisation substantially 
benefited the quality of our learning and will continue to do so.) 
• to seek assistance from a person based in Uganda who possesses the wide range of skills 
required and who could work with us over time.  (We found what we were looking for in 
the person of Tom Barton, who wrote these guidelines.)   
Thanks in very large measure to the effort of our consultant/author, I believe these guidelines 
have met the objectives we set.  My hope now is that CARE Uganda and our partners will find 
the guidelines practical in developing and using monitoring and evaluation systems; and that 
these systems will provide everyone involved in our work with better quality and more timely 
information. 
 
The document will be provided to CARE’s Design, Monitoring and Evaluation unit for wider 
distribution together with a companion document - a workshop report.   If you obtain and use 
either document please let CARE Uganda know what you think of it. 
 
Nick Ritchie                        Country Director, CARE Uganda
<<<PAGE=7>>>
CARE M&E Guidelines 5 
Acknowledgements 
 
Acknowledgements 
 
The inspiration for these guidelines came from Nick Ritchie, Country Director, CARE Uganda, 
and Geoffrey Chege, Assistant Country Director.  Their initial ideas and sustained enthusiasm 
for the project have contributed enormously to its design and evolution.  Along the way, the 
author was very privileged to collaborate closely with Geoffrey, truly a master facilitator, and 
the CARE M&E Task Force in a participatory M&E workshop, which helped considerably in 
the development of the guidelines. Mary Babirye, Programme Officer, CARE Uganda, has 
given considerable support to the project, including expanding the horizons of its layout.  
Mary, together with Polly Dolan, University of Michigan Population and Environment Fellow, 
produced a wonderful report on the workshop that has been a rich mine of examples for these 
guidelines.  Sincere appreciation goes to the entire CARE M&E Task Force for their 
conscientious reading and constructive criticism of multiple drafts: Caroline Abeja, Geoffrey 
Chege, Polly Dolan, Sandra Erickson, Philip Franks, Fred Mukholi, David Mwesigwa and 
Nick Ritchie.  Appreciation also goes to Gimono Wamai and Rose Asera for supportive reading 
and layout suggestions.  Finally, a big thank you to Jim Rugh, CARE International, and all the 
other CARE staff who participated in the Kabale ’96 M&E workshop for their many ideas and 
good feedback on the place of Monitoring and Evaluation in CARE projects.   
Tom Barton 
1 January, 1997
<<<PAGE=8>>>
CARE M&E Guidelines 6 
Introduction 
Introduction  
 
Background to the guidelines: 
For some time, CARE Uganda has been working to improve its monitoring and 
evaluation systems.  Each project has made some individual progress, and a 
general workshop was held on M&E in 1994.  That workshop led to a set of 
guidelines that did not meet our needs and were hardly used by program staff.  A 
review of current project M&E systems and discussions with staff revealed that 
we did not have a common understanding of what CARE wanted from a 
monitoring and evaluation system nor how to create and use one. The skills of 
staff, both national and international, varied tremendously, as did the systems in 
use.  Difficulties in common evaluation exercises, e.g., development of an M&E 
plan, a baseline survey for a new project or an external evaluation of a project 
coming to closure, pointed to the need for a common set of expectations and 
requirements.  Thus, we began a systematic process of strengthening our skills to 
design and use M&E systems. 
 
CARE International has also been working over many years to develop the 
capacity of Country Offices.  Sectoral technical assistance teams have produced a 
variety of documents that are now in use.  Following the creation of a CARE 
International Design, Monitoring and Evaluation Unit (DME), workshops were 
held in West and East Africa, and in Asia, aimed at increasing linkages among 
countries and programmes, developing a world-wide DME cadre and building 
capacity.  A parallel development at CARE International is the Household 
Livelihood Security concept, aimed at unifying CARE’s work across sectors and 
spanning the relief to development continuum; this effort has now progressed to 
the stage of testing methods to assess household impacts. 
 
The CARE Uganda initiative started with a number of planning sessions by the 
senior management team, selection of a consultant and his subsequent visits to 
each project to become familiar with the activities, M&E systems and staff 
expertise in our projects. An M&E task force, comprised of experienced staff 
from each project, was formed and meetings held with the consultant to map out 
tasks and approaches.  Following these meetings, a workshop was planned and 
carried out for about 25 senior staff.  (The report of this workshop – the Kabale 
’96 M&E Workshop –provides a session by session record of the proceedings.)  
Subsequently, the guidelines were drafted a number of times, each draft reviewed 
by the task force members and comments integrated into the ensuing draft of the 
document.  
Objectives of the guidelines:
<<<PAGE=9>>>
CARE M&E Guidelines 7 
Introduction 
• Improve monitoring and evaluation in CARE projects  
• Provide a useful technical resource for planning project monitoring and 
evaluation systems 
• Strengthen skills in information systems for project staff 
 
Anticipated audience:  
This set of guidelines is designed primarily for CARE project staff, supervisors 
and managers.  Everyone in these categories uses information about their projects, 
and most are also contributing in some capacity to information gathering and 
analysis.   
 
Other parties involved with or interested in CARE projects may also find the 
guidelines useful, e.g., counterpart agencies, collaborating partner organisations, 
and consultants working with CARE.  
 
How to use the guidelines:  
Building on the organisation of CARE development projects, the chapters in these 
guidelines are arranged in a series that moves from planning to implementation, 
analysis and application.  Readers with relatively little experience in planning, 
research or information management may find it most useful to read the chapters 
one after another as they are arranged.  More experienced readers are also 
encouraged to skim all the chapters to understand the linkages to any specific 
topics they are pursuing in more depth.   
 
The body of the guidelines starts with the importance of information to CARE 
projects (Chapter 1), identifies users of information about CARE projects and 
their needs (Chapter 2), and discusses some of the common strengths and 
weaknesses of information gathering, analysis and use in development projects, 
including CARE’s projects (Chapter 3).  Project planning elements and the key 
concepts of monitoring and evaluation are reviewed in Chapter 4.   
 
Chapter 5 prepares the way for creating specific monitoring and evaluation plans 
for existing projects.  The following section focuses on the crucial issue of 
assessing project progress and achievement, i.e., indicators (Chapter 6).  Sources 
of indicator information and ways to select smaller samples that represent the 
larger target population of a project are discussed in Chapter 7.  The next chapter 
reviews methods to gather such information (Chapter 8).  
 
The important steps of analysing and making sense of the information that has 
been collected are dealt with in Chapter 9, followed by presentation of findings
<<<PAGE=10>>>
CARE M&E Guidelines 8 
Introduction 
and ensuring action in Chapter 10.  The final chapter in the body of the text is 
concerned with ways to institutionalise information management (monitoring and 
evaluation) plans within CARE projects (Chapter 11).   
 
The annex section of the guidelines also includes some very useful reference 
material.  First, there is a glossary of key terms and concepts (Annex 1), then a set 
of relevant abbreviations commonly used by CARE (Annex 2), followed by a set 
of suggestions for some key M&E documents (Annex 3).  Annex 4 is comprised 
of short presentations about a variety of techniques for data collection and 
analysis.  Annex 5 is a useful table comparing the preferred terms used for similar 
planning concepts by a wide range of donors and support agencies.  The final 
annex lists the references used in preparing the guidelines, and serves as a guide 
for readers wishing to pursue topics in even greater detail.
<<<PAGE=11>>>
CARE M&E Guidelines 9 
Chapter 1. Why M/E? 
CHAPTER 1 
 
Why is information 
(gathering, analysis, use) 
important to projects?   
 
 
Projects, and the people involved with them, need to have accurate and timely 
information to assess the value of what they are doing.   The following list shows 
some of the key reasons why people need information about projects:  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
The collection of information in projects, in combination with its analysis and 
use, is collectively referred to as the ‘Monitoring and Evaluation’ (M&E) 
component of a project.  
 
  
 Information Needs 
  
• Achievement – what has been achieved?  How do 
we know that the project caused the results? 
• Assessing progress – are the objectives being met? 
Is the project doing what the plans said it would do?   
• Monitoring – is the project well-managed? 
• Identifying strengths and weaknesses – where 
does the project need improvement and how can it 
be done?  Are the original objectives still 
appropriate?   
• Checking effectiveness – what difference has the 
project made? Can the impact be improved? 
• Cost-effectiveness – were the costs reasonable? 
• Sharing experiences – can we help to prevent 
similar mistakes or to encourage positive 
approaches? 
Adapted from: Feuerstein, 1986
<<<PAGE=12>>>
CARE M&E Guidelines 10 
Chapter 1. Why M/E? 
When considering the M&E system, it is important to reflect on the purpose of 
Monitoring and Evaluation as:  
 
The collection and management of data to be analysed and 
used for the regular and periodic assessment of a project’s 
relevance, performance, efficiency, and impact in the context of 
its stated objectives.   
 
The M&E system is a form of ‘information system’, which is a broad term for 
information selection, gathering, analysis, and use.  It can be described as a 
logical chain of linked ideas starting (and continuing) with information users.   
 
 
    Project information systems – a chain of logic 
  
  
     Who: information users 
     
     Why: what purposes 
 
   What: specific information 
 
    When: timing needed 
 
     Where: sources of data 
 
               How: gathering, analysis 
 
          What next: ensuring action 
 
 
 
Information users include persons who are influenced by projects as well as those 
who influence the project, e.g., target communities, project staff, donors.  The 
major uses of the information include informing decisions in the project and 
sharing information with other persons or organisations.  Specific information is 
needed in order to ensure that the project is relevant, efficient and effective within 
its stated objectives.  
 
If accurate information is planned, but it is not feasible to collect it or it can’t be 
collected in time, then the project may get off track, i.e., it can become ineffective 
or irrelevant to local priorities.  If the information is gathered to answer such 
needs, but it is not analysed, then it cannot be used by the project.  Finally, if the
<<<PAGE=13>>>
CARE M&E Guidelines 11 
Chapter 1. Why M/E? 
information is collected and analysed but not available to the persons who need it, 
critical decisions about the project may not be made or may be poorly taken. 
 
The bottom line:  
Projects need logical information systems that maintain and strengthen the 
project, as well as meeting the needs of many other kinds of information users, 
including the target population.
<<<PAGE=14>>>
CARE M&E Guidelines 12 
Chapter 2. Information Users and Uses 
CHAPTER 2   
 
Who needs information about 
CARE projects (within or 
outside the project)? 
 
 
Information users 
One of the most important first steps in developing an information system is to 
identify who are the users of project-related information.  Once users are 
identified, it is then possible and necessary to determine what kind of information 
they need and for what purposes, what questions or concerns about the 
information users have and what constitutes quality information. 
 
Many people and organisations are interested in each and every CARE project.  
All of these people can be called ‘information users’.  Some persons will be 
interested in the achievements and lessons learned in a project, e.g., other NGOs 
working with similar target populations in another district.  Other persons may 
want information so that they can participate in various decisions related to the 
project.  The latter group are often referred to as ‘stakeholders’, or potential 
‘owners’ of the project.  Project stakeholders include all persons or groups who 
have the capacity to make or influence decisions that have an impact on project 
design or implementation.   
  
Ultimately, all of the stakeholders may be involved in the implementation phase 
of a project; therefore, they should be consulted and informed regularly about 
project planning and developments. Involving potential users (especially project 
management, staff, and target population) in the design of M&E will not only 
help them clarify their information requirements, but also ensure their support for 
the M&E system and utilisation of its findings.
<<<PAGE=15>>>
CARE M&E Guidelines 13 
Chapter 2. Information Users and Uses 
Key categories of people and organisations who may be interested in obtaining 
information about CARE projects include:  
 
(sometimes called ‘clients’ or ‘beneficiaries’ or ‘target 
population’): may be individual community members, 
families, community 
groups, or whole villages. Specific categories of importance to CARE include 
community leaders, target groups in the community, and the community at large.   
 
includes Community-based Organisations (CBOs), and 
Non-Governmental Organisations (NGOs).  CBOs are 
potential local collaborators: e.g., mutual assistance 
societies,  
cultivating groups, and local associations.  NGOs, whether local or international, 
have shared and potentially overlapping interests; they are also potential 
collaborators with supplemental resources.  
 
the collaborating and co-ordinating local counterparts, 
policy-makers and planners; includes district officials, 
officials in line  
Ministries, and politicians like Members of Parliament.  
 
the CARE-Uganda project managers and field staff who 
implement projects.  
 
 
the CARE-Uganda programme level staff such as the 
country director (CD) and assistant CDs,  
sector advisors and project managers.  
 
the Atlanta headquarters level staff, such as the 
Regional Monitoring Unit (RMU), sector co-ordination 
group (PAD), fund raisers (External Relations), finance 
and advocacy. 
 
Funders, external support agencies. 
 
 
Community 
Local 
Organisations 
Government 
Project staff 
Country office 
CARE  
International 
Donors
<<<PAGE=16>>>
CARE M&E Guidelines 14 
Chapter 2. Information Users and Uses 
Additional categories of persons or organisations which may need to be 
considered in some projects include:  
 
• Other CARE International members: potential funders of some 
projects, and professional colleagues with shared interests 
• Academicians, researchers, consultants: shared professional interests, 
potential for further analysis and alternative applications of project 
information 
• Media, journalists: dissemination of significant results; showing 
transparency and public accountability 
 
 
 
What kinds of information are 
needed?  
 
 
Content concerns 
Among the many different people are interested and actively involved in project 
M&E are the project target population, staff responsible for routine collection and 
management of data (e.g., on finances and outputs), internal and external 
evaluation teams responsible for periodic assessments (e.g., of project 
performance and progress).   The differences between these groups will be in 
their:  
• perceptions of the purpose of M&E 
• reasons for collecting data 
• interests in the information generated as a result of M&E.   
 
Another group of people who influence the M&E system are the various 
specialists involved within the project, e.g., economists, ecologists, agronomists, 
sociologists, health workers, etc.  Many of their information needs (and what 
information they think the project needs) will be largely determined by their 
professional training (e.g., economists who tend to search for information relating 
to income).  As a result, although their experience and training can bring useful 
perspectives to the M&E system, these groups may also introduce an element of 
professional ‘bias’.  Caution is needed to ensure that the views of these 
professionals do not over-influence the design of the M&E system.
<<<PAGE=17>>>
CARE M&E Guidelines 15 
Chapter 2. Information Users and Uses 
Quality concerns   
Information users have many concerns about the quality of information they are 
seeking.  Some key criteria are shown in the following box:  
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Addressing Issues of Quality 
The first four quality concerns above were prioritised in a recent CARE 
workshop, which went on to suggest strategies for ensuring that data is of good 
quality (from CARE Uganda, Report on M&E workshop, 1996).  Below are the 
strategies identified for each of these four concerns: 
 
How can we ensure information is accurate and 
reliable? 
• Plan in advance; be specific with regard to information needed and 
processes for acquiring it  
• Simplify information needs and systems for its collection and analysis; 
be selective with regard to information collected, samples, methods, etc. 
• Develop guidelines and standardise how to collect and analyse 
information 
• Triangulate information sources and methods of collection where 
possible (i.e. use more than one method/source for the same data item) 
  
 Quality of Information 
  
• Accuracy, validity: does the information show 
the true situation?   
• Relevance: is the information relevant to user 
interests? 
• Timeliness:  is the information available in time 
to make necessary decisions? 
• Credibility: is the information believable? 
• Attribution: are results due to the project or to 
something else? (see Chapter 4) 
• Significance: is the information important? (see 
Chapter 4) 
• Representativeness: does the information 
represent only the target group, or also the wider 
population? (see Chapter 7) 
 
Accuracy
<<<PAGE=18>>>
CARE M&E Guidelines 16 
Chapter 2. Information Users and Uses 
• Encourage commitment to collecting accurate information 
• If appropriate, acquire and use modern equipment, e.g.,  computers (but 
remember ‘GIGO’: garbage in, garbage out) 
 
 
How can we ensure information is relevant to 
user’s needs? 
• ‘Relevance’ differs for different information users.   
• Gain the perspective of project target populations by engaging their 
participation in information collection and analysis 
• Avoid being donor-driven, while meeting donor requirements  
• Be selective and prioritise information needs; know in advance who 
needs what information, and how it will be used.   
• Ensure the project can analyse information; and present results in an 
accessible form for the various users/audiences (i.e., don’t use a written 
report with illiterate community members or a 200 page report with a 
busy Ministry official) 
 
 
How can we ensure information is available in 
time? 
• Use simple tools for collection and analysis 
• Plan in advance: consult information providers; seek commitment from 
partners/counterparts/communities 
• Create a schedule with deadlines; delegate and share responsibilities 
related to information collection, analysis and presentation; sensitise 
participants about the need for timeliness 
 
 
How can we promote the credibility of 
information? 
• Design information gathering methods carefully; be consistent (by using 
repeatable methods which can show trends); be objective when 
gathering, analysing and interpreting information 
• Be transparent about processes used; explain methods used to obtain 
data and draw conclusions (including assumptions, statistical links 
between sources; methods of collection, analysis and results) 
• Address and discuss attribution issues (whether results can be claimed 
by the project) 
• Maintain your personal and organisational reputation 
Relevance 
Timeliness 
Credibility
<<<PAGE=19>>>
CARE M&E Guidelines 17 
Chapter 2. Information Users and Uses 
 
 
 
 
Why is the information 
needed?   For what purposes?  
What decisions or actions will 
be affected? 
 
 
Purposes of information 
The two main uses for information produced by or about projects are:  
a) informing people who have to make decisions (whether inside or outside of the 
project); and b) description for persons who want to learn from the project 
(including achievements, constraints and failures).   
 
Some common examples of these two purposes include the following:    
• to monitor physical and financial progress so that decisions can be 
made (or revised) about spending and resource distribution that will 
keep the project functioning and within its budget.  
• to monitor distribution of project benefits; e.g., some people may 
benefit more than others.  This information is useful to groups wanting 
to monitor project equity and accountability.   
• to examine the responses of the target population to the services and 
inputs being provided by the project; such information can help ensure 
acceptability and usefulness of project activities.  
• to study specific implementation problems facing a project so that the 
cause(s) can be identified and practical solutions recommended.  
• to determine what is the impact on the target population, especially on 
quality of life and living standards (income, health, empowerment, 
relationship to environment, etc.) as a direct result of the project, i.e., to 
assess the attributable impact of the project.  Where project benefits are 
identifiable, impact information can be useful for advocacy. 
• compliance and accountability, e.g., meeting donor requirements. 
Purposes, Needs and Concerns of Six Key Information  
Users
<<<PAGE=20>>>
CARE M&E Guidelines 18 
Chapter 2. Information Users and Uses 
The charts on the following two pages summarise information purposes, needs 
and concerns for the six of the most significant users of information related to 
CARE-Uganda’s projects, as identified by the Kabale ’96 workshop participants: 
 
• Community 
• Local organisations - CBOs, NGOs 
• Government 
• Project staff 
• CARE Country Office - Uganda HQ 
• CARE International
<<<PAGE=21>>>
CARE M&E Guidelines 19 
Chapter 2. Information Users and Uses 
Purpose, Information Needed and Concerns About Information by Key Information Users 
USERS PURPOSE KIND OF INFORMATION  CONCERN 
Community 
Leaders: LCs; 
Opinion, 
Cultural, and 
Religious 
• To clear suspicion; for deciding whether to support activities 
• For planning and mobilisation of members  
• To integrate project activities into parish/village activities 
• To understand project within cultural/social/ religious norms 
• Aims/objectives, Targets, Activities 
• Resources, support from project, Duration 
• Effect on community 
• Simplicity, Consistency, 
Accuracy, Timeliness 
Target group: 
e.g., women, 
farmers, 
veterans, etc. 
• To know benefits of project 
• To know what contributions have been made 
• To gain feedback from the project  
• To know support expected from participants 
• Aims/objectives, Targets, Activities 
• Resources, support from project, Duration 
• Effect on community 
• Simplicity, Consistency, 
Accuracy, Timeliness 
General 
community 
• Why not me?  To clear suspicion 
• To know expected benefits and expected contributions 
• For feedback 
• Aims/objectives, Targets, Activities 
• Resources, support from project, Duration 
• Effect on community 
• Simplicity, Consistency, 
Accuracy, Timeliness 
Local Organisations 
CBOs • For shared planning and mobilisation of members 
• To integrate project activities into group’s activities 
•  •  
NGOs • For shared planning and collaborative efforts 
• To learn from project activities and experiences 
•   
Government 
Counterparts: 
District and 
field staff 
• Planning, Co-ordination 
• Allocation of time, personnel, resources 
• What to expect from project; what expected by project 
• Annual plans 
• Status reports, Evaluation reports 
• PIR 
• Timeliness, Relevance 
Central: 
Line ministry 
• Project approval  
• Budget approval, Accountability 
• Co-ordination, Planning 
• Coverage, Financial and Qualitative information 
• Status reports,  Evaluation reports 
• Project documents, and MoU  
• Completeness, Accuracy, 
Accountability, Validity, 
Timeliness, Credibility
<<<PAGE=22>>>
CARE M&E Guidelines 20 
Chapter 2. Information Users and Uses 
 
USERS PURPOSE KIND OF INFORMATION  CONCERN 
Project Staff 
Field officers • To monitor budgets and expenditures, tracking expenditures 
• Other inputs, e.g., materials,  personnel 
• Staff performance appraisal 
• To identify constraints, obstacles,  gaps,  etc., for planning 
• Financial statements 
• Quantitative 
• Quantity and quality of outputs (IOP) 
• Qualitative - beneficiary needs and perceptions 
• Accuracy, Objectivity, 
Feasibility, Timeliness, 
Validity, Relevance, 
Representativeness 
FEWs • To compare activities achieved against targets 
• To assess effectiveness of methods and strategies  
• To report on  communities 
• Quantity and quality against time/plans 
• Beneficiary response, e.g., utilisation adoption 
• Quality, Effectiveness, 
Cost, Time, Validity, 
Relevance 
CARE Country Office - Uganda HQ  
Country 
Director 
• Preparation of annual project information • Annual Portfolio/Project Information, AIP 1.1 
• API 
• Follow agreed formats 
• Significance, Attribution 
Programme 
(ACD, PMs, 
Advisors) 
• Compile PIRs,  Prepare AIPs, Staff appraisals/action plans  
• Overall management of sectors, Monitoring budget 
• Advocacy/fundraising, Identifying areas of project support 
• Annual Implementation Plans (AIPs 1.1, 1.2, 1.3) 
• PIRs, API 
• Annual project performance reports 
• Relevance 
• Good quality English 
Prog. support 
(Finance, 
Personnel)  
• Compilation of budgets 
• Preparation of OFR (Overseas Financial Report) 
• Human resource planning 
• Monthly Overseas financial Reports (OFR) 
• AIP 1.1 
• Project progress reports 
• Relevance, Accuracy 
CARE International - Atlanta HQ 
RMU • To measure project performance against plans • Actuals against plans 
• API 
• Significance, 
Representativeness, 
Sustainability 
Sector (PAD) • To identify areas that need support 
• To compare project globally; To draw lessons learned 
• To assess performance against standards 
• Weaknesses and constraints  
• Outputs/progress, API 
• Evaluators’ findings 
• Relevance, Credibility, 
Significance, Accuracy, 
Attribution, Sustainability 
External 
Relations 
• To convince donors of need to intervene 
• To convince USA government to support projects 
• Human interest stories, Major achievements 
• Relevance of needs to USA interests: API, PIR 
• Credibility, Attribution, 
Significance 
Finance • For accountability 
• To assess adherence to policy 
• Budgets and projections 
• Expenditure reports, Contracts 
• Accuracy, Timeliness
<<<PAGE=23>>>
CARE M&E Guidelines 21 
Chapter 3. Strengths/Weaknesses of M/E 
CHAPTER 3   
 
What are some of the common 
strengths and weaknesses of 
information gathering, 
analysis, and use in 
development projects?   And 
why? 
 
 
Poor project design 
Sometimes projects are too hastily developed in response to available funds, 
omitting a thorough analysis of the community needs and situation.   The donors 
themselves are sometimes relatively unsophisticated about M&E, either lacking 
interest in proper planning for information management in a project or regarding 
M&E only as a tool for accountability and not a part of on-going project design.   
 
Human resource development needs 
The available staff may be unqualified for tasks related to information 
management, in part because there is relatively little local opportunity for 
practical training/learning in this field.  Coupled with this issue is staff 
apprehension about the ‘difficulty’ of monitoring and evaluation, which is not 
helped by the lack of common agreement about standards and methods among 
professionals.  These factors sometimes (too often, in fact)  lead to reliance on 
consultants to design systems and outsiders to evaluate projects.   
 
Quantitative bias 
A frequent complaint by project staff and other information users is the 
quantitative bias of project information systems.  One contributing factor to this 
weakness is an organisational trend toward almost exclusive use of log frames 
(see Chapter 4).  The nature of information requested in the typical log frame is 
numerical.  Thus, over-dependence on log frames can result in over-reliance on 
quantitative information that leaves out explanations, human voices and the actual 
nature of what is going on.
<<<PAGE=24>>>
CARE M&E Guidelines 22 
Chapter 3. Strengths/Weaknesses of M/E 
Low priority for information systems 
Persons expected to carry out data collection are frequently expected to take this 
role on as an ‘additional’ task, to be worked in and around the more ‘important’ 
service-oriented tasks of the project interventions.   
 
Involvement limited to collection 
Many staff do not understand why they have to collect the information, i.e., they 
have no sense of how the information contributes to or can even be used in their 
own work.  This problem is most common when staff members do not participate 
in either the planning for information gathering or the analysis of the data 
collected.   
 
Poor feedback to the data collection (and respondent) levels  
Failure of field staff to get feedback about information that has been collected 
contributes to low morale and a perception that such an activity is not as 
important as other duties, e.g., intervention tasks that are more regularly 
supervised and/or assessed for job performance.  Failure to give feedback to the 
community level respondents also convinces them that the data collection 
exercise was a waste of time, and breeds reluctance or even resentment toward 
any repetitions in the future.   
 
 
What about CARE?  How are 
we doing with M&E?  
 
 
Sources of information about strengths and weaknesses in CARE projects came 
from two main sources: contributions by the M&E Task Force (19/6/96),  and the 
participants at the Kabale ’96 M&E Workshop (9-13/9/96).   The results of  these 
participatory discussions are presented in following table that shows strengths, 
weaknesses, opportunities and constraints to M&E within CARE.  
 
Among the main strengths of M&E within CARE is data collection, due to 
committed staff, standard formats, and regular schedules for collecting and 
reporting information.  As an organisation, CARE ensures that resources for 
M&E are built into project proposals.  Information dissemination is also 
encouraged as a tool for promoting institutional development and community 
empowerment.
<<<PAGE=25>>>
CARE M&E Guidelines 23 
Chapter 3. Strengths/Weaknesses of M/E 
 
CARE - Status of present M&E within CARE International in Uganda                 
Strengths Weaknesses Opportunities Threats, limitations, or external 
constraints 
• Regularity: information is 
collected regularly through 
well-established reporting 
systems 
• Standardised formats 
within projects: uniform 
formats and reporting forms 
in each project help facilitate 
data collection 
• Resources:  resources for 
M&E are available 
• Information dissemination: 
information is usually 
disseminated to the 
community and other 
stakeholders 
• Commitment: collective 
awareness in staff of M&E 
needs and importance of 
gathering good quality data 
• Useful: information collected 
is usually put to good use 
• Capacity: most projects have 
log frames; some projects 
with M&E frameworks; some 
projects with an M&E officer 
• Weak information planning and 
management at project level due to 
inadequate technical skills, including poor 
sampling, gathering too much data, and 
inability to do data analysis 
• One-way information flow 
(‘bottom→up’) and lack of feedback 
• No standard information system across 
projects to guide projects; lack of 
consistency between projects 
• Quantitative bias: Over-emphasis on 
quantitative information 
• Donor-driven systems limit relevancy: 
e.g., assessment of institutional and 
capacity-building effects (or impacts) not 
done 
• Partners not involved: Relationship of 
projects and partner or stakeholder (e.g., 
data requests, shared planning for M&E) is  
inadequate 
• Weak link from log frames to M&E 
plans; methods for data collection not 
always specified; lack of attention to 
assumption issues in log frame 
• Projects with similar/shared objectives 
and/or activities 
• Community participation in M&E could 
be strengthened 
• Community M&E for: a) CARE, b) 
community’s own projects could be 
improved  
• Selection of appropriate indicators 
could be improved  
• Supportive link exists with CARE USA 
and the DME unit 
• Sentinel surveillance is a possible tool 
for rapid, participatory community 
assessment 
• More translation of project objectives 
and related outcomes into job 
descriptions (via IOPs) could improve 
perception of value for information 
management 
• Household livelihood security impact 
concept not yet clarified or 
operationalised (CARE-Uganda has a 
chance to help develop) 
• Mandatory link with government 
system can lead to difficulty with: 
poor fit of data into existing 
system, or dependency on 
government workers and 
government information system 
• Attribution of effects and impacts 
can be difficult in a fluid socio-
economic setting, especially 
when multiple other groups are 
working in overlapping areas 
• M&E can be time- and resource-
consuming, requiring careful 
planning to balance M&E needs 
against intervention needs 
• Multiple stakeholders request (or 
require) a wide range of M&E 
information 
 Adapted from CARE M&E Task Force meeting 19/6/96, and the CARE Kabale ’96 M&E  Workshop
<<<PAGE=26>>>
CARE M&E Guidelines 24 
Chapter 3. Strengths/Weaknesses of M/E 
The priority concern and reasons for weaknesses of CARE-Uganda’s information 
systems, as identified by participants during the Kabale ’96 workshop are 
presented below. 
 
• Inadequate skills for data analysis and weak data management at project 
level:  Projects often lack data analysis skills so collected information 
sometimes ends up unanalysed and unused.  Lacking training, staff shy away 
from monitoring as something ‘mystical’ rather than an everyday activity.   
With inadequate skills in data management, there are clear concerns about the 
quality, content, dissemination and utilisation of information collected. There 
is need for tools which staff are capable of learning and utilising.  
  
• Lack of feedback:  The flow of CARE’s information systems is one-way – 
‘bottom→up’.  Feedback is rarely given from “further up the system” on 
submitted reports. When feedback is given, it is usually in response to a 
specific critical issue, and is dependent on an individual rather than a system.  
Project staff from the ‘lower’ levels feel the information system would be 
more effective if they systematically received feedback on quality of reporting, 
lessons learnt, and project performance.   
   
• No standard system:  Currently, there is no standard information system to 
guide projects on M&E within CARE Uganda.  As a result, different projects 
have inconsistent reporting systems, non-similar data management systems, 
and widely varying approaches to dissemination.  Because “we do not really 
know what we need,” M&E consultants are not used in the most effective way.  
In addition, information is often collected and reports made in response to 
isolated needs, rather than as an integrated part of daily project activities. 
  
• Emphasis on quantitative system:  Many donors have principally requested 
numerical (quantitative) information about projects as it is easier to compare 
and summarise than qualitative information. However, an over-emphasis on 
quantitative data within projects means that little information is being gathered 
about the qualitative effects and impacts of CARE projects on people’s lives.  
  
• Donor driven:  Many staff tend to see M&E as something that is necessary to 
please donors, rather than as important for the project and for their own work.  
Donor schedules and demands can mean that M&E work, such as conducting 
and interpreting a baseline, may be rushed and not undertaken carefully.  
Without a baseline, subsequent demonstration of project effects and target 
population change is generally very difficult and unconvincing.
<<<PAGE=27>>>
CARE M&E Guidelines 25 
Chapter 4. Key Concepts 
CHAPTER 4   
 
What key concepts are 
fundamental to understanding 
and planning for information 
management?  
 
 
Project definition 
A ‘project’ is usually defined as a one-time activity with a well-defined set of 
desired results.  Ideally, a project will have the elements shown in the following 
box:  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
The various stages in the life of a project may be sliced into many tiny pieces, 
each with a specific label.  Frustratingly, every agency seems to use a different set 
of terms (for examples, see Annex 5).   
 
A project goes through various stages: from the first idea to greater and greater 
clarification of setting, problems, objectives, choices and action.  When funded, it 
is then implemented, revised during implementation, and eventually evaluated.  
These progressive stages in the lifespan of a project are sometimes referred to as a 
‘project cycle’.   Used in this way, the concept mostly refers to the overall ‘life 
Elements of a project 
 
• a beginning, a middle, and an end (project 
lifetime) 
• a clear set of objectives and goals linked to 
anticipated (desired) effects and impacts in a 
target population (sometimes called 
‘beneficiaries’) 
• various activities with related inputs and 
outputs
<<<PAGE=28>>>
CARE M&E Guidelines 26 
Chapter 4. Key Concepts 
cycle’ of the project from beginning to end.  In fact, however, some elements of 
projects are cyclical – they get repeated regularly (see box below). 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Each CARE project reviews its progress against plans every six months 
(‘semesterly’) and prepares a Project Implementation Report (PIR).  Each project 
is also responsible for reviewing annual performance at the end of each year and 
identifying lessons learnt.  This annual process is integrated with a review of the 
multi-year (life of project) plans contained in the project document in order to 
prepare an Annual Implementation Plan (AIP 1.2) for the following year.   
 
Project stages and information needs 
For the purposes of these guidelines, we will refer principally to the following 
stages in a project: 
  
What are the problems?  What are the resources?  What 
are the unmet needs?  
 
This is when the problems that need a project  
are identified, contributing factors clarified, needs assessed, and then the 
project is designed.  
Before 
Project 
 
 
Reflection Self- 
evaluate 
Act 
Plan 
Assess 
Self-
evaluate 
Analysis 
“Impact”? 
The Participatory Evaluation Cycle 
From: Pfohl, J. “Participatory Evaluation: A users’ guide” PACT 
As cited in: Narayan, D. “Participatory Evaluation” World Bank 1993
<<<PAGE=29>>>
CARE M&E Guidelines 27 
Chapter 4. Key Concepts 
 
What is the current situation?   
 
During this phase, after funding is secured, but shortly 
before project services and activities  
begin, the project carries out a ‘baseline’ study.  
 
 
Is the project proceeding according to plan? 
 
This is an on-going stage, during which the project 
interventions (services and activities)  
are being carried out, together with various forms of regular assessment to ensure 
that the project is on track. 
 
 
Are the project strategies working?  
 
This stage occurs at approximately the mid-point in the project 
funding cycle.  It is the time for re- 
assessing project strategies, management systems, linkages with partners, and 
looking for preliminary evidence of project effects.   
 
 
What effect(s) did the project have? 
 
This is the point where project interventions (and funds) are 
terminated, and an assessment is made of  
project achievements during the period of support.   
 
 
What impact did the project have on the lives of the people it 
was designed to affect? 
   
Ideally, after the withdrawal of project support, the  
benefits of projects are sustained and can be demonstrated among the target 
community. 
 
As noted in these descriptions of stages in a project lifespan, information of one 
kind or another is gathered at every stage. 
 
Project  
Start-up 
Implementation 
Mid-term 
End of  
Project 
After 
Project
<<<PAGE=30>>>
CARE M&E Guidelines 28 
Chapter 4. Key Concepts 
Project Logical Framework (‘log frame’) 
The log frame of a project is a tool for planning and managing development 
processes.  Not just a static multi-year outline for a project, log frames are 
actually dynamic; in other words, they can change as the project develops.  Using 
periodic monitoring information, a project can adjust the annual plan, and even 
modify the lower levels of the log frame, to reflect what can realistically be 
achieved in the coming year.   
 
The process of creating a log frame begins from the premise that if we know what 
the problem or situation is that we want to change, then we can envision a 
resolution or a better future (i.e., the objectives or goals of a project).  Next, the 
Logical Framework Approach (LFA) reasons that if we know our objectives, then 
we can identify a set of project outputs that will achieve the objectives.  
Continuing in this line of thinking, we can then identify the project activities and 
inputs that are essential for generating the necessary outputs in order to reach the 
objectives.   
 
The format of a completed log frame is usually a four column grid that shows the 
linkages between project intentions (‘goals’, ‘objectives’),  assessments of 
achievements (‘indicators’), ways of checking progress (‘means of verification’) 
and expected events or situations outside project control that can influence the 
project (‘assumptions’).  Other agencies or various donors may request (or 
demand) a variety of terms for very similar elements in the log frame (see Annex 
5).  For consistency, in these guidelines, we will use the preferred terminology of 
CARE International.  As typically seen in CARE Log Frames, the assembled 
elements look like the following table:  
 
     Typical CARE Log Frame Structure 
 
Hierarchy of 
objectives 
Objectively 
verifiable 
indicators (OVIs) 
Means of 
verification 
(MoVs) 
Assumptions 
Final Goal 
(FG) 
   
Intermediate 
Goal   (IG) 
   
Outputs    
Activities
<<<PAGE=31>>>
CARE M&E Guidelines 29 
Chapter 4. Key Concepts 
Presented in rank order, the important levels in a hierarchy of project 
objective/goals are:  
 
What the project intends to contribute in the long term as a 
result of achieving the intermediate goal(s).  E.g., improve the 
rural standard of living.  This is the ultimate level, and only 
reached when the community is able to sustain the positive benefits without 
continued project inputs. 
 
What response the project intends to achieve among the 
target population groups.  E.g., increase the production 
and sale of high quality bananas by small farmers.  
  
What the project intends to achieve in the short term as a result 
of the project activities.  E.g., 100 farmers trained to carry out 
improved banana farming.  
 
What the project staff and target population are going to do.  
E.g., provide technical support to existing farmer groups.  This 
is the ‘lowest’ level in the sense that it occurs first, and is 
completely dependent on project inputs.  
 
What resources are necessary for performing the project 
activities.  E.g., stationery supplies for workshops and training 
sessions. These are not usually shown in the log frame itself, 
though they are a key element in producing project outputs.  Inputs occur only 
during the period of project support.     
 
In order to determine where results from project interventions fall on the 
hierarchy, the matrix on page 31 can be useful.  The first column shows the levels 
of the ‘Hierarchy of objectives’ as they appear in the log frame.  The second 
column shows CARE’s preferred terms for the ‘Kinds of results’ that are expected 
at each level;  a description of each concept is presented under the ‘What’ 
column.  The next two columns of the matrix, ‘Caused by whom’ and ‘Claimed 
by whom’ also help define what kinds of project interventions and results fall at 
each level.  The second last column ‘Time-frame’, shows when a project can 
expect to be able to measure the progress and results at each level.   A final 
column gives examples of the different levels of objectives, as drawn from 
existing CARE projects.   
 
Final Goal 
Intermediate 
Goal 
Outputs 
Activities 
Inputs
<<<PAGE=32>>>
CARE M&E Guidelines 30 
Chapter 4. Key Concepts 
Inputs (funds, technical assistance, commodities, in-kind) are used to support 
Activities (project processes done with the input resources).  Both contribute to 
the Outputs (the products of the project).  All of these three elements are within 
the control and responsibility of the project and, therefore, the project is 
accountable for the extent and quality of their achievement.   
 
The final two levels depend on responses within the target community; these are 
Effects (target population response to the project outputs, such as change in 
behaviour), and Impacts (sustainable changes in conditions at the household 
level).  Although the project is not strictly accountable for the latter two levels 
since they depend on the target population and other external stakeholders, the 
project is responsible for the strategies that are supposed to produce the desired 
effects and impacts.
<<<PAGE=33>>>
CARE M&E Guidelines 31 
Chapter 4. Key Concepts 
Hierarchy of Objectives 
 
Hierarchy of 
Objectives 
Results What: description Caused by Whom Claimed by Whom Time-Frame Examples of objective 
by level 
Final Goal Impact sustainable changes in 
human conditions or 
well-being of target 
population at 
household level 
target groups  
experience it; may 
come from target 
group or local 
institutions 
attribution is difficult 
with other influences 
substantial and 
inevitable 
sometimes 
measurable within 
life of project (e.g., 
through case studies) 
but most often ex-
post 
Child mortality in 
Nyarusiza sub-county 
of Kisoro district 
reduced by 20%  
Intermediate 
Goal 
Effect reactions and actions 
of target populations as 
a consequence of 
exposure to project 
interventions 
target groups  
experience it; comes 
from response of target 
group to project 
interventions 
should be largely 
attributable to the 
project, with other 
influences relatively 
minor 
within life of project 
Community 
involvement in, and 
demand for 
reproductive health 
services increased 
Output Output products produced by 
the project 
project staff produce it 
(and are accountable) 
100% attributable to 
the project 
within life of project 75 community based 
FP distributors trained  
Activity Process interventions or 
activities done by the 
project 
project staff do it (and 
are accountable) 
100% attributable to 
the project 
within life of project 
8 training courses 
conducted for district 
medical staff in FP 
methods 
Input Input resources used by  the 
project 
project staff use them  
(and are accountable) 
100% attributable to 
the project 
within life of project FP supplies available 
at health units without 
stock-outs all year
<<<PAGE=34>>>
CARE M&E Guidelines 32 
Chapter 4. Key Concepts 
The following graphic shows another way of understanding the LFA levels (read 
the figure progressively from the bottom up to the top).  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
For example, imagine a project seeking to reduce the amount of childhood 
diarrhoea by getting the community to use ‘safe’ water.  If this project drills and 
equips boreholes that are then not being used, then the project logic needs to be 
re-assessed and strategies changed in order to achieve the desired effects.   
 
Objectives 
Outputs 
Activities 
Inputs 
Assumptions 
about the 
context 
Assumptions 
about the 
context 
Preconditions 
be sufficient to 
perform the  
will under given 
achieve or 
contribute to the 
will under given 
be sufficient to 
perform the  
will under given 
From: DANIDA, LFA, 1996
<<<PAGE=35>>>
CARE M&E Guidelines 33 
Chapter 4. Key Concepts 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Objectives: 
Reduced incidence of 
water borne diseases 
Outputs: 
A sustainable 
supply of water to 
the community 
Activities: 
Design and install a 
piped water supply 
scheme in a 
community and 
develop capacity to 
manage and maintain 
it. 
Inputs: 
Pipes, tubes, pumps,  
labour, engineers, and 
an advisor on water 
supply management.  
Assumptions about the 
context: 
Health authorities 
conduct hygiene 
awareness campaigns 
Assumptions about the 
context: 
New tariff (local tax) 
proposal approved 
Preconditions: 
The Water Utility 
(agency) is given 
autonomous legal 
status. 
be sufficient to 
perform the  
will under given 
achieve or 
contribute to the 
will under given 
be sufficient to 
perform the  
will under given 
From: DANIDA, LFA1996
<<<PAGE=36>>>
CARE M&E Guidelines 34 
Chapter 4. Key Concepts 
The M&E System 
The Monitoring and Evaluation system is another planning and management tool 
of projects; it is actually the information system used to assess project progress, 
performance and impact.  Monitoring refers to the regular collection (plus 
analysis and use) of information within the project about its progress.  Evaluation 
refers to periodic reviews of information from within, as well as about, projects 
and their performance.  The M&E system is very important in its ability to assist 
project staff, target population, and other stakeholders to develop the project 
throughout its lifespan.  As with the log frame, the structure of the M&E system 
is also characterised by several levels.  Each level relates closely to the hierarchy 
of objectives in the log frame.  The following table shows how each level of 
objectives links with specific monitoring and evaluation assessments (see also the 
chart on page 40).   
 
Overview of structure of M&E information system 
 
Hierarchy of 
objectives 
Types of 
information 
Monitoring 
activities 
Evaluation activities 
Final Goal Impacts 
(fundamental 
changes for target 
population)  
Impacts 
(relatively 
little at this 
level) 
Ex-post assessment 
Final evaluation 
(mostly done by 
evaluation) 
Intermediate 
Goal 
Effects  
(target population 
response) 
Effects  
(more 
important at 
evaluation) 
Annual review 
Mid-term evaluation 
Final evaluation 
(more by evaluation) 
Output 
(intervention) 
Outputs  
(project products) 
Semesterly: 
Physical 
Annual, mid-term 
and final 
(with monitoring 
data) 
Activities Process indicators Semesterly: 
Physical 
Annual, mid-term 
and final 
(with monitoring 
data) 
Inputs Input indicators Semesterly: 
Financial 
and physical 
Annual, mid-term 
and final 
(with monitoring 
data)
<<<PAGE=37>>>
CARE M&E Guidelines 35 
Chapter 4. Key Concepts 
MONITORING 
Monitoring is the collection and management of data which relate to the 
predefined target values for the indicators (OVIs) in the log frame.  Monitoring 
information is collected on a continuous basis throughout the implementation 
phase of the project.   
 
There are four main types of monitoring activities:  
 
This category refers to internal monitoring of financial, 
physical and organisational issues affecting the project.  
Financial monitoring tracks project inputs and costs by 
activity within predefined categories of expenditure. 
Physical monitoring tracks the distribution and delivery of project activities and 
outputs/interventions.  Organisational monitoring tracks sustainability, 
institutional development and capacity building in the project and direct partners.   
 
The process of tracking the context in which a project is 
operating, as it affects critical assumptions and risks to 
the project.  This includes monitoring institutional and 
policy issues that may affect the capacity of the project 
to act or the capability of the target population to respond to the project. These 
concerns are handled to some extent during monitoring, but principally during 
evaluations.   
 
The process of tracking project effects (target 
population responses to project outputs/interventions) 
and project impacts (the contribution that the project 
makes to  
fundamental and sustainable change for the target 
population).  Concerns about effects are handled to some extent during 
monitoring, but mostly by evaluation.  Assessment of impacts is rarely dealt with 
by monitoring, and is principally in the domain of evaluation. 
 
The process of tracking project objectives and strategies 
for continuing relevance to the target population and its 
changing needs.  
 
These monitoring activities vary in terms of where the data is collected from (i.e., 
the source), the frequency of collection, and the methods used for gathering and 
analysing the data.   
 
Institutional 
monitoring 
Context 
monitoring 
Results 
monitoring 
Objectives 
monitoring
<<<PAGE=38>>>
CARE M&E Guidelines 36 
Chapter 4. Key Concepts 
 
Project Monitoring Activities 
Hierarchy of 
objectives in 
the Log 
Frame    
Monitoring 
activity 
WHO is 
responsible 
WHAT is monitored WHY is it monitored HOW is it 
monitored 
WHERE is it 
monitored 
(source of 
information) 
WHEN is it 
monitored 
What 
format for 
reporting 
(in CARE) 
Final Goal  
(FG) 
Impact, 
Context and  
Assumptions, 
Objectives 
Project staff,  
target 
population, 
other 
stakeholders 
Impact indicators 
(fundamental changes 
for target population, 
e.g., improved standard 
of living); Policy and 
institutional changes 
To assess sustainable 
contribution of IG to 
FG (successes);  
To assess risks,  
constraints, and 
negative outcomes 
Special 
assessments by 
project staff and 
target 
population, e.g., 
case study 
Primary: rural 
households 
Secondary: 
regional 
statistics, other 
institutions 
Annual 
assessments 
and after 
project 
terminated 
Evaluation 
reports 
Intermediate 
Goal (IG) 
Effects, 
Context and  
Assumptions,  
Objectives 
Project staff, 
target 
population, 
other 
stakeholders 
Effects indicators 
(response of target 
population to project 
outputs, e.g., behaviour 
change); Policy and 
institutional changes 
To assess contribution 
of outputs to IG 
(successes);  
To assess risks, 
constraints and 
negative outcomes  
Regular  
assessments by 
project staff and 
target population 
Primary: rural 
households 
Secondary: 
regional 
statistics, other 
institutions 
Annual 
assessments  
 
PIR, API, 
Evaluations 
Outputs Institutional, 
including 
organisationa
l and physical 
issues 
Project staff, 
project 
managers 
Output indicators 
(project products, e.g., 
farmers trained in a 
specific farming skill) 
To assess progress 
being made by project 
in delivery of outputs, 
to assess institutional 
development issues 
Using data 
collected by field 
staff and target 
group from 
monthly reports 
Primary, e.g., 
training units in 
project 
Monthly and 
according to 
level of output 
API, PIR 
Activities Physical  Project staff, 
project 
managers 
Distribution and 
delivery (actual 
compared to planned) 
Scheduling and 
allocation of resources 
Monthly reports 
by field staff 
In the project 
office 
Monthly and 
according to 
level of 
activity 
EARs, API, 
PIR 
Inputs Financial, 
Physical 
Project staff, 
financial 
controller, 
project 
accountant 
Resources for project 
activities (e.g., people, 
materials, funds)  
Scheduling and 
budgetary control 
Expenditure 
reports, by 
category of 
expenditure 
In the project 
office and 
country HQ 
Monthly   EARs, API, 
PIR
<<<PAGE=39>>>
CARE M&E Guidelines 37 
Chapter 4. Key Concepts 
Institutional Monitoring 
Project inputs (i.e., resources required to implement project activities) are 
assessed by monitoring financial information.  Monitoring input data helps keep 
the project management informed of the degree of financial efficiency with which 
the project is operating.   Inputs include physical and human resources (the 
means) and financial resources (the costs).  These data are managed according to 
specific expenditure categories (sometimes called “cost centres”), and are 
reported in regular financial reports (e.g., EARs).   
 
Physical monitoring is carried out to assess progress in the delivery of project 
outputs and activities (interventions) to the target population group(s).  This kind 
of monitoring keeps the project management informed about scheduling, 
distribution (equity), and effectiveness of the project in delivering the outputs and 
activities. Indicators for outputs and activities typically quantify the amount 
delivered by the project, to whom, and within what period of time.  The sources 
of information for physical monitoring include various project records (e.g., 
monthly reports by project field workers) and second-hand information from the 
routine records of other institutions collaborating with the project.   Results of 
physical monitoring are reported in the regular semesterly Project Implementation 
Reports (PIRs).  
 
Many information users are coming to recognise that even when implementation 
is proceeding ‘according to plan’, many projects do not produce their intended 
amount of benefits, or the benefits are not sustained during and after the project.  
Aspects that need to be monitored to track these issues could include the 
following examples: human capacity – staff recruitment, training and turnover;  
organisational linkages – intra-organisational co-operation, inter-organisational 
co-ordination, relations with other public and private institutions, including those 
in the target communities; internal organisation of the project – including function 
of the monitoring and evaluation systems.   
 
Data for financial and physical monitoring are collected on a regular and frequent 
basis throughout the implementation phase of the project, according to the level 
of project activities and outputs.  The team members who are responsible for 
financial and physical monitoring are internal project staff members, such as the 
project manager, the accountant or an administrative assistant.
<<<PAGE=40>>>
CARE M&E Guidelines 38 
Chapter 4. Key Concepts 
Context monitoring  
The assumptions and risks identified in a project log frame are contextual or 
environmental factors that, although beyond the direct control of the project, have 
the potential to significantly affect the implementation of activities and the 
achievement of objectives.  It is important that these factors are assessed on a 
regular basis so that changes in strategy or interventions can be made before 
pending problems become critical.  In general, the indicators for the assumptions 
will relate to the project environment: physical, socio-economic, institutional and 
government policy. 
 
Results monitoring 
Project effects are monitored by assessing the perceptions (opinions and 
reactions) and responses (behaviour change) of the project target population to the 
project outputs.  Such monitoring helps the project to understand the level of 
acceptance (or adoption) of project outputs or interventions among the target 
population.  Indicators that assess effects focus on changes in attitudes and 
behaviours, e.g., changes in farming practices and acceptance of family planning 
methods.  
 
Relatively little impact monitoring generally occurs during the lifetime of a 
project, due to the duration of time necessary for impacts to become manifest and 
measurable.  Some impact monitoring may be carried on as case studies of 
selected sub-groups who are most likely to be affected by the project, e.g., 
farmers who have been actively participating in project-related trainings and 
assistance since the early days of a project.   Monitoring project impacts helps to 
understand whether the strategies of the project are really working in the direction 
of the final goal.  Indicators at this level tend to focus on development, e.g., 
change in household income or consumption patterns, self-reliance, and capacity 
to cope with seasonal fluctuations.  
 
Data about project effects and impacts are collected during periodic monitoring 
assessments and can be either qualitatively descriptive or numerical 
(quantitative).  While the principal source of information is direct interviews and 
observations of target population members, this form of monitoring can also 
include data from routine records of other collaborating institutions.
<<<PAGE=41>>>
CARE M&E Guidelines 39 
Chapter 4. Key Concepts 
Objectives monitoring 
 
The purpose of objectives monitoring includes checking on whether project 
objectives are being achieved or are likely to be achieved within the existing 
circumstances.  Objectives monitoring also means looking into the presence of 
any unanticipated effects/impacts or unwanted side effects (negative 
consequences of the project).  This kind of assessment is mostly done in the 
course of mid-term and final (or terminal) project evaluations, but can also be a 
part of the annual review process.
<<<PAGE=42>>>
CARE M&E Guidelines 40 
Chapter 4. Key Concepts 
EVALUATION  
Evaluation is the periodic assessment, analysis and use of data about a project.  
The main evaluation points in the project cycle are:  
 
The assessment of a selected set of indicators about target 
population conditions after project start-up but before the 
beginning of project interventions.   
 
 
The internal assessment of the performance and progress of a 
project’s development over successive one year periods.  
Usually includes an assessment of effects (target population 
responses to project outputs/interventions) and project 
strategies. 
 
Usually an external (and thus ‘objective’) assessment of a 
project which focuses on its performance, organisational 
capacity, and mid-course corrections to improve achievement 
in the remaining project period.    
 
An external or internal assessment of the effects and impacts 
generated by the project, as well as a cost-effectiveness or 
cost-benefit assessment.  Usually done just before or just after 
the project ends.   
 
An external and in-depth study of the impact of a project on 
the target population.  The preferred interval between project 
termination and an ex-post evaluation is 5-10 years.  Rarely 
done due to lack of donor willingness to fund. 
 
 
Baseline studies rely on the collection of new data. All of the evaluation activities 
after the baseline rely on various combinations of monitoring data, data from 
other organisations, and new data to be collected from the field.   
 
Baseline 
study 
Annual 
review 
Mid-term 
evaluation 
Final 
evaluation 
Ex-post 
evaluation
<<<PAGE=43>>>
CARE M&E Guidelines 41 
Chapter 4. Key Concepts 
Project Evaluation Activities 
Phase of project 
lifespan    
Evaluation 
activity 
WHO is 
responsible 
WHAT is 
evaluated 
WHY is it evaluated HOW is it 
evaluated 
WHERE is it 
evaluated (source 
of information) 
WHEN is it 
evaluated 
Reporting 
Format 
(CARE) 
Start-up Baseline 
study 
Project staff, 
target 
population 
Indicators (OVIs) at 
FG & IG level  
Benchmark for later 
assessment of effects 
and impacts 
Pre-intervention 
descriptive 
survey, often 
quantitative  
Primary: target 
population 
Prior to starting 
implementation 
of  interventions 
Baseline 
report 
Implementation Annual 
review 
Project 
management 
team 
Financial, Physical, 
Effects 
To assess progress and 
strategies  
To keep project on 
track 
To adjust Log Frame 
Using existing 
monitoring 
information 
Annual survey 
Monitoring data,  
Annual and 
semester reports, 
reports of 
diagnostic studies 
Annually API 
Implementation Mid-term 
Evaluation 
Mid-term 
Evaluation 
team  
Organisational 
structure & design 
Physical,  financial 
progress 
Assess effects  
Analysis of risks 
and assumptions 
Assessment of  project 
performance 
Identify possible 
improvements in 
project strategies and 
interventions 
Comparative 
analysis of targets 
and actual 
achievements; 
may include 
qualitative 
interviews 
Annual reports, log 
frames, survey 
reports 
Target population, 
staff, collaborating 
institutions 
Half-way 
through the 
implementation 
phase 
Mid-term 
Evaluation 
Report 
End of project Final 
evaluation 
Project 
management 
or external 
evaluation 
team 
As above, plus  
impacts, cost-benefit 
and sustainability of 
benefits 
Extract lessons learnt 
to improve design of 
on-going and future 
projects 
new survey 
repeating OVIs 
from baseline  
Cost-benefit 
Targets vs. 
actuals 
Document review,  
Household survey, 
Interviews with 
staff, other 
institutions 
At the end of 
the project 
implementation 
phase 
Final 
Evaluation 
Report 
After project  Ex-post 
evaluation 
External 
evaluation 
team 
Detailed study of 
impacts: economic, 
social, 
environmental, 
institutional 
To assess the 
sustainability of 
benefits for target 
population, 
government 
Before and after 
analysis, 
investigation of 
unintended 
impacts 
Review documents 
on general context 
Repeat survey, 
other interviews  
Usually 5-10 
years after 
termination of 
the project 
Ex-post 
Evaluation 
Report
<<<PAGE=44>>>
CARE M&E Guidelines 42 
Chapter 4. Key Concepts 
Baseline study 
The principal focus of the baseline is on collecting and analysing pre-intervention 
data relating to the indicators (OVIs) for the Intermediate and Final Goals (IG, 
FG).  Baselines are done to establish benchmarks for the chosen indicators, i.e., to 
provide data on their initial status so that subsequent monitoring and evaluation 
can assess the effects and impacts of the project for the target population.  The 
baseline also helps to assess the measurability of the selected indicators and can 
be used to fine tune them for future follow-up.  To do this, baselines are carried 
out after the project is designed and funded, but before starting project 
interventions.   
 
If a baseline study can be planned, designed, implemented and analysed in a 
participatory fashion, the commitment of partners (including the target 
population) to the project interventions can be enhanced.  For example, in a recent 
health project baseline that used social mapping (a PRA tool, see Annex 4), a 
community in southern Malawi found that the western two-thirds of one village 
did not use latrines, vs. the eastern one-third where most households had latrines.  
Within three months after the baseline, more than half of the homes that 
previously did not have latrines had now spontaneously built latrines – as a direct 
consequence of  public opinion arising from the baseline.   
 
Very specific and clear objectives need to be established for baseline studies since 
they will be of enduring importance in the project.  See box below about potential 
limitations of baseline studies.  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Potential limitations of baseline studies   
• Collecting excessive and non-specific information that 
is too overwhelming to ever be analysed and used 
• Extracting information and not actively involving 
target population members in planning and 
implementing the assessment; this happens most 
commonly if the approach is a complex quantitative 
survey.  
• Collecting data related to a single point in time, i.e., 
the season and year when the assessment was done; this 
means that subsequent comparison studies need to be 
scheduled at a similar time. 
• Errors in sampling:  the respondents can spoil the 
value of the analysis, e.g., sampling only farmers who 
are particularly likely to be changed by project 
interventions such as farmers with land, or educated 
f
armers who can easily answer a questionnaire.
<<<PAGE=45>>>
CARE M&E Guidelines 43 
Chapter 4. Key Concepts 
 
Annual review 
The annual review is an internal evaluation done by the project management 
team.  It is a form of on-going evaluation because it occurs every year during the 
implementation phase of the project.  The data used in the annual review includes 
most of the kinds of monitoring information: financial, physical, effects, and 
assumptions.   
 
The objective of this evaluation is to assess project progress and performance and 
to keep the project on track towards its objective.  A further objective is to review 
the strategies and log frame of the project and, if necessary, modify the log frame.  
Such modifications are generally limited to the level of activities and some 
outputs.  This connection between Planning, Monitoring and Evaluation is called 
the PME cycle, and it is an annual process.   
 
In the CARE context, this means that the annual review is usually carried out in 
January or early February prior to development of the Annual Implementation 
Plan (AIP) for the coming year.   Each CARE project is responsible for an annual 
review that leads to preparing their AIPs (1.1 - budget; 1.2 - operational plan; and 
1.3 - procurement requests) for every fiscal year.  The Country Office expects that 
these reviews and the associated planning will be conducted as a participatory 
team effort within each project, reflecting on progress and lessons learnt, using 
internal monitoring data and whatever data is available about target population 
responses to the project.  On this latter point, currently, there is no routine, 
CARE-mandated process for collecting new data about the target population in 
the annual reviews.   
 
During the initial stages of the project implementation (i.e., the first two years) 
the emphasis of PME will be mostly on using the data collected to measure means 
and costs relating to project inputs, activities and delivery of their associated 
outputs.  Assumptions and preconditions for project interventions, including 
institutional development may also be tracked.  The evaluation of information 
relating to project effects and impacts is usually premature at this stage.  As the 
project develops the full PME cycle is established.   
 
Analysis of the annual review assessment data is done by comparing monitoring 
data about actual achievements with targets stated in the log frame.  This type of 
comparative analysis facilitates reporting of deviations from targets in actual 
spending and outputs.  A weakness of relying only on information from financial 
and physical monitoring (i.e., meeting physical targets within an accepted degree
<<<PAGE=46>>>
CARE M&E Guidelines 44 
Chapter 4. Key Concepts 
of financial efficiency) does not say anything about the effects of these 
outputs/interventions among the target population.   
 
Diagnostic study 
Occasionally, a more detailed investigation of a particular constraint or 
opportunity for intervention is required to assist the project.  In this case, a 
diagnostic study may be done by the project staff as a one-time activity in order to 
provide additional information.  Although not a regular (recurrent) part of the 
monitoring and evaluation system, the diagnostic study provides a quick and 
significant contribution of information to the project’s planning and management.   
 
Mid-term Evaluation 
The Mid-term Evaluation (MTE) is an external evaluation activity which takes 
place approximately halfway through the project implementation phase.  The data 
analysed and used during the MTE originates from the routine financial, physical, 
effects and assumption monitoring activities.  This information has been reported 
within the project in a number of project documents, including annual reports, log 
frames, and diagnostic studies.   
 
The MTE team aims to identify possible improvements in the nature of project 
outputs/interventions.  These recommendations are based on the understanding by 
the evaluation team of the process by which the project has reached its present 
stage (see box below).  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Mid-Term Evaluation:  
Criteria for assessing project performance   
• the organisational structure, institutional 
development, and capacity building of the 
project  
• the project design, including project strategies 
linkages and lines of collaboration with other 
institutions 
• procurements 
• physical and financial progress 
• target population response to project 
outputs/interventions 
• an analysis of risks and assumptions.
<<<PAGE=47>>>
CARE M&E Guidelines 45 
Chapter 4. Key Concepts 
Final evaluation 
As the project comes to the end of its cycle, a final evaluation is completed by the 
project management team (internal), or more commonly, by an evaluation team 
that includes external persons.  The objective of a final evaluation is to draw upon 
the experiences of the project in order to improve the design of future and on-
going projects.   
 
The data for analysis during this form of evaluation is the same as that in the Mid-
term Evaluation, but it may also include a cost-effectiveness (and sometimes a 
cost-benefit) assessment.  Sources of data for a final evaluation include project 
documents, and discussions with all the different groups of people involved in or 
with the project from its conception.   This includes project target population, 
project staff, regional and national government policy makers, and donors.  
 
Two principal analytical methods used in final evaluations are a)  comparing 
before and after (re-gathering selected indicators originally documented in the 
baseline study, and comparing values at start-up and end-of-project);  b) 
comparing with and without  (assessing selected indicators among groups of 
people who have and have not been exposed to the project interventions).  
Comparative analysis of ‘actuals’ and targets is less satisfactory when it comes to 
assessing effects monitoring data, especially with the more qualitative OVIs about 
target population opinions.   The results of the evaluation are reported in the Final 
Project Evaluation Report (Project Completion Report).   
 
Ex-post evaluation   
This evaluation activity is done approximately 5-10 years after the termination of 
the project and is done by an external evaluation team.   In reality, they are 
seldom done because it is very difficult to find a funder willing to support such a 
study.  The objective of an ex-post evaluation is to assess the sustainability of the 
benefits of the project, both to the rural households/communities and to the 
government and collaborating institutions in the project area.    
 
Sources of data for analysis in the ex-post evaluation include interviews, 
observations, project documents (especially the baseline and final evaluation); 
and reports of any on-going monitoring of the target population (e.g., by 
government counterparts or community agencies).    
 
The ex-post analysis usually includes a detailed study of the project in terms of: 
a) economic impact;  b) social impact;  c) environmental impact;  and d)  
institutional impact.
<<<PAGE=48>>>
CARE M&E Guidelines 46 
Chapter 4. Key Concepts 
Linkages Between Monitoring And Evaluation 
 
Kind of  
information 
 
MONITORING 
ACTIVITIES –   
INFORMATION 
COLLECTION  
When is it 
collected 
(Phase of 
project cycle) 
Frequency 
of collection 
(PY = Project 
Year) 
How 
reported 
EVALUATION 
ACTIVITIES – 
INFORMATION 
USE  
When? 
(Phase of 
project cycle) 
Frequency? How 
reported 
Target 
population 
impacts 
Target population 
impact monitoring 
During 
implementation 
Not often 
done; but can 
start after 
PY2 
PIR Baseline survey 
Final evaluation 
Ex-post evaluation 
(these should 
include repeats of 
baseline survey) 
5 yrs after 
project 
 
End of project 
once (if 
done) 
 
once 
ex-post 
(seldom 
done) 
FER 
Effects 
(target 
population 
responses) 
Effects monitoring  During 
implementation 
Annually 
from PY 2 
PIR, API Annual Review 
Mid-term and  
Final  eval.  
Implement. 
End of project 
 
Annually 
from PY2 
API 
MTER 
FER 
Assumption 
and risks 
Assumption (and 
risk)  monitoring 
During 
implementation 
Annually, 
from PY 1 
PIR Annual Review 
Mid-term eval.  
Implement. Annually 
from PY 1 
MTER 
FER 
Outputs  Physical 
monitoring 
During 
implementation 
Monthly 
from PY1 
PIR, API Annual Review 
Mid-term and  
Final eval.  
Implement. 
End of project 
Annually 
from PY 1 
API 
MTER 
FER 
Processes 
(activities) 
Physical and 
financial monitor 
During 
implementation 
Monthly 
from PY1 
PIR, 
EAR 
Annual Review 
Mid-term and  
Final eval.  
Implement. 
End of project 
Annually 
from PY 1 
API 
MTER 
FER 
Inputs Financial 
monitoring 
During 
implementation 
Monthly 
from PY1 
EAR Annual Review 
Mid-term and 
Final eval.  
Implement. 
End of project 
Annually 
from PY 1 
API 
MTER 
FER
<<<PAGE=49>>>
CARE M&E Guidelines 47 
Chapter 4. Key Concepts 
Design issues in information systems 
As mentioned earlier (see Chapter 2), experience has shown that users of 
information about projects commonly have a number of concerns about the 
quality of the information they are seeking.  General issues about accuracy, 
relevance, timeliness and credibility were reviewed in Chapter 2. Four additional 
issues that require specific information management plans are discussed in this 
section.  These four issues are:  
 
How can we/they be satisfied that results (effects, 
impacts) claimed for the project are actually due to 
project interventions and not to other outside factors? 
 
How can we/they find out whether project resources are 
being used wisely, i.e., obtaining maximum benefits for 
minimum costs? 
 
How do we/they know that the problems being 
addressed are important, and that any effects or impacts 
reported are valuable (fundamental)?  
 
How can we/they know whether any positive impacts 
(or effects) can continue to happen without direct 
project support (financial or otherwise)? 
 
Let us take these critical issues in sequence.   
 
Attribution 
Capacity to assess and show project influence requires planning and specific 
information gathering designs from the very beginning of a project.  A number of 
design strategies are available that can help to demonstrate attribution.   Among 
the main types are the following:  
 
• the ‘with/without’ scenario.  This approach relies on a comparison between 
two distinct groups of people, one of which has received project interventions 
and another community which has not been exposed to the project.  The 
weakness of this approach is difficulty in being sure that the two communities 
are truly equal or similar.  If they are not exactly alike (which is usually the 
case), then it is hard to be sure that any observed effects or impacts in the 
‘with’ community are actually due to project interventions.  Nonetheless, this 
is a strategy commonly used for end of project evaluations because it is 
relatively inexpensive.  
Attribution 
Effectiveness 
Significance 
Sustainability
<<<PAGE=50>>>
CARE M&E Guidelines 48 
Chapter 4. Key Concepts 
  
• the ‘control group’ scenario.  If the with/without arrangement is planned and 
two groups are monitored from the very beginning of the project, the ‘without’ 
group is referred to as a ‘control group’.  The strength of this strategy is that 
attribution of changes to project influence is more clearly demonstrable than it 
is in the other designs.  Changes occurring in the ‘with’ community during the 
life of the project are ‘controlled’ by being able to identify and then subtract 
changes seen in both communities.  Any remaining changes in the ‘with’ 
group can then be assumed to be due to project influence.  In reality, although 
control groups are closer to a scientific ideal, they are expensive and 
logistically difficult to carry out.  They may be most suitable in pilot projects 
or when mandated by a donor interested to clearly determine attribution.   
  
• the ‘before and after’ scenario.  This is a comparison between two distinct 
time periods.  A specific set of information (selected indicators) is collected 
from a representative group of intended beneficiaries (target population) 
before the project has been implemented (i.e., a baseline study is essential for 
this approach) and then compared a similar collection of information at the 
end of the project after implementation (e.g., at the final evaluation).  The 
before and after design is weak in addressing attribution; it also cannot answer 
whether the project target population could have done better without the 
project.   
 
Effectiveness 
The core issue in assessing effectiveness is value for money.   Within CARE, this 
is generally done only at the output level, i.e., assessing cost-effectiveness for 
project products/results that are within the control of the project.  This approach is 
thus able to be done within the lifetime of the project.   
 
A deeper level of assessing effectiveness is a cost-benefit analysis, i.e., comparing 
resource inputs to effects and impacts for the target population.  A major 
weakness in such analyses is a tendency to focus only on numbers to the 
exclusion of many qualitative aspects, e.g., local target population perceptions 
about the significance of the indicators being used.   
 
Significance 
One of the principal design strategies to address this concern is participatory 
planning and management, including participatory evaluation.  The weakness of a 
participatory approach can be the logistical efforts needed to gain and sustain 
active participation.  Other considerations of significance include scale (how
<<<PAGE=51>>>
CARE M&E Guidelines 49 
Chapter 4. Key Concepts 
many people are reached) and replicability (whether or not this model could be 
repeated in other projects in other communities). 
 
Sustainability 
The core concept of sustainability is the continuation of project activities after the 
end of project support.  It may also refer to self-financing (financial 
sustainability) and/or continued flow of support to target populations through the 
resources and initiative of local institutions (operational sustainability).   If a 
specific institution is being enhanced to continue project benefits, then criteria for 
assessing institutional sustainability may include issues of organisational 
maturity, efficiency, effective implementation, consolidation, and financial 
viability.  Another dimension of sustainability relates to environmental impact.  
Are the practices promoted by the project in harmony with ecological 
considerations, or do they deplete natural resources? 
 
It is important to be clear about what element(s) of sustainability are being 
assessed, and what are the indicators of these aspects.  For example, in an ANR 
project, the assessable aspects of sustainability can include:  
• maintenance of a certain project activity (reflecting sustained demand for a 
service, as well as financial sustainability and the sustained provision of that 
service; i.e., effects on the farmers and the system) 
• adoption by farmers of a specific technology (sustained use, effects at the level 
of the individual farmer) 
• an extension system that allows farmers to continue to identify new 
technologies (sustained feasibility, capacity, and effects of institutional 
development) 
• productivity of the farming system (sustained effects) 
• environmental impact 
• impact on household livelihood security.   
 
Many projects focus on the first two levels in the above list.  Other ANR experts, 
however, feel that these issues are actually of lesser significance than the lower 
levels in the long run.   
 
An ultimate design strategy for assessing beneficiary sustainability is to do an 
‘ex-post’ evaluation on the target population several years after the project has 
ended.  Impacts that continue to be demonstrated after such long intervals show 
that changes in the community were fundamental and ‘sustained’.  Two major 
weaknesses in this strategy are the duration of time before getting information 
about sustainability and the rarity of any donor being willing to fund an ex-post 
evaluation.
<<<PAGE=52>>>
CARE M&E Guidelines 50 
Chapter 5. Planning for Usable Information 
CHAPTER 5   
 
What needs to be included in 
detailed project planning in 
order to have the desired 
information at the right time 
in usable form?   
 
 
Responsibility for M&E 
Projects have a responsibility to identify a process that ensures the design of the 
M&E system is both appropriate and sustainable for its providers and users.  
When we are assessing the resources required to operate an M&E system, we 
need to assess the means and costs of collecting, managing and analysing the data 
against the value of the ‘end product’, i.e., the usefulness of the information 
produced.  The requirement is for an M&E system which is sustainable, i.e., able 
to be operated and managed by collaborating institutions, their staff and the 
project target population.  Achieving sustainability has implications as far back as 
the project preparation phase when the OVIs are first identified and described. 
 
This process involves the active participation by all the people who have an 
interest in the information contained within the system.  The providers of data 
collected, and those responsible for its ‘input’ into the system via the project 
monitoring activities, are invariably among the users of the information ‘output’ 
from the system.  There is an obvious causal relationship between the quality of 
data ‘in’ and the information ‘out’.  If the M&E system is deemed as useful 
among the target population during the implementation phase, the chances are 
good that it will also be sustainable.  A well-designed participatory M&E system 
should represent one of the benefits of the project. 
 
Participation involves not only giving people opportunities to become involved 
with planning and M&E, but it also means empowering those people to influence 
the final outcomes or decisions based on the information generated.  The 
following box is a short checklist that can be used for assessing the participatory 
aspects of a project M&E design.
<<<PAGE=53>>>
CARE M&E Guidelines 51 
Chapter 5. Planning for Usable Information 
 
 
Checklist for assessing participation in M&E design 
[ ]  Has it been designed with participation of all stakeholders?   
[ ]  Does it involve the target population?  
[ ]  Can it be fitted into the activities of collaborating agencies?  
[ ]  Do the staff (and community) responsible for M&E have the  
      necessary skills?  
[ ]  Is it going to be sustainable for the duration of the project?  
[ ]  Can it be sustained by other groups after the project is ended? 
 
 
 
Pre-project planning for M&E 
Ideally, thinking about the M&E system for a project should start at the stage of 
appraisal and project design, not when the project has already been approved and 
implementation has begun.  There are four important reasons for this, as shown in 
the box below:  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
When consideration for M&E is not included from the earliest point in project 
planning the M&E systems may be constrained by the design of the preliminary 
assessments.   The possible limitations include lack of specificity in the project 
log frame (e.g., vague project objectives and outputs, or unclear indicators and 
means of verification), and designs for information management that simply 
Reasons for early planning of project M&E 
• Concern about M&E encourages clearer thinking 
and a more refined statement of the project 
objectives, assumptions, indicators and activities.  
• Adequate provision can be made at the outset for 
meeting the cost of M&E 
• M&E can be built from the start into the various 
project components 
• Information users (including target population 
members) can participate in designing an 
appropriate M&E system that is acceptable and 
useful for their needs, not just for project and 
donor use.
<<<PAGE=54>>>
CARE M&E Guidelines 52 
Chapter 5. Planning for Usable Information 
extract data without actively involving the target population in planning and 
implementation of the system.  
 
Planning for M&E in an existing project 
The optimal time for creation of a full M&E plan for a project is after funding, 
but before the initial baseline and start-up of interventions.  All too often, 
however, the reality is that projects are faced with creating their M&E plan when 
they realise that, although implementation is occurring, information is not 
flowing.  
 
Project documents (and their ‘log frames’) are an important tool for project 
management, but they do not usually contain sufficient detail when it comes to 
information systems.  Log frames do list some essential items for planning 
information management: desired information (as ‘objectively verifiable 
indicators’) and sources of information (as ‘means of verification’).   These two 
categories, however, do not include any answers for the following key questions: 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Recognising that the log frame does not provide enough detail by itself for 
creating the M&E plan, it is necessary to develop a strategy for generating the 
missing elements.  A useful way to do this is to prepare and complete an 
Monitoring and Evaluation Planning Matrix that expands the Log Frame matrix to 
include the key elements of an M&E plan (see chart on next page). 
Key information system requirements  
not included in standard Log Frames 
• How will the information be gathered?  Who will 
collect it?  When will it be obtained?   
• How will the gathered information be analysed?  
Who will analyse it?  When will the analysis be 
done?   
• Who will receive the results?  In what format will 
they be distributed?  And what decisions in (or 
about) the project are dependent on getting the 
analysed information?
<<<PAGE=55>>>
CARE M&E Guidelines 53 
Chapter 5. Planning for Usable Information 
Monitoring and Evaluation Planning Matrix (expanding beyond the Log Frame) 
Objectives OVIs Means of verification (MOV)  
Hierarchy 
of 
Objectives  
Indicators  Sources of 
information 
Method for 
data 
collection 
Method for 
analysis of 
data 
Type of 
activity: 
monitor, 
evaluation 
Frequency Application 
(expected 
uses) 
Circulation 
(expected 
information 
users) 
 
 
 
 
 
 
 
        
 
Operational definitions for the table:  
• Objectives - hierarchy of objectives in the log frame (e.g., Final Goal, Intermediate Goal, Output, Activity) 
• Indicators - details about exact information desired; clarify meanings of vague terms; link to impact, effect, output 
levels 
• Methodology - what specific sources of information (which records located where, what persons to interview); which 
data gathering methods, what tools, who to collect the data, and when; which means of data analysis, who to do, and 
when 
• Type of M&E activity - regular monitoring, or periodic evaluation (or one-off diagnostic study)  
• Frequency - how often will information about each specific indicator be gathered 
• Application - what anticipated uses for the information, what decisions will be influenced by the results  
• Circulation - information  users; dissemination, who should get the information and analyses, and in what form
<<<PAGE=56>>>
CARE M&E Guidelines 54 
Chapter 5. Planning for Usable Information 
Below are two examples from completed M&E matrices of CARE projects done at the Kabale ’96 M&E workshop.  The 
extracts here show only one indicator at the IG level for each project.  
 
Community Reproductive Health Project 
 
IG:  Increased Number of Women Seeking Maternal Health Services at a Health Facility 
 
Indicators Sources Methods Who Data 
Analysis 
Who/Why M or 
E 
Frequenc
y 
Application Circulation How 
 
% of all 
deliveries in 
project area 
attended by 
trained health 
worker  
 
 
Original Sources
 
• HMIS (DMO) 
• CRHW 
records 
• CREHP clinic 
• CRHW data 
 
 
 
New Sources
 
• Community 
women 
having birth 
in past year 
• LC3 health 
committees 
• Women 
bringing 
babies for EPI 
• TBAs 
 
Review 
records,  
census 
projections 
 
 
 
 
 
Survey 
 
Group 
meetings 
 
Key 
informants 
 
Focus 
groups 
 
Project 
M&E 
person 
 
 
 
 
 
 
 
Project 
team,  
Partners 
 
Counterpart 
 
NGOs 
 
Community 
workers 
 
Quantitativ
e 
tallies and 
trends 
 
 
 
 
 
 
Quantitativ
e 
correlation 
 
Triangulate 
 
Qualitative 
patterns, 
ask and 
answer 
why? 
 
Project 
M&E person 
 
 
 
 
 
 
 
Project team 
and partners 
for 
interpreting 
meaning 
 
 
 
 
Mon. 
 
 
 
 
 
 
 
 
Eval 
 
Monthly;   
Quarterly;  
Semi-
annually;  
Annually 
 
 
 
 
Baseline;  
 
 
 
Mid-term; 
 
 
Final 
 
 
Assess trends: 
are we on 
track?  If not, 
why?  Make 
adjustments;  
Comparative 
assessment 
 
 
Set 
foundation for 
measuring 
change 
 
Assess 
strategy 
effectiveness 
 
 
Assess project 
effects 
 
Direct 
partners;  
CARE HQ 
CARE USA 
Donor - 
USAID 
 
 
 
Partners; 
CARE; 
Donors;  
Interested 
groups 
 
Reports, PIRs, 
API 
 
 
 
 
 
 
 
 
Group 
meeting:  
presentation 
with support 
graphs, tables, 
maps, 
discussion 
Informal 
meetings,  
radio 
programmes
<<<PAGE=57>>>
CARE M&E Guidelines 55 
Chapter 5. Planning for Usable Information 
Bushenyi-Ntungamo Agricultural Innovations Project  
 
IG: 700 Participating rural HHs in Bushenyi and Ntungamo achieve significant increase in agricultural production through environmentally sound practices by 1999 
 
Indicator Sources of 
information 
Methods of 
data 
gathering 
Who Data 
analysis 
Who Type 
of 
M&
E 
Frequency Application Circulation How 
Percent (%) of 
participating 
poor rural HHs 
practising one 
or more project 
promoted 
environmentally 
sound 
agricultural 
practices 
‘Contact’ 
farmers 
 
 
 
Participating 
HHs 
(farmers) 
 
 
Participating 
HHs 
(farmers) 
 
 
 
Community, 
all farmers 
 
 
 
 
Interviews of  
a sample of 
contact 
farmers 
 
Update records 
of 
participating 
HHs 
 
 
Observation of 
a sample of 
farmers with 
checklist 
 
 
Update of 
social map 
with farmers, 
community  
Field 
officers, 
FEWs 
 
 
FEWs 
 
 
 
 
Field 
officers, 
FEWs 
 
 
 
Field 
officers, 
FEWs 
Qualitative; 
advantages, 
disadvantage
s 
constraints 
 
Quantitative:  
tallies, 
proportions 
 
 
Qualitative 
and 
quantitative 
achievements 
 
 
Quantitative: 
tallies, 
distribution 
Qualitative: 
explanations 
Field officer,  
M&E person 
 
 
 
Field officer,  
M&E person 
 
 
 
Field officer,  
M&E person 
FEWs 
 
 
 
Field officer,  
M&E person, 
FEWs, 
farmers 
Mon 
Eval 
 
 
 
Mon 
 
 
 
 
Eval 
 
 
 
 
 
Eval 
Monthly 
 
 
 
 
Monthly 
 
 
 
 
Twice a 
year  
 
 
 
 
Twice a 
year  
 
 
Track 
achievements 
 
Reassess 
strategy 
 
Modify 
interventions 
if necessary 
 
Project staff 
District officials 
CARE 
Community 
Narrative 
reports 
 
Tables 
 
Histograms 
 
Maps 
 
Photographs 
and sketches 
 
Examples of  
pages from 
farmer’s 
records 
(scanned or 
photocopied)
<<<PAGE=58>>>
CARE M&E Guidelines 56 
Chapter 6. Indicators 
CHAPTER 6   
 
Indicators - what do we (or the 
users) specifically want to 
know about projects? 
 
 
Indicators 
Indicators are qualitative or quantitative criteria used to check whether proposed 
changes have occurred.  In the context of the log frame, indicators (column 2) are 
defined as specific (explicit) and objectively verifiable criteria which can be used 
to assess whether the objectives (column 1) have been met. In other words, 
indicators are designed to provide a standard against which to measure, or assess, 
or show, the success or progress of a project against stated targets.   
 
While indicators can be used to assess progress toward project targets, the 
indicators are not the same as targets. Targets specify desired results within a 
specified time span (e.g., 700 farmers trained in compost mulching techniques 
within 3 years, or 50 community health workers trained in each of 4 districts 
within the first year of a project); but there can be targets that apply to inputs, 
outputs, effects or impacts.  As used in the CARE log frame format, indicators are 
assessments of progress towards achieving desired changes in the target 
population, i.e., reaching intermediate or long-term objectives.  Indicators are not 
generally presented as numerical targets in themselves.  Some donors, however, 
do vary in their degree of separating or merging indicators and targets (see Annex 
5). 
 
The five main types of indicators used in project monitoring and evaluation 
correspond to the main levels in the project hierarchy of objectives.  By objective 
level, the corresponding indicators are shown in the following table:
<<<PAGE=59>>>
CARE M&E Guidelines 57 
Chapter 6. Indicators 
Types of indicators by objective level 
Hierarchy of 
objectives 
Indicator 
type 
Description of indicator 
type 
Examples 
Final goal Impact assess actual change in the 
conditions of the basic 
problem identified; shows 
changes that are 
fundamental and 
sustainable without 
continuing project support 
• household livelihood 
security levels, as 
shown by measures of 
health, nutrition, 
education, community 
participation and 
economic security 
Intermediate 
goal 
Effect describe target population 
responses to project 
outputs, e.g., behaviour 
change, reactions and 
perceptions; systemic 
changes in institutions 
• % of households in 
target area using 
improved fuel-
conserving stoves 
• number of health units 
with a cost-sharing 
system 
Outputs Output describe project products, 
i.e., the direct outcome of 
project activities and 
inputs for which the 
project is responsible 
• number of health 
workers trained in FP 
services 
• number of farmers 
trained in proper 
handling of pesticides 
Activities Process describe project activities 
(or processes) 
• number of trainings 
held 
Inputs Input describe what resources go 
into the project 
• number of TBA kits 
provided 
• number of staff 
supported by project 
 
 
Indicators and information users 
Data about inputs and activities are essential for the day to day job of the project 
manager.  The project can follow these levels through ‘process indicators’.  For 
example, the project manager needs to know the number and kinds of training 
courses in a specified time period in order to budget for the required activities, 
prepare training materials, etc.   
 
Once the project activities are started, the project will be able to measure output 
indicators (e.g., the number of providers trained).  Output indicators will tell the 
project manager how close the project is to achieving the expected targets.  At the 
same time, output indicators permit managers and programme offices to track 
trends for achievements, and to spot difficulties indicating the existence of
<<<PAGE=60>>>
CARE M&E Guidelines 58 
Chapter 6. Indicators 
problems needing attention.  Output indicators should come from the routine 
information gathering (i.e., monitoring) activities required of all projects.   
 
In contrast, effects indicators showing the interaction of project products and 
community responses will require other means for data collection than routine 
monitoring of daily activities.  They need more probing methods, such as 
evaluation surveys and qualitative or participatory approaches.  Effects data is 
useful for project managers, country directors, regional managers and the 
international headquarters.   
 
Finally, indicators are needed that will permit analysis of the project’s impact on 
the household and household members, as well as at the institutional level.  This 
dimension will usually not be clear enough for reliable assessment until several 
years after an intervention is implemented (e.g., 5-10 years after project start-up).  
This information is critical to government, to donors, and to CARE’s Board for 
setting direction and long-range strategic plans. 
 
Issues affecting selection of indicators  
Although not their exclusive information need, donors always ask for some 
numbers (i.e., ‘quantitative’ information).  Project logical frameworks written to 
meet donor requirements tend to support this number-crunching orientation.  
Fundamental and sustainable changes in people’s lives are a ‘final goal’ that is 
rarely measured.  Providing information on numbers of people reached, number 
of trainings, etc. is easier than assessing deeper changes in people’s lives.  For 
these reasons, both donors and NGOs have been more comfortable with measures 
of project effectiveness than project impact.  It is only recently that donors have 
begun to ask about effects and impacts that are best illustrated in words or 
pictures (i.e., ‘qualitative’ information). 
 
Input and output indicators are easier to assess than effect or impact indicators, 
but the ‘lower’ level indicators only provide an indirect measure of the success of 
a project.  To use them, one has to assume that the achievement of certain 
activities will automatically result in positive changes (e.g., desired effects and 
impacts), but the lower level indicators cannot demonstrate the reality of such 
change.   On the other hand, however, it can take many years for impacts to 
become measurable when looking at the target population as a whole.  For this 
reason, it is sometimes appropriate to make qualitative preliminary assessments of 
the direction and nature of impacts by doing cases studies of selected households 
within the lifetime of the project.
<<<PAGE=61>>>
CARE M&E Guidelines 59 
Chapter 6. Indicators 
Measuring cost-effective use of inputs and overall project effectiveness will 
always be important.  Donors want to know how their money has been spent and 
ensure that activities are in line with those outlined in the project agreement.  
However, there is an increasing recognition that measuring impact is also 
important, although difficult.   It is difficult because it is necessarily subjective, 
and because one has to wait so long to identify changes that qualify as impacts 
(fundamental, sustainable, and attributable to the project).  Quantitative 
information alone cannot adequately assess impact level changes in people’s 
lives.  Moreover, changes that development workers expect may not be the 
changes that the members of the target population desire.  It is important to 
recognise differing perceptions of reality.    
 
Ultimately, the selection and nature of indicators for a project should be guided 
by the nature of the objectives and the intended effects and impacts of the project.  
The first step, therefore, is a clear and unambiguous statement of the hierarchy of 
objectives: short-term, intermediate, and final goals.  These may pertain to short-
term achievements, such as construction of wells (outputs), or changes in 
behaviours among the target population (intermediate goal), such as starting a 
small enterprise.  Or they may be long-term impacts such as the eradication of 
rural poverty or better health of the target population (final goal).  
 
There is little conceptual problem with outputs and effects, which are generally 
straightforward and directly measurable, but concepts such as poverty and health 
are not easily assessed.  For instance, with health, it is first necessary to specify 
the exact aims of the given project: better health status of the target group as a 
whole or specifically for women and children; prevention of specific diseases or 
improved health care services; or all of these.  Depending on the specifications, 
appropriate indicators can be selected.   
 
Criteria for selection of ‘good’ indicators 
While the choice of indicators is a matter of common sense, or of experience and 
knowledge of statistical data sources, certain basic criteria can be applied.  At the 
Kabale ’96 workshop, the participants prioritised the following criteria to assist in 
selecting good indicators:
<<<PAGE=62>>>
CARE M&E Guidelines 60 
Chapter 6. Indicators 
Priority criteria for indicators  
 
The indicators should be directly linked to the project 
objectives, and to the appropriate levels in the 
hierarchy.   
 
The indicators should be capable of being assessed (or 
‘measured’ if they are quantitative).  
 
 
The indicators should be verifiable and (relatively) 
objective; i.e., conclusions based on them should be the 
same if they are assessed by different people at different 
times and under different circumstances. 
 
People in the project should be able to understand and 
use the information provided by the indicators to make 
decisions or improve their work and the performance of 
the project. 
 
The steps for working with the indicator should be 
capable of being carried out with the target community 
and other stakeholders in a participatory manner: i.e., 
data collection, analysis and use. 
 
Other criteria which can also be helpful in selecting indicators include the 
following:  
• comprehensible - the indicators should be worded simply and clearly 
so that people involved in the project will be able to understand them.  
• valid – the indicators should actually measure what they are supposed 
to measure, e.g., measuring effects due to project interventions rather 
than outside influences. 
• sensitive – they should be capable of demonstrating changes in the 
situation being observed, e.g., measuring the GNP of Uganda doesn’t 
tell us much about the individual households in one district.   
• cost-effective – the results should be worth the time and money it costs 
to collect, analyse and apply them. 
• timely – it should be possible to collect and analyse the data reasonably 
quickly, i.e., in time to be useful for any decisions that have to be made.  
• ethical – the collection and use of the indicators should be acceptable to 
the communities (target populations) providing the information.   
Relevant 
Technically 
feasible 
Reliable 
Usable 
Participatory
<<<PAGE=63>>>
CARE M&E Guidelines 61 
Chapter 6. Indicators 
 
Few indicators fulfil all these criteria.  But they may still indicate direction and 
general magnitude, thereby assisting in comparisons over time or among different 
areas or groups of people at a point in time.   
 
Choice of appropriate indicators is an art that requires experience and skill.  It 
requires thorough understanding of the information needs of project management 
and information users at different levels.  Choosing indicators also requires 
knowledge of how best to obtain (and analyse) the data for the indicators, and of 
the limits imposed by both costs and techniques.   
 
Thus, infant mortality rate (or maternal mortality rate) may be a suitable indicator 
to monitor health in countries with comprehensive systems for registering vital 
statistics, i.e., births and deaths.  It may be quite unsuitable for project monitoring 
where the target population is relatively small and/or where the data must be 
obtained by a household survey.   
 
Similarly, agricultural production may be relatively easy to measure in a country 
like Malawi that has Ministry of Agriculture staff to collect crop data and the 
country relies on one staple food (maize).  In contrast, it can be very difficult in 
Uganda to ensure enough staff in order to monitor so many crops and varied 
times of harvesting; the only option may be the unreliable one of expecting 
farmers to keep their own records.   
 
How indicators can be improved 
Project staff responsible for developing an M&E plan may need to improve the 
indicators presently in the log frame, or to reassign them to different levels in the 
hierarchy of objectives.  The box on the next page gives some examples of how to 
fix inappropriate indicators.
<<<PAGE=64>>>
CARE M&E Guidelines 62 
Chapter 6. Indicators 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
The chart on the next page shows how the Kabale ’96 M&E workshop 
participants modified some existing indicators from two CARE projects their 
reasons for doing so, based on the criteria for good indicators previously defined.
Finding and fixing inappropriate indicators - some examples 
 
Does the indicator get to the heart of the issue reflected in the Intermediate goal (IG)?  Is the 
indicator valid?  Does it measure (or assess) what it is supposed to?   
IG:  By December, 2005, a functioning and sustainable benefit-sharing programme between the 
Bwindi National Park and surrounding communities, and between the state farms and 
surrounding communities will exist.   
Indicator: 20% of sampled households will participate in income-generating activities.   [Problems: 
indicator not clearly linked to goal, expressed as target] 
Better indicator: % of communities within X km border zone around Bwindi Park with self-funded 
natural resource programmes in place for at least XX (time).   
 
Is the IG level (‘effect’) indicator statement actually at an activity or output level of the project?  
IG: 60% of families in project area will have adopted appropriate farming techniques.  
Indicator:  % of families that have received training in better agricultural methods.   [Problems: 
output level, non-specific statement] 
Better indicator: % of target families that have adopted mulching banana stems for weevil control.  
(i.e., a specific agricultural method) 
 
IG: Improved access to clean water for target population through repair of old pumps, installation of 
new pumps and hygiene education.   
Indicator:  Re-assessment of existing water systems completed.   [Problems: activity level] 
Better indicator: % of identified old pumps repaired by local water committees after project-
supported training.     
 
Is it relevant to the project environment?  
IG:  To increase the proportion of youth in Kabale (Arua, Mbale, Kampala) who will be able to 
practice STD/HIV prevention and control by 1999.   
Indicator:  Percentage of participants who are able to name a virus as the cause of AIDS.    
[Problems: knowledge does not equal skill; this knowledge may not be essential] 
Better indicators:  
♦  % of randomly sampled youth (15-20 years old) who are able to recognise a condom (and 
condom packet) and describe its use.  
♦  % of randomly sampled youth who are able to dress a condom properly on a wooden condom 
demonstrator.
<<<PAGE=65>>>
CARE M&E Guidelines 63 
Chapter 6. Indicators 
Applying Indicator Skills to BAIP and CREHP 
CREHP    IG: Increased number of women seeking maternal health services at health facility.   
Original indicators: Modified Indicators  Changes made and reasons  
Women delivering under  trained care 
from 24%-45% of all pregnant women in 
the project area 
% of all deliveries in the project area 
attended by trained health worker  
• Target taken out 
• Simplified/clarified language 
 
# of women attending ante-natal services 
at least once in a given pregnancy 
% change in women attending ANC at 
least once in a given pregnancy 
• Indicator measured in % instead of # because % may be easier to 
measure 
# of women referred early to and seeking 
for services from health units in order to 
prevent obstetric complications 
# women referred early to prevent 
obstetric complications 
 
# of women referred who actually seek 
services 
• Simplified language 
• “referred early” and “seeking services”  were separated; the first 
is at the output level and within  control of the project, while the 
second is at the effect level and is less within the control of the 
project 
BAIP   IG: 7000 Participating rural HHs in Bushenyi and Ntungamo Districts realise significant increase in agricultural production through environmentally 
sound practices by 1999 
At least 60% of the participating poor 
rural farm HHs will practice 
environmentally sound agriculture by 
1999 
% of participating poor rural HHs 
practising one or more project promoted 
environmentally sound agricultural 
practices 
• Target (60% and year 1999) removed  
• Indicator made more specific: (“one or more environmentally 
sound practices”) 
At least 25% of the participating HHs 
have increased their marketable produce 
by at least 20% by 1999 
% of participating poor rural households 
with production increased by at least 20% 
for any of the following: (milk, bananas, 
etc.) 
• Target removed  
• Indicator made more specific to help measurability (i.e. produce 
is defined by item, and only significant items are selected – 
instead of all crops including minor ones) 
• “marketable” deleted because  IG aims at overall production, not 
just marketable crops 
At least one functional marketing group 
is formed in each sub-county reached by 
the project. 
# of active marketing groups formed by 
participating HHs 
 
 
• Target of “one group” removed 
• Indicator made more specific:  identifying who forms groups 
• The vague word “functional” replaced with “active” to increase 
measurability
<<<PAGE=66>>>
CARE M&E Guidelines 64 
Chapter 6. Indicators 
Technical considerations 
 
Numbers vs. Percentages:  
The goals (which include targets) and the corresponding indicators should be 
consistent in terms of using numbers or percentages (%).  For example, in a 
reproductive health project in a rural area of Uganda, the total numbers of 
pregnant women may be very difficult to assess; therefore, framing targets and 
indicators in terms of  the proportion (%) of those attending antenatal clinics may 
be more manageable.   
 
However, it can also be important to consider the value of using both numbers 
and percentages.  Continuing with the above example of a reproductive health 
project, it is important to remember that due to the natural growth of the 
population, there are increasing numbers of girls becoming reproductive age 
adults each year.  Since the total population of reproductive age women in the 
project area is rising every year, if the proportion (%) of women served remains 
the same, in fact, the project is likely to be reaching increasing numbers of 
women.  Therefore, it can be important to document both numbers and 
percentages in order to describe project achievements (or target population 
needs).  
 
Aggregation of Data:  
An important factor affecting the cost of data collection and the method of 
analysing any indicator is the level of the data collected.  Indicators may be 
aggregated (pooled or combined) at the national level, derived from national 
sources and only applicable at this level.  An example is the gross national 
product (GNP) derived from national accounts.  A second category of aggregate 
indicators comes from the local level (community, village, district).  Examples are 
the availability of medical facilities or schools in each village/district and their 
condition.  A third category of indicators is based on households or individuals, 
usually obtained through a census or survey.  The extent of literacy and the height 
and weight of children are examples.   
 
By and large, aggregate indicators are easier to collect than household indicators, 
but because they cannot readily be disaggregated (e.g., separated by gender, age, 
or specific community), distribution data cannot be obtained from them and their 
utility is very limited.  Hence, we cannot use GNP to arrive at the gross product 
for a district, or for the poor.  On the other hand, household data can be 
disaggregated, but they are generally costly to collect.
<<<PAGE=67>>>
CARE M&E Guidelines 65 
Chapter 6. Indicators 
As far as possible, the indicators selected should be separable by gender, income 
group, etc., in line with project objectives.  Disadvantaged groups such as the 
rural poor and women cannot receive equitable benefits from development 
projects unless they are specified as target populations with strategies indicated 
whereby their disadvantaged status can be overcome and their conditions 
monitored.  Aggregate indicators cannot achieve this; indicators based on the 
household or the individual are required to provide data separately for men and 
women or for socio-economic categories such as the poor or landless.   
 
Direct vs. Proxy Indicators:  
Indicators may be direct, such as reported personal statements by reproductive 
age women about use of family planning methods including condoms, or indirect 
(proxy), such as the number of condoms sold or distributed in a community.  
Indirect indicators are useful where direct measurement is not feasible or cost 
effective.  A good example of applying proxy indicators is estimating income 
based on nature and size of assets, type of house construction, or expenditure 
patterns – because few people are willing or able to accurately report their income 
from all sources.  
 
Precision requirements:  
Both indicators and related information requirements should be periodically 
reviewed to take into account changing needs or ways to improve data quality.  
For each indicator, we must consider the degree of precision needed in the 
measurement and whether we can achieve it.  For example, it might do little good 
to measure performance if our measures are so gross that we cannot tell whether 
the standards have been met.  In this connection, indicators already in use, or 
indicators used in other projects, should be reviewed before new ones are 
considered. 
 
Nature of information required:  
In addition to considerations about indicators by the various categories above 
(hierarchy of objective, qualitative or quantitative, direct or proxy), it can also be 
useful to consider the intended content of the indicators.  The following chart 
shows nine types of indicators classified by expected content.
<<<PAGE=68>>>
CARE M&E Guidelines 66 
Chapter 6. Indicators 
Common Types of Indicators 
Indicator 
types 
What they show Examples 
Indicators 
of 
availability 
These show whether 
something exists and if it is 
available.   
Whether there is one trained local 
worker for every ten houses. 
Indicators 
of relevance 
These show how relevant or 
appropriate something is. 
Whether new stoves burn less fuel 
than the old ones. 
Indicators 
of 
accessibility 
These show whether what 
exists is actually within 
reach of those who need it. 
A health post in one village may 
be out of reach of other villages 
due to mountains, rivers, lack of 
transport or poverty. 
Indicators 
of utilisation 
These show to what extent 
something that has been 
made available is being used 
for that purpose. 
how many non-literate villagers 
attend literacy classes regularly. 
Indicators 
of coverage 
These show what proportion 
of those who need something 
are receiving it. 
of the number of people estimated 
to have tuberculosis in a given 
area, what % are actually 
receiving regular treatment. 
Indicators 
of quality 
These show the quality or 
standard of something. 
whether water is free from 
harmful, disease-causing 
substances or organisms.  
Indicators 
of effort 
These show how much and 
what is being invested to 
achieve the objectives. 
how long it takes how many men 
to plant what number of palm 
trees in a week. 
Indicators 
of efficiency 
These show whether 
resources and activities are 
being put to the best possible 
use to achieve the objectives. 
the number, frequency and quality 
of supervisory visits after 
introducing bicycles to replace 
heavy vehicles. 
Indicators 
of impact 
These show if what you are 
doing is really making any 
difference. 
after a campaign against measles, 
does the incidence of measles 
reduce over the next several years  
 
[Feuerstein, 1986] 
 
The bottom line:   
Would the information be ‘nice to know’, or do we ‘need to know’?   The 
temptation to collect data merely for the sake of interest (or ‘it might be useful 
someday’) should be resisted.  If there is a serious doubt as to whether an item 
should be collected or not, the general rule is to leave it out.
<<<PAGE=69>>>
CARE M&E Guidelines 67 
Chapter 7. Sources and Samples 
CHAPTER 7 
   
Means of Verification: where 
can we find the information 
we need (sources)?   
And how can we be sure that 
the information is 
representative (sampling)?  
 
 
This chapter (and the next two chapters after it) deal with the third column in the 
project logical framework, the ‘Means of Verification’ (MoV).  The MoV column 
is a very important column for monitoring and evaluation, but may not have been 
recognised as such until the real M&E planning begins.   
 
The Means of Verification is often interpreted by log frame planners to only mean 
‘sources’ of information.  In actual fact, it refers to a much broader set of issues 
related to assessing the project indicators (OVIs) which need to be expanded in 
the M&E planning process.  The key elements are:  
 
Where the information comes from (e.g., people, 
institutions, documents, etc.).  As it is generally not 
feasible to talk with everyone involved with a project 
(all target households, all stakeholders, etc.), strategies 
are 
usually necessary for getting information from a ‘representative’ sample of the 
complete set of potential information sources.  (See later section in this chapter) 
 
Sources of 
information
<<<PAGE=70>>>
CARE M&E Guidelines 68 
Chapter 7. Sources and Samples 
 
How the information about the indicators is 
actually obtained (e.g., documents review, 
interviews, participatory mapping exercises with 
the community, focus group discussions, farmers’ 
self-maintained records, etc.).  (see Chapter 8) 
 
How the collected information is consolidated, 
described, and interpreted in order to make it 
useful.  (see Chapter 9)   
 
 
How the information is prepared for 
application/use and circulation to information 
users.  (see Chapter 10) 
 
 
Major sources of information 
Sources of information may be classified as either primary or secondary. Primary 
sources refer to people or places where one can obtain new information (not 
previously existing).  Secondary sources refer to information which has already 
been gathered (possibly for reasons other than the purposes of the present 
assessment). 
 
Pre-existing information (secondary data) 
The term ‘secondary data’ refers to information which is already existing, i.e., it 
has been previously gathered by some other person or organisation.  Secondary 
data includes many kinds of written and visual materials, e.g., reports of previous 
surveys, maps, organisational archives, aerial photographs.   
 
Quantitative (numerical) data may be obtainable from the records of government 
agencies and other institutions.  District or national statistical offices may have 
extensive data on file which can be obtained for diagnostic studies and impact 
evaluations.  Qualitative (descriptive) information may be available from 
universities or other research institutions.  Secondary sources also include the 
project reports and documents that have been produced for other purposes, e.g., 
reports of training workshops, or monthly reports of field staff. 
 
Obtaining data from secondary sources is obviously cheaper and easier to access 
than going out to the field to gather fresh information.  Therefore, gathering and 
Methods of data 
collection 
Methods of data 
analysis 
Methods of 
dissemination
<<<PAGE=71>>>
CARE M&E Guidelines 69 
Chapter 7. Sources and Samples 
using secondary data should generally be considered as a first option when it is 
available.  That said, however, all secondary data must be used with caution 
because it has certain inherent disadvantages (see box below). 
    
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
New information (primary data) 
Primary data is obtained by going to the field to collect new information, i.e., it 
requires that a specific study be planned and carried out.  Typically, primary data 
is needed for monitoring, as well as baseline, final and ex-post evaluations.  Data 
gathering can be done by various methods, e.g., rapid observation by a team of 
trained observers (who can include staff, target population, and other 
stakeholders); sample household surveys by enumerators and field staff; or in-
depth case studies by skilled teams.  (see Chapter 8) 
 
One of the big advantages of arranging for primary data is that the project has 
control over what data is gathered, as well as when and how the information is 
collected.  In this way, it is easier to maintain control over quality of information, 
and to do follow-up for any critical findings or missing information.   
Potential limitations of secondary data include:  
• Inadequacy:  If the necessary data is not in the 
existing reports, it is usually not possible to go back 
to the same sources to get the missing information.  
• Potential for poor quality:  Secondary data is 
collected by others, and sometimes the means and 
circumstances of data collection are not recorded.  
Thus, the project using the secondary data may not be 
sure how it was collected and has no control over its 
quality.   
• Variation in concepts: There can be differences in 
definitions of indicators (e.g., some studies may use 
10-19 years as the ages of adolescence, others use 13-
24; some studies may have one definition for a 
‘commercial’ farmer or a ‘cash crop’.   
• May be out-dated:  The information may exist, but it 
may be old. 
• Inaccessibility:  Some government agencies, 
organisations, or individuals may not allow access to 
their data.
<<<PAGE=72>>>
CARE M&E Guidelines 70 
Chapter 7. Sources and Samples 
 
There are also disadvantages, especially the skills requirement and costs.  Skills 
needed for successfully planning and implementing primary data collection are 
substantially greater than those needed for working with secondary data.   Costs 
of primary data collection can be high, particularly if the persons doing it are 
relatively inexperienced (causing waste of resources, collecting too much data) or 
the study design is very complex. 
 
A central principle to keep in mind, therefore, is that the projects should aim to 
keep collection of primary data to a minimum.  Caution is needed in selecting 
indicators which can be readily assessed (i.e., easily gathered and analysed).  
Information requirements and costs of collection should be kept to a minimum by 
focusing only on the most significant issues and using straightforward designs.   
 
Examples of primary sources include:  
• the target population (e.g., personal experience of issues affecting their 
lives; observations and opinions about the project strategy) 
• project personnel (e.g., observations about the target population they are 
serving; personal experiences of the project organisation) 
• other interested parties, such as agencies working with the same or 
similar populations 
 
Bias and sources of data (issues affecting selection of 
information sources) 
 
There are several potential errors in selecting the sources of information for 
indicators in the information system.  Two critical risks not to overlook in project 
M&E designs include seasonality and sampling.  
 
‘Seasonal bias’ refers to the effects of collecting information at a specific season. 
Indicators that are influenced by seasonality or weather are more likely to be 
affected, e.g., incomes related to specific cash crops.  Seasonality can also 
influence respondents’ willingness to participate, e.g., it is unwise to expect adult 
household members to be home in the morning (and available for interviews) 
during planting season in Uganda.   
 
‘Sampling bias’ refers to errors of judgement in selecting the persons or places 
from which to gather information, e.g., arranging to sample only communities 
along a tarmac road – and thereby not reflecting the issues of the project 
participants or target populations who do not live in those areas.  As a general
<<<PAGE=73>>>
CARE M&E Guidelines 71 
Chapter 7. Sources and Samples 
strategy, it is wise to obtain information from multiple kinds of sources so that 
their individual perspectives are balanced and a truer picture emerges.  (See also 
following section on sampling) 
 
Specificity of sources 
When preparing the information matrix (and preferably, even when preparing the 
original project log frame), it is desirable that the types of sources mentioned be 
as specific as possible.  It is all too easy to write ‘project reports’ in the MoV 
column of the log frame, or the ‘sources’ column of the M&E planning matrix.   
This can result in projecting information from (or about) an indicator that may 
later prove impractical.  
 
The bottom line:  
Data collection for M&E should be limited in scope and sharply focused.  The 
main reasons for this include constraints on time, skills and budgets.
<<<PAGE=74>>>
CARE M&E Guidelines 72 
Chapter 7. Sources and Samples 
Examples of sources and selection issues - CARE projects 
 
Community Reproductive Health Project 
Indicator Sources Advantages/Disadvantages 
% of women 
with recent 
deliveries who 
attend/obtain 
post-natal 
services 
Secondary sources: 
HMIS records (DMO) 
CREHP clinic records 
CRHW records 
TBA records 
 
 
 
Primary sources: 
Community women having 
a birth in past one year 
Women bringing babies for 
EPI 
Midwives 
TBAs 
Secondary sources: 
(+) Records exist with information about 
post-natal visits 
(-) Reliability, accuracy and accessibility 
of records is questionable 
(-) Clinic records may inflate client 
numbers to ensure provision of resources 
 
Primary sources: 
(+) First hand (primary) information is 
important to the project 
(-) There are divisions in the community 
(the community is not homogenous) 
(-) Sources can be determining factors on 
what results the information will show 
 
(+)  =  Advantage ;  (-)  =  Disadvantage 
HMIS Health Management Information systems    TBA   Traditional Birth Attendants 
CRHW Community Reproductive Health Worker    EPI   Expanded Programme on Immunisation 
 
Bushenyi-Ntungamo Agricultural Project 
Indicator Sources Advantages/Disadvantages 
# of active 
marketing 
groups formed 
by 
participating 
HHs  
Secondary sources: 
FEW and FO records 
District agricultural 
extension office 
records 
Marketing group records 
 
 
 
Primary sources: 
Project staff 
Marketing group members 
District marketing 
department officer  
Heads of participating HHs 
and spouses 
 
Secondary sources: 
(+) Records exist and cheap to access 
(-) Inadequate group records 
(-) Information may not be reliable and 
relevant 
(-) Variable quality of project records 
(-) District offices may not have current 
information 
 
Primary sources: 
(+) Collecting information from groups is 
easier and cheaper than going to 
individual households 
(+) Responsible district officers exist and are 
stable 
(-) Unstable membership of groups formed 
(-) Relying on farmers’ recall from memory
<<<PAGE=75>>>
CARE M&E Guidelines 73 
Chapter 7. Sources and Samples 
Sampling - how can we know 
what is happening with a large 
population by gathering data 
from a smaller group?   
 
 
In the design of an M&E system, the objective is to collect indicator data from 
various sources, including the target population for  monitoring project progress.  
Sampling is a strategy for selecting a smaller sub-group of the target population 
(intended beneficiaries) that will accurately represent the patterns of the target 
population at large.    
 
The main purposes of sampling are to:  
• economise on the resources required to collect and manage the desired 
data 
• improve quality of the data.   
 
Key questions in thinking about sampling:  
   
Why is information being collected from these sources? What 
is the purpose of the study (survey)?  For example, is it being 
done to gather information for planning, monitoring, 
advocacy,  
    identification of vulnerable populations, etc. 
 
For what population sub-groups are results needed?  For 
example, is it specifically women farmers growing bananas on 
at least ¼ hectare of land or is it generally any farmers 
growing at least some bananas for commercial sale? 
 
Who is in the ‘sampling frame’, i.e., what group of persons (or 
households or farms, etc.) will be eligible to be drawn for the 
sample?  And what larger group is the sampling frame 
supposed to represent?  For example, some ANR projects have 
only used trained farmers as their sampling frame, and then 
erroneously tried to draw conclusions about effects and 
impacts among the larger target population of all farmers 
resident in the area. 
Why? 
About 
whom? 
From 
whom?
<<<PAGE=76>>>
CARE M&E Guidelines 74 
Chapter 7. Sources and Samples 
 
What accuracy of results is needed?  If comparisons are going 
to be made (e.g., by sub-group or theme), how large a 
difference is considered important and expected?   Is it 
necessary to know that 10 out of 100 people behave in a 
certain way, or is it essential to know if 10 out of 10,000 
people behave in that way? 
 
Example of sampling frame in CARE project: 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Probability sampling for quantitative studies 
Sometimes, projects need to quantitatively assess changes (effects, impacts) that 
are widely distributed in the project area.  In such circumstances, the M&E 
sample design should, if possible, use a ‘probability sample’ (see box below).   
This means that each and every unit of assessment (e.g., each household) in the 
target area has an equal and positive chance of being selected.  Probability 
sampling relies on randomisation among all of the eligible candidates, e.g., by 
 
Development Through Conservation Project 
When monitoring for adoption rates of project promoted activities in the DTC 
project, the project used three methods of sampling and acquired three different 
results:  
1)  The project first sampled people it worked with directly.   
2)  Then, the project asked people if they knew of anyone who had copied them. 
Based on this information, the project calculated an average diffusion rate 
factor.   
3)  Following that, a random sample of people in the target area was asked if they 
had taken on any new agricultural activities in the last five years, which 
activity, and where they had gotten the idea.   
 
Comparing the results of the three approaches was revealing:   
1)  extension staff reported giving beans to 572 households;  
2)  when the diffusion rate was factored in, the number of adopting farmers rose to 
744;  
3)  but when the random sample was analysed, an estimated 5,700 farmers had 
adopted the improved bean varieties.  
 
This example shows the importance of defining the target population, and then 
ensuring the sample represents that group. 
 
With what 
precision?
<<<PAGE=77>>>
CARE M&E Guidelines 75 
Chapter 7. Sources and Samples 
numbering households and drawing numbers from a hat or a random number 
chart.   
 
 
 
 
 
 
 
 
 
 
 
The graphic below and the following table illustrate major types of probability 
sampling methods:  
Major probability sampling methods 
 
                                                                                
 
 
 
 
 
 
 
 
 
 
a) Simple Random Sample   b) Systematic Random Sample 
 
 
 
 
                                                                             
 
 
 
 
 
 
 
 
c) Stratified Random Sample      d) Cluster Sample  
 
Adapted from: East Africa DME Workshop, ‘96 
 
 
     
     
     
     
     
     
     
 
 
     
     
     
     
     
     
     
 
 
     
     
     
     
     
     
     
 
 
     
     
     
     
     
     
     
 
Advantages of a probability sample for a quantitative analysis  
• it allows you to measure the sampling error (the likelihood that your results 
are just due to the effects of sampling) 
• it allows you to test the statistical significance of the observed trends (the 
likelihood that results are due purely to chance) 
• it reduces the risk of a biased selection of sampling units.
<<<PAGE=78>>>
CARE M&E Guidelines 76 
Chapter 7. Sources and Samples 
Comparing methods for probability sampling 
 
METHOD ADVANTAGES DISADVANTAGES 
Simple random samples 
(e.g., household numbers drawn 
from a hat) 
• Avoids bias 
• Relatively simple to implement 
• Requires sampling frame for full population 
• Samples may be very dispersed 
• May be unrepresentative for key sub-groups 
• Ignores differences among sub-populations 
Systematic random samples 
(e.g., every third household in a 
community) 
• Easier to select 
• More likely to represent sub-groups 
(depending on size of the sample) 
• Also requires sampling frame for full 
population 
• Samples may also be widespread 
Stratified random samples  
(e.g., a random sample among 
female-headed households, or 
among households growing at 
least 30 banana plants) 
• Makes sure key sub-groups are represented 
in the sample 
• Can fix sample size for each sub-group to 
get representative sample 
• Need to know enough about complete target 
population to divide into sub-groups relative 
to interests of study 
• Need to use special analytical techniques 
when results are combined for different sub-
groups, especially when the groups are 
different sizes 
Cluster samples  
(e.g., random selection of 30 out 
of 100 villages in the target area, 
and then random selection of 7  
households per village) 
• Savings in travel costs and time 
• Only need detailed sampling frame for 
selected clusters 
• May miss out on important sub-groups 
• Communities selected may not be 
representative
<<<PAGE=79>>>
CARE M&E Guidelines 77 
Chapter 7. Sources and Samples 
Purposive sampling 
Sometimes it is desirable to purposively (intentionally) choose the respondents in 
a study for a specific reason, e.g., adolescents attending a family planning clinic.  
The project is choosing who it is that should be interviewed or surveyed, a choice 
that should be made very carefully and thoughtfully.  In other words, if this 
strategy is used, it will be very important to clearly define the selection 
procedures.  Purposive sampling can be used with quantitative or qualitative 
studies.   
 
Such selective sampling is quite different from the sampling based on statistical 
probabilities used in quantitative studies.  Probability sampling depends on 
randomness for being able to confidently generalise results from a small sample 
to a larger population.  The power of purposive sampling lies in selecting 
information-rich cases for in-depth analysis related to the central issues being 
studied.   
 
The skill in designing the sampling strategy is in assessing the degree of variation 
within the project area, and how the distribution of the sampled households can 
capture (or portray) this variation.  Examples include different agro-ecological 
zones, proximity to forest areas, etc.   
 
Example of purposive sampling in CARE project: 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
A list of different purposive sampling strategies that can be used in qualitative 
studies (either for individuals or groups) is presented in the box on the next page. 
 
Uganda Family Health Project  
When the project completed its baseline, the three target districts had been broadly 
covered by a randomised sample survey.  However,  based on local experience, an 
earlier qualitative pre-project assessment, and the preliminary results of the 
baseline, the project management recognised that certain sections of the project 
area were very different than other areas.  Therefore, additional intentional 
sampling was done to get representative information about four distinct cultural 
areas plus variations due to landscape and geography.  This turned out to be very 
important because, if sampling had not been done in this purposive (intentional) 
way, the project would have missed out on valuable information about how the 
mountainous area influences health behaviour.
<<<PAGE=80>>>
CARE M&E Guidelines 78 
Chapter 7. Sources and Samples 
 
 
 
Choosing a Sample:  
                 Purposeful Sampling in qualitative evaluation and research 
 
There are several different strategies for purposefully selecting information-rich cases; the 
logic of each strategy serves a particular data gathering and analysis purpose. 
 
1) Extreme case sampling: focuses on cases that are rich in information because they are 
unusual or special in some way. E.g., the only community in a district that has taken 
the initiative to prohibit pesticides.  
 
2) Maximum variation sampling: aims at capturing and describing the central themes or 
principal outcomes that cut across participant or program variations. E.g., persons of 
different ages, genders, religious groups, and marital status in an area considering 
family planning interventions. 
 
3) Homogeneous sampling: picking a small sample with similar characteristics to describe 
some particular sub-group in depth. E.g., firewood cutters or charcoal makers in a 
specific area. 
 
4) Typical case sampling: using one or more "typical" cases to provide a local profile.  These 
cases (individuals, families/households, communities, etc.) are selected with the co-
operation of key informants, such as project staff or knowledgeable participants, who 
can help identify what is typical.  
 
5) Critical case sampling: looking for critical cases that can make a point quite dramatically 
or that are, for same reason, particularly important in the scheme of things. E.g., the 
life history of a poacher.   
 
6) Snowball or chain sampling: begins by asking people in the project, "Who knows a lot 
about __?  Who should I talk to?"  By asking a number of people who else to talk 
with, the sample gets bigger and bigger.  Useful for identifying specific kinds of 
cases, e.g., critical, typical, extreme, etc.  
 
7) Criterion sampling: reviewing and studying all cases that meet some pre-set criterion of 
importance. E.g., the economic strategies of women-headed households.   
____ 
Adapted from: M.Q.Patton. 1987. How to Use Qualitative Methods in Evaluation. Newbury Park: SAGE Publications (pp. 51-56) 
 
 
 
Sample size 
In a project environment, M&E activities and resulting sample sizes are 
determined by limitations of cost and time.  The decision whether to gather 
quantitative or qualitative data in a particular case also influences decisions 
regarding the scale of the survey and the procedures for selecting respondents.  
Realistically, sample sizes of 75-125 are adequate for monitoring purposes in
<<<PAGE=81>>>
CARE M&E Guidelines 79 
Chapter 7. Sources and Samples 
most projects.  The application of ‘cluster sampling’ is particularly effective in 
being able to save valuable resources.   
 
Another approach is to use in-depth case studies of the target group. Qualitative 
methods are best used with small numbers of individuals or groups – which may 
well be sufficient for understanding the human perceptions and behaviours which 
are the main justification for a qualitative approach.  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
The bottom line:  
 
Larry’s Law: “Sample size is primarily determined by money and politics, not 
statistics.”       
Dr. Lawrence Grummer-Strawn 
Center for Disease Control and Prevention (CDC) 
 
 
 
 
 
 
Example of case study approach 
The CARE DTC project in Southwest Uganda has begun using case studies 
specifically as means of trying to show HH level impacts within the lifetime 
of the project.  In this situation, the sampling frame is comprised of HH 
‘adopters’ of specific interventions.  Taking adopters as the sampling frame 
allows the project to get an assessment of impact in a shorter period of time 
than if they sampled the whole target population.  Then, from their records of 
adoption rates in the target population as a whole, they can get an indirect 
estimate of overall impact in the target population.
<<<PAGE=82>>>
CARE M&E Guidelines 80 
Chapter 8. Data Gathering Methods 
CHAPTER 8   
 
Methods for gathering 
information - how can we 
collect the information we 
need? 
 
 
Selection of methods and tools for data collection 
Selecting methods for data collection can be confusing, even overwhelming, 
unless it is approached in a logical fashion.   These guidelines will try to clarify 
some of the main issues to consider in the search for the best methods to use.  
From the outset, it is worth emphasising that rarely is any one method perfect for 
a given information gathering situation.  Instead, using multiple methods helps to 
validate the monitoring or evaluation results and ensure representativeness for the 
various perspectives usually present in communities and development settings 
(see discussion of validity and reliability later this section).    
 
The first selection issue to consider has been mentioned earlier in these 
guidelines: secondary vs. primary data (i.e., previously existing vs. new data).   
 
 
 
 
 
 
 
 
 
 
 
QUESTION 1:  Existing or new data?   
Based on the project’s specific information 
requirements (indicators, variables needed), does some 
or all of the necessary information already exist as 
secondary data (e.g., as reports, maps, photographs, 
diagrams)?
<<<PAGE=83>>>
CARE M&E Guidelines 81 
Chapter 8. Data Gathering Methods 
Secondary data 
If the answer to Question 1 is YES, then the following questions can be used to 
assess whether the available secondary information is sufficient and useful.  
 
What is the available content, relative to the information 
needed?  Is it only about the local context (e.g., political 
history, general demography, etc.), or is it specific to the 
nature and needs of the project? 
 
Is the information sufficiently disaggregated to be 
useful (e.g., by age groups, gender, or specific 
localities)? If not, are the original data accessible and 
was disaggregated information collected in the original 
study? 
 
What is the quality of the available secondary information?  Is 
it from a reliable source?  Are the methods of data gathering 
for the information explained?  Is the information in any 
particular resource also confirmed by any other independent 
source?  Is the information timely, current? 
 
How accessible is the information?  Is it easy to obtain 
copies or access for reading; or is it constrained in any 
way?   
 
Extracting useful information from secondary data can be facilitated by creating 
and using a checklist comprised of a set of open-ended questions to be 
systematically posed to the data (reports, etc.).  See Annex 4, file A-2, for 
suggestions about such a strategy.      
 
Primary data 
If the answer to the above question 1 is NO, or if the available secondary data 
does not completely answer the information needs of the project, then the project 
will need to gather new information.  This leads to additional guiding questions:  
 
 
 
 
 
 
Content 
QUESTION 2: Qualitative and/or Quantitative?   
What types of data are needed – Qualitative (visual or words) or 
quantitative (numerical)?  What precision is needed? 
Disaggregation 
Quality of 
the data 
Accessibility
<<<PAGE=84>>>
CARE M&E Guidelines 82 
Chapter 8. Data Gathering Methods 
Qualitative and Quantitative data 
There are two main types of information produced by the data collection process: 
qualitative and quantitative.  The most obvious difference between the two is that 
quantitative data is numerical data (e.g., amounts, proportions) and qualitative 
data is information which can best be described in words or diagrams and pictures 
(e.g., descriptions of events, observed behaviours, direct quotations, maps)  
 
Quantitative data are obviously needed when a number, rate, or proportion related 
to the target population must be estimated or a variable such as crop production 
must be measured.  Qualitative data are needed when the attitudes, beliefs, and 
perceptions of the target population must be known in order to understand its 
reactions and responses to project services.   
 
Most information systems within projects require the collection of both 
quantitative and qualitative data.  Projects need qualitative data about the nature 
of results (e.g., beneficial or harmful effects, intended or unintended impacts).  
Projects also need quantitative data (e.g., about the distribution or intensity of the 
results) to ensure the accuracy and representativeness of the analysis. 
 
 
 
 
 
 
 
Participatory and Non-participatory approaches 
The main methods of primary data collection used in M&E are individual 
interviews, group discussions and observation.  Interviewing has traditionally 
been the most common data gathering strategy in M&E.  But increasing attention 
is being paid by donors and projects to the value of participatory methods, many 
of which involve group discussions or observation.  
 
In monitoring and evaluation, interviews with structured questionnaires are 
widely used for collecting quantitative data, i.e., data which can be processed by 
means of arithmetic and statistical formulas. Many  participatory M&E 
practitioners, however, share a critical view of surveys which are solely 
dependent on questionnaires. 
 
Two major complaints about questionnaires relate to the loss of human touch and 
QUESTION 3: Participatory or Non-participatory?   
What orientation/approach is desired/needed?  How will the 
process of information gathering be used by the project (or its 
partners)?
<<<PAGE=85>>>
CARE M&E Guidelines 83 
Chapter 8. Data Gathering Methods 
the extent of technical expertise required.  Structured questionnaires are often not 
well accepted by respondents and have many problems with reliability of the 
information collected.  Doing a good job in carrying out quantitative survey 
studies requires specialised skills for questionnaire design.  If a questionnaire is 
not well designed, the information will be of poor quality.  Among the problems 
with quantitative surveys are excessive use of pre-coded questions which expect 
(or allow) answers only within a limited range.  Such questions can be asked 
quickly and rapidly entered into a computer for later analysis, but they can easily 
become leading questions which only elicit the answers the respondent thinks the 
interviewer wants.   
 
By starting from local knowledge and empowering people, participatory 
approaches challenge the conventional tendencies to rely on ‘scientific’ 
knowledge and a strong central authority.  But in accepting this challenge, project 
staff will need to ask themselves self-critical questions, such as the following:   
• How can we be sure that the local classification of soils is really leading 
to the best use of this resource?   
• On what basis should we assume that a traditional means of 
contraception is really safe and effective? 
• To what extent do perceptions of the community history in the region 
provide a basis for decision-making?   
• In what way can we assess or measure the degree of consensus achieved 
during a participatory planning or evaluation meeting?   
• How can we be sure that local institutions are really committed to use 
external support for maximum community benefit?
<<<PAGE=86>>>
CARE M&E Guidelines 84 
Chapter 8. Data Gathering Methods 
Participatory data collection techniques:  
Some well-known examples  
Technique/tool Objective/use Means 
Participatory 
mapping 
(File A-3)  
To understand the 
distribution of 
activities and resources 
People use the ground, floor 
or paper to make health, 
natural resource, farm or 
enterprise maps 
Seasonal 
diagramming 
 
To understand the 
dynamics between 
time of year/season 
and activities/events 
People use ground, floor or 
paper to create matrix 
showing trends of 
activities/events by 
month/season 
Opportunities 
and resources 
diagramming 
 
To identify social 
and/or economic 
relationship or linkages 
between individuals, 
groups and institutions 
People draw schematic 
(mobility) maps illustrating 
links, or use circles to show 
points of contact and overlaps 
(chapati/Venn diagrams) 
Scoring and 
ranking  
(File A-12) 
To identify and apply 
local criteria for rating 
different items 
People use objects or pictures 
to symbolise various issues, 
and then arrange the symbols 
that are of similar value (‘pile 
sort’) or put them in value-
ranked sequence 
File numbers refer to Annex 4 
 
The bottom line:  
A question to always keep in mind during a participatory evaluation is:  
 
“Does this process help users generate information to solve problems 
they have identified, using methods that increase their capacity to solve 
problems in the future?”      
From Narayan, 1993
<<<PAGE=87>>>
CARE M&E Guidelines 85 
Chapter 8. Data Gathering Methods 
Main techniques for collection of new data  
 
A matrix by data expected and strategy/approach:  
qualitative/quantitative vs. participatory/non-participatory 
 
Data products Strategy/Approach 
 Participatory Non-participatory 
Qualitative Open-ended interviews 
Focus group discussions 
Participant observation 
Some PRA tools,  e.g., mapping, 
ranking, charts, etc.  
Direct observation without 
discussion 
Photos (if done by outsider) 
Spontaneous data (e.g., letters to 
newspaper) 
Quantitative Some PRA tools (e.g., scoring) 
Sentinel surveillance surveys 
Self-completion of questionnaire 
or records(e.g., by literate 
farmers or TBAs) 
Structured surveys 
Measurements (e.g., birth 
weights) 
 
 
Primary data collection – methods  
The major methods of primary data collection include observation, individual 
interviews, and group discussions.   Each of these methods may be carried out 
with varying degrees of structure and formality, which is linked to their potential 
for quantitative/qualitative data and participation or not.  The various methods 
also have different strengths and weaknesses, related to the skills and resources 
required for their implementation.   Details about selected methods and tools are 
given in the following table and in the Files of Annex 4 in these guidelines. 
 
Observation may be carried out informally, e.g., by 
paying attention to the state of crops as one drives along 
a road in a rural area.  It can also be done formally with 
a structured checklist, e.g., assessing specific aspects 
of the structural and hygienic status of latrines in a given community.   While 
observation has the advantage of relying on physically observed phenomena, it is 
subjective and can generate mistaken conclusions based on the interpretation of 
the observer.  For example, an observer noticed housewives in a village boiling 
water and concluded that the villagers were health conscious, boiling water for 
drinking.  When questions were asked for verification, she found out that the 
water was actually being boiled for the husbands’ baths.  
 
Observation
<<<PAGE=88>>>
CARE M&E Guidelines 86 
Chapter 8. Data Gathering Methods 
Interviews basically consist of asking questions and 
listening to individuals.  They can be done very 
informally, e.g., as conversations with people met on 
the street or in the fields. In these settings, one question 
leads to the next based on the responses or answers given to the previous one.  On 
the other end of the scale, highly structured interviews often rely on 
questionnaires with pre-coded, closed-ended questions that allow the respondent 
only a limited range of possible answers.  In between these extremes are in-depth 
interviews, which may be done with a topic guide (a list of topics which can be 
asked in any order and the interviewer creates the necessary questions) or a 
questionnaire comprised of open-ended questions.   Such questions are designed 
to probe and stimulate the respondent to think rather than just giving quick 
answers.    
 
Structured questionnaires are easier to complete than unstructured ones and 
require less skill among data collectors.  At the same time, highly structured 
questionnaires yield little insight into how people feel.  With the more open-
ended tools, more skills are required of the data collector to avoid being diverted 
from the original purpose of collecting information.  Open-ended data gathering 
can also generate enormous amounts of data and lead to information overload for 
the less cautious or over-enthusiastic data collector.   
 
Less structured interviews (e.g., in-depth, open-ended) are more flexible and 
allow one to revise and adjust the individual interviews or even the whole process 
of the study.   Structured interviews, on the other hand, cannot be altered 
midstream.  The difference between the two can be compared to being on a 
highway vs. being on a path in a village. 
 
Listening and asking questions of groups includes using 
methods and tools that range from formal to informal 
such as: 
 
• community meetings (formal, best with large groups) 
• focus groups (semi-formal, best with 6-10 people) 
• natural groups or conversation (informal, best with small groups), e.g., 
talking with women while waiting in line at the well. 
 
With groups, information from one individual can be cross-checked with others 
and more than one opinion gathered.  Data collectors with less-structured 
techniques, however, need many skills, e.g., to carry out a focused group 
discussion that can easily stray off track. Some individuals may try to dominate 
Interviews 
Groups – large 
and small
<<<PAGE=89>>>
CARE M&E Guidelines 87 
Chapter 8. Data Gathering Methods 
the discussion, others may have good ideas but be shy to mention them. When 
multiple opinions arise in a group discussion, it can be difficult determining 
which ones are right.     
 
When unstructured  discussion in an informal setting is used to gather 
information, it is possible to get information without raising expectations.  On the 
other hand, with structured group discussions, it can sometimes be difficult to 
gather a group, or when they come, they have expectations of some compensation 
for their time.   
 
Open-ended interviewing and group techniques are best carried out with detailed 
note-taking aimed at catching the exact words and phrasing of respondents’ 
answers (i.e., quotes or "verbatim statements").  Tape recording can be of great 
assistance in this effort, but only where and when it is acceptable to the 
respondent(s).  There is a need to be sensitive to communities, particularly if 
recording responses either with a paper and pen, and even more so with a 
recorder.
<<<PAGE=90>>>
CARE M&E Guidelines 88 
Chapter 8. Data Gathering Methods 
PRINCIPAL TECHNIQUES FOR COLLECTING NEW DATA:  A COMPARISON CHART TO FACILITATE 
SELECTION 
 
Techniques Means Resulting data Re quirements Advantages Disadvantages 
OBSERVATION  Observing settings, behaviour, 
interactions, events, physical/material 
items 
Conclusions depend on observer’s 
interpretation unless accompanied by 
interviews, discussion 
Can be improved with more than one 
observer or more than one observation 
Mostly qualitative 
Can be quantitative, 
especially if done 
with a structured 
checklist 
 
Much skill 
needed for 
adequate 
observation. 
Can be rapid 
 
Is a good way of 
starting a project 
Can be a good 
discovery process 
May be biased by 
observed persons 
changing their 
behaviour 
Is very subjective; 
needs verification 
by other methods 
• Participant 
observation 
working side-by-side with members of 
target group, which enables discussion, 
observation of interactions, first-hand 
experience 
Good 
understanding of 
constraints, 
difficulties, 
decisions, choices 
Careful 
thinking 
needed about 
ethics 
Can validate 
observations on the 
spot 
Time-consuming 
Individual observer 
only 
INDIVIDUAL 
INTERVIEWS  
Inquiring into another person’s 
perceptions about one or more topics 
May be structured (e.g., questionnaire 
survey)  or semi-structured (e.g., in-
depth interviews)  
Qualitative or 
quantitative data 
Knowledge, 
attitudes,  beliefs,  
behaviours  
Skill needed in 
creating the 
interview 
guide or 
questionnaire  
Can ask for the 
information desired 
Can observe 
respondent 
reactions to issues 
Interviewer can 
easily bias the 
respondent 
• Open-ended 
interviews   
Uses a sequence of questions or topics 
requiring open-ended, long answers 
(e.g.,   not a plain ‘yes/no’ and not a 
number); needs detailed note-taking 
Includes in-depth interview and key 
informant interview (KI).  KIs are 
carried out with persons having 
specialised knowledge about a topic  
Qualitative 
Good for discovery 
Good on range and 
nature of problem 
Can get verbatim 
answers (quotes) 
Great 
sensitivity and 
skills required 
of interviewer 
May need to 
schedule 
appointments 
Way of catching 
the point of view of 
the local actors 
Can rapidly get 
inside information 
Can revise 
questions if needed 
Interviewer can 
easily influence 
quality and content 
of information 
Interviewer can be 
diverted
<<<PAGE=91>>>
CARE M&E Guidelines 89 
Chapter 8. Data Gathering Methods 
 
Techniques Means Resulting data Re quirements Advantages Disadvantages 
• Closed-
ended 
interview 
(survey) 
Uses structured questionnaires: carefully 
organised questions which allow only a 
limited range of answers, e.g.,  yes/no,  
categorical answer (male or female, 
etc.),  or an answer expressed by a 
number (time period, distance, land size, 
etc.).   
If small scale, can be done in 
participatory way with community (e.g., 
sentinel survey) 
Quantitative 
Good for 
prevalence and 
distribution of an 
issue 
Much skill 
needed in 
creating the 
questionnaire  
Requires time 
for pre-testing, 
training 
 
May be completed 
rapidly in the field 
Less skill needed in 
interviewers 
Good for getting 
information from 
large numbers of 
people 
Usually done to 
(not with) the 
target population 
Yields little insight 
into how people 
feel 
GROUP 
INTERVIEWS,  
DISCUSSIONS  
Asking questions and listening to groups 
in formal and informal settings 
May involve group tasks, e.g., mapping, 
ranking, scoring, charts, etc.  (PRA) 
Can be informal groups, e.g., ‘natural’ 
or conversation groups such as talking 
with women while waiting at the well 
Qualitative 
Good for range and 
nature of issues 
Skill and 
sensitivity 
needed to keep 
focused and to 
get ideas the 
whole group 
Sharing tasks with 
members of the 
group can result in 
much deeper 
information 
Inexpensive 
Poor for personal 
information 
 
 
• Focus group 
discussions 
(FGDs)  
(File A-6) 
Semi-formal discussions, based on a 
limited set of topics, with a facilitator 
and a note-taker, usually about 6-12 
persons, preferably similar background 
Qualitative 
Can be very good 
for perceptions, 
attitudes 
Skill needed in 
setting topics 
and facilitation 
Multiple opinions 
at the same time 
Shows differences 
and similarities 
Can be dominated 
by one person 
Sensitive personal 
data unlikely 
• Community 
meetings 
Formal discussions, may be done with a 
semi-structured question guide 
Qualitative Meeting place, 
Mobilising, 
Facilitation 
skill 
Good for 
brainstorming, e.g., 
for solutions 
Easily dominated 
Little discussion
<<<PAGE=92>>>
CARE M&E Guidelines 90 
Chapter 8. Data Gathering Methods 
 
 
 
 
 
 
 
Relying exclusively on verbal methods (e.g., questionnaires) can be problematic, 
especially with low literate or mixed language target populations, or in situations 
where the desired information is not easily expressed in either words or numbers. 
 
Verbal, literate methods:   
Verbal or literacy-based techniques include: questionnaires, checklists, tape 
recording, and diaries or self-completed records (e.g., BAIP farmer records).   
These methods can be less subject to bias from data collectors than observation 
and the non-verbal methods.  However,  they can also be more subject to errors or 
bias built into the design.   
 
One such problem is the researcher (or evaluator) making assumptions about 
common understandings of concepts between himself/herself and the target 
community.  For example, a person wanting to know about total household 
income may not find out about gifts, allowances and barter exchange unless they 
are specifically asked for since the family is unlikely to consider them as income.  
Another bias arising from the design can be lack of flexibility.  If one is over-
structured with a checklist, problems or observations of items not on the checklist 
may not be recorded.     
 
If a project is using self-maintained records, such as farmer diaries or TBA 
records, then the data is likely to be biased toward literate members of the target 
group.  There are, of course, ways to compensate for this problem, for example, 
participatory design with the target population of pictorial records rather than 
written ones.   
 
Visual and less verbal tools:   
Non-verbal methods tend to be more effective for gaining participation of 
communities and target population.  It is good to balance verbal methods with 
less verbal ones to help minimise misunderstanding and miscommunication.  
Non-verbal techniques can be very effective discussion starters.  
 
QUESTION 4: Verbal or less verbal approach?   
Are some of the potential sources of information non-literate, e.g., 
children, or adults who have never been to school?  Can some of 
the information desired be extracted more effectively with maps, 
charts, photographs, drawings, or skits and role plays?
<<<PAGE=93>>>
CARE M&E Guidelines 91 
Chapter 8. Data Gathering Methods 
Visual and less verbal tools include the use of:  
• maps 
• diagrams, charts 
• photos, video, drawings 
• role-play, skits 
 
Viewing visual information can be a powerful stimulus for action, e.g., when the 
results of visual methods for collecting data are also used for disseminating data.  
In CARE’s UFHP project, for example, gender-based information was gathered 
with calendars showing how women and men spend their day.  Upon reviewing 
the calendars, health unit staff suddenly realised that their clinics were being 
closed too early to accommodate community women’s daily schedules.   
 
Combining strategies:  how to improve the quality of M&E 
data  
As mentioned earlier, information users are concerned about the issues of validity  
and reliability for the findings arising from M&E activities.  In conventional 
research, validity is usually taken to mean how close the findings are to ‘reality’; 
and reliability is equated with constancy of findings.  When it comes to 
participatory and action-oriented monitoring and evaluation, the concept of 
validity is interpreted somewhat differently.  In striving for sustainable 
development, M&E results may be considered valid and reliable when their 
utilisation can be linked with an actual improvement of the living conditions of 
the people, providing also that the change can be replicated and sustained over 
time.  
 
To help address such concerns about quality of findings and decisions, M&E can 
make use of a validation method known as triangulation.  In a strict sense, to 
triangulate means to utilise at least three different points of view for analysing a 
given event or situation.  More generally, triangulation is based on the idea that 
using multiple sources and methods is the best assurance of  the validity, 
reliability and completeness of  information.   
 
Two main modes of triangulation are used in participatory M&E: external and 
internal triangulation. 
  
This is basically a comparison between the information 
generated by an M&E activity and data from external 
sources, such as censuses, official statistics, aerial 
photographs, or local research and technical studies. 
External 
triangulation
<<<PAGE=94>>>
CARE M&E Guidelines 92 
Chapter 8. Data Gathering Methods 
External triangulation is based on a review of secondary data, i.e., information 
already existing and available from national and local agencies, academic 
institutions or published in papers and books.   
 
This refers to strengthening validity within the process 
of M&E itself, principally by the use of multiple 
methods and techniques for exploring the same topic:  
For  instance, a description of the way in which the 
community uses its natural resources may be developed through a combination of 
observational walks, interviews with groups and a participatory mapping exercise 
with community members. 
 
To meet the needs for representativeness in monitoring and evaluation, three 
simple solutions have been used most often:  
 
 
 
 
 
 
 
  
 
Strategies to enhance representativeness of data 
• Combining qualitative and quantitative methods:  This can be 
sequential, e.g., by open-ended interviews first to assess the range and 
nature of responses, followed by closed-ended questionnaires to check 
on the prevalence and distribution of responses.  It is also possible to 
integrate the two methods, e.g., with semi-structured interviews which 
use both closed-ended and open-ended questions, or rapid sentinel 
surveillance type surveys created with the target population (see 
Annex, File A-9). 
• Rating and ranking techniques:  Semi-quantitative and participatory 
methods of ranking can help individuals and groups of respondents to 
express values, opinions, and preferences about different elements 
(discovered through interviewing and/or observation) in a democratic, 
and visible way (see Annex , File A-12). 
• open analysis and discussion of findings during the data collection 
phase:   Analytical discussion of findings can be held with groups 
which are representative of specific stakeholders, information users, 
and/or the community at large.  These discussions can focus on the 
prevalence, interpretation, and validity of the findings.  The meetings 
can also explore the significance of emerging issues and elicit 
recommendations for identified problems or constraints to the project. 
Internal 
triangulation
<<<PAGE=95>>>
CARE M&E Guidelines 93 
Chapter 8. Data Gathering Methods 
EXAMPLES OF DATA COLLECTION METHODS: CARE Projects 
 
Community Reproductive Health Project 
IG: Increased Number of Women Seeking Maternal Health Services at a Health Facility 
Indicators Sources of 
Information 
Methods for data collection Who to collect  When to collect (Frequency) 
#  of women 
referred early 
to prevent 
obstetric 
complications 
HMIS records 
CRHW records 
Community Women 
TBAs 
Service providers 
Referral units 
Secondary data: 
Review of health service records, 
including TBAs’ records 
Routine collection of health service 
statistics 
Primary data: 
Key informant interviews 
Structured questionnaire  
Service providers 
CRHWs 
TBAs 
Project staff 
Partner staff 
Community members 
Consultant (for evaluation) 
Routine data: daily at service 
points 
Monthly review of service 
records 
Mid-term & final surveys 
Annual surveys 
 
Bushenyi-Ntungamo Agricultural Innovations Project 
IG: 7000 Participating rural HHs in Bushenyi and Ntungamo Districts achieve significant increases in agricultural production through 
environmentally sound practices by 1999 
Indicators Sources of 
Information 
Methods for Data collection Who to collect When to collect (Frequency) 
% of 
participating 
HHs that report 
increased 
marketable 
produce 
-Heads and spouses 
of participating HHs  
-Farmers’ records 
-Marketing group 
members 
-Some non-
participating HHs in 
same area 
- Qualitative PRA ranking to assign 
value to levels of increase 
-Focus groups with selected 
participating HHs 
-Mapping, from PRA and records 
-Survey of participating HHs 
Field Officers and Project 
Officer (because of their 
contact) 
Marketing groups, and other 
participating farmers 
Consultant and project staff (to 
train staff and for 
unbiased findings) 
Baseline 
Mid-term 
Seasonal (after harvest) 
EOP
<<<PAGE=96>>>
CARE M&E Guidelines 94 
Chapter 9. Data Analysis 
 CHAPTER 9 
   
Analysis methods - how to 
understand and give meaning 
to raw data/information 
 
 
The words “data analysis” often are a source of fear and apprehension for many 
project staff.   Undoubtedly, analysis can be overwhelming, particularly if the 
amount of data to be analysed is unmanageable, or if the skills or technology for 
performing data analysis are lacking.  However, analysis need not be a complex 
function involving the use of sophisticated computer programs and technical 
experts. 
 
The information system planning should include arrangements for analysis and 
interpretation of all data that is collected.   In this way, the project can ensure that 
raw data is converted into useful information for facilitating decision-making and 
other applications.  This may seem like a common-sense statement, yet there are 
countless examples where valuable data has been rendered valueless by remaining 
unanalysed.  
 
General steps in analysis  
The following six steps for organising and analysing data can be applied to either 
qualitative or quantitative findings.  Additional specific comments about specific 
strategies for qualitative and quantitative analysis follow this general section.  
Suggested six steps for the analysis and organisation of data:  
 
The original problem should drive the 
analysis.  Just as the project is based on a 
logical framework, the conclusions of a 
project information exercise need to be 
logical. Conclusions about specific content 
issues should be clearly linked to the overall project and the objectives of the 
study (evaluation, review, diagnostic study).  The connecting linkages should be 
traceable through the methods of data analysis, data gathering, sources of 
information and indicators.  (see Chapters 1 and 5) 
 
First - go back to the 
original objectives and 
intentions of the study
<<<PAGE=97>>>
CARE M&E Guidelines 95 
Chapter 9. Data Analysis 
Always come back to the reasons for the study, and then regularly weigh the 
available resources and the value of new information.  It is easy to be 
overwhelmed and 'drowned in data'; each new 'finding' or point almost begs for 
its own full consideration.  On the other hand, it is also possible to over-examine 
a relatively trivial point with too much complexity in the approach; rather than 
attaching too much importance to some small detail that is present, the significant 
finding may be a much larger absence of data in another area.   
 
The raw data which has been gathered 
needs to be validated, i.e., confirmed by 
different sources and/or different methods 
(see Chapter 8 on triangulation).  Data that 
can be validated by multiple observations 
(e.g., many people report the same 
experience, or multiple observers see the same problem) can be considered a 
‘fact’ for the purposes of this particular analysis exercise.   
 
If the analysis process stops, however, with only a set of isolated facts, it is 
unlikely to be of much value in project planning or decision-making.  The facts 
need to be put into context and assessed in relation to each other, as well as in 
relation to the study and project objectives. The analytical process of extracting 
and presenting meaning for these isolated facts is referred to as ‘interpretation’.   
   
Start the analysis process by assembling all 
the data; a checklist for the planned data 
will be very helpful in cross-checking 
against the actual data now present. The 
checklist might cover: how many focus 
groups from which locations, how many KIs, how many of any other methods, 
etc.  The original data (questionnaires, interview notes, social maps, etc.) needs to 
be thoroughly checked to be sure all pieces have adequate identifiers (e.g., place, 
time, date, who was responsible, who were the respondents, etc.).  Check all the 
data for completeness, e.g., make sure there are no missing pages, missing 
answers, or pages which are loose and separate from their sessions.
Second - remember to 
think of ‘facts’ and 
their ‘interpretation’
 
Third - follow a 
systematic and logical 
path in the analysis
<<<PAGE=98>>>
CARE M&E Guidelines 96 
Chapter 9. Data Analysis 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
The description process is a way of extracting ‘facts’ from the data and 
developing generalisations about the sample population.  The following steps will 
be helpful in this activity:  
a)  write out lists of issues (themes, indicators), including the key ideas in 
each sub-category.   
b)  note any emerging issues, i.e., ideas that are repeating and substantive, 
but not included in the original plan of study.   
c)  where appropriate, do tabulations, i.e., counting answers (or observed 
events, etc.) 
 
The final level, interpretation, is the most complex; it is the process of presenting 
meaning rather than just a description. At this stage, one will be checking 
carefully on the representativeness and reliability of the data.  One should look 
purposely for contrasting cases and be sure that all cases are developed to the 
same amount of detail.   
 
Look with care for researcher effects on the respondents and note any researcher 
bias in the interpretation.  Social desirability for certain outcomes can alter the 
information gotten and its interpretation.  The researcher's age, sex, ethnicity, 
personality, and other aspects will influence what he/she is told or allowed to see 
and how he/she perceives the information received.   For example, in a recent 
study of household medicines, one person who interviewed members of 12 
Logical steps in systematic analysis 
Organise 
raw data 
Prepare 
descriptions 
Generate 
interpretation
<<<PAGE=99>>>
CARE M&E Guidelines 97 
Chapter 9. Data Analysis 
households found that no-one kept any medicines in the home.  In the same 
village, another interviewer described at least one and sometimes several 
medicines in each of the 12 homes he interviewed.    
 
The process of analysis is continuous, 
beginning already when the pretesting is 
going on, and continually being refined 
during the course of the whole exercise.   
It is not just an isolated event at the end of 
the data collection.  The persons 
responsible should feel comfortable asking new questions of their colleagues, 
other information users, and the respondents at any stage in the process in order to 
help clarify the evolving analysis.   
 
Reflect on the findings with other staff, M&E team members, or participating 
information users/stakeholders.  Different perspectives can help clarify puzzling 
issues and strengthen conclusions.   Multiple perspectives are also more likely to 
generate solutions and recommendations that are feasible and relevant.   
 
As mentioned in Chapter 2, information 
users have some common concerns about 
the quality of information.   Accuracy and 
validity: is the information true and right? 
Relevance: is the information relevant to 
user interests? Timeliness:  is the 
information available in time to make necessary decisions?  Credibility: is the 
information believable? 
 
Making conclusions and recommendations 
as specific as possible will increase their 
usefulness.  Be very clear who will (or 
should) be responsible, by what time an 
action is expected, and how will it be 
evident to the project management (or other information users) that a response has 
occurred.   
 
 
Specific Types of Data Analysis: 
There are two major types of data analysis methods, quantitative and qualitative. 
Both of  these methods aim for ‘objectivity’ by trying to minimise the subjective 
Fourth - Discuss the 
findings and emerging 
analysis
 
Fifth - Consider any 
limitations to 
believability 
 
Sixth - Make specific 
recommendations
<<<PAGE=100>>>
CARE M&E Guidelines 98 
Chapter 9. Data Analysis 
or individual point of view.   Quantitative methods are used with numerical data, 
and the analysis is done by statistical manipulation. Qualitative methods use 
narrative or pictorial information for analysis of content and meaning.  These 
methods have a positive interest in the consequences of differing points of view.  
The process of analysis should be systematic and verifiable, even if some of the 
qualitative data seems 'soft' compared to 'hard' numbers.  At the end of the 
process, another researcher should be able to arrive at similar conclusions from 
the same set of data. 
 
Quantitative Techniques 
Data from closed-ended survey or most monitoring questions can be easily 
quantified, i.e., expressed in numbers.  Once the data is in numbers, it can be 
handled with mathematical or statistical techniques.  All of the statistical 
techniques listed below do not require a university degree; they can be done with 
a hand calculator.  
 
Descriptive statistics – These statistics are fairly straightforward ways of 
summarising a single set of scores or numerical results (e.g., the numerical pattern 
of results if everyone took a test on what they learned in the workshop).  They are 
relatively simple concepts, used in everyday life.   Tallies (totals),  frequency 
(sub-totals), averages, proportions, and distribution are among the most common 
descriptive scores.  Two other descriptive concepts are also important: prevalence 
and incidence.  
 
The concept of prevalence refers to how many people have a specific condition 
(or show a specific attribute like a behaviour) at a given time.  For example, the 
proportion of farmers in a sub-county who mulch their bananas is an indication of 
the prevalence of mulching practices.  The concept of incidence refers to how 
many new cases arise in a given period of time (or how many persons newly 
demonstrate a specific condition or behaviour).  For example, how many farmers 
newly adopt growing beans within the span of a year. 
 
Inferential statistics – These are somewhat more complicated techniques, but 
useful analyses can still be done within the capability of hand calculators for 
monitoring and evaluation purposes.  The two main categories are:   
a)  examining differences between groups, whether matched or independent 
(e.g., assessing differences in impact indicators between groups that 
have participated in project interventions and control groups outside the 
project area for an ex-post evaluation);  
b)  examining relationships between variables, such as cause and effect 
relations (e.g., assessing differences in the numbers of people who
<<<PAGE=101>>>
CARE M&E Guidelines 99 
Chapter 9. Data Analysis 
report changing their family planning behaviour after seeing a video 
programme versus receiving individual counselling).    
 
Qualitative Techniques 
Analysis of quantitative or numerical data can be very seductive.  The researcher 
can manipulate a set of 'facts' and it comes out the same way each time; there is a 
sense of accomplishment and confidence that it must be 'right'.  However, if the 
question and/or the answer was ambiguous, the researcher cannot be sure his/her 
interpretation is reliable unless qualitative data and qualitative methods were also 
available for cross-checking.  
 
Unprocessed, raw data – Sometimes, one can or does use the direct content from 
the respondents because they are so eloquent in discussing issues that directly 
affect their lives.  Larger examples might include direct unedited texts, 
maps/pictures, or films that are presented without explanation except that given 
by the respondents themselves.  More often, small, selected extracts from the 
respondents are used as typical or illuminating quotes. It is sometimes difficult to 
decide which quotes to use; the selection will be easier, however, if one always 
comes back to the purpose of the study. 
 
Simple description – Read the full text of all data sessions (interviews, focus 
groups, observations, etc.) from beginning to end.  First look for passages 
(paragraphs or sentences) that talk about the original topics planned in study.  
Using the right hand margin, you can mark all the passages that relate to each of 
the planned and emerging themes.  Cluster the passages by their major themes.  
This can be done, for example, by photocopying or writing the passages on cards 
and physically grouping the ideas. Review the various sub-groups within any of 
the major themes; determine whether the listing is complete.   
 
Generating meaning,  i.e., interpretation – The key elements at this point are 
building a logical chain of evidence, seeking plausibility (does it make sense or 
not?) and assessing significance of the results.  Working with qualitative data 
requires good summarising skills and insight capabilities in order to extract 
meaningful content from the often long and wandering statements provided by 
respondents. 
 
A variety of useful aids are available for thinking systematically and logically 
about this data, e.g., diagrams like organisational charts, flow charts, growth 
charts, or maps.  Matrices (tables) can be produced that allow 'eyeballing' the data 
for trends and patterns.  Other helpful approaches are checklists and various ways
<<<PAGE=102>>>
CARE M&E Guidelines 100 
Chapter 9. Data Analysis 
of clustering the variables.   Consider the use of various qualitative analysis 
matrices (e.g., see SWOL analysis in Annex 4). 
 
Regarding plausibility, check representativeness; for example, when several 
people are consulted about the same issue, do they give several different opinions 
or is the same opinion reflected each time?  Check for researcher influence, e.g., 
do different interviewers get very similar or very different responses from female 
farmers?  The bottom line on plausibility, however, is checking with the 
informants themselves - does the analysis make sense to them and their 
perceptions of how things are?  
 
Rating the significance of findings is a process of prioritising the most important 
results for inclusion in the final report.  This ranking of importance might be done 
on the basis of range of respondents’ answers (agree/disagree, strong/weak), 
typical responses (most frequent), or extremes of responses (quite apathetic, very 
affirmative, etc.).  It can also be done by seeing how often the issue was 
mentioned by the respondents, how strongly they felt about the topic, how much 
risk they felt was linked to the topic, etc.  Note that it is possible, even desirable, 
to include diverse or opposing opinions and statements.   
 
 
CARE-Specific Issues Related to Data Analysis 
The following issues were raised in the Kabale ’96 M&E workshop concerning 
data analysis within CARE-Uganda: 
 
• Time constraints: Project Managers felt that the balance between data 
collection, analysis, and reporting tends to get skewed.  So much time is spent 
organising data and reporting on it that there is little time to critically analyse 
information and make sound conclusions.  
  
• Expectations of what data is for: While volume of information is a problem 
for projects, it may not be as big an obstruction to analysis as lack of 
understanding about the uses of data. Often, project staff and counterparts may 
perceive that information is just being collected because other people require 
it, or to prove a point that is already well understood. 
  
• Knowing how to analyse and interpret: at present, projects reported 
frequently needing outside expertise to assist in analysing and interpreting 
data.  Collective or co-operative strategies of analysis within the projects and 
the country programme have not generally been done.  Lack of computers or 
statistical skills have been overly blamed for lack of analysis.
<<<PAGE=103>>>
CARE M&E Guidelines 101 
Chapter 9. Data Analysis 
  
• Importance of budgeting for analysis:  While recognising the importance and 
resource needs of data collection in the budget, analysis is usually not 
allocated sufficient time and staff resources in project budgets.   
 
 
The bottom line:  
Most, if not all, project M&E can be done with descriptive statistics and 
qualitative summaries, i.e., there is little or no need for complex statistics for most 
projects.  
 
 
 
Example of analysis logic - CREHP  
IG: Increased Number of Women Seeking Maternal Health Services at a Health Facility 
Indicators Sources of 
Informatio
n 
Methods for 
data collection 
Value Methods for 
data analysis 
Who to 
analyse 
# women 
referred early 
to prevent 
obstetric 
complications 
HMIS 
records 
 
CRHW 
records 
 
 
 
 
 
Community  
Women 
 
 
 
Health 
workers, 
TBAs 
Routine 
collection of 
health service 
statistics,  
Review of 
health service 
records 
 
 
 
KAP survey: 
structured 
questionnaire 
 
 
Key informant 
interviews 
Available to a 
certain extent 
May be 
inaccurate 
Staff & partners 
able to analyse 
Limited by 
standard govt 
formats 
 
Surveys 
expensive 
 
 
 
Wider scope 
flexible over time 
Statistical:  
frequencies, 
proportions 
and  
comparisons  
 
 
 
 
 
KAP Surveys: 
quantitative & 
qualitative  
synthesis 
 
KIs: 
qualitative 
summaries 
CRHW, 
TBA  
Supervisors 
Project staff 
Partner staff: 
DHT, H/U 
in-charges 
 
 
Project staff 
& 
consultants 
 
 
Project staff 
and partners
<<<PAGE=104>>>
CARE M&E Guidelines 102 
Chapter 10. Presentation and Use of M/E Results 
CHAPTER 10 
   
And then what?  
How can we circulate and use 
the information effectively to 
ensure action? 
 
 
Format of Information 
Information needs to be well presented so that it is usable.  Formats for 
presentation will depend on the anticipated users; not all ways of presenting 
information are appropriate for all users.  For example, the format for sharing the 
results of a reproductive health project with a group of TBAs is likely to be quite 
different from the format expected by a donor agency.   Good quality information 
will go unused if it is not presented in a suitable way.   The following ideas may 
be helpful in determining how to present information:   
 
 
 
 
 
 
 
 
 
 
 
 
 
 
The following table shows the linkages between types of information,  
audiences and reporting formats for CARE. 
Guidelines for presenting information 
• Know your audiences (information users) 
• Know what they need to know, and why (applications) 
• Know when the information is needed (timing, frequency) 
• Relate the information presented to the anticipated 
applications (uses) 
• Choose presentation methods that fit the audience (e.g., not 
using written materials with non-literate audiences; or very 
long reports for busy politicians) 
• Choose a variety of ways to present information (figures, 
numbers, pictures etc.).  Users digest new information in 
different ways and providing a mix of methods ensures that 
it will be accessible to all.
<<<PAGE=105>>>
CARE M&E Guidelines 103 
Chapter 10. Presentation and Use of M/E Results 
Comparison of different CARE reporting formats 
Tool PIR API Project evaluation HHLS evaluation 
Type of 
indicator 
(framework) 
Inputs 
Process 
Outputs 
Outputs 
Effects 
Effects 
Impacts (potential) 
Impacts 
Main purpose Day to day 
management at the 
country level 
Analysis of sub-sector 
for CO  & sectoral ‘big 
picture’ 
Midterm: assess changes needed in implementation 
Final: assess systems and behavioural changes achieved 
Assess improvement in:   
a) HHLS 
b) institutional capacity 
Main users Project manager 
(PM) 
Country office (CO) 
RM, PAD, Marketing Country director 
Donors 
Country director 
PAD, RM 
Other users PAD, Marketing 
Donors 
Programme SVP 
PM, CO 
Donors 
Project manager 
RM, PAD 
HQ SMT 
President 
Board 
Periodicity Quarterly Annual Baseline, Midterm,  Final 
Ex-post 
Baseline 
Every 5-10 years 
Format Narrative 
Tables: achievements 
Questionnaire, 
quantitative data 
Narrative report 
Research 
Report 
Data source Field staff PIRs Project documents 
PIRs, AOPs 
External assessment may include survey 
HHLS baseline 
Project evaluation 
Sample surveys 
Method of 
collection 
Continuous 
monitoring 
Aggregation of 
quarterly PIRs 
Document review 
Research 
Project evaluation 
Research 
Persons to 
implement 
Project manager / 
project MIS staff 
Project manager / 
project MIS staff 
Project manager 
CO: sector co-ordinator,  M&E co-ordinator 
ACD 
CO: M&E  co-ordinator 
PHLS 
Persons  to 
supervise 
Country director 
ACD 
Country director 
ACD 
Country director 
ACD 
Country director 
Global: RM, PAD, PHLS 
From: PMTF - API Framework, 1/97
<<<PAGE=106>>>
CARE M&E Guidelines 104 
Chapter 10. Presentation and Use of M/E Results 
Flows of information 
Project M&E systems are generally designed as ‘reporting systems’ which have a 
tendency to exclusively serve the information demands of the project 
management team, the higher echelons of the national government (policy 
making level) and the donor.  Unfortunately, information usually flows only one 
way – from the target population upwards.   
 
Among the reasons for this one-way flow are:  
• reports are demanded so frequently by higher level users that project 
staff do not have the time to use one report before the next one is due.       
• the standard type of information contained in reports does not permit the 
higher level users to generate significant comments, e.g., progress 
reports that report only on whether targets are being met or not.   
• the various information users do not perceive that it is their 
responsibility to give feedback to the information providers (including 
to the target population).   
 
Tracking the feedback of information from users back to providers is a key issue 
for ensuring that M&E information is actually being used.  If the target 
population gets information in a usable way, they can be  empowered to 
participate meaningfully in project planning and activities related to their 
problems and needs.  Two way dialogue also helps ensure motivation in the 
community to continue involvement with the project.  
 
The chart above showing CARE formats for structured information flow, is 
basically oriented ‘upwards’.  Ideas about ‘downward flow’ of information are 
presented in the next section.  
 
Dissemination formats 
Project information (whether it comes from baseline survey, monitoring, 
evaluation or diagnostic study) can also be disseminated beyond the upward 
reporting requirements through a range of outputs (products), from discussion 
meetings to advocacy papers, from brochures to detailed analytical reports.
<<<PAGE=107>>>
CARE M&E Guidelines 105 
Chapter 10. Presentation and Use of M/E Results 
 
The validity and utility of analyses of project information can 
be enhanced by advisory discussions with various stakeholders 
and users before the report is finalised.  At least two different 
kinds of workshops can be held for presentation of preliminary 
project information system results.  The first level is a very practical session with 
representatives of the study communities and target populations.  A second level 
is a more technical workshop with managers, professionals, agency 
representatives, and donors.  
 
A basic purpose of these advisory workshops is to allow information users and 
project stakeholders to see the preliminary data before a final report has been 
written.  In this way, data interpretation also becomes part of their responsibility, 
and not solely the domain of the team producing the information. A second major 
objective of the workshop is to obtain agreement on the implications of the data 
for the project.  
 
In addition to written documents, target communities 
and/or districts where the data was gathered can also 
benefit from multi-sectoral planning meetings to 
generate local strategies for identified issues.  A 
consensus 
building seminar will provide an opportunity to bring together a variety of people, 
many of whom would not have access to, or time to study, the formal reports.  
Importantly, the seminar can be the occasion for an interchange of ideas and 
experiences between those who carried out the study (both researchers and staff), 
policy makers and planners, district level officials, representatives of other 
sectors, and community leaders. An interactive workshop format can promote 
mutual exchange of ideas and provide important insights into alternative 
strategies for dealing with some of the issues raised during the assessments. 
Representatives of the media can also be appropriate as participants in this 
session, since they can be the means of sharing the results with an even larger 
audience. 
 
The project should consider diverse methods of 
dissemination to ensure maximum and 
widespread use of the findings.  These include 
various methods in order to reach policy makers, 
professionals in different fields, volunteers and activists in the community sector, 
and the target population themselves.  Seminars and workshops are valuable, as 
are mass media interviews (e.g., radio has a wide listenership in vernacular 
Advisory 
meetings 
Dissemination 
meetings 
Other widespread 
dissemination
<<<PAGE=108>>>
CARE M&E Guidelines 106 
Chapter 10. Presentation and Use of M/E Results 
languages in Uganda) and press releases.  In addition, the findings can be 
circulated through academic channels via books, journal articles, newsletters, and 
other print media which serve those working similar target populations.
<<<PAGE=109>>>
CARE M&E Guidelines 107 
Chapter 10. Presentation and Use of M/E Results 
Examples from CARE projects 
The following charts show examples of upward and downward information flow planned in the Kabale ’96 workshop.  
 
 
Community Reproductive Health Project 
 
IG:  Increased Number of Women Seeking Maternal Health Services at a Health Facility 
Indicators Application Circulation How 
The percentage (% )  of women in 
the project area who attend ANC at 
least once in any  pregnancy 
occurring during a given time period 
• Assess trends: (are we on track?: 
if not, why?): make adjustments 
• Comparative assessment: Setting 
foundation for measuring change 
• Assess strategy effectiveness and 
revise strategy 
• Assess project effects 
• Direct partners 
• CARE Uganda HQ 
• CARE USA 
• USAID 
• Other donors,  
• Interested organisations 
• Discussion - presentation with 
support graphs 
• Informal meeting, tables, 
discussion 
• Reports: PIRs, API 
• Presentation, report/graphics 
 
 
Bushenyi-Ntungamo Agricultural Innovations Project 
 
IG: 700 Participating rural HHs in Bushenyi and Ntungamo have significant increase in agricultural production via environmentally sound practices by 1999 
Indicators Application Circulation How 
# of marketing groups formed by 
participating HHs 
PM-Track Progress, compile reports 
Field Officer, planning 
MKT. Dept: Tracking GPS and 
planning 
MKTGP-Information  
 
 
Donors 
District officials 
Community  
AID program 
CD CARE HQ 
Reports 
Community meetings and discussion 
API reports (condensed and graphic)
<<<PAGE=110>>>
CARE M&E Guidelines 108 
Chapter 10. Presentation and Use of M/E Results 
Writing process and style 
 
The report writer(s) should exercise judgement 
and restraint.  It is not necessary to report every 
minor fact, occurrence and detail. Expand only on 
the really important data, condense the less 
important, and recognise that some matters do not require reporting at all.  In a 
really well written report, the reader should be able to understand, on first 
reading, the main findings and conclusions, without having to refer to the 
appendices.  
 
Proper balance between text, tables and diagrams makes the report easy to read, 
as well as clear and informative.  It also results in considerable economy of space, 
as text without supporting tables and diagrams tends to become too long and 
wordy.  Avoid repetition - it lengthens a report unnecessarily and bores the 
reader.  
 
 
Use simple words where possible, rather than 
unusual or highly technical words.  A common 
difficulty to be overcome in an M&E report is the 
diversity of educational backgrounds among 
the intended readers.  Avoid a stuffy style.  Long sentences with too many ideas 
are confusing.  It is nearly always possible to break up long, involved sentences 
into several shorter ones that are clearly understood.   
 
Divide the text into short paragraphs that concentrate on a single aspect or idea.  
Link the sequence of paragraph themes by careful use of the first and last 
sentences of the adjoining paragraphs. The feeling of continuity is increased if the 
first sentence of the next paragraph takes up the topic mentioned by the previous 
sentence.   
 
 
A clear, consistent, and logical order in which the 
topics are discussed is immensely helpful to the 
reader for two reasons.  First, a logical sequence 
is much easier to understand and to follow. 
Second, the serious reader will need to refer back 
to earlier sections of the report as he or she 
studies it.  Referral to other sections is much easier if the report has a consistent 
and logical order.  For convenience of cross-referencing within the report, include 
Be brief, concise 
and to the point 
Use simple, clear 
language
 
Follow a logical 
sequence of 
presentation
<<<PAGE=111>>>
CARE M&E Guidelines 109 
Chapter 10. Presentation and Use of M/E Results 
some logical system of numbering and headings for sections, sub-sections, tables 
and diagrams.   
 
 
All conclusions should be backed up with actual 
data.  Intelligent readers will be unconvinced by 
emotional and subjective statements.  
Unsupported statements may lead the reader to 
question the reliability of the writer/researcher to 
the point of rejecting or ignoring  the entire 
report. 
Look back to the objectives, reflect on how the actual results obtained relate to 
the objectives.  Remember that it can help to understand the issues by including 
opposing opinions, where they exist. 
 
 
A good evaluation report will be practical in 
orientation, conclusions and recommendations.  
In this way readers can easily utilise the 
evaluation results in their own working situation. 
A further justification for the pragmatic approach is that project evaluation and 
monitoring reports are not principally scientific documents in the first place; 
instead, they are tools to produce improvement in project strategies and outputs.   
 
Reports also need to be tactful and constructive rather than negatively critical.  If 
the writer fails to do this, then the report is unbalanced and will lose the interest 
and concentration of all but the most determined and dedicated readers.  Instead 
of becoming widely read, the report will, at best, remain with a small circle of 
specialists.  Specialists are not always the people with the influence or the 
resources to help implement the recommendations of the report.  
 
 
Make the report pleasant to read and well laid 
out.  Start with an attractive cover; take pride in 
your hard work and make the end result look 
nice. Break up written text with appropriate 
graphics. 
Some information, e.g., discussions and conclusions, is best conveyed in words 
and text.  Other information is better understood when expressed visually as 
tables, charts and diagrams. Information presented in this way is quick to 
Avoid unsupported 
statements and 
recommendations
 
Be pragmatic 
and constructive
 
Make the final 
product attractive
<<<PAGE=112>>>
CARE M&E Guidelines 110 
Chapter 10. Presentation and Use of M/E Results 
understand and it provokes thinking.  Maps are particularly useful in presenting 
data such as  catchment areas, population density, or farming systems.   
 
Use firsthand, direct quotations from different perspectives, e.g., target 
population, community leaders, service providers, planners, etc. Quotes give dry 
text more flavour and a sense of reality.  As much as possible, quotations should 
be left in the phrasing and words of the respondents.  Not only will the report be 
more readable, but people from the target community will also be more likely to 
identify with the content and feel that the report is truly or usefully addressing 
their issues and concerns.  Be sure to include a minimal identifier with the quote, 
(e.g.: women's group, Arua district); this can help the readers to identify patterns 
without breaking confidentiality.  
 
The following box includes some general guidelines on the size of documents for 
different groups of anticipated readers. 
 
 
 
Formatting findings for different user audiences 
Format Audience/users Length 
Short forms General public, media release, 
summary for busy planners 
1-4 pages 
Medium form Programme implementers 5-10 pages 
Long form Libraries, interested agencies 
and programmes, researchers  
Unlimited 
pages 
 
 
 
Overview of the final report 
The final report should include a discussion of the qualitative and quantitative 
data collected during the study, organised and analysed in order to provide the 
project with information regarding: 1) the magnitude of current problems, and 2) 
the achievements and constraints of the existing project with respect to the 
expected impacts on these problems.  Findings and recommendations will be most 
usable if they are prioritised in order to enhance planning that can address the 
most important issues.  The final report should provide adequate information 
upon which to base technical and political decisions to improve the project, 
ideally including an action plan for the coming year.
<<<PAGE=113>>>
CARE M&E Guidelines 111 
Chapter 10. Presentation and Use of M/E Results 
Follow-up 
Two areas of follow-up are particularly recommended. 
 
a. Strategy implementation and subsequent evaluation 
Once specific plans have been designed and strategies implemented in response to 
the findings, appropriate indicators or descriptors from the study can be selected 
for monitoring.  These could include indicators of output (e.g., did the proposed 
revisions of the project actually get started) as well as effects (e.g., what were the 
perceptions and behaviours of the target population in response to the new 
activities?).   
 
b. Subsequent analyses 
Although project information systems have been presented as a relatively rapid 
action-oriented research strategy, the richness of data they can generate makes it 
highly desirable to consider additional or subsequent analyses.  One such 
application is to make the data set accessible for secondary analysis by other 
researchers, e.g., graduate students, planners from various sectors, etc.  A second 
application is to make comparisons between the findings of the study with other 
research studies.  Finally, there are likely to be a number of potential operational 
research topics emerging from the study which could be prioritised and developed 
into proposals for funding.
<<<PAGE=114>>>
CARE M&E Guidelines 112 
Chapter 11. Planning for M/E 
CHAPTER 11   
 
How do we organise it?  Issues 
affecting internal project 
planning and operations 
related to M&E 
 
 
Strategy for developing an M&E plan 
Having explored the various elements of an information system for projects, it is 
now time to consider assembling these elements together as a total M&E plan.  
The sequence of steps developed in the previous chapters can be used as a logical 
path for preparing an M&E plan within projects, e.g., as done in the Kabale ’96 
CARE M&E workshop.    
 
A monitoring and evaluation plan: step-by-step 
 
State the project’s final and intermediate goals (see Chapter 4).  
Plan for assessment of the project’s intermediate and final 
goals. This is principally done through a baseline survey, 
mid-term and final evaluation.  Design issues to be considered include whether to 
use ‘before/after’,  ‘with/without’, and control groups.  (see Chapters 5 and 7)   
 
List indicators for each goal which will most accurately 
indicate their achievement.  Specify the data to be collected 
for each indicator (see Chapter 6). 
 
State the data collection methods, tools, data sources, data 
gatherers, and dates. Show which is routine monitoring and 
which is evaluation.  (see Chapter 8) 
 
 
Explain how the data will be analysed – description and 
interpretation.  (see Chapter 9) 
 
 
Goals 
Indicators 
Data 
collection 
Data 
analysis
<<<PAGE=115>>>
CARE M&E Guidelines 113 
Chapter 11. Planning for M/E 
Describe the method to disseminate information to 
project staff and communities and how it will be used to 
improve the project (see Chapter 10). 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Allocating resources - time, personnel, budgets 
In order to develop a final M&E plan, one of the intermediate steps will be 
assembling sufficient management information about tasks, persons responsible 
and timing.  This is an essential step for making decisions about the allocation of 
resources, including time, personnel and budgets.  The following matrix is a tool 
which can help in this process. 
 
Outline of a formal M&E plan - An example  
 
     Table of contents 
     Executive summary 
     Project background: general, project objectives, strategies, conceptual 
model, current status 
     M&E background: process of designing the M&E plan, operational 
terminology 
     The M&E plan 
          - narrative explanatory statements 
          - M&E matrix: project log frame objectives, indicators, sources, 
methods of data gathering and analysis, frequency of collection, 
circulation of results (i.e., categories in the Information Extension 
matrix in Chapter 5 of this book);  
          - project risks/assumptions (including relevant indicators, means of 
verification);       
          - project management (indicators, means of verification) 
          - lines of communication and feedback mechanisms 
          - monitoring chart: monitoring activity, frequency, person responsible, 
timing and total for LoP;  
          - evaluation chart: activity, person responsible, timing 
     Useful annexes 
          - forms (quarterly/annual monitoring, key questions for evaluations, 
etc.) 
          - GANTT chart for timing of M&E activities 
          - references used (including specific project documents) 
Example based on the UFHP M&E Plan
Dissemination 
and use
<<<PAGE=116>>>
CARE M&E Guidelines 114 
Chapter 11. Planning for M/E 
Matrix for generating an M&E workplan 
 
 Why? 
(purpose) 
For whom? 
(report to..) 
When?  
(schedule) 
Who is 
responsible? 
Who 
participates? 
What means? 
(data collect) 
Who to 
gather data? 
Who to 
analyse data? 
How 
disseminated? 
 
Baseline 
 
         
 
Monitoring 
system 
 
         
 
Mid-term 
Evaluation 
 
         
 
Final 
evaluation 
 
         
 
Ex-post 
evaluation
<<<PAGE=117>>>
CARE M&E Guidelines 115 
Chapter 11. Planning for M/E 
Logistical planning 
 
Planning for project logistics principally refers to the preparation of workplans 
for personnel (and project activities) and budgets. 
 
 
It is assumed that projects are familiar with the 
preparation of workplans and budgets.  This is just a 
short reminder that a thorough workplan will be 
critical to the rapidity and smoothness of information systems, including 
fieldwork and the ensuing analysis. A good workplan will have a detailed 
timeline for each activity, budget, equipment and supplies listing, and supervision 
plan (including persons responsible and tasks).   
 
 
The aims of any project related study or information 
gathering activity should include integrating the 
information generated with the planning and decision- 
making process.  Therefore, it will also be very important to budget accordingly 
for the post-fieldwork phases of analysis, write-up, printing, dissemination and 
subsequent action plans.   
 
 
 
 
 
 
 
 
 
 
 
 
 
Workplan 
Budget 
Common logistical problems  
• Cost overruns, e.g., M&E budget line used up with 
the baseline study 
• Project management takes on a ‘controlling’ role, 
e.g., lack of staff and target population participation 
in M&E  
• Donor (or project) insistence on international 
consultants with inappropriate skills and lack of local 
knowledge 
• Donors adopt a demanding, not consultative, position 
• Information system ignores socio-cultural values of 
the target population.
<<<PAGE=118>>>
CARE M&E Guidelines 116 
Chapter 11. Planning for M/E 
Detail: planning for a specific study 
Logistical considerations for a field study or evaluation (short list only) 
Personnel  
• stipends and per diem for any non-project staff 
• transportation costs and arrangements  
• training and preparation for the fieldwork 
• hotel and lodging bookings; also venue for any large group/community 
meetings 
• field equipment and supplies (forms, recorders, paper, field manuals, 
etc.) 
Data and communications flow  
• secretarial and data entry support 
• data entry arrangements: photocopying (if computers are being used, 
then: computers, software, printers, diskettes, etc.) 
• storage (for raw data) 
• communications (phones, faxes) 
Administration 
• administrative support 
• office accommodations 
• notification to facilities and communities of visits  
 
Data management 
Data generated in the process of M&E comes in many forms, e.g., maps, 
diagrams, field notebooks, computer generated spreadsheets, etc.  There has to be 
a common system of managing and storing data within a project.  Among the 
considerations is whether the information is expected to be the common property 
of both providers and users.  If so, it will need to be kept organised in a form and 
location where both groups can have access to it.  Ideally, management of data 
should be centralised and co-ordinated throughout all the categories of users.  
 
How the data is managed has implications on the sustainability of the M&E 
system itself.  For example, if the data is kept exclusively on a computer, it will 
be difficult to involve people who:  
• lack access to the computer 
• don’t know how to use the computer (or the software) 
• don’t have the resources to maintain it.
<<<PAGE=119>>>
CARE M&E Guidelines 117 
Chapter 11. Planning for M/E 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
The bottom line: 
A good M&E system is useful to its audiences (information users), practical to 
implement (feasible for the project), timely, conducted ethically, and technically 
sound.   
 
 
 
Suggested criteria for a 
project information system 
• Must be able to consistently and honestly measure 
key indicators of project impact, effects and outputs 
to support CARE’s goals, including Household 
Livelihood Security (HHLS).  
• Should measure only necessary and sufficient 
project data for management decision-making.  
• Should enable measurement of bottom-line portfolio 
performance for CARE global information system 
• Should consider needs to measure empowerment, 
participation,  impact disaggregated by gender and 
other key target groups 
• Managers in the field and headquarters should be 
held accountable for implementing sound project 
management 
• Should not be overloaded with excessive data 
gathering requirements (for HQ or project). Too 
much data leads to bad data and ‘information 
overload’, and therefore is not utilised. 
• Need to narrow the focus to the most important 
indicators of impact and outputs 
Adapted from PMTF-API framework, CARE 1996
<<<PAGE=120>>>
CARE M&E Guidelines 118 
Annex 1. Glossary 
Annex 1  
 
Glossary 
 
Activity 
A specific project task that requires resources (personnel, funds, time, etc.) and 
transforms the resources into outputs.  E.g., training sessions, workshops, etc. 
 
Adoption 
The acceptance and application of project interventions by the target population, 
whether governments or rural households.  Adoption may be ‘primary’ (occurring 
among persons who have been contacted directly by the project) or ‘secondary’ 
(occurring among persons who have learned about some portion of the interventions 
from primary adopters). 
 
Assumption 
Circumstances or conditions important for the success of a project but not within its 
control.  These may include beliefs held by the designers of a project about the 
environment in which the project takes place.  They can include assumptions about 
outside influences (e.g. external conditions such as trends in weather patterns or 
national economies, or the role of government or other agencies), and assumptions 
about participants (e.g. that women in a target group can control HH income, or that 
farmers can control grazing on fields planted with trees).  Even though a project may 
not have direct control over many of these factors, it is important to state them (in a log 
frame), and to monitor them during the life of a project, so that changes can be made in 
project design if necessary.” 
 
Baseline study 
In CARE projects, the baseline is a preliminary assessment of target populations carried 
out shortly before starting implementation.  Baselines are collected at the outset of  a 
project (or an activity) to establish the pre-project conditions against which to measure 
future change.  The information gathered (and analysed) in the baseline consists of 
indicators specifically chosen for their anticipated use at a later time to investigate 
project effects and impacts.  The investigation is done by carrying out repeat 
assessments using the same set of indicators after the implementation of project 
interventions (see ‘before and after’).  Indicators (and methods of data collection and 
analysis) used in baseline surveys may be qualitative or quantitative.   
 
Before and After (design) 
An evaluation design that uses the data generated in the project baseline for comparison 
with a comparable study after project interventions have been in place for some time.  
Typically, this means a repeat data collection similar to the baseline will be carried out 
at the end of the project.  The follow-up survey can also be done some years after the 
project when there is concern about sustainability of impacts (i.e., an ‘ex-post’ 
evaluation).
<<<PAGE=121>>>
CARE M&E Guidelines 119 
Annex 1. Glossary 
 
Beneficiary 
Direct beneficiaries are individuals who receive services or resources directly from 
CARE or through a joint implementation partner.  This category is sometimes referred 
to as participants, clients, or recipients.  Indirect beneficiaries are individuals who 
benefit indirectly from the project.   
 
Bias 
Distortion of data/information (whether monitoring, evaluation, or research) brought 
about by various errors: planning (design error), selection of respondents (sampling 
error), collection (interviewer error), social desirability (respondent error), or analysis 
(researcher error). 
 
Closed-ended question 
Questions answered by marking an answer from a set of predetermined choices in a 
questionnaire.   
 
Control (control group) 
An evaluation design for determining whether any changes observed over time in the 
target community are actually effects and impacts due to project interventions.  The 
control group design requires identifying and periodically assessing a non-intervention 
community (i.e., a group of  persons or households that will not be getting project 
interventions) for comparison with project target areas.  This ‘control’ community must 
be as identical as possible to the project target communities, so that comparisons 
between the two communities can show which changes are attributable to the project.  
(see with/without) 
 
Data 
Facts, figures, opinions, observations which become information when they have been 
analysed and interpreted.  
 
Data sources 
The origin of information, including people, records, documents, soil, water, etc. 
 
Diffusion 
The spread of knowledge or practices beyond the point of initial project contact 
(sometimes referred to as ‘secondary adoption’), e.g., the spread of improved banana 
cultivation among farmers who have not been directly taught or visited by a project.  
This spread is usually a desirable effect of projects, but it may require special methods 
in sampling and evaluation studies in order to be identified and assessed.   
 
Effects  
In CARE terminology, effects refer to target population responses (e.g., changes in 
behaviours), or improvements in system conditions (access to or quality of resources) 
that result from the use of goods and services provided by the project.  Project effects 
describe results in the target populations that happen at the Intermediate Goal (IG) level 
as a consequence of some degree of exposure to project interventions. These 
intermediate level changes provide beneficiaries with the necessary tools to bring about
<<<PAGE=122>>>
CARE M&E Guidelines 120 
Annex 1. Glossary 
sustainable improvements in their well-being (i.e., leading to project impacts).  Effects 
can be positive (beneficial) or negative (harmful, e.g., adopting cash crops that increase 
women’s labour without increasing their access to funds).   People who act as a result of 
project interventions may or may not be aware of the project (e.g., diffusion of farming 
practices to farmers who have never been directly contacted by the project, or 
“secondary beneficiaries”).    
 
Effectiveness 
The extent to which a project meets its objectives through its interventions (delivery of 
goods and services).   
 
Efficiency 
The extent to which a project uses resources appropriately and completes activities in a 
timely fashion.   
 
Enumerator 
A common term for the person who collects data to complete a structured (quantitative) 
questionnaire; contrasts with an interviewer.   
 
Equity 
The extent to which the resources and opportunities generated by the  project are 
equally distributed within and among households.  It pertains to the allocation of 
resources according to gender, ethnicity, social status and class.   
 
Evaluation 
An evaluation is a careful examination and analysis of an on-going or completed project 
(see mid-stream, final, ex-post).  Evaluations usually include examination of the project 
design (goals and plans), implementation (inputs and outputs) and results (effects and 
impacts).  Typically, evaluations look at project efficiency, effectiveness, sustainability 
and relevance.  Attention is paid to both intended and unintended results, and to factors 
affecting the level and distribution of any benefits produced.  The main purpose of 
evaluation is to guide decision-makers (see stakeholders).  
 
Ex-post evaluation 
This is an evaluation conducted at a substantial time interval after the termination of 
project interventions, e.g., 5-10 years after the end of a project.  The purpose of ex-post 
evaluations is to investigate the sustainability and nature of long-term project impacts.  
In reality, ex-post evaluations are rarely done because few donors are willing to fund 
them.  (see also evaluation)  
 
Final evaluation 
This is an evaluation that occurs at or near the end of the project (sometimes referred to 
as “summative” evaluation); and contributes to the end of project summary report.  In 
order to examine the effects and impacts of the project, the final evaluation is usually 
linked to the conditions in the target population before the project by collecting and 
analysing similar information to that done in the baseline study (see “before and after”). 
 
Final goal
<<<PAGE=123>>>
CARE M&E Guidelines 121 
Annex 1. Glossary 
In log-frame terminology, this refers to what the project hopes to achieve in the long 
term (i.e., beyond the life of the project).  Usually stated as substantive improvements 
(impacts) that are expected to take place in some aspect of the lives of the project 
participants or target population.   
 
 
Focus group discussion 
A semi-structured discussion with a small group of individuals selected on set criteria 
so that they are relatively homogeneous.  The discussion is guided to elicit individual 
and group ideas, reactions, opinions, perceptions, and solutions to a short list of key 
topics.   
 
Hypothesis  
In terms of project design, refers to presumed correlations between outputs (causes) and 
effect, and between effect and impact. For example, a common hypothesis is that the 
provision of sources of clean water will lead to reduced incidence of water-borne 
diseases.  If a hypothesis can not be accepted (e.g. by citing research literature or 
evaluations of projects where this hypothesis was proven under essentially similar 
conditions) it may need to be tested as a part of project’s evaluation design. 
 
Impacts 
As used in CARE project terminology, ‘impact’ refers to fundamental and sustainable 
changes in the human conditions or well-being of target populations, reflecting the 
satisfaction of basic needs.  Basic needs include food, health services, favourable 
environmental conditions (potable water, shelter, sanitation), primary education, and 
community participation.  To obtain the essential resources necessary to meet basic 
needs, households must have adequate access to finances, skills, time and social 
positions.  To qualify as impacts, these changes should be observable at household 
level, and be able to be attributed to project interventions. Because of the duration of 
time needed to attain household level impacts, they may be difficult to identify within 
the lifetime of a project.  Impact indicators are usually the ones associated with the final 
goal level in the project’s logical framework.  As with ‘effects’, impacts may be 
intended or unintended and beneficial or harmful. 
 
Implementation 
This phase in a project is when project interventions directed to target populations are 
taking place.  The project is drawing on the resources specified in the project document 
(and log frame) to carry out activities toward the described project objectives.   
 
Indicator 
Something which provides a basis to demonstrate change as a result of project activity 
for a target population, i.e., for measuring progress towards objectives.  It may express 
quantitative elements (i.e., be written as numbers) or qualitative aspects (i.e., 
descriptive words).  An indicator is like a ‘marker’ which shows what progress has been 
made (targets show what progress is still expected).  Indicators may also be summary 
measures, e.g., when they are a composite of several lower level indicators into a single 
index indicator, such as the Human Development Index used by the UNDP
<<<PAGE=124>>>
CARE M&E Guidelines 122 
Annex 1. Glossary 
Input 
Inputs are the resources needed by a project to implement activities.  These include the  
human and financial resources, physical facilities, equipment, materials, in-kind 
contributions.  Inputs only occur during the life of a project.  Inputs are one of the items 
routinely tracked in project monitoring, especially for cost-effectiveness and 
accountability.   
 
Intermediate goal 
A log-frame term that states the changes intended by a project in systemic or 
behavioural conditions in order to reach the final goal.   
 
Interventions 
The physical items and services to be delivered through a project to its intended target 
population.   
 
Key informant interview 
An interview with a person having special information about a particular topic, e.g., 
someone with first-hand experience of a certain condition, someone who is providing 
training or other direct services to people with a certain condition, or in a particular 
community, etc.  These interviews are generally conducted in an open-ended or semi-
structured fashion, allowing the interviewer to probe and follow up topics of interest in 
depth.   
 
Logical framework 
The logical framework (log frame) is a planning tool, designed before the start-up of 
project activities.  The main elements of the log frame illustrate the project’s hierarchy 
of objectives and targets, its indicators for assessing achievements of the objectives, 
sources of the indicator information, and key assumptions outside the scope of the 
project that may influence its success.  A log frame is constructed in a systematic and 
logical manner based on an analysis of information collected on constraints and 
opportunities for interventions to a specific problem.  The log frame is referred to 
continuously throughout the life of a project; it is the most important document telling 
in detail what the project intends to achieve, and how it intends to achieve the 
objectives.   
 
Mid-term evaluation (mid-stream) 
Mid-term evaluations are generally carried out about half-way through the life of a 
project, with the anticipation that implementation of project interventions is in full 
operation.  These evaluations, which are also known as ‘formative’ evaluations, are 
intended principally to assess project progress and make recommendations for 
strengthening the project during its second half.   
 
 
 
Monitoring 
Monitoring refers to the on-going process of regularly collecting, analysing and using 
information to guide project implementation.  The main foci of monitoring are project 
inputs, performance and progress.  A well designed M&E plan links monitoring
<<<PAGE=125>>>
CARE M&E Guidelines 123 
Annex 1. Glossary 
information with evaluation, including periodic measurement or output and effect 
indicators (when feasible).  An effective monitoring system is crucial to good project 
management.    
 
Open-ended question 
A question that allows for a full-text, freely given answer in the respondent’s own 
words, rather than a closed-ended question that restricts responses to predetermined 
categories.   
 
Outcomes 
Outcomes (or results) often refer to all that happens as a consequence of a project’s 
interventions.  This concept is usually divided into the more specific terms of effect and 
impact.   
 
Outputs 
Outputs are the products that the project produces.  They are direct results of project 
activities, i.e., generated through the project and within project control.  They are 
usually expressed numerically (quantitative data) and have a time frame.  Outputs occur 
within the life of the project, and are among the items assessed in routine monitoring.  
Monitoring indicators of outputs allows projects to track project efficiency, i.e., 
achievements versus expected targets. Project outputs may refer to: a) the results of 
training, such as the number of farmers trained in improved agricultural techniques 
(note that this can include assessment of changes in knowledge, skills and attitudes); b) 
capacity building, such as the number of extension staff trained, water systems built, 
committees established; c) service outputs, such as an increase in the number of project 
locations; and d) service utilisation, such as the number of people fed, or number of 
children measured.    
 
Participant observation 
A method of observational data gathering wherein the observer lives with the people 
being observed and takes part in their daily activities.   
 
Participation 
The active involvement of intended beneficiaries in project needs assessment, design, 
implementation, monitoring, evaluation and decision-making.  The main purposes of 
participation are to encourage self-determination and sustainability of the development 
process.  
 
Pre-code 
A method for structuring and limiting the possible responses to questions on a 
questionnaire.  This technique can facilitate rapid data gathering, but requires very 
careful design and pre-testing to be sure that the instrument is accurately obtaining the 
desired information.   
 
Pre-test 
To be sure of efficacy, accuracy and feasibility, it is essential to pilot test (make a trial 
run of) questionnaires and other data gathering instruments with a small group of 
respondents before conducting an actual data collection exercise.  A full-scale pre-test
<<<PAGE=126>>>
CARE M&E Guidelines 124 
Annex 1. Glossary 
would also give a trial to methods of respondent selection, data management and 
analysis.   
 
Primary data 
Data collected specifically to meet information requirements of a project, e.g., a 
baseline survey or a set of focus groups for an evaluation.  Is contrasted to secondary 
(existing) data from sources outside the project.   
 
Probability sample 
A method of selecting respondents (or other sources of information) where all members 
of the source group (e.g., households in a project target area) have an equal chance of 
being chosen.  Also known as a ‘random sample’.  Can be combined with purposive 
sampling, e.g., a random sample of female-headed households.   
 
Processes 
The interventions or set of activities through which project’s inputs are used to obtain 
the expected outputs.  This is the activity level for CARE.  These activities include 
management and supervision, counterpart training, logistics and service delivery, 
technical assistance and the monitoring and evaluation information systems.   
 
Purposive sample 
A method that selects respondents (or other sources of information) based on specific, 
defined criteria.  The criteria are not based on mathematical (statistical) probability, but 
other intentional choices, e.g., extreme examples for in-depth study that illustrate the 
potential range of a given situation.   
 
Qualitative information (or methods) 
Qualitative data is descriptive, expressed in words or visual/auditory images, and gives 
a more holistic picture of a situation than one can get with quantitative data.  Qualitative 
approaches are particularly useful for describing the range and nature of issues in a 
given situation; for eliciting perceptions, beliefs, and explanations; and for spontaneous 
discovery of issues emerging from the field.   
 
Quality of services 
Quality is assessed by the range of choices that clients have, the completeness of 
information given to clients, technical competence of the provider, quality of 
interpersonal relations, and appropriateness of services available.   
 
Quantitative data (or methods) 
Quantitative data is numerical, i.e., it is data in a form that can be counted (numbers) 
and manipulated mathematically (statistically).  Quantitative approaches are especially 
good for assessing the prevalence and distribution of a phenomenon.  It is easier to 
aggregate numerical information, but it can be subject to misinterpretation, i.e., 
‘missing the point’.  Quantitative approaches can be good for testing hypotheses, but 
less satisfactory than qualitative methods for identifying the core issues to include in a 
hypothesis in the first place.   
 
Questionnaire
<<<PAGE=127>>>
CARE M&E Guidelines 125 
Annex 1. Glossary 
A data collection instrument containing a set of questions organised in a systematic way 
(as well as a set of instructions to the enumerator/interviewer about how to ask the 
questions).    
 
Reliability 
The extent to which a study (or evaluation) can be repeated, i.e., the degree to which 
data collected are consistent among different observers or the same observer at different 
times.  For example, if ten persons (trained as data collectors) observe the same farm 
practice using the same checklist, they should be reporting the same findings.   
 
Sample 
A portion of a larger population selected for data collection in order to reduce time, 
labour and cost.  Ideally, the sample should be qualitatively and quantitatively 
representative of the larger group from which it is drawn.   
 
Sample size 
The number of source members in the sample.  The sample size depends on precision 
requirements for the data, as well as feasibility and resources available.   
 
Sampling frame  
The list of all potential respondents (e.g., a list of all villages or all households in the 
target area) from which the sample will be drawn.   
 
Secondary data 
Data collected by someone outside the project, for purposes outside the project, e.g., 
national census data.   
 
Stakeholders 
Potential or actual ‘owners’ of a project, i.e., persons who have a direct interest in the 
project.  Often taken to mean persons (or organisations) that have the capacity to make 
or influence decisions affecting the design and implementation of a project.  Typically, 
these include the target population/participants, project and country office staff, 
counterparts, donors, and other interested agencies.   
 
Stratified sample 
A sampling procedure that combines purposive and random sampling.  Purposive 
sampling is done to identify relevant sub-groups or ‘strata’ out of the overall 
population, e.g., female-headed households.  The potential members in each sub-group 
are then listed (preparing the sampling frames), and random sampling is used to select 
the final respondents from within each of the sub-groups.   
 
 
Sustainability 
The concept of sustainability, as it is applied to projects, includes multiple aspects.  
Some of the main ones are: a) potential for project’s impact to continue after CARE’s 
intervention terminates;  b) capacity of target population to be able to continue to 
practice an innovation or technique without continued project intervention;  c) Capacity 
of local institutions to continue project activities after the project ends.  This includes
<<<PAGE=128>>>
CARE M&E Guidelines 126 
Annex 1. Glossary 
self-financing of activities via contributions of users of goods and services provided, 
complementary funding from local funding sources, and decreasing dependency on 
complementary funding from external sources; d) Sustainability also has an aspect of 
environmental protection.  In this case, sustainability refers to the maintenance or 
enhancement of resource productivity on a long-term basis, minimising the depletion of 
non-renewable resources and enabling communities to care for their own environment.   
 
Systematic sampling 
A method of sampling respondents whereby the first member in the sampling frame is 
selected, followed by every ‘n
 th’ member (e.g., every third household in a north-south 
line through the centre of a village).  These periodic selections become the sample.    
 
Target 
Numeric expression of achievements anticipated by a project.  These may be written in 
absolute terms (e.g., 10,000 farmers will replace tobacco farming with alternative cash 
crops), or as a proportion/percentage change (e.g., the proportion of single adult men 
reporting use of condoms at their last sexual encounter will increase from 5% to 50%).  
Targets are generally embedded within objectives, which specify the time frame in 
which the achievement is supposed to occur.   
 
Target population 
Some projects are targeted at particular population groups (who thereby become special 
interest groups, i.e., ‘target groups’).  Examples include women farmers, demobilised 
soldiers, forest dwellers, sexually active adolescents, etc.  Sometimes the projects are 
aimed at or focus on whole communities, i.e., ‘target communities’. 
 
Validity 
The extent to which the findings accurately represent the actual or true situation.  There 
are three main kinds of validity.  Design validity means that the structure of a data 
collection exercise can yield the desired information (e.g., a ‘before and after’ design to 
be able to assess achievements).  Technical validity means that the methods of data 
gathering will get the necessary data (e.g., observation of farms to see adoption of 
crops, rather than relying on reports by non-farming public officials).   Instrument 
validity means the instrument being used will measure what it is supposed to measure 
(e.g., in a study of safe water, questions about boiling water will find out about water 
being treated for drinking purposes, and not be confused by water being boiled for 
bathing).
<<<PAGE=129>>>
CARE M&E Guidelines 127 
Annex 2. Abbreviations 
Annex 2:  Abbreviations (acronyms) 
 
[terms in bold font are related to CARE] 
 
ACD .......................Assistant Country Director  
AIP ........................Annual Implem entation Plan  
ANR .......................Agriculture and Natural Resources  
API ........................Annual Project Implementation report  
BAIP ......................Bushenyi-Ntu ngamo Agricultural Innovations Project 
CBO ........................Community-Based Organisation 
CD ..........................Country Director   
CREHP .................Community Reproductive Health Project 
CRHW ...................Community Reproductive Health Worker 
DHT .......................District Health Team 
DME ......................Design, Monitori ng and Evaluation  
DTC .......................Developmen t Through Conservation project 
EARs .....................Expenditure Analysis Reports 
EOP.........................End of Project 
EPI ..........................Expanded Programme on Immunisation 
FEW .......................Field Exte nsion Workers 
FG ...........................Final Goal 
FO ..........................Field Officer 
GNP ........................Gross National Product 
GoU ........................Government of Uganda 
HH .........................Household 
HHLS ....................Household Livelihood Security 
HMIS ......................Health Management Information System 
IG............................Intermediate Goal 
IOP ........................Individual Operating Plan 
KI ...........................Key Informant 
LC ..........................Local Council (government administrative unit) 
LF............................Log Frame (part of the project document) 
LFA ........................Logical Framework Approach (to planning) 
LOP.........................Life of Project 
MoU .......................Memorandum of Understanding 
MOV .......................Means of Verification 
MTE........................Mid-Term Evaluation 
M&E .......................Monitoring and Evaluation 
NGO........................Non-Governmental Organisation 
OFR .......................Overseas Financial Report 
OVI .........................Objectively Verifiable Indicator 
PAD .......................Programme Assessment and Development (part of CARE-USA 
Programme Division)
<<<PAGE=130>>>
CARE M&E Guidelines 128 
Annex 2. Abbreviations 
PIR ......................... Project Implementation Report 
PM.......................... Project Manager 
PRA ........................ Participatory Rapid Appraisal 
RDC ....................... Resident District Commissioners 
RMU ..................... Regional Management Unit (part of CARE-USA Programme 
Division) 
SWOL..................... Strengths, Weaknesses, Opportunities, Limitations 
TBA........................ Traditional Birth Attendant 
UFHP .................... Uganda Family Health Project
<<<PAGE=131>>>
CARE M&E Guidelines 129 
Annex 3. Key Document Outlines 
Annex 3  
 
Suggested components for some key M&E documents 
 
1.  Evaluation report 
• cover (authorship, date of report, reporting period) 
• executive summary  (and data base abstract for CARE evaluation data base): short 
description of project, including final and intermediate goals, purpose of the 
evaluation, overall assessment and conclusions, main findings and 
recommendations, lessons learnt (addressed to other professionals who design and 
evaluate similar projects) 
• table of contents 
• background of project (start/finish dates, origin of concept, goals (and targets), 
description of interventions, persons involved; wider context in which project has 
taken place, including key events likely to have affected the project) 
• description of evaluation (purpose, design, methodology, outcome/effect measures, 
implementation measures) 
• findings/results (identification and appraisal, implementation and monitoring, 
outcome/effect and impact; achievements and distribution of benefits; beneficiaries; 
institution-building, organisational linkages; problems; sustainability) 
• discussion (including attribution, cost-benefit considerations, potential for 
replication) 
• summary of conclusions and lessons learnt 
• recommendations (the project management, to CARE, to donors,  for subsequent 
M&E of this project and others) 
• annexes: ToR, itinerary and list of persons consulted, references, methods of data 
collection, statistical information 
 
 
2.  
Terms of reference for an evaluation or research study 
• background and purpose of the study 
• questions to address 
• study approach – data collection and analysis methods 
• special skills and characteristics of the investigator(s) 
• time frame and level of effort 
• reporting requirements – final work plan, preliminary and final reports, participatory 
review meetings, other 
• deliverables
<<<PAGE=132>>>
CARE M&E Guidelines 130 
Annex 3. Key Document Outlines 
3.  Contract: final agreement about services and responsibilities for an 
evaluation 
• parties to the agreement and date 
• focus of the evaluation (major questions, outcomes/effects, implementation, costs, 
other) 
• instrumentation (tests, questionnaires, interviews, observations) 
• data collection plans (sites, methods, sampling, persons involved and their roles, 
schedule) 
• methodology to be used for analysis 
• staff/project participation: roles in co-operating with data collection and analysis; 
participation in reporting and review meetings, data to be made available 
• reporting: participatory review meetings, date of draft report, review period, final 
report, dissemination (audience) 
• budget
<<<PAGE=133>>>
CARE M&E Guidelines 131 
Annex 4. Methods: Toolkit 
Annex 4 
 
Methods: Selected techniques for M&E data 
collection and analysis – short takes 
 
File A-1  Introduction: participatory rapid toolkit 
File A-2  Reviewing and analysing secondary data 
File A-3  Social mapping (PRA) 
File A-4  Historical mapping (PRA) 
File A-5  Rapid social organisation profile (PRA) 
File A-6  Focus group discussions 
File A-7  Semi-structured interviews 
File A-8  Qualitative interviews  
File A-9  Rapid surveys 
File A-10  Question design for surveys and interviews 
File A-11  Group brainstorming (PRA) 
File A-12  Ranking exercises (PRA) 
File A-13  Strengths, weaknesses, opportunities, limitations/threats (SWOL/T)
<<<PAGE=134>>>
CARE M&E Guidelines 132 
Annex 4. Methods: Toolkit 
File A-1  
 
INTRODUCTION: PARTICIPATORY RAPID TOOLKIT 
 
This toolkit emphasises qualitative methods, including interviews and PRA (Participatory 
Rapid Appraisal) tools,  because most monitoring and evaluation efforts will need to use them 
for limited, non-random coverage of respondents. 
 
Various participatory tools for information gathering, communication, education and project 
management have been developed; we can refer broadly to this growing family of managerial 
tools for participatory and sustainable development as “participatory learning and action” or 
"action research" methodologies.  The main features of action research include: 
 
L
OCAL FOCUS:  
* A strong link with local, community-based development initiatives. 
Action research aims at generating information and supporting decision-making 
processes useful for local project planning, implementation, monitoring and evaluation 
purposes. 
* Involvement of local actors and development professionals in a joint learning process.  
Action research is participatory by definition. It promotes collective discussion and 
negotiation, on the basis of facts, between local actors' and development professionals' 
perceptions about the issue(s) under investigation. 
* A focus on the felt needs of community members and local institutions.  
Action  research deals with issues directly experienced and explicitly acknowledged as 
problems by the people who are asked to participate. 
 
A
CTION ORIENTATION: 
* Minimal time-gap between data collection and feedback.  
Timeliness of analysis and rapidity of feedback are meant to increase cost-effectiveness 
of the research and promote the practical use of its results. 
* Carrying results into planning and action. 
Action research goes beyond just recommending changes based on the findings (as 
often happens with conventional research).  The action research process generally 
incorporates methods for translating the knowledge gained into practical decisions 
and/or feasible courses of action. 
 
P
ARTICIPATORY PROCESS: 
* Equal concern for process and results.  
Action research consists of collecting "fairly quick and fairly clean" information, but it 
doesn’t stop there.  It also aims at making all participants aware of the implications of 
the issue (problem, situation, etc.) being investigated and supporting them in 
undertaking relevant action. 
* Built-in communication and educational strategy to facilitate local involvement.  
While final written reports are useful for institutional or training purposes, active-
learning workshops are considered the most important means for providing feedback to 
local institutions and the community at-large.
<<<PAGE=135>>>
CARE M&E Guidelines 133 
Annex 4. Methods: Toolkit 
* Re-definition of the role of the development professional.  
The professional is expected to act more as a “facilitator” and less as an “expert” in his 
or her field.  Working methods are selected and assessed from the perspective of 
"appropriate technology" for the community.  Precision and accuracy of findings are 
traded off against timeliness and user-friendliness of research and decision-making 
techniques. 
 
Together with skilful and non-intrusive facilitation, creative use of visual aids is an important 
strategy for supporting group exercises in action research.  Some examples of visual techniques 
that can be used (for data gathering, for analysis, for dissemination and for planning) include 
the following:   
• Graphic representations by means of pie-charts or bar-charts (or better yet – 
pictograms – graphs built of pictures) are suitable for conveying quantitative 
information even to non-literate participants.  The pictograms (whose shape is often 
inspired by daily objects such as trees, animals, pottery or food) can be used to 
describe and analyse time trends; patterns of relationship among different actors; or 
sequences of causes, problems and solutions.  
• Sorting, counting and ranking exercises may be done in written form, but if literacy 
is low, they can equally be carried out with everyday objects, such as seeds, stones 
or simple sketches on small slips of paper.  
• Maps and transect representations can be used very effectively in groups to 
describe and analyse the community’s spatial distribution of features of special 
interest (e.g., natural resources, types of soil, vulnerable families, types of services, 
water points, land tenure patterns, etc.). 
• Drawings, posters, pictures, and slides as well as open-ended stories, popular 
theatre and community-directed videos are widely used as an entry point for 
focusing group discussions.  
• Analytical matrices (e.g., column and row, Venn/chapati diagrams – see Chapters 3 
and 4) can be used to organise and analyse findings, including qualitative 
statements.  They can also be used on flip-charts or chalkboards for assembling the 
ideas developed in a brainstorming session with a group.  
 [Barton et al, 1996]
<<<PAGE=136>>>
CARE M&E Guidelines 134 
Annex 4. Methods: Toolkit 
File A-2  
 
REVIEWING AND ANALYSING SECONDARY DATA  
 
A review of existing data has several potential benefits, such as: refining specific objectives, 
identification of potential informants for interviews, further clarification of target groups in the 
population, and summarising what is known versus what remains to be answered in the field.  
Costs are very low, information can be gathered quickly and it can usually be done with a 
relatively small amount of local travel.  Depending on its quality, existing data can also permit 
greater depth of analysis for the population and environment situation.   
 
However, there are also some potential limitations.  Data may be incomplete, biased, or 
unreliable.  The methods originally used to collect the data may not be described.  Access to 
the materials will vary; and some agencies may expect a fee to respond to information requests, 
others may not allow access without several permission letters.  
 
The exercise of extracting content and meaning from secondary data will be improved if a set 
of open-ended questions are systematically used with the data.  Some potential questions are as 
follows:  
 
Problems (nature, range, distribution) 
- What information do we already have about the population and environment; problems that 
affect persons in this region?   
- What do we know about the distribution of leading problems among the residents in the study 
region?  E.g., what are the influences and relationships between age, gender, ethnicity, 
residence location, family structure, educational status, etc.?  
Behaviour patterns 
- What behaviours place the communities at risk?  which behaviours are protective? 
- What do we know about factors affecting behaviour change among people in this region?  
E.g., social competencies, supportive attitudes, social groups, etc.? 
Context 
- What do we know about external factors affecting the problems?  E.g., social norms, religion, 
economics?   
Institutional responses 
- What policies exist that aggravate or solve any of the problems? 
- What programmes and services are currently addressing the problems?      
- What is their coverage and how effective are they?   
- Who is funding and who is conducting these activities and services?      
- What future activities are planned? 
 
At the conclusion of the documents review, there are two other useful questions:  
a) What additional information about population and environment is needed but not 
available?  
b) For whom would this information be useful and why?
<<<PAGE=137>>>
CARE M&E Guidelines 135 
Annex 4. Methods: Toolkit 
File A-3  
 
SOCIAL MAPPING 
 
Participatory mapping starts with collective discussions among groups of community members 
and then proceeds to drawing maps of their perceptions about the geographical distribution of 
environmental, demographic, social, and economic features in their territory.  The participants 
are usually requested to draw their own map, e.g., on a flip-chart or on the ground, plotting 
features with symbols that are understood and accepted by all members of the group, regardless 
of literacy.  In certain cases purchased maps or aerial photographs can also be used. 
 
Purposes 
Participatory mapping is especially useful for providing an overview (or "snapshot") of the 
local situation.  It can also serve as a good starting point for environmental and social 
assessment.  Use of periodically repeated participatory mapping is very helpful in monitoring 
and evaluating changes in the target community (e.g., adoption of farming practices, 
distribution of social resources like schools and health units) and in the use of natural 
resources.  ‘Historical’ and ‘anticipated future’ mapping (i.e., drawing a series of maps 
referring to different moments) is helpful in describing and analysing trends over time.  
 
Steps in using the technique 
*  Explain the purpose of the exercise to the participating group. 
*  Agree beforehand on the subject of the mapping exercise and on the graphic symbols to be 
used.  Allow participants to choose their own symbols. 
* Ask a participant to be responsible for drawing or plotting symbols according to the 
suggestions of the group. 
*  Promote participation of all group members by posing individual questions.  Allow the group 
to discuss different opinions and perceptions. 
*  Once the map is finalised, ask participants to interpret the overall picture.  Suggest that they 
identify the main problems revealed by the map and ask them about possible solutions 
within the locally available resources (which are already drawn, or could now be drawn, 
on the map). 
* Remember that the map is community property; leave a good copy of the map in the 
community for their own use.   
 
Strengths and weaknesses 
+ Mapping and the associated discussions quickly provide a broad overview of the situation . 
+  Encourages two-way communication. 
+  Helps people in seeing links, patterns, and inter-relationships in their territory. 
+  Individuals who are non-literate can participate. 
-  Subjectivity and superficiality: mapping exercises must be complemented by information 
generated by other participatory assessment tools. 
-  Some cultures may have difficulties in understanding graphic representations.
<<<PAGE=138>>>
CARE M&E Guidelines 136 
Annex 4. Methods: Toolkit 
File A-4  
 
HISTORICAL MAPPING 
 
Historical mapping uses a series of participatory mapping exercises to portray the demographic 
and natural resources situation of the community at different moments of its history.  Three 
maps are drawn showing the situation as it existed one generation ago, at the present time, and 
what is expected after one generation’s time in the future. 
 
Purpose 
Historical mapping can be extremely helpful to introduce the time dimension in participatory 
environmental appraisal and/or participatory census exercises.  It can provide visual evidence 
of changes that have occurred and expected trends.  In this way it can help identify 
determinants of environmental degradation and population growth and enable participants to 
consider more suitable means of balancing or controlling these issues.  
 
Steps in using the technique 
* A map of the current demographic and environmental situation is drawn with participants. 
* With the help of older community members, the same exercise is repeated to show the 
situation as it was approximately twenty years ago. 
* The current and past maps are then compared, often with a brainstorming, to collectively 
identify major changes and their root causes. 
* Based on the list of changes and causes, a prospective map can be drawn by the participants 
to show their expectations of the situation which will exist in the community in 20-30 
years from now if the current trends are maintained.  
* The future map can be reviewed to explore differences between what is projected and what a 
desirable future status would be.  This discussion can then progress to identify potential 
means for addressing environmental degradation and population growth. 
 
Strengths and weaknesses 
+ The  technique can be very appropriate to summarise the results of a comprehensive 
participatory appraisal on environment and population dynamics. 
+ It may increase participants’ understanding that most positive and negative changes in 
environments and populations are shaped by historical, man-made actions. 
+ It can help to identify mid- or long-term solutions to the population and environment 
problems affecting the community. 
-  The exercise is long and complex.  At least three sessions with the group will be needed to 
get though the whole sequence of mapping and discussion. 
-  Sensitive issues from the past may be raised, including conflicts within the community and 
between the community and outsiders. 
- The analysis is likely to identify effects and causes which are beyond community control.  
Discouragement and frustration may develop among participants.
<<<PAGE=139>>>
CARE M&E Guidelines 137 
Annex 4. Methods: Toolkit 
File A-5  
 
RAPID SOCIAL ORGANISATION PROFILE (PRA) 
 
Information about social groups can be readily identified by community members as a 
participatory discussion and analysis tool.  Use a flip chart with the community working group 
to facilitate their collective work on this exercise.  The categories listed below (see also the 
following matrix) are usually very useful; additional columns, however, could be added by the 
community, e.g., date group started, where group is located, etc.  Such additions are quite 
acceptable, if they are not too many, and if the community can express how they think the extra 
information might be used.  
 
Group name – the group’s own name, in vernacular 
Size – of the group; number of members (if there are degrees of membership, or individual and 
household members, that information would also be useful.   
Gender of members – may be one gender or mixed; if mixed, give proportions 
Age – of members; can be given as a range, with some indication of whether there is a 
particular pattern of most members in a certain range 
Admission rules – how do persons acquire membership status: by appointment, nomination, 
paying a fee (and if so, how much), residing in a certain location, etc.?  Is there a 
recurrent fee to maintain membership, e.g., on a monthly or annual basis? 
Activities: level, focus – what is the nature of the group and what are its principal activities 
(e.g., cultivation, rotating credit, assistance to orphans, income generation, religious 
fellowship, political, etc.) 
Date group started – when was the group formed?  This gives some idea of the stability of the 
group.   
Location – where do the group’s activities take place?  At times, it can also be useful to get the 
mailing address or physical location for the group.   
Link person in the group – generally a resident of the community, and often the chairperson 
for the group.  Someone who can be contacted about group activities, or sharing 
information with the group. 
Link person in the project – if this data is being collected for a project activity, e.g., planning 
an intervention, there may be multiple project-related persons in contact with the 
community, but usually one individual who has or can have a stronger tie to the 
particular group for information sharing.   
Potential relevance to project – projects have different objectives (e.g., development, health 
education, gender sensitisation, social research, etc.);  this column can encourage 
thinking about the importance of all groups in the community. 
 
After completing the matrix, a discussion can lead to an exploration of the groups as resources, 
including potential relevance to the project (e.g., development, health education, gender 
sensitisation, social research, etc.).  Seeking comments and opinions from the community and 
project staff about the potential relevance of each group can help to discourage dependency on 
an external project.
<<<PAGE=140>>>
CARE M&E Guidelines 138 
Annex 4. Methods: Toolkit 
 
COMMUNITY ORGANISATIONAL PROFILE 
   
Community __________________   Date form completed ______________________         Person completing form 
____________ 
 
 
Group name Size Gender of 
members 
Age Admission 
rules 
Activities:  
level, focus 
Date 
group 
started 
Location Link person 
in group 
Link person 
in project 
Potential Relevance to 
project
<<<PAGE=141>>>
CARE M&E Guidelines 139 
Annex 4. Methods: Toolkit 
File A-6  
FOCUS GROUP DISCUSSIONS 
 
Focus groups are semi-structured discussions with a small group of persons sharing a common 
feature (e.g., women of reproductive age, shareholders in an irrigation system, users of a certain 
service, etc.).  A small list of open-ended topics, posed as questions (see example, boxes 3.14, 
3.15), is used to focus the discussion.  
 
Purposes 
Focus groups have been increasingly used in participatory research to identify and describe 
insider perceptions, attitudes, and felt needs. 
 
Steps in using the technique 
* Design a discussion topic guide (interview framework) (see boxes 3.14, 3.15).   
* Decide on the number of focus groups.  In a small community, two groups of 6-12 persons 
each and representing key opposing categories (e.g., men and women, peasants and 
herders, wealthy and poor, etc.) may be sufficient.  Be ready to hold additional sessions 
if the discussion does not succeed  (e.g., people don’t show up, the facilitator can’t keep 
the discussion on course, etc. ) 
* Select appropriate facilitators; which may involve matching by age, gender, or language 
ability (focus groups are best done in the local vernacular)   
* The interviewer acts as a group facilitator, and a second person acts as a rapporteur (note-
taker).  The rapporteur needs to write rapidly to capture people’s expressions as exactly 
as possible.  It may be useful to tape record the session, but only if the community and 
the group give permission.   
* Conduct practice focus groups with members of a similar nearby community; in small 
communities, this helps prevent people coming with pre-set answers. 
* Before starting, explain the purpose of the session to the group.  After posing topics, be sure 
each person has at least one opportunity to provide his/her ideas.  Over-talkative 
participants need to be controlled and silent ones stimulated. 
* As with semi-structured interviews (see File A-7), the facilitator is free to use a variety of 
probing questions to help extract ideas and to keep the talk focused.  Limit the length of 
the session to about an hour (including introduction). 
* Notes and recordings of interviews should be carefully reviewed immediately after the 
session  (and tape recordings transcribed as soon as possible).  
* Analysis consists of extracting key statements from the discussion. These statements should 
be reported in the matrix exactly as phrased by the participants.  
 
Strengths and weaknesses 
+  Group interaction enriches the quality and quantity of information provided 
+  Focus group discussions are quite good at disclosing the range and nature of problems, as 
well as eliciting preliminary ideas about solutions. 
-  Practice and experience in qualitative research procedures are needed. 
-  Large amounts of information are easily obtained, necessitating skills in extracting and 
summarising for the analysis
<<<PAGE=142>>>
CARE M&E Guidelines 140 
Annex 4. Methods: Toolkit 
File A-7  
 
SEMI-STRUCTURED INTERVIEWS 
 
Semi-structured interviews are lists of broad, open-ended questions to be addressed to 
knowledgeable individuals in a conversational, relaxed, and informal way. The interviewer is 
left free to rephrase these questions and to ask probing questions for added detail (e.g., "Who?", 
"Where?", "When?", and "How?") based on respondents' answers and conversation flow.  This 
form of interview is more likely to yield in-depth opinions and perceptions than can be done 
with a rigid closed-ended questionnaire.   
 
Purposes 
Semi-structured interviews can be used to obtain specific quantitative and qualitative 
information.  Household features, gender-related issues, use of natural resources, household 
economics, and many other topics can be effectively explored.  
 
Steps in using the tool 
* Design an interview guide and a results summary form. 
* Decide who is going to be interviewed (purposeful sampling procedures); and select 
appropriate interviewers (may mean matching respondents and interviewers by age or 
gender; will depend on topic and local cultural values) 
* Pre-test the questionnaire guides with several individuals who are representative of the types 
of persons to be interviewed in the actual study (make sure the questions are 
comprehensible, that the answers are relevant, etc.) 
* Conduct a training for all persons who will be doing the interviews (i.e., the interviewers); be 
sure the training includes a number of practice interviews with other interviewers or 
community members and subsequent review to improve performance. 
* Teach the interviewers to make relatively brief notes during the interview, filling-out the 
summary form immediately after the interview; this will require practice to capture 
exact words and phrasing for quotations 
* Arrange for daily (or nightly) editing of all forms for completeness, errors, etc. 
* Hold daily discussions about problems encountered during the interviews and to review the 
preliminary results with other members of the team. 
 
Strengths and weaknesses 
+  Less intrusive than questionnaires; can be paced to fit the needs of the respondent 
+  Encourages two-way communication. 
+  Administered in an atmosphere that makes respondents feel at ease, which may include 
privacy and confidentiality, depending on topic. 
+ Can obtain very detailed information and richly expressive quotations 
-  Practice and experience are needed for appropriately using this tool; requires sensitivity and 
the ability to recognise and suppress one’s own biases.   
-  Interviewers should have good literacy, communication, and summarising skills. 
- Interviewers will need some grasp of the general topics covered in the interview.   
-  Facilitator support is needed for analysing data.
<<<PAGE=143>>>
CARE M&E Guidelines 141 
Annex 4. Methods: Toolkit 
File A-8  
 
QUALITATIVE INTERVIEWS  
One of the most important sources of information for monitoring and evaluating agriculture and 
rural development projects is qualitative interviews.  Qualitative interviews with project 
participants and other key informants help in understanding the complex ecological, 
sociological, cultural and other situations with which the project must deal.  They can also 
provide an in-depth understanding of the perspectives, attitudes, and behaviour patterns of the 
target population, which will not be fully captured by other modes of data gathering.  
Moreover, qualitative interviews can be used to generate hypotheses and propositions which 
can then be tested on a wider population using a structured questionnaire.  
 
Qualitative interviews are usually classified according to three broad types: a) informal, 
conversational; b) topic-focused; and c) semi-structured, open-ended.   
 
Reliability and validity of the interview  
How is the reliability of the information generated by a qualitative interview to be assessed?  
How can we be sure that the respondent has provided accurate information?  This problem, of 
course, is not unique to qualitative interviewing; it is common to all types of interviews.  But 
because of the subjective nature of the written summary notes, the issue of reliability is 
particularly pertinent in this context.  Because by definition, there is no totally objective test 
that can be applied in qualitative interview situations, judgement of accuracy must be based on 
an assessment of respondent-related factors.   
 
Knowledge 
Obviously, the first consideration is the knowledge that the respondent may be expected to 
have.  Remember, too, that the respondent may be knowledgeable about some items and 
relatively ignorant about others.  Therefore, the interviewer should ask himself the following 
questions with reference to each of the principal sub-topics in the interview.  Questions for a 
checklist include:  
• is the respondent’s knowledge of the matter direct and first-hand?  
• is the respondent in a position to provide accurate information? 
• if the respondent is relying on second-hand information, are these sources credible? 
 
Credibility 
Some people have a tendency to boast; others have a fertile imagination and unconsciously 
exaggerate; still others aim to enhance their self-importance by giving misleading answers.  
Questions for a checklist include:  
• is the respondent eager to make strongly authoritative statements? 
• does the respondent consider before replying and seem perceptive about the issues? 
• are the respondent’s answers based on practical considerations?  
 
 
Ability and willingness to respond
<<<PAGE=144>>>
CARE M&E Guidelines 142 
Annex 4. Methods: Toolkit 
Some respondents find it difficult to articulate their feelings, judgements, and opinions, 
especially to outsiders.  This problem is compounded when the interviewer comes from a 
higher socio-economic stratum.   
 
Ulterior motives 
Respondents may have an ulterior motive for providing inaccurate information.  Extension staff 
may exaggerate the performance and impact of agricultural extension activities.  A health 
worker may magnify the problems encountered on reaching out to target populations.  Staff 
directly involved in project efforts have a professional stake in promoting their activities and 
covering their shortcomings; often this bias is more sub-conscious than a deliberate attempt to 
mislead.  Questions for a checklist include:  
• was the respondent trying to paint only a positive picture? 
• was the respondent trying to rationalise a distasteful fact? 
• was the respondent dwelling excessively on problems and difficulties in order to 
seek sympathy?  
 
Bars to spontaneity 
The social context of the interview also affects the expression of ideas and opinions by the 
respondents.  For example, when a farmer is interviewed in the presence of government 
officials or project staff, he might not reveal the truth because he is afraid to antagonise them.  
Questions for a checklist on this include:  
• were there some people around whose presence might have affected the 
respondent’s answers? 
• was he anxious that others might overhear him? 
• was the location private enough to ensure total confidentiality for the interview? 
 
Desire to please 
There is a tendency for respondents to give answers which they believe the interviewer wants 
to hear, either from politeness, hope of benefits, or in the hope of shortening the questioning.  
In such a case, it is particularly important to avoid giving the respondent clues regarding the 
interviewer’s opinions.  Questions for a checklist:  
• did the respondent show undue deference?  
• did the respondent seek the interviewer’s opinion before replying? 
• did the interviewer say anything which silenced the respondent or changed the 
thrust of his responses?  
 
Other factors 
Finally, one should not forget that recent events might have influenced the views expressed by 
the informant.  The mental and physical status of the respondent also affect his responses.  
When he is tired, he can be irritable and react negatively to questions. 
 [Casley and Kumar, 1988]
<<<PAGE=145>>>
CARE M&E Guidelines 143 
Annex 4. Methods: Toolkit 
File A-9  
 
RAPID SURVEYS   
 
Methodology notes:  
• 20 questions (or less), fitting on one to three sheets of paper with room for answers 
• about 2/3 of questions pre-set, rest to be contributed by or specific to the concerns 
of the given community 
• capable of being administered by local people (e.g., local volunteers) in 
collaboration with trained supervision (e.g., divisional staff) 
• capable of being analysed rapidly in the field and raw results given to the 
community during the field phase 
• able to generate reasonable prevalence data for the community (e.g., based on visits 
to every household, or a sample of households which has been identified and 
numbered on the social resource map) 
 
Alternative strategies for identifying information to gather 
• Community-generated: what do community leaders want or need to know that 
would help them to better serve the needs of their community?  Begin with 
qualitative techniques (focus groups, key informant interviews, etc.) to get 
community input into what should be included in a survey questionnaire. 
• Project-generated, exploratory: what range of activities would the project like to 
consider for this area (or the programme for the project); what indicators would help 
in deciding where to focus their efforts 
• Project-generated, specific: based on a selected group of anticipated activities, what 
indicators would be likely to be measured at the outcome stage (and therefore need 
to be collected at the baseline for later comparison)? 
• Service-related: based on services reportedly available in the area, how often have 
the individual households received or made use of any services and what services 
from these various providers? 
 
Other data considerations 
• Data to be gathered should be useful (i.e., not just collected because it is ‘nice to 
know’) 
• Data should be anticipated to be more accurate (exact) or more accessible through a 
survey approach than would be possible in group sessions 
• Information to gather at the community level might already be available at a larger 
scale, but not for the micro-environment of the community, e.g., employment 
patterns, reasons for school drop-out, nature of disability, adolescent health (sexual 
and reproductive), latrine quality and usage, etc.
<<<PAGE=146>>>
CARE M&E Guidelines 144 
Annex 4. Methods: Toolkit 
File A-10  
 
QUESTION DESIGN FOR SURVEYS AND 
INTERVIEWS 
 
Avoiding inappropriate questions 
To make sure our questions are appropriate, we must become familiar with respondent groups – 
their knowledge of certain areas, the terms they use, and their perceptions and sensitivities.  
What may be an excessive burden for one group may not be for another.  And what may be a 
fair question for some may not be for others.  For example, in a survey of the handicapped, 
those who were not obviously handicapped were very sensitive about answering questions 
while the converse was true for the obviously handicapped.   
 
Questions are inappropriate if they:  
• cannot or will not be answered accurately 
• are not geared to the respondents’ depth and range of information, knowledge and 
perceptions 
• are not relevant to the evaluation goals 
• are not perceived by the respondents as logical and necessary 
• require an unreasonable effort to answer 
• are threatening or embarrassing 
• are vague or ambiguous 
• are part of a conscious effort to obtain biased or one-sided results.   
 
The best way to avoid inappropriate questions is to know the respondent group and not rely on 
stereotypes.  A brief story may bring this point home.  A researcher was pretesting a 
questionnaire on people who used mental health services.  During the test, the researchers 
expressed surprise that this group of respondents could handle certain difficult concepts.  
Annoyed, one of the respondents rejoined, “I may be crazy, but I’m not stupid.” 
 [GAO, 1986]
<<<PAGE=147>>>
CARE M&E Guidelines 145 
Annex 4. Methods: Toolkit 
File A-11  
 
GROUP BRAINSTORMING 
 
Brainstorming is a basic idea gathering technique employed in many group exercises.  It is 
based on a freewheeling discussion started by an open-ended and somehow provocative 
question forwarded by the facilitator.  At the same time, avoid opening statements that are 
leading, i.e., ensure that they do not promote or overemphasise a particular point of view that 
can bias the ideas of the participants.   
 
Purpose 
Brainstorming can elicit multiple perceptions of a given issue, and the group discussion which 
follows can help find the basis for a consensus among group members.   
 
Steps in using the technique. 
*  The issue to be discussed is introduced by the facilitator. 
*  The key-question is written on the blackboard or on a flip-chart. 
*  Participants are asked to provide short answers, i.e., no speeches at this stage.   
*  An important point to stress at the beginning is that ‘all ideas are good ideas’; if anyone does 
not agree with someone else’s point, they should give what they think is a better idea.  
Accept only additional contributions during the brainstorming, not disagreements or 
arguments; defer them to the discussion afterwards.  Encourage fresh ideas rather than 
repetitions of earlier items.   
*  Each participant is allowed to express his/her view.  Over-talkative participants will need to 
be quieted, and silent participants can be explicitly asked for ideas.  
*  The facilitator picks the basic point out of participant statements and ensures that it is written 
(or portrayed with a picture) on large cards tacked to a bulletin board or wall.  
Appropriateness of the summary is checked with the concerned participants. 
*  Keep the brainstorming relatively short, i.e., 15-30 minutes is usually sufficient to obtain 
most of the ideas on a specific topic without tiring the participants.   
* Review the results with the participant group.  Remove duplicated items and cluster groups of 
similar ideas.  (Having the ideas on cards facilitates rearranging them.) Highlight 
differences of opinion and discuss until a consensus is achieved. 
*  Results of the brainstorming can then be summarised and kept for future reference. 
 
Strengths and weaknesses 
+  A properly conducted brainstorming facilitates participation of all group members in the 
idea-building process. 
+  It helps to understand and, if needed, consolidate the degree of consensus and homogeneity 
within the group. 
+  It is a good introduction for more structured and focused exercises. 
-  Solid experience in dealing with group dynamics is needed by the facilitator to keep the 
discussion on track as well as good mediation and summarising skills. 
-  Setting and dynamics may hide conflicts existing within the group and affect the reliability of 
the brainstorming results.
<<<PAGE=148>>>
CARE M&E Guidelines 146 
Annex 4. Methods: Toolkit 
File A-12  
 
RANKING EXERCISES 
 
Ranking exercises, which may be done with groups or individuals, are a way to enable people 
to express their preferences and priorities about a given issue.  The technique may generate 
insights about the criteria through which different individuals, groups or social actors make 
decisions on the kinds of issues under investigation. 
 
Purpose 
Ranking exercise have been used for a variety of specific purposes, such as: 
- identification of needs, priorities and preferences 
- quantification of opinion and preferences as elicited through interviewing or 
brainstorming; 
- comparison of preferences and opinions as expressed by different social actors. 
 
Steps in using the tool 
*  Make a list of items to be prioritised (these could come from a brainstorming exercise); 
*  Recruit appropriate participants to be involved in the exercise; 
*  Define a simple ranking mechanism.  This may be based on a pair-wise comparison of items 
in the list; on sorting cards representing items in order of preference; or by assigning a 
score to the different items. 
*  Prepare a matrix on which preferences identified by participants could be jotted down (e.g., 
on the ground, with a flip chart, on a chalk board) 
*  Explain the ranking mechanism to each participant and ask them to carry out the exercise 
(e.g., give them three stones to place on any categories they want in response to a 
specific guiding question – which crop is the most difficult, which type of health 
provider is the most effective, etc.); 
*  Ask participants to explain the criteria on which their choice has been made 
*  Carry out a quantitative analysis of ranking series and interpret the findings on the base of 
qualitative statements about the criteria of choice. 
 
Strengths and weaknesses  
+  Ranking is a flexible technique which can be used  in a variety of situation and settings. 
+  Whenever categorical judgements are needed, ranking is a suitable alternative to closed-
ended interviewing.  
+  Ranking exercises are generally found to be amusing and interesting by participants and are 
helpful to increase their commitment to action-research. 
+  Information is provided on both the choices and reasons for the choices. 
-  Pre-testing is needed for the ranking mechanism and the tools to be used to facilitate it. 
-  Choices may be affected by highly subjective factors.  In order to generalise results to the 
whole community, a proper sampling strategy is needed.
<<<PAGE=149>>>
CARE M&E Guidelines 147 
Annex 4. Methods: Toolkit 
File A-13  
 
STRENGTHS, WEAKNESSES, OPPORTUNITIES AND 
LIMITATIONS (SWOL) ANALYSIS 
 
SWOL analysis is a powerful tool for group assessment of the issues of concern, particularly 
interventions or different potential courses of action.  It is based on a structured brainstorming 
aimed at eliciting group perceptions of the positive factors (strengths), the negative factors 
(weaknesses), the possible improvements (opportunities) and the constraints (limitations) 
related to the issue. 
 
Purpose 
SWOL analysis is especially useful for evaluating activities carried out in the community.  It 
can be focused on services provided by external agencies, as well as using it for self-evaluation 
of the interest group’s own performance. 
 
Steps in using the tool 
*  A four column matrix is drafted on the blackboard or on a flip-chart and the four judgement 
categories are explained to participants.  It will help to phrase the four categories as key 
questions, to which participants can respond.  
*  The facilitator starts the brainstorming by asking the group a key question about strengths.  
Responses from the group are jotted down on the relevant column of the matrix. 
*  For each strength, the related weaknesses, opportunities and limitations are also identified by 
the group. 
* Participants may have different opinions about an issue, and contradictory statements may be 
forwarded.  In such cases, the facilitator can work toward a consensus, which may 
require a point to be discussed at some length.  Each entry is left on the final matrix 
only after achieving a group agreement. 
 
Strengths and weaknesses 
+  The technique stresses consideration of different sides (positive and negative) of the issues.  
It therefore helps to set the basis for negotiations and trade-offs. 
+  SWOL is a good means to build a consensus within the group and to prepare the group to 
discuss with outsiders. 
+  SWOL can promote group creativeness.  It helps to link perceptions of things as they are 
with realistic expectations about how things could be. 
-  Sensitive topics and differences of opinion may arise during the discussion. 
-  Some group members may dominate the discussion. 
-  Summarising long discussions in short statements requires that the facilitator have good 
synthesising skills.
<<<PAGE=150>>>
CARE M&E Guidelines 148 
Annex 5. Log Frame Terms 
Annex 5: Alternative terms for log frame concepts   
 
Organisation/Agency Citation  
CARE terminology 1 Impact Effects Outputs Processes Inputs 
CARE LogFrame terms  Final Goal (FG) Intermediate Goals (IG)  Outputs Activities Inputs 
CIDA 2 Overall goal Project purpose Results/outputs Activities Inputs 
DANIDA 3 Development Objective Immediat e Objective Outputs Activities Inputs 
European Union 4 Overall objectives Project purpose Results Activities  
FAO 5 Development objective Immediate objectives  Outputs Activities Inputs 
GTZ 6 Overall goal Project purpose Results/outputs Activities Inputs 
NORAD 7 Development objective Intermediate objectives Outputs Activities Inputs 
ODA 8 Goal Purpose Outputs Activities  
PC/LogFrame 9 Goal Purpose Outputs Activities  
UN Agencies 10 Impact Effect Outputs Processes Inputs 
USAID 11 Final goal Strategic goal, objective Intermediate results Activities 202E 
World Bank 12 Goal Project purpose Outputs  Inputs 
1.  Cause and effect levels of indicators  proposed by the Programme Management Task Force, CARE 1996 
2.  Guide for the use of the Logical Framework Approach in the Management and Evaluation of CIDA’s International Projects, Evaluation Division, nd. 
3.  Logical Framework Approach: a flexible tool for participatory development; DANIDA 1996 
4.  Project Cycle Management: integrated approach and logical framework, Commission of the European Communities Evaluation Unit Methods and Instruments for Project Cycle Management, No.1; 1993 
5.  Project Appraisal and Use of Project Document Formats for FAO Technical Co-operation Projects; Pre-course review activity;  Staff Development Group, Personnel Division, 1992 
6.  ZOPP in steps, 1989 
7.  The Logical Framework Approach (LFA): handbook for objectives-oriented project planning; nd. 
8.  A guide to Appraisal, Design, Monitoring and Management and Impact Assessment of Health and Population Projects, ODA, 1995 
9.  PC/LogFrame ™, TEAM technologies, inc.  1988-1992 
10. Monitoring and Evaluation Guiding Principles: for the design and use in rural development projects and programmes in developing countries; UN ACC Task Force on Rural Development; 1985 
11. The Logical Framework Approach to Portfolio Design, Review and Evaluation in AID: Genesis, impact, problems and opportunities, CDIE, 1987 
12. Valadez, J. and Bamberger, M.  (eds.)  Monitoring and evaluating social programs in developing countries: a handbook for policy-makers, managers and researchers; World Bank, 1994
<<<PAGE=151>>>
CARE M&E Guidelines 149 
Annex 6. References 
Annex 6 
 
REFERENCES:  
 
A.  Internal CARE documents:  
CARE 
Guidelines to M&E framework design 
CARE Bangladesh, nd 
 
CARE-Uganda 
Report on Monitoring and Evaluation Workshop, 9-13 September, 1996 
CARE-Uganda, 1996 
 
Leyland, S. 
Uganda Family Health Project: Monitoring and Evaluation Plan, Draft 3 
CARE-Uganda, 1996 
 
DME 
CARE Programme Design, Monitoring & Evaluation Resource Packet, Version 1.1 
CARE-USA, 1996 
 
DME 
Report of the East (Anglophone) Africa DME Workshop 
CARE-USA, 1996 
 
B.  External documents 
 
Barton, T. 
Project ownership - idea paper 
HNI, 1996 
 
Barton, T.; Borrini-Feyerabend, G.; de Sherbinin, A.; and Warren, P. 
Our People, Our Resources: supporting rural communities in participatory action 
research on population dynamics and the local environment 
IUCN, 1996 
 
Biggs, S.D.   
Resource-poor farmer participation in research: a synthesis of experience from nine 
national agricultural research systems. International Service for National Agricultural 
Research, The Hague, Netherlands.  OFCOR Comparative Research Paper No.3    As 
cited in: Biggs, S. and Farrington, J.  Agricultural Research and the Rural Poor: A 
review of social science analysis; IDRC, 1991
<<<PAGE=152>>>
CARE M&E Guidelines 150 
Annex 6. References 
Casley, D.J. and Kumar, K. 
The collection, analysis, and use of monitoring and evaluation data 
The World Bank; International Fund for Agricultural Development; FAO 
Johns Hopkins University Press, 1988 
 
Evaluation Office, UNICEF 
A UNICEF guide for monitoring and evaluation: Making a difference? 
UNICEF, 1991 
 
Evaluative Studies Branch and Centre for Development Information and Evaluation 
Selecting data collection methods and preparing contractor scopes of work 
AID Program Design and Evaluation Methods Report, No. 3 
USAID, 1985 
 
Feuerstein, M-T. 
Partners in evaluation: evaluating development and community programmes with 
participants 
TALC, 1986 
 
Gosling, L. and Edwards, M. 
Toolkits: A practical guide to assessment, monitoring and evaluation 
Development Manual 5 
Save the Children, 1995 
 
Greeley, M.; Kabeer, N.; Davies, S.; and Hussein, K. 
Measuring the poverty reduction impact of development interventions: research 
proposal 
IDS, Univ. of Sussex, 1992 
 
Hageboeck, M.  
Manager’s guide to data collection 
USAID, Practical Concepts Inc.; 1979 
 
Herman, J.L.; Morris, L.L.; Fitz-Gibbon, C.T. 
Evaluator’s Handbook 
Sage Publications, 1987 
 
Narayan, D. 
Participatory Evaluation: Tools for managing change in water and sanitation 
World Bank Technical Paper Number 207 
World Bank, 1993 
 
NGO Unit, ODA 
Project Evaluation: a guide for NGOs 
ODA, The Joint Funding Scheme, 1993
<<<PAGE=153>>>
CARE M&E Guidelines 151 
Annex 6. References 
Panel on Monitoring and Evaluation   (ACC) 
Monitoring and Evaluation Guiding Principles: for the design and use in rural 
development projects and programmes in developing countries 
UN ACC Task Force on Rural Development, IFAD, 1985 
 
Popular Participation Programme; Development Studies Unit 
Guidelines for consultations and popular participation in development processes and 
projects 
Department of Social Anthropology, Stockholm University, 1991 
 
Ritchie, A. 
Evaluation of the economic and social benefits of income generation projects: Small 
Economic Activity Development Sector  (SEAD) workshop report 
CARE Bangladesh, 1994 
 
Ritchie, A. 
USAID/Uganda PRESTO project concept paper; technical annex: monitoring and 
evaluation 
USAID, 1995 
 
Rugh, J. 
Self Evaluation: Ideas for Participatory Evaluation of Rural Community Development 
Projects. 
World Neighbours, 1984, 1992 
 
Scriven, M. 
Evaluation Thesaurus, Fourth Edition 
Sage Publications, 1991 
 
Sebstad, J.; Neill, C.; Barnes, C.; and Chen, G. 
A framework for assessing the impact of micro-enterprise interventions at the level of 
the household, the enterprise, the individual and the community 
USAID, PRISM, 1995 
 
Technical Advisory Service, DANIDA 
LFA – Logical Framework Approach: A flexible tool for participatory development 
DANIDA, 1996 
 
Valadez, J. and Bamberger, M.  (eds.) 
Monitoring and evaluating social programs in developing countries: a handbook for 
policy-makers, managers and researchers 
EDI Development Studies 
The World Bank, 1994