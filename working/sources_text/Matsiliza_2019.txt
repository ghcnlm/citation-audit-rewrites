<<<PAGE=1>>>
490 Journal of Reviews on Global Economics, 2019, 8, 490-499  
 
 E-ISSN: 1929-7092/19  © 2019 Lifescience Global 
Strategies to Improve Capacity for Policy Monitoring  and 
Evaluation in the Public Sector 
N.S. Matsiliza* 
Durban University of Technology, South Africa  
Abstract: Scholars around the globe have contested the inadequ ate infrastructure and tools used by public  s e c t o r  
agencies to monitor and evaluate public policies and programmes. Some of th e urgent issues of concern deal with the 
inadequate human capacity in  public agencies and departments to conduct fair and cre dible evaluations in the public 
sector. South Africa is not the only country that has adopted a government wide monitoring and evaluation system, other 
countries like Ghana, Kenya, Benin and Uganda have also endorsed fo rmal monitoring and evaluation practice in the 
public sector. This article argues that monitoring and evaluation must not just measure the effec tiveness and efficiency of 
public programmes and processes, but it must create a sustainable process w hereby participants and evaluators can 
learn from the process. Capacity building in monitoring and evaluation must be fairly and continuous conducted to offer  
credible and valid information and knowledge on M&E by training agencies and institutions like universities. Thi s 
theoretical paper adopted document analysis strategy to  review and evaluate do cuments used as data source. Lessons 
learnt from this article contribute towards the existin g strategies to enhance monitoring and evaluation.  
Keywords: Appraisal, capacity, evaluation, infrastructure, monitoring, t echniques, tools. 
INTRODUCTION AND BAC KGROUND 
The government in South Africa has adopted the 
Government Wide Monitoring and Evaluation 
(GWM&E) to assess the performance of public 
departments and identify gaps which are causing 
challenges to the provision of services and goods.  The 
GWM&E goals and strategies are to identify the gaps in 
supporting planning, budgeting, programme 
implementation, ﬁnancial management and reporting 
processes (The Presidency, 2009). The public sector, 
over the last decade, has been concerned with 
improving capacity in developing government systems 
in le ss and semi -developed nations like South Africa. 
Currently, public service is experiencing moderate a nd 
serious challenges that affect the implementation of 
GWM&E in South Africa. Majola (2014) holds the view 
that M&E implementation is still at an incipien t stage in 
South Africa, hence there is a need to broaden human 
capacity that is designated to conduct M&E in public 
organisation. Hence, this article explores various 
strategies and methods to enhance the capacity for 
monitoring and evaluation, with the i ntention of 
improving performance in the public sector. Human 
capacity building should be a priority for improving 
performance in the public sector, especially to those 
departments and organisations that conduct systematic 
performance evaluation and monito ring and evaluation. 
The improvements in capacity of evaluators must focu s 
on the needs of their clients and stakeholders, the skills  
 
 
*Address correspondence to this author at the Durban University of 
Technology, South Africa; Tel: +2733 8458852;  
E-mail: NoluthandoM1@dut.ac.za 
needed for evaluation and the resources and technical 
tools required during the evaluation process.  
Since the adoption of GWM&E government has 
issued the National Policy Evaluation Framework (The 
Presidency, 2010) to consolidate the strategies and 
principles of monitoring and evaluation public 
organisations in South Africa. On its adoption, the 
GWM&E provided broad goals on its institutional 
arrangements that focused on a transversal approach 
underpinning legal mandate, financial responsibilities, 
roles and responsibilities of government officials and  
that of agencies targeted to implement GWM&E. Even 
though government departments have complied with 
the adoption of M&E, they are still grappling with the 
change that has been brought  by GWM&E due to lack 
of human capacity (Maphunye, 2013). The main 
problem is that public departments have not yet 
developed sufficient human capacity and sufficient 
skills to conduct policy M&E. Mthethwa and Jili (2016) 
demonstrated that some municipaliti es lack the 
required necessary knowledge, skills and competence 
to carry out duties related to the M&E of public projects.  
Thus, government and other stakeholders that are 
involved must acquire appropriate skills and capacity to 
manage and utilise M&E effe ctively and efficiently. 
Similarly, Naidoo (2012) warns that poor planning of  
appraisal plans and high political expectations on M&E 
outcomes may produce poor results and 
recommendations that can later affect evidence -based 
decision-making.  
It goes withou t saying that monitoring and 
evaluation has moved from being a performance 
evaluation tool to an emancipating and empowering
<<<PAGE=2>>>
Strategies to Improve Capacity for Policy Monitoring  Journal of Reviews on Global Economics, 2019, Vol. 8      491 
process that can instill a new culture of building 
capacity in the public service (Abrahams, 2015). 
Therefore, this article argues that there is a need to 
continuously advance the skills and knowledge needed 
for M&E in the South African public sector. For this 
article to respond to the problem statement, it first 
reviewed literature on the discourse of M&E and 
conceptualise few concep ts that are mainly framing the 
discourse of M&E. It was necessary to review 
challenges of implementing M&E in South African 
public organisations in order to establish what kind of 
strategic positions are needed to advance capacity of 
M&E in the South Afric an public sector. This article 
reviewed literature and adopted a document analysis 
strategy in collecting and analysing secondary data 
which were mainly electronic books, articles from 
accredited journals, government policy reports, 
published minutes of th e parliamentary monitoring 
group and other research reports focusing on 
monitoring and evaluation. Data was drawn from 
printed and electronic documents that reports various 
empirical studies on strategies for improving monitoring 
and evaluation in the publ ic affairs. Public affairs 
includes public organisation, non -profit organisations 
and agencies’ experiences on M&E. The researcher 
further filtered down and the articles and focused on 
those that are closer to the practice and capacity 
improvement on M&E i n public organisation. The main 
focus of the researcher is to draw lessons on how 
public organisations can enhance their capacity of 
M&E. The researchers sought to review literature pri or 
to document analysis, and incorporated it into the 
information from the reports for further analysis. 
Literature review and document analysis enabled the 
researcher to draw themes from the data and respond 
to the aim of this article, which is mainly to explore 
strategies that can enhance skills, techniques, human 
capacity for M&E. The researcher adopted both 
literature review and document analysis in order to 
address the limitation identified by Bowen (2009) as the 
over-reliance on few documents.  
THE DISCOURSE OF MON ITORING AND 
EVALUATION 
Various scholars have paid attenti on to the 
discourse of monitoring and evaluation, by providing 
diverse approaches towards the discourse of M&E with 
the intention of improving the way government works 
(Motingue and van der Waldt, 2013). There is a 
growing devotion of scholars, consultants  a n d  
institutions that envisage M&E to be upgraded to a 
disciplinary niche area (Basheka and Byamugisha, 
2016). However, it is important to understand what 
monitoring is and what evaluation entails in order t o 
understand the discourse of M&E. The World Ban k 
(2010) has demonstrated that monitoring and 
evaluation are inseparable since they are both applied 
in order to check the progress in the performance of an 
activity or a programme. Monitoring is viewed as  an 
ongoing process of data collection and analysis  o f  
performance indicators that permits one to relate to a 
progressive programme result (Ile, Eresia -Eke and Ile, 
2013). Monitoring can therefore assist supervisors and 
middle managers to constantly monitor progress on the 
implementation of their departmen tal key performance 
indicators on a daily and weekly basis by collecting all 
the reports to be consolidated for evaluation purposes.  
The Organisation for Economic Cooperation and 
Development (OECD) defines monitoring and 
evaluation as an ongoing function that practices the 
systematic gathering of data on specified indicators, to 
offer management and key stakeholders in a 
continuous developmental reporting interlinked with 
indications of the extent of progress and achievement 
of objectives and progress in t he use of allocated funds 
(OECD, 2018). Meyers (2002) is of the view that 
evaluation must provide opportunities for revisiting the 
learning programme strategy needed to improve the 
knowledge of recipients through continuous 
amendments and improvements. Sim ilarly, Basheka 
and Byamugisha (2016) demonstrated that M&E in 
Uganda is implemented through a formalised mode of 
transmitting knowledge and is part of disciplinary 
inquiry. Similarly, the government in Ghana uses the 
Directorate of planning, monitoring an d Evaluation 
(DME), which focuses on the implementation of critica l 
government programmes as outlined by the Ministry of 
Trade and Industry (Catalogue of Ghana Standard of 
Authority, 2018). The move to align M&E with quality 
and standards of authority is a  g o o d  m o v e  t o  a l l o w  
governments and evaluators to be guided on how they 
can better track the performance of public programmes 
and processes.  
Therefore, evaluation will encompass more 
thoughtful assessment  of activities than monitoring. 
Evaluation is the p rocess of defining the merit, worth 
and value of things (Public Service Commission, 2014). 
There are various types of evaluations, and each can  
be distinguished as formative (or process) or 
summative evaluation. Formative evaluation is often 
allied with a mid-term evaluation (for performance 
improvement), while summative evaluation includes an 
end-of-initiative review (for issues like accountability,
<<<PAGE=3>>>
492     Journal of Reviews on Global Economics, 2019, Vol. 8 N.S. Matsiliza 
policy- a n d  d e c i s i o n-making). Evaluation in research 
includes a ‘set of research questions and research 
methods aimed at examining activities, processes and 
strategies for the indication of whether the objectives 
have been achieved, or whether the programme 
yielded better results to the beneficiaries (Vedung, 
2011). In these two examples, the evaluator implies 
more of an independent, external, and objective role.  
Evaluation is the organized and objective ongoing 
assessment of tasks or completed project, programme, 
together with its planning, implementation, and 
conclusion and results (Ille, et al. 2019). Evaluation can 
also identify priorities and relevance of actions and 
their intentions measured through objectives, to 
determine outcomes, progress on effectiveness and 
efficiency, and the impact of interventions and 
sustainability of programmes. An evaluation shou ld 
provide information about processes and programmes 
regarding their credibility and usefulness, especially 
when there are beneficiaries, to provide lessons to be 
learned in order to improve the decision -making 
process for governments, donors and recipien ts. It is 
evident that both monitoring and evaluation are distinct, 
and they complement each other. Information on 
monitoring can be collected on a daily and monthly 
basis from reports about a policy, programme, or 
project (and over an extended period) to determine 
outcomes, whereas evaluation explores causality and 
provides evidence on the worth of programmes and 
projects, and substantiates why targets and outcomes 
are, or are not, achieved.  
Monitoring and evaluation systems are not new to 
current governm ents. The ancient governments 
conducted monitoring of their grain and livestock 
production on a regular basis, more than 5,000 years 
ago. Today, modern governments also conduct 
monitoring and evaluation to create a synergy of eve nts 
on checks and balances on a daily basis, monthly 
reports and annual auditing and assessments that 
would produce a consolidated assessment to track 
their expenditures, revenues, personnel performance, 
resources, programmes and project activities, goods 
and services produced, and so forth (Lopez -Acevedo, 
Krause and Mackay, 2012).  
While public organisations seek capacity building to  
be at the core of their performance targets, they must 
build it to incorporate improvements in their vision, 
culture and values, internal organisational  s y s t e m s  
such as planning, cooperative affairs and human 
resources. Evaluators and senior managers must be 
subjected to specific internal training on M&E or attend  
professional training through training providers such as 
universities and colleges. This wil l enable them to trace 
gaps at an early stage and identify wider results 
(whether positive or negative) in the due course of the ir 
work. The accounting officers or senior managers will  
need to record the whole process, in particular the 
changes that occurr ed before the employees were 
trained and then after they have been trained. This will 
illustrate whether the capacity building programmes 
offered by the department on M&E are really working 
and are necessary for specific units or for all 
departments.  
The heads of departments, political appointees and 
line managers can also identify organisations with the 
best practices on M&E and pair with them with other 
organisations in order to share their practices and 
benchmarks on delivery of goods and services. This  
can assist evaluators and evaluates in understanding 
how they can add value to the evaluation process. 
Similarly, managers can also use the formal tools to  
help make an organisational assessment on the 
availability of the skills and knowledge required for  
M&E. Organisational assessment (OA) tools, often 
known as organisational capacity assessment tools 
(OCATs), must be designed to assess capacity, and 
plan capacity improvement when it is needed (Nigel 
and Smith, 2010). These tools should also be identified  
along the lines of the key performance indicators of the 
departments/units in order to monitor and evaluate 
capacity development or capacity building.  
Leaders, at political and senior official levels and the 
CEO’s of state enterprises as well as members of the 
executive, must lead by example and empower their 
followers by knowing more and by sharing information 
with their subordinates about M&E to ensure that goo d 
evaluations are conducted regularly, and that 
evaluations are properly designed for the task . Leaders 
must also partner and collaborate on M&E projects to  
share their experiences with NGO’s and private sector 
managers who coordinate M&E for quality 
improvements so that they can learn how M&E 
processes are reported and interpreted and how 
information on results is disseminated. Leaders must 
have the capacity to establish whether 
recommendations have been acted upon. Moreover, 
they should be able to investigate whether there is 
compliance on those recommendations and take 
actions if there are none b ased on the existing policy or 
laws relating to the implementation of programmes.
<<<PAGE=4>>>
Strategies to Improve Capacity for Policy Monitoring  Journal of Reviews on Global Economics, 2019, Vol. 8      493 
CHALLENGES OF MONITO RING AND EVALUATION  
The professional field of monitoring and evaluation 
is fairly new, as a result employees and consultants 
conducting M&E have limited e xperience to support the 
evaluations. This in turn leads to inadequate skills to 
carry out the evaluations (Mthethwa and Jili, 2013). In  
some departments the units depend on a few senior 
evaluation managers to carry out the work. For 
instance, municipaliti es in South Africa rely on 
consultants and on the department of cooperative 
governance to conduct evaluations. Motingoue (2012) 
is of the view that most M&E assessments fail due to 
the shortage of qualified evaluators with skills needed 
to successfully con duct evaluations that will according 
to the work plan. There is an endless demand for 
experts who can develop the capacity of M&E systems 
in government departments in conjunction with existing 
training institutions. Motingoe (2012) further points out 
that few departments have still not yet reached an 
acceptable level of understanding of the monitoring and 
evaluation process and are operating in a lame -duck 
style. This has crippled the entire notion of monitoring  
the performance of these departments.  
According to Majola (2014), the process of 
monitoring and evaluation is always the responsibili ty 
of managers, hence it sometimes endorses a top -down 
approach. Subordinates have to take orders from their 
managers. The challenge is that M&E systems may be 
part of the centralisation of power and it can be seen by 
programme managers to be a tactic to control the 
responsibilities performed by managers. With the 
additional task of M&E, managers become overloaded 
with tasks they need to account for. Similarly, the public 
sector is experiencing some delays in the central 
coordinating of M&E since some departments/units do 
not have a comprehensive view of the existing M&E 
practices across all spheres of government (Engela 
and Ajam, 2010).  
The recent adoption of the GWM&E  f i e l d  i n  t h e  
public service, with a centralised arrangement is a risk 
to agencies partnering with government since data is 
drawn from a single M&E system. Trained and skilled 
personnel with technical advice are still scarce, hence it 
becomes a problem for  d e p a r t m e n t s  t o  r e p l a c e  
employees that migrate from one office to another. 
According to Mapitsa and Khumalo (2018), monitoring 
and evaluation has overlooked the technical aspects 
associated with its design and the tools needed to 
conduct the M&E process. M ost evaluations focus on 
the socio -economic outcomes. However, there is an 
escalation of demand for M&E systems at national and 
cross-sectoral systems of governance due to the 
decentralisation of government structures and 
programmes.  
The GWM&E has inheren t risks in the existing 
structure on data and information management that 
needs greater accountability and security. There is also 
a desire to make data more widely available and for it 
to be used for political gain. Addressing these 
challenges will not be easy, it will require lot of time and 
professional support. One approach is to create a 
professional and systematic approach of M&E. The 
following section will elaborate on the strategic 
priorities for improving the capacity required to conduct 
policy M&E  m o n i t o r i n g  a n d  e v a l u a t i o n  i n  t h e  p u b l i c  
sector. 
Monitoring and evaluation is criticised for being 
paired together by scholars during their 
conceptualization, with less consideration of their 
dichotomy and the  i n d e p e n d e n c e  o f  e v a l u a t i o n .  
According to Picciotto (2013), evaluation can be treated 
as an independent process without being isolated from 
organisational performance evaluation. In addition, 
evaluation is sometimes treated as a learning process 
where evaluators receive certification to augment th eir 
knowledge of evaluation. There can be a danger to 
treat evaluation as only an educational process since it 
can ignore the benefits that can be brought by 
evaluation as an emancipatory approach. An 
empowerment and emancipatory approach can add 
value to goal attainment of ECB, in which this paper 
seeks to advocates as a necessity for the transforming 
South African public service. Vedung (2010) supports 
emancipatory evaluation that has emerged as an 
alternative for organisations that has lost trust in 
believing i n  s c i e n t i f i c  e v a l u a t i o n s  t h a t  a r e  b a s e d  o n  
experiments and positive evaluation research.  
If an organisation hires certified evaluators and still 
produce bad evaluation results that can hamper the 
strategic progression of the organisation, there is a 
need to support empowerment evaluation in public 
organisations (Guba and Lincoln, 1989). Peterson 
(2017) affirms that social programmes desires social 
issues, values and stakeholders perceptions to be 
taken into account during evaluation in order for 
evaluation goals to be achieved. In participatory 
evaluation, stakeholders can provide credible and 
reliable performance information that can have lessons  
to be submitted to the policy makers. Finally, it goes 
without saying that both educational evaluation and
<<<PAGE=5>>>
494     Journal of Reviews on Global Economics, 2019, Vol. 8 N.S. Matsiliza 
emancipatory evaluation must be adequately resourced 
to enhance its impact on the organization and to evade 
the perception that they are only there for window 
dressing.  
DISCUSSION 
Improving M&E Capacity  
The implementing of M&E systems in an 
organisation needs extensive efforts to improve 
performance that is required by the organisational 
structure and culture (Lomofsky, 2014). Some 
departments have developed a participatory M&E that 
include empowerment of skills during the M&E process. 
The rationale for a participatory process is to deve lop 
an institutional knowledge and enhance the application 
of the strategies and tools while including the members 
of the unit being evaluated (F etterman & Wandersman, 
2002). It is necessary for organisations to be selective 
in choosing the type of M&E and skills needed to 
assess the worthiness of their activities and processes.  
This article uses the evaluation capacity (ECB) to 
illustrate the exte nt to which capacity can be 
developed to improve M&E.  
Figure 1 demonstrates a comprehensive evaluation 
capacity building (ECB) model that can be adopted by 
public organisations. The strength of ECB is in its 
nature of work that has a clear direction and a flow of 
duties and responsibilities organised through a 
framework of individual, organisational and public 
levels. The ECB is imperative since it can address 
gaps in identifying the need for M&E and improve 
capacity by developing the organisational M&E pla ns 
based on the demands of the stakeholders, 
communities and governments, building on the strength 
of its people and addressing their challenges. Capacity 
building (and development) is the process by which 
employees (at an individual level) and organisatio ns 
attain or improve their existing skills and knowledge to 
work better in a suitable environment with the proper  
tools and equipment needed to accomplish their jobs 
competently (McKegg, Wehipeihana and Pipi, 2016).  
In the case of M&E, human resources, sk ills and 
information are part of the capacity needed for both the 
evaluators and the users of evaluation reports to 
understand better the system of M&E and its use. 
Assessing performance of the organisation and that o f 
employees can enhance M&E capacity. T he ECB 
supports the enhancement of performance in order to 
improve the overall of the organisations. Bourgeois 
(2016) assessed the relation between performance and 
evaluation in developed and developing nations, and 
found that performance measurement can b roaden 
organizational evaluation capacity. At organisational 
level, there are merits in the application of the ECB 
such as the following:  
 
Figure 1: Evaluation Capacity Building (ECB).  
Source: McKegg and Pipi (2016).
<<<PAGE=6>>>
Strategies to Improve Capacity for Policy Monitoring  Journal of Reviews on Global Economics, 2019, Vol. 8      495 
• According to McKegg, Wehipeihana and Pipi 
(2016), ECB can provide long -term outcomes in 
monitoring and evaluation of organizational 
capacities.  
• Vedung (2010) is of the view that improvement in 
tools and techniques used during evaluation can 
improve the performance in relation to the 
organisational mission.  
• Moeng and van der Waldt (2012) demonstrated 
that improvement on M&E capacity can enhance 
delivery of effective services.  
• According to Picciotto (2013), clients and 
suppliers can accept the credibility and 
legitimacy of the organization that provide better 
trained M&E evaluators who know their job.  
• Vedung (1997), affir ms that clients easily shift 
from a down -graded brand to a better evaluated 
brand when services are rated after evaluation. 
Therefore, evaluation capacity building can 
increase the ability to renew and continually 
adapt and achieve sustainability in the pr ovision 
of goods and services.  
According to McKegg, Pipi (2016), M&E has to take 
account managerial requirements such as 
communication systems, data management, ongoing 
tracking of deliveries, legislative requirements and a 
clear M&E framework that indicat es all the lines of 
accountability and responsibilities. Ile et al . (2019) are 
of the view that M&E must be well -coordinated through 
a systematic framework to avoid errors and mistakes 
that can compromise the achievement of M&E 
outcomes. Based on the liter ature reviewed, there are 
resources and skills that can be tapped to improve the  
capacity of M&E in public organisations, and some of 
them include the following:  
1. Developing a Clearly Defined M&E Unit  
In 2011, the Cabinet adopted that National 
Evaluation Policy Framework that was mainly providing 
a set of guidelines that would make evaluations to 
improve government’s performance and development 
impact, accountability, decision -making and to widen 
the knowledge base around government’s work. Even 
though th ere is the department of Monitoring and 
Evaluation within the Presidency, departments have 
incorporated their M&E work within the existing units. 
Kustel et al . (2017) are of the opinion that public 
departments need to de velop an M&E system that will 
support the leadership and management of the 
organisation, whether it is in the context of people or 
learning-oriented to enhance the development of M&E. 
The M&E unit can augment the M&E process when 
organisations provide improved and effective 
communication pro cesses that support the diverse 
strategies to promote the use of M&E. Mapitsa (2018) 
is of the view that i t is necessary for departments to 
arrange and establish a new organisational unit that 
highlights the roles and responsibilities  for monitoring, 
evaluation and reporting. Some departments can 
establish M&E plans that will encompass the mandates 
and outcomes for achieving evaluation and the 
guidelines for the process of the M&E as identified in 
the M&E planning in as far as collection of data, 
analysis a nd reporting. According to Visser, Kusters, 
Guijt, Roefs, and Buizer (2014), an organisation must 
have the c apability to act and commit to working 
properly, including planning, taking decisions and being 
practical on these decisions together. According to 
Matsiliza (2012), strengthening organisational 
arrangements must be conducted along with 
performance appraisals of departments and 
programmes. Managers must crop in employees when 
conducting organisational evaluations, and exposed 
them to diverse tools of participatory M&E. The merits 
of using participatory and empowerment evaluation is 
its replicability, the enhancement of sustainability, and 
effectiveness of programmes and projects through the 
establishment of community knowledge on M&E and 
people’s organisational capacity.  
The advantage of setting a separate organisational 
unit for M&E is that there can be a clear indication of 
accountability lines from the senior manager to the 
evaluators and the administrative assistants who carry 
out evaluations for d ifferent programmes. There can be 
overlapping of duties and less commitment when a 
department is using the same staff to conduct 
evaluations, performance management and other 
departmental duties and there will be a shortfall in 
ensuring that all institutio nal arrangements are taken 
care of. The senior personnel in charge must also give 
guidance on the processes and lead the unit in 
scheduling programmes and projects that are due for 
monitoring and evaluation and identifying accountabi lity 
measures. Naidoo ( 2013) is of the view that a separate 
unit for M&E can add value to systematic evaluations, 
but at the same time it can bring discomfort to other 
units in the organisation. However, the evaluation unit 
is not totally independent at national level since it i s 
situated within a managerial hierarchy. It negotiates 
decisions with the top government officials since it’s in
<<<PAGE=7>>>
496     Journal of Reviews on Global Economics, 2019, Vol. 8 N.S. Matsiliza 
the apex of decision -making, and the risk is that 
employees might not trust the evaluation managers 
since it may seem that they are policing t hem or 
assessing their performance.  
2. Human and Physical Resources   
It must be a priority to improve M&E by making sure 
that there are adequate human resources and 
infrastructure to implement and lead the M&E system. 
Human resources include the expertise of staff and the 
skills needed for monitoring and evaluation.  Visser et 
al. (2016) alluded to the pillars of improving human 
behaviour as an increase of their commitment to M&E. 
These scholars suggest that evaluators must be 
motivated to think about what t hey can learn from 
behavioural changes and what that means for 
participants in order to think about and understand 
what needs to be done to increase the use of M&E by 
making sure that the staff are ready to focus on the  
process. However, in some organisati ons, behaviour 
change goes hand in hand with the mind -set. 
Employees must be exposed to various formal and 
informal training to learn about evaluation dynamics 
that can assist them in deciding on options to 
participate and understanding the expectations of  t h e  
evaluation process.  
Buckley et al. (2015), agrees that critical thinking is 
imperative during planning and implementation of 
evaluation since it can empower managers to decide to 
accept and not to accept certain ideas based on their 
belief and knowle dge. Critical thinking is needed in 
decision-making since it involves posing rational 
questions, critiques about costs and resource 
allocation, identification of assumptions and preparing 
evaluators to reflect on options and making informed 
decisions in pr eparation for actions. In addition, 
effective monitoring and evaluation requires negotiation 
skills, research skills, writing skills and presentation 
skills. At an institutional level, monitoring and 
evaluation must be unique since it is systematic, and 
cannot involve everyone, only a selected and qualified 
team to do the work, and must differentiate itself by 
affirming clear goals to be achieved once it is done. To 
add to that, the institutional category must also consist 
of national M&E policies, internal  o r g a n i s a t i o n a l  
policies, control measures, operational systems, 
stakeholders and collaboration with other institutions 
and institutions dealing with professionalisation of 
M&E. Lastly, the governance category must involve 
leadership capability in dealing with the supervision of 
M&E activities, such as accountability, transparency , 
oversight and project and programme management.  
3. Costs and Budget 
Monitoring and evaluation can be improved by 
allocating adequate and sufficient budget to conduct all 
evaluations, and money must be appropriated 
according to what is required by the M&E plans. Each 
department/unit must submit votes that include M&E 
tasks ahead of deadlines for submitting votes. 
According to the National Treasury (2018), the Cabin et 
is required to  p r o v i d e  f i n a n c i a l  s u p p o r t  i n i t i a t i v e s  t o  
avoid problems and to accelerate implementation of 
M&E in key sectors of the economy through initiative s, 
such as Operation Phakisa, on an ongoing basis. 
However, to be able to improve capacity for M&E, a 
department must be able to estimate all the necessary 
resources that will be included as part of the monitori ng 
and evaluation of programmes. The most commonly 
identifiable expenses on resources include staff time, 
expenses of consultants, field data collection, da ta 
analysis costs, office equipment (computer, phones, 
and stationery), logistics like accommodation and 
travelling expenses.  
It is crucial for an organisation to acquire M&E that 
meets an acceptable standard in order to improve 
planning and to budget for  e a c h  o f  t h e  d i f f e r e n t  
elements of M&E results in a system that is fit -for-
purpose in completing evaluations. Data for monitoring 
must not suit monitoring and performance only, but it 
must ensure that there is sufficient capacity to col lect, 
store, and ana lyse information needed for evaluation 
purposes. In return, this will save costs by shared 
learning through data within different clusters. In that 
fashion, M&E data cannot be analysed only to ensure 
accountability on an ad hoc basis. The South African 
government uses an incremental budgeting system, 
hence it would be proper to assess the previous 
appropriations and variations in the auditor’s reports of 
previous years so that managers don’t repeat mistakes 
and errors that were identified by the auditors, s uch as 
the improper and misuse of public funds. Where there 
were shortages in resources allocated by managers of  
programmes and projects, evaluators must make 
recommendations for improvement.  
4. Information and Electronic Database  
Monitoring and evaluatio n require information 
systems for data storage and for data analysis. There 
is a need to strengthen all information frames and 
security for systems that store collected information 
from various units/departments of an organisation. 
There is a great necessi ty for information 
communication technology ( ICT) based multi -sectoral
<<<PAGE=8>>>
Strategies to Improve Capacity for Policy Monitoring  Journal of Reviews on Global Economics, 2019, Vol. 8      497 
and integrated M&E systems to support and build the 
capacity of government M&E departments at national, 
provincial and local levels in order to develop M&E 
systems which are responsive to specific needs and 
conditions. The GWM&E provides for the assignment 
of a policy framework that is considered by the M&E 
working group of the Presidency.  
Proper information is the basis for good decision -
making in M&E, hence it must be properly managed , 
shared and stored. Without accurate information, 
protocols and standards, information can be vulnerable 
to information abusers. There must be proper quality 
and security systems to manage information well, and 
to make managers and other information users  
accountable. The use of technology can boost the 
speed and quality of the process of M&E. The GWM&E 
in South Africa took the advantage of existing 
information management systems’ infrastructure (like 
the National Treasury, Performance reports and 
Statistics SA) and aligned it with the M&E system that 
is coordinated by the Presidency. Information from the 
source systems of various departments will also be 
used by other stakeholders in the GWM&E system to 
generate an overall picture of national, provincial a nd 
local performance. The secondary users of information 
can use derived IT systems to organise and analyse 
the data from the underlying organisational source 
systems (The Presidency, 2009).  
The use of a Programme Performance Information 
Framework (PPIF) can assists in clarifying the 
standards for performance and support of regular 
audits, in order to improve the structures, systems and 
processes required to manage information. Bad and 
weak information systems can threaten the security o f 
a department in a dvancing its M&E targets. The PPIF 
in Monitoring and evaluation must be able to provide 
clarity on checks and balances on the national statistics 
before it is published to the public domain. To ensure 
that the national statistics are reliable and valid, th e 
national statistical agency (STATS SA) and the 
Presidency must apply the national statistics standa rds 
properly and be monitored on a regular basis. The 
primary aim of building capacity can only be achieved if 
all information systems and data storage are  ef f ect i ve 
and efficiently completed .  
5. Coaching, Training and Mentoring  
Consultants and Grantmakers can improve M&E by 
providing technical assistance in the form of coaching 
(usually one -on-one customised support), and/or 
training (more often group lea rning and practice) and 
mentoring to build knowledge and skills. They can al so 
offer input regarding evaluation practices of different 
organisations, and ensure alignment between 
programme goals, the evaluation, and opportunities for 
learning and improveme nt. Departments can also invite 
experienced consultants to support the delivery of a 
variety of programme strategies, and/or implement a 
custom programme framework during programme 
evaluation.  
In the South African context, the department of 
Cooperative go vernance and traditional affairs 
(COGTA) conduct M&E of projects and programmes 
for various departments. They also rob -in academics to 
assist them with advice on evaluation of their M&E 
reports. The aim of COGTA is to enhance capacity for 
all spheres of go vernment, to support and build their 
knowledge and ability to conduct M&E, facilitate and 
coordinate stakeholder engagement in pursuance of 
people-centred service delivery (COGTA, 2015). The 
department of Cooperative Governance and Traditional 
Affairs have  a  s t a n d i n g  u n i t  d e d i c a t e d  t o  m o n i t o r i n g  
and evaluation. The senior officials are responsible for 
providing leadership and guidance to the other 
departments responsible for training in various 
provinces with the assistance from The Presidency. 
The COGTA co nduct evaluation to ensure that 
departments at provincial level and the municipality 
receive support and to recommend strategies that 
would increase efficiency levels and improve 
communication and co -ordination across programmes 
(COGTA, 2015).  
CONCLUSION AND LESSONS LEARNT  
In conclusion, this article explored strategies and 
methods to improve M&E in public organisations. This  
article revealed that the evaluation capacity building 
model can inform this study to understand the context  
of improving capacity f or policy monitoring and 
evaluation. This article revealed challenges facing 
organisations that have adopted M&E approaches, and 
suggests that knowledge and skills can be improved at 
an individual and organisational level. It is suggested 
that public organ isations need to place more effort on 
improving human resources, infrastructure, budget 
allocations, organisational information systems and 
institutional capacity that requires rethinking 
organisational structure and culture. This article 
revealed some les sons that can be learnt in improving 
M&E, which would require strengthening aspects on 
planning and strategizing a separate unit for M&E,
<<<PAGE=9>>>
498     Journal of Reviews on Global Economics, 2019, Vol. 8 N.S. Matsiliza 
building capacity of human, financial and physical 
resources, providing adequate information and data 
management and a dopting unique technical aspects 
needed by specialists. By improving and building 
capacity of M&E systems, one would establish an M&E 
that is trustworthy, timely, and effective for the 
organisation, civil society, the private sector and 
programmes. Further more, it will have the ability to 
face the challenges of M&E and adapt to change.  
The majority of M&Es projects are treated as more 
of a task than a tool, or as a requirement rather than 
assuming that it is part of the programme or project 
evaluation. Som e organisations which take M&E 
seriously are seldom inspired by the modern global 
framework, but rather are approving their innovative 
methods out of their dedication to improving the 
capacity of government work. Evaluators also need to 
do a reality check,  b y  c o n d u c t i n g  a  f e a s i b i l i t y  s t u d y  
prior to the formation of programmes to ensure that 
these programmes are being implemented correctly 
and the benefits are going to the targeted beneficiaries 
at the right time and place. In some public institutions 
and no n-governmental organisations, they have 
developed a participatory process to design the M&E 
system with the intention to capacitate the communities 
with more information on what M&E is and how it can 
work better to achieve its results. A participatory 
process is important because it shapes the legitimacy 
of the organisation, institutional knowledge and 
enhances the relevance of the plans and tools. It is 
important to start where the organisation is at, building 
on their strengths and addressing their challe nges. 
Monitoring and evaluation can add more value in the 
decentralisation of structures by using M&E systems 
required by sub - n a t i o n a l  a n d  n a t i o n a l  s y s t e m s  t o  b e  
developed to harmonise the M&E structure and that of 
the government structure . 
This paper rec ommends an integrative approach of 
capacity building that recognises the needs for M&E 
based on the local context and community needs 
aligned with that of the public sector policy framework 
towards monitoring and evaluation. Data during 
evaluations must be  s c i e n t i f i c a l l y  a n d  s y s t e m a t i c a l l y  
collected and must also include opinions from diverse 
participants as part of the evaluation.  
Public organisations must develop an evaluation 
capacity building checklist that will provide a set of 
guidelines for public o rganizational evaluation capacity 
building (ECB), which will also form part of the routine 
practice of an organization. The effectiveness of the 
key aspects of the checklist must be continuously 
reviewed after each evaluation process to guard 
against error s and failures during evaluations. Such 
continuous improvement can add value to stakeholders 
who seek to increase their long -term capacity to use 
policy and programme evaluation on continuous 
intervals like daily, monthly and annually.  
This article warns S outh African evaluators to be 
cautious of copying evaluation models from other 
countries without a national benchmark of ECB needs 
emanating from South Africa communities, 
organisations and the state departments. Scholars 
have already demonstrated that the  g e n e s i s  o f  
monitoring and evaluation in Africa and South Africa  
was benchmarked from foreign evaluation models 
(Basheka, 2016; Mouton, 2010). It is crucial for 
evaluators to benchmark from global experiences but 
focus on what is needed nationally and reco gnise the 
current challenges and complexities of the South 
African broader society. Evaluations must be designed  
to suit the desired local needs in order to produce 
credible evaluation results .  
REFERENCES 
Abrahams MA. A review of the growth of monitoring and evaluation in 
South Africa: Monitoring and evaluation as a professi on, an 
industry and a governance tool. African Evaluation 
Journal 3(1) 2015; p.142-146.  
https://doi.org/10.4102/aej.v3i1.142 
Basheka BC, Byamugisha AK. The state of Monitoring and 
Evaluation (M&E) as a discipline in Africa from infancy  to 
adulthood? African Journal of Public Affairs 8(3) 2015; p 75 -
95.  
Blaser Mapitsa C, Khumalo L. Diagnosing monitoring an d evaluation 
capacity in Afr ica, African Evaluation Journal, 6(1) 2016; P1 -
10.  
https://doi.org/10.4102/aej.v6i1.255 
Bowen, AG. Document Analysis as a Qualitative Researc h Method. 
Qualitative Research Journal, vol. 9, no. 2, 2009;  p 27-40. 
https://doi.org/10.3316/QRJ0902027 
Engela, Ronette; Ajam, Tania. Implementing a Government -wide 
Monitoring and Evaluation System in South Africa . ECD 
Working Paper Series;No. 21. World Bank, Was hington, DC. 
© Independent Evaluation Group, World Bank. 2010, 
https://openknowledge.worldbank.org/handle/10986/27574 
License: CC BY 3.0 IGO.” 
Fetterman D, Wandersman. Empowerment Evaluation Principles  in 
Practice, Edited by David M. Fetterman. Guilford 
Publications. 2005. 
Ghana Directorate of Standard Authority. Catalogue o f Ghana 
Standards. Accra: Ghana standard authority. 2018.  
Görgens, JZ Kusek. Making Monitoring and Evaluation Systems 
Work: A Capacity Development Toolkit. The Internatio nal 
Bank for Rec onstruction and Development: The World Bank. 
2009. 
https://doi.org/10.1596/978-0-8213-8186-1 
Guba, EG and Lincoln, YS. Fourth generation research.  News Bury 
Park: Sage.  
Ile IU, Eresia -Eke and Ile A. Monitoring and Evaluation of policies,
<<<PAGE=10>>>
Strategies to Improve Capacity for Policy Monitoring  Journal of Reviews on Global Economics, 2019, Vol. 8      499 
programmes and projects. Pretoria: Van Schaik. 2019.  
Ile IU, Eresia -Eke, Ile A. Monitoring and Evaluation of policies, 
programmes and projects. Pretoria: Van Schaik. 2012.  
Kusek JZ, Rist R. Ten steps to a Results -Based Monitoring and 
Evaluation System. Washington, DC: World Bank. 2004.  
Kusters C, Batjes K, Wigboldus S, Brouwers J, Baguma D S. 
Managing for sustainable development impact. 
Warwickshire: Practical action publishing. 2017.  
https://doi.org/10.3362/9781780449807  
Lahey R, Nielsen BS. Rethinking the Relationship among Monitoring, 
Evaluation, and Results -Based Management: Observations 
from Canada. Special Issue: Performance Management and 
Evaluation. Volume 2013(137). 2013.  
https://doi.org/10.1002/ev.20045 
Lahey R, Nielsen S B. Rethinking the relationship among monitoring, 
evaluation, and results -based management: Observations 
from Canada. In Nielsen SB. Hu nter DEK (Eds.). 
Performance management and evaluation. New Direction s 
for Evaluation. 2013; pp.45–56.  
https://doi.org/10.1002/ev.20045 
Lomofsky D. How can organisations better implement Monitoring and  
Evaluation plans? Politics and Ideas. 2014.  
Lopez-Acevedo, Krause, Mackay P, Building Better Policies, M: The 
Nuts and Bolts of Monitoring and Evaluation. Washing ton 
D.C: The World Bank. 2012.  
https://doi.org/10.1596/978-0-8213-8777-1 
Majola M. The implementation of government wide monitoring and 
evaluation system in South Africa: A provincial case study of 
Kwazulu-Natal Department of Economic Development and 
Tourism. Unpublished dissertation. Univers ity of KwaZulu -
Natal. South Africa. 2014. 
Maphunye, E. 2013. Human Capacity Challenges in the 
Implementation of a Monitoring and Evaluation System. 
Unpublished Masters Dissertation. Wits University. Sou th 
Africa.  
Mapitsa BC, Khumalo L. Diagnosing monitori ng and evaluation 
capacity in Africa, African Evaluation Journal, 6(1). 201 8. 1-
10. 
https://doi.org/10.4102/aej.v6i1.255 
Matsiliza NS. Participatory Monitoring and Evaluatio n: Reviewing an 
Inclusive App roach in South Africa’s Government Wide 
Monitoring and Evaluation. Africa’s Public Service D elivery 
and Performance Review, 1(2).2013.  
https://doi.org/10.4102/apsdpr.v1i2.31  
McKegg K, Wehipeihana N, P ipi K. The Evaluation Capacity Building 
Project, Developing And evaluation capacity assessme nt tool 
and process for New Zealand NGOs. Superu, Wellington. 
2016. 
Motingoe RS. Monitoring and Evaluation System utilisat ion for 
municipal support. Unpublished the ses. North West 
University. South Africa. 2012. 
Mouton, C. 2010, ‘The history of programme evaluation  in South 
Africa’, MPhil thesis, Faculty of Arts and Social Scie nces. 
Sociology and Social Anthropology Department, Universi ty of 
Stellenbosch. 
Mthethwa RM , Jili NN. Challenges in implementing monitoring and 
evaluation (M&E) 102 The case of the Mfolozi Municipality. 
African Journal of Public Affairs, 9(4). 2013.  
Naidoo I. Monitoring and Evaluation in South Africa.  Many purposes, 
multiple systems, In Sergone,  M .  ( E d )  F r o m  P o l i c i e s  t o  
Results: Developing Capacities for Country Monitoring and 
Evaluation Systems. New York: UNICEF. 2010; p. 303 -320. 
Nigel S, Smith S. Praxis Paper 23: Monitoring and Ev aluating 
Capacity Building: Is it really that difficult? INTRAC  2010.  
OECD. Agricultural Policy Monitoring and Evaluation. Paris: O ECD 
Publishing. 2018. 
Petersen, A. 2017. Evaluations that matters in social work. 
Unpublished theses. 2017. 
Picciotto, R. 2013. Evaluation Independence in orgnai sations. 
Journal of Multi -Disciplinary Evaluation Volume 9, Issue 20: 
18-32. 
Republic of South Africa. KZN COGTA’S Mid -term Review of 2015 -
2020 Strategic Plan Report. Pietermaritzburg: COGTA 
Province of Kwazulu-Natal. 2018. 
Republic of South Africa. The National Treasury. Budg et Est imates 
for the National Treasury Expenditures. Pretoria: The 
National Treasury. 2018. 
Republic of South Africa. The Presidency. Policy fra mework for the 
Government-wide Monitoring and Evaluation Systems. 
Pretoria: The Presidency. 2011. 
Valadez JJ, Pamperge r. Monitoring and Evaluating Social Programs 
in Developing Countries: A Handbook for Policymakers, 
Managers, and Researchers. World Bank Business 
Economics. 1994. 
https://doi.org/10.1596/0-8213-2989-8 
Vedung ELL. Politics as Rational Action: Essays in Public Choice 
and Policy Analysis. 2011 Netherlands: Springer. 2011.  
Visser, I, Kusters CSL, Guijt I, Roefs M, Buizer N. Im proving the Use 
of Monitoring and Evaluation Processes and Findings; 
Conference Re port. Centre for Development Innovation, 
Wageningen UR (University & Research centre). Report  CDI-
14-017. Wageningen. 2014. 
 
Received on 30-04-2019 Accepted on 01-06-2019 Published on 07-08-2019 
 
DOI: https://doi.org/10.6000/1929-7092.2019.08.42 
 
© 2019 N.S. Matsiliza; Licensee Lifescience Global.  
This is an open access article licensed under the te rms of the Creative Commons Attribution Non -Commercial License 
(http://creativecommons.org/licenses/by -nc/3.0/) which permits unrestricted, non -commercial use, distribution and reproduction in 
any medium, provided the work is properly cited.