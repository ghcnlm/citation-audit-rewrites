<<<PAGE=1>>>
http://www.aejonline.org Open Access
African Evaluation Journal  
ISSN: (Online) 2306-5133, (Print) 2310-4988
Page 1 of 8 Original Research
Read online:
Scan this QR 
code with your 
smart phone or 
mobile device 
to read online.
Authors:
Dugan I. Fraser1 
Candice Morkel1 
Affiliations:
1Centre for Learning on 
Evaluation and Results in 
Anglophone Africa (CLEAR-
AA), Faculty of Commerce, 
Law and Management, Wits 
School of Governance, 
University of the 
Witwatersrand, 
Johannesburg, South Africa
Corresponding author:
Candice Morkel,
candice.morkel@wits.ac.za
Dates:
Received: 02 July 2020
Accepted: 13 Aug. 2020
Published: 06 Nov. 2020
How to cite this article:
Fraser, D.I. & Morkel, C., 
2020, ‘State of monitoring 
and evaluation in Anglophone 
Africa: Centre for Learning 
on Evaluation and Results 
in Anglophone Africa’s 
reflections’, African 
Evaluation Journal 8(1), a505. 
https://doi.org/10.4102/aej.
v8i1.505
Copyright:
© 2020. The Authors. 
Licensee: AOSIS. This work 
is licensed under the 
Creative Commons 
Attribution License.
Introduction
The Centre for Learning on Evaluation and Results in Anglophone Africa (CLEAR-AA) is one of 
the six regional centres in the CLEAR Initiative working globally to strengthen capacity to 
undertake monitoring and evaluation (M&E) and to use evidence to improve programmes and 
support policymakers and implementers in making better decisions. It has been operational for 
nearly 10 years, focusing on African countries in which English is an official language, and has 
developed a rich body of experience and an extensive network of relationships that give it 
valuable insights into the M&E capacity development endeavour. 
At the time of writing this article, we are being faced with one of the most significant global events 
in the history of the current generation of people inhabiting the earth. The Coronavirus Disease 
2019 (COVID-19) pandemic has set for the world’s leaders the gargantuan task of ensuring that 
good evidence leads their decision-making around securing the safety of and saving the lives of 
millions of people. More than ever before, governments around the world need systems of 
evidence that will enable them to make the right decisions rapidly. The potentially catastrophic 
effects that may come about as a result of the absence of good evidence (or the use of bad evidence) 
highlight, now more than ever, the critical demand for stronger, more effective M&E systems, 
particularly at the level of the state. 
Although the literature on a system approach to building national M&E systems is fairly nascent, 
there is an emerging body of knowledge that we can begin to draw from. One of these is a book, 
published by Routledge and available in July 2020, 1 entitled Using Evidence in Policy and Practice: 
1.Available from https://www.routledge.com/Using-Evidence-in-Policy-and-Practice-Open-Access-Lessons-from-Africa/Goldman-Pabari/p/
book/9780367440077 and other booksellers.
This article is an overview of what the Centre for Learning on Evaluation and Results in 
Anglophone Africa (CLEAR-AA) is currently learning in its work implementing monitoring 
and evaluation (M&E) capacity strengthening programmes in our partner countries. This 
article is based on the reflections drawn from the authors’ experiences and the work of CLEAR-
AA in strengthening M&E systems across the continent. It serves as a contribution to larger 
ongoing strategic conversations about how to promote evidence-informed decision-making 
for better development outcomes. The article begins with a discussion on systems broadly and 
M&E systems in particular, with a specific focus on some of the historical roots of the current 
ways in which M&E is defined and implemented in African systems of governance. We 
continue to discuss the various elements that come into play in establishing and institutionalising 
M&E systems, in particular the ‘M&E Market’ and the demand for evidence, where we also 
challenge the notion of the unidirectional demand and supply chain of evaluation. The 
institutional architecture within which M&E systems operate is next discussed, and how the 
formal (and informal) laws, policies, boundaries and rules continue to provide some degree of 
leverage in support of these systems. The article finally addresses two key elements of 
developing and sustaining M&E systems: the role of leadership and developing an evaluative 
culture. The authors explain why these elements, which often receive less attention than the 
technical elements in building and strengthening M&E systems, carry such weight in sustaining 
national evaluation systems.
Keywords: Evaluation systems; Evaluation capacity development; Leadership; Evaluation 
culture; Evaluation management systems; Evaluation supply and demand.
State of monitoring and evaluation in Anglophone 
Africa: Centre for Learning on Evaluation and 
Results in Anglophone Africa’s reflections
Read online:
Scan this QR 
code with your 
smart phone or 
mobile device 
to read online.
Note: Special Collection: SAMEA 7th Biennial Conference 2019.
<<<PAGE=2>>>
Page 2 of 8 Original Research
http://www.aejonline.org Open Access
Lessons from Africa edited by Ian Goldman and Mine Pabari. 
Based on a case-study approach of five countries and the 
Economic Community of West African States (ECOWAS) 
(West African) region and drawing from a range of sectors 
and types of evidence used, the book provides some insight 
into how African governments can use evidence to the benefit 
of their citizens by improving decision-making, policy-
making and programme implementation. Works such as 
these are important in ensuring that we build a robust body 
of knowledge to guide our work in partnering with 
governments (and non-state actors) across the African 
continent in strengthening national M&E systems.
As a further contribution to this growing body of knowledge, 
this article is an overview of what CLEAR-AA is currently 
learning in its work implementing M&E capacity strengthening 
programmes in our partner countries. This article is based on 
the reflections drawn from the authors’ experiences and the 
work of CLEAR-AA in strengthening M&E systems in the 
continent. It serves as a contribution to larger ongoing strategic 
conversations about how to promote evidence-informed 
decision-making for better development outcomes. The article 
begins with a discussion on systems broadly and M&E systems 
in particular, with a specific focus on some of the historical 
roots of the current ways in which M&E is defined and 
implemented in African systems of governance. We continue 
to discuss the various elements that come into play in 
establishing and institutionalising M&E systems, in particular, 
the ‘M&E Market’ and the demand for evidence, where we 
also challenge the notion of the unidirectional demand and 
supply chain of evaluation. The institutional architecture 
within which M&E systems operate and the ways the formal 
(and informal) laws, policies, boundaries and rules continue to 
provide some degree of leverage in support of these systems 
are discussed next. The article finally addresses two key 
elements of developing and sustaining M&E systems: the role 
of leadership and developing an evaluative culture. The 
authors explain why these elements, which often receive 
less attention than the technical elements in building and 
strengthening M&E systems, carry such weight in sustaining 
national evaluation systems (NESs). 
This article is limited by the anecdotal nature of the 
observations presented here and concludes with a number of 
lessons that have been learnt as part of our work on the 
continent. These include the importance of collaborative 
partnerships in working at scale, of embedding M&E in 
broader institutional systems of decision-making, the critical 
role that leadership plays in providing momentum to (and 
sustaining) efforts at institutionalising M&E, as well as 
the growing of African-centred approaches to build and 
strengthen local and regional evaluation systems.
The integration of monitoring and 
evaluation into management 
systems 
A system-based approach to M&E strengthening is essential, 
as the utility of M&E almost always relies on the extent 
to which systems for collecting, synthesising, analysing, 
reporting and using evidence are integrated into systems for 
policy-making, planning, learning and adaptation. 
Monitoring and evaluation are often treated as adjuncts to 
policy, programme and project implementation, but to add 
real value, they need to be integrated from the outset into the 
management planning and decision-making processes and 
components of institutional systems. In generic terms, a 
system usually refers to an interdependent group of items 
forming a unified whole (Arnold & Wade 2015). At an 
institutional level, specifically one in which systems of 
evidence production and use operate, we recognise that this 
includes the enabling environment, the human and non-
human, technical and financial elements that make up the 
system, as well as rules (formal and informal) about how 
decisions are made and actions are taken. Although our work 
focuses primarily on these elements, we are also mindful of 
their interconnectedness to broader local and global socio-
politico-economic systems, and the potential influence of the 
various parts on each other. 
There has been significant growth in the efforts to establish 
M&E systems and functions in governments, particularly in 
the Global South. Countries, such as South Africa, Tanzania 
and Uganda (amongst others), have built M&E systems to 
assess various strategies and national development plans 
(CLEAR-AA 2013). One of the reasons for this is the pressure 
on governments to implement their Sustainable Development 
Goals (SDGs), and report on their performance in the 
periodic Voluntary National Reviews (VNRs) presented by 
Heads of State to the High-Level Political Forum at the 
annual United Nations General Assembly (United Nations c. 
2020). One of the effects of the growth in M&E systems is a 
shift from accounting for budget expenditure to a focus 
on the achievement of development results, which is a 
welcome development. Monitoring and evaluation now 
needs to be located in the broader discourse around 
sustainable development and the achievement of system-
wide development outcomes. 
However, the maturity of both M&E is uneven across the 
African continent, where systems of routine monitoring of 
performance exist, even if they are often poorly curated and 
managed. The bifurcation and decoupling of monitoring 
from evaluation are worsened by the widespread split 
between policy, planning and M&E structures and functions. 
In many administrations, ministries of finance (or treasuries) 
remain primarily responsible for fiscal planning and 
budgeting, which they do with little or no engagement with 
entities responsible for the generation and utilisation of 
evidence. This concurs with Masuku (2015), highlighting that 
government departments work in silos and other entities are 
often not included. Government sectors take their cue from 
decisions about programme delivery made by national fiscal 
and sector planning processes, and evaluation findings rarely 
find their way into the budget decision-making system. One 
key observation has been that there are prevailing weaknesses 
in national systems for the collection and management of
<<<PAGE=3>>>
Page 3 of 8 Original Research
http://www.aejonline.org Open Access
administrative data, and in some cases, even basic record-
keeping on the delivery of public goods is poorly managed. 
These systems are often treated as entirely separate from 
initiatives to build NESs, which contribute to weaknesses in 
integrated governance and accountability, and ultimately the 
broader concerns of evidence-informed policy-making.
For developing countries, implementing results-based 
management is costly and requires time to plan and develop 
(Pazvakavambwa & Steyn 2014), and there is an ongoing 
demand to strengthen results-based management practices 
in the public sector. Although public sector strategic 
planning, goal-setting and prioritisation are implemented, 
these processes often miss key elements that would make 
the underlying programme logic visible. These include 
accounts of the mechanisms by which change is intended to 
happen, as well as the risks and assumptions that underlie 
programmes’ theories of change. Many of the fundamental 
principles of M&E, such as developing theories of change for 
all programmes or interventions, are still not part of planning 
and budgeting vocabularies and thus need to be routinised 
and promoted. 
Policies informed by a ‘New Public Management’ orientation 
and visions for development that prioritise economic 
development have shaped the way M&E operates in 
contemporary African society. In the case of South Africa, for 
example, the pursuit of a capable, efficient and effective state 
has created a distinctly hierarchical form of governance, 
which propels a compliance and oversight-driven approach 
to M&E. In fact, research on the state and use of M&E systems 
in the South African national and provincial government 
suggested ‘a rather narrow use of M&E for internal 
monitoring and control’ (Umlaw & Chitepo 2015:13). These 
audit-oriented processes create perverse incentives, where 
senior government executives chase the certainty of quick 
wins and ‘low hanging fruits’ over complex outcomes. 
In addition to strengthening public governance and 
administration systems, there needs to be more room for non-
state actors in government M&E practices. Representatives of 
civil society, academic institutions and other producers of 
evidence are rarely part of institutional planning, performance 
monitoring, evaluation and improvement processes, and 
there are few mechanisms to include their evidence in policy-
making, planning and budgeting. In research around the co-
production of public services by Fledderus, Brandsen and 
Honing (2014), the relationship between government and 
civil society is based on the general posture or orientation of 
the state towards co-production. The inclusion of outside 
voices requires an embracing of a collaborative approach by 
the state and the nurturing of closer, more cordial relationships 
between government and civil society, which can help to 
strengthen collaboration (Tsai 1999:70). Addressing M&E at a 
system level, therefore, requires that we consider broad M&E 
ecosystems and become more inclusive in our approaches 
towards institutionalisation. 
The monitoring and evaluation 
‘market’: Supply and demand 
In the M&E context, supply refers to those who produce 
evidence, whilst demand refers to those who use M&E 
products or services. In government-led evaluation systems, 
policymakers or programme leaders could be thought of as 
representing the demand side and evaluation consultants 
representing the supply side. However, one could also think 
of demand as the donor agencies that commission evaluations 
on programmes they run in partner countries, or even supply, 
when they co-produce evaluations with sub-contracted 
consultants for use in government policy and decision-
making. Therefore, we can also make a distinction between 
supply and demand as it is expressed within a government 
M&E system versus supply and demand within the broader 
ecosystem. 
Twende Mbele’s (2018) three-country study on supply and 
demand revealed that the nature of demand for and supply 
of M&E goods and services varies widely depending on the 
country context. For example, demand is driven largely by 
donors in Benin, whereas government largely drives demand 
in South Africa (Twende Mbele 2019a). A number of factors 
interact together to shape the supply and demand chain 
rather than a linear cause-and-effect process (Blaser Mapitsa 
& Khumalo 2018:4). Weaknesses in supply are, therefore, not 
necessarily because of weaknesses in the skills and capabilities 
of the supply side. The Twende Mbele study (Blaser Mapitsa 
& Khumalo 2018:4) as well as analyses conducted by CLEAR-
AA, such as the Compass, 2 suggested that the tendency to 
use external, international evaluators was a policy preference, 
rather than being caused by shortages on the local supply 
side (Blaser Mapitsa & Khumalo 2018:4). 
However, the problem is often articulated as one of supply 
– that there are not enough good evaluators to meet the 
demand. The diagnostic report on supply and demand 
(Phillips 2018), part of the Twende Mbele study, highlights 
that supply may be seen as inadequate in relation to demand 
as in some cases submitted evaluation reports must be 
reworked by government officials. On the other hand, the 
study inferred that the supply of evaluators may actually be 
adequate to meet demand and that the real problem lies 
with the demand side. In some cases, evaluators choose not 
to work with government because of the bureaucratic 
burden, onerous procurement procedures and overbearing 
management of evaluations by government clients. The 
poor quality of evaluation specifications has also been 
raised, both in the Twende study and in the evaluation 
of the South African NES undertaken in 2017 (Department 
of Planning, Monitoring and Evaluation [DPME] 2017:107). 
One way that Twende Mbele (2019) recommends remedying 
the misalignment between supply and demand is to 
2.In 2017 and 2018, CLEAR-AA conducted a cross-country comparison study of M&E 
systems in Anglophone Africa and produced ‘The Compass’. The first Compass was 
produced in 2017 and constituted of 11 countries. These countries were Benin, 
Botswana, Cote d’Ivoire, Ghana, Kenya, Niger, South Africa, Tanzania, Uganda, 
Zambia and Zimbabwe. The second Compass was produced in 2018, and focuses on 
six Anglophone Countries; Uganda, Ghana, Kenya, South Africa, Rwanda and Zambia.
<<<PAGE=4>>>
Page 4 of 8 Original Research
http://www.aejonline.org Open Access
encourage researchers within academic institutions to 
conduct evaluations, although it is not convincing whether 
this would be an adequate response to the more systemic 
challenges. 
Despite these factors, most literature on African evaluations 
highlights weaknesses in supply (Merkle 2016:4; Podems, 
Goldman & Jacob 2014). Studies on evidence supply and 
demand conducted in 2005 and 2014 both indicated the 
popular belief in the weak individual capacities for 
evaluation and the poor quality of evaluation training 
(Abrahams 2015:4; Podems et al. 2014:76). Capacity building 
seems to hinge on the ability to produce more and better 
evidence, but the issue of integrating that evidence into 
evaluation systems is not widely considered. The issue of 
evidence utilisation is frequently raised as a concern in our 
work in strengthening NESs and the pre-occupation with 
just strengthening the capacities of individual evaluators 
needs reframing. 
Our own work in building NESs has led us to move away from 
thinking about linear supply chains. We are increasingly 
adopting a system perspective in our country strategies, where 
we recognise the need for diverse, tailored packages of 
interventions that include, but are not limited to, building 
individual capacities. Although the demand continues to be 
presented as a need for training, we seek to combine this with 
technical assistance, policy support, institutional system 
development, the creation of enabling environments and the 
building of individual capacities. In working together with 
country partners, there is greater appreciation of the need to 
view capacity strengthening in a more holistic and integrated 
manner, which builds in-country sustainability in the area of 
M&E, and can (in a sense) be thought of as capacity building 
through the process of engagement. We have also developed a 
real appreciation of the limits individual organisations face in 
strengthening country M&E systems. Specialised organisations 
that focus on, for example, certain kinds of evaluation or 
training can have a catalytic impact on strengthening parts of 
the system, but no single intervention, on its own, can 
constitute the whole solution. The work of CLEAR-AA (and 
indeed the work of the CLEAR network as a whole) is, 
therefore, built on a highly collaborative approach, and our 
partnership with a multitude of organisations (both state and 
non-state, local and international) is an intentional aspect of 
our practice. 
The recognition that partnerships are essential to achieve 
success in strengthening the M&E evidence production 
and use value chain is gaining traction in the sector, and 
we have seen a global shift towards such collaborations 
(such as the Global Evaluation Initiative, in which the 
CLEAR network is a key element). Such efforts recognise 
that collaborative partnerships are essential to achieve 
success at scale (particularly in the light of the urgency 
towards the achievement of the SDGs as well as other 
pressing global challenges such as the COVID-19 and 
climate crises). 
Enabling environments: Laws, 
policies and practices
In any context, government-driven M&E systems reflect 
country traditions and dynamics, are shaped and constrained 
by the state and social architecture in which they function, 
are driven by local political and ideological dynamics and are 
enabled and limited by the prevailing human and financial 
capacities. The Centre for Learning on Evaluation and Results 
in Anglophone Africa (2019a:6) states that, in many ministries, 
there is institutional architecture which is a foundation for 
the production and use of evaluation within government. 
Few Anglophone African countries have formal policy or 
legislation guiding the practice of M&E. Uganda, South 
Africa, Zambia, Botswana, Zimbabwe and Nigeria are the 
Anglophone countries with approved M&E policies, whilst 
Kenya and Ghana have draft policies awaiting formal 
adoption. Whilst some evaluations are undertaken in certain 
English-speaking African countries, these are mostly 
commissioned by donors or multilateral agencies (rather than 
the state), with public agencies playing a limited role in their 
commissioning or utilisation. Goldman et al. (2018:7) provided 
evidence of donors, highlighting the roles that donors play; in 
South Africa, donors are scarcer and do not form a part of the 
M&E system; in Benin, evaluations are funded by donors; and 
in Uganda, donors are integrated within the system, whilst 
financing and involvement in the oversight mechanisms are 
done by donors. Even in countries where the legislation or 
policy is clear, implementation is often patchy, and those 
administrations need to rethink elements of their approach in 
order to achieve the widespread evidence-informed decision-
making sought through their policies. 
Monitoring practices and processes in the countries where 
CLEAR-AA works are characterised by a common feature: 
they seldom operate across internal organisational boundaries, 
making it hard for decision-makers and policymakers to 
get a view of a whole sector or system, and encourage a 
silo perspective that limits the ability to plan and think 
systemically as required to address complex challenges. In 
most instances, the data systems used for performance 
reporting are paper-based and where they are digital, they 
use very basic software without the necessary governance 
policies to ensure interoperability or to protect privacy. 
In Zambia, challenges with performance monitoring are 
intensified by the constraints of having paper-based systems 
and in Uganda, it is difficult to coordinate the NES because of 
technical constraints (CLEAR-AA 2019b).
The public policy environment, in most instances, does not 
do enough to enable M&E because in many African countries, 
their frameworks and systems were historically determined 
by a colonialism that was centred around domination and 
the facilitation of extraction. In post-independence Africa, 
this was exacerbated by a reliance on aid and structural 
adjustment programming, which anchored M&E in the grip 
of accountability and compliance. As a result, accountability
<<<PAGE=5>>>
Page 5 of 8 Original Research
http://www.aejonline.org Open Access
and learning have not been grounded and indigenised in the 
post-colonial context. Whilst this is changing, the process is 
a slow and complex one beset by the prevailing structural 
conditions that hinder change at scale. 
Our analysis of African M&E policies makes it clear that we 
need to be doing more to support their development and 
ensuring that they are context appropriate and do not simply 
mimic policies developed elsewhere by others. We have also 
concluded that data governance is an important, under-
addressed priority and supporting countries to develop 
strategies and policies in this regard will become an important 
area of work for us. 
Leadership in the field of 
monitoring and evaluation
Leadership plays a critical role in any institution or 
system, particularly if the intention of its interventions is 
transformational. Both M&E are practices with enormous 
potential to drive improvements, transform systems 
and make them more effective, responsive, inclusive and 
participatory; however, if done badly, there is a serious risk 
that they will deflect attention, divert resources and 
undermine authentic accountability. For M&E to realise their 
potential, they require inspired leadership at different levels. 
Such leadership should drive both monitoring, as a managerial 
function, and evaluation, as a strategic function, highlighting 
the value that evidence-based decision-making offers in the 
context of competing and conflicting priorities. 
Unfortunately, with M&E often seen as an administrative 
function at the service of political agendas, conflict at the 
political–administrative interface often scuppers even genuine 
attempts by state officials to drive a programme of authentic 
reflection and adaptation. Political leadership and political–
administrative coherence are needed in championing the 
development of sustainable and effective M&E systems. 
Embedding government-wide M&E needs strong political 
will, dedicated staff and active participation across all levels and 
institutions of government (Twende Mbele 2018). 
Providing leadership in M&E can be thought of as having 
three dimensions. The first dimension is providing 
stewardship in integrating M&E into existing processes and 
ensuring that they support and complement procedures in 
ways that add real value and enhance outcomes. The second 
dimension of leadership needed for effective M&E is the 
ability to persuade internal and external stakeholders of 
the value and importance of evidence and deliberation 
in decision-making processes. This requires an ability to 
advocate for and promote participation of others and a 
commitment to improve results rather than the pursuit 
of private or sectional interests. The third dimension of 
leadership in M&E is the ability to demonstrate effective 
practices and to show (rather than tell) how these improve 
results and enhance accountability. Demonstrating the 
value of M&E in practice moves the agenda out of the 
theoretical and academic realm into a more practical and 
meaningful mode where the value added becomes a 
motivator and incentive. 
Since management practices are usually determined in the 
centres of government – in President’s and Prime Minister’s 
offices, development planning ministries and ministries of 
finance – having people work as integrators, persuaders and 
demonstrators in these institutions has proved particularly 
important. 
We recognise that there is nothing coincidental about the 
spread of M&E: it has been achieved intentionally and 
purposively and we draw from this realisation an appreciation 
of how important it is to forge in-country partnerships with 
champions and advocates who provide leadership now and 
in the future. The challenge is to develop a clearer, more 
actionable sense of exactly what kinds of support will make 
it easier for leaders to act to build M&E systems and to put in 
place interventions that meet these needs. 
Culture: Curiosity, reflection 
and enquiry
For M&E to add real value, they need an organisational 
culture that supports curiosity and enquiry. This is often also 
called an evaluative culture. An organisation with a strong 
evaluative culture is one that engages in self-reflection and 
self-examination and deliberately seeks evidence on what it 
is achieving. An organisation with a strong evaluative culture 
uses information on results to challenge itself and support 
what it is doing, depending on what is being discovered, and 
values candour, challenge and dialogue, not just superficially 
but in an authentic way. Government institutions require 
ongoing strengthening of evaluation culture as this will 
improve evaluation management skills (Twende Mbele 
2019). Such organisations are engaged in evidence-based 
learning, allocating time and resources to learn in a structured, 
systematic way and encouraging the sharing of knowledge. 
Encouraging experimentation and a preparedness to take 
risks by seeking out new and different ways of doing business 
are also part of evaluative cultures (Mayne 2008). 
Promoting an evaluative culture requires that senior 
management shows leadership and commitment by making 
regular, informed demand for results information and 
ensuring that capacity for results measurements and 
management is built. There also need to be strong 
organisational support structures with effective incentives, 
systems, practices and procedures and an outcome orientation 
across the organisational system (Mayne 2008). Perhaps more 
than anything, there need to be a tolerance for mistakes and 
a capacity to take on board lessons from failure, because 
without this, everything that happens in programmes gets 
framed as a success and learning is short circuited. For 
instance, the M&E culture in Kenya according to Twende 
Mbele (2019:22) has a blend of doing things together 
(collaborative or clan culture), doing new things (adhocratic 
or creating culture), doing things fast (competition culture) 
and doing things right (control or hierarchy culture).
<<<PAGE=6>>>
Page 6 of 8 Original Research
http://www.aejonline.org Open Access
In evaluation literature, the focus is increasingly on evaluative 
thinking, which is (Buckley et al. 2018):
[C]ritical thinking applied in the context of evaluation, motivated 
by an attitude of inquisitiveness and a belief in the value of 
evidence that involves identifying assumptions, posing 
thoughtful questions, pursuing deeper understanding through 
reflection and perspective making and informing decisions in 
preparation for action. (n.p.) 
Both M&E processes require a strong base in evaluative 
thinking to ensure that there is an appetite for what is learnt. 
The general growing global consensus on the importance of 
M&E brings with it an inherent danger: that the effort 
required to undertake these challenging and resource-
intensive processes becomes over-regulated, ritualised and 
loses their meaning. They become a requirement that needs 
to be complied with rather than an opportunity for real-life 
learning and practical accountability. In some contexts, this 
takes on an ominous edge, morphing into what gets called 
‘malicious compliance’. In the South African context, the 
dangers long identified by Winston (1999), such as data 
gaming and goal displacement, remain common, despite an 
incremental shift in the direction of evaluation as learning in 
some places.
We appreciate that M&E are profoundly political processes 
that echo and reflect the contexts in which they are 
undertaken. Amisi (2015) highlights this aspect, with the 
National Evaluation Plan (NEP) in South Africa widespread 
in terms of budget, number of people they reach and 
political significance. Politically, evidence produced by 
evaluation must be readily available to decision-makers in 
order for them to make an informed decision for continuity, 
modification or elimination of programmes (Lazaro 2015:15). 
Formal African governance systems were mostly shaped in 
the context of colonial control and domination and can be 
understood to be grafted on top of older organic structures 
and traditions. They are in many instances constrained and 
limited by this history which is complex and contradictory 
at every level, with a widespread tendency to Weberian 
forms of control and even bureaucratic authoritarianism – 
‘command and control’ are valued over ‘enquire and reflect’. 
This is true of government systems as well as those of 
donors, which in many of the countries where CLEAR-AA 
operates have an outsized voice in how processes operate 
and what kind of evidence is solicited, how it is received and 
what kinds of organisational cultures are nurtured. 
In contexts where authorities do not have a tradition of 
acknowledging difficulties or are committed to a particular 
– often triumphalist – narrative around performance, the 
culture needed for effective M&E is unlikely to thrive. On the 
other hand, in situations characterised by robust political 
competition, which is increasingly the case in Africa, political 
parties are under pressure to prove their legitimacy by 
reporting positive results to the electorate, which puts 
another kind of pressure on M&E systems to produce good 
news. Because public officeholders often have limited time 
to demonstrate the success of their leadership and garner 
political support from the electorate, there is a rush to provide 
evidence of performance and a distinct short-termism often 
comes to characterise public systems. 
In neo-patrimonial states where there is extensive collusion 
amongst and between elements of the private sector and 
corrupt state officials to use public funds for private benefit, 
a climate of curiosity and enquiry is antithetical. Indeed, 
there is an inbuilt inclination to reject authentic enquiry into 
performance and expenditure. Monitoring and evaluation 
systems may, therefore, either not be prioritised or be 
designed in such a way that they could deflect attention from 
real problems (e.g. by encouraging a focus on ‘safe’ areas of 
enquiry), where they pose no real threat to corrupt practices.
For CLEAR-AA, we recognise that a culture of curiosity and 
enquiry is essential if the evidence is to be used in improving 
decision-making, and that doing so is neither simple nor 
quick. It is a complex, iterative process that takes many years, 
but that must be attempted as part of a broader reform and 
innovation agenda. For us, this means working in close 
partnership with country governments and civil societies 
and acting as a facilitator and adviser on a range of diverse 
projects that have a cumulative effect bigger than the sum 
of their parts. Central elements for us include, as noted 
above, policy development, so that there is an overarching 
framework to guide M&E system strengthening efforts; 
research, so that system strengthening actions are based on 
an understanding of what currently exists; and capacity-
building processes that take account of what capacity already 
exists and is thoughtful and careful to complement what else 
is being done. 
Conclusion: Partnerships for system 
strengthening 
There are five key lessons we have distilled from our 
experience in adopting a system approach to strengthen 
M&E systems in our work in Anglophone African countries 
over the last decade. The first and most important of these is 
that the journey cannot be taken alone, and the domination of 
one or few partners or approaches working in enclaves will 
not achieve the result of a system-wide change. Adopting a 
collaborative, partnership-based approach to strengthen 
systems is therefore essential, and we need to draw on the 
strengths of various partners in development broadly, and in 
the M&E and evidence sectors more specifically, in order to 
address the challenges we have outlined in this article at 
various scales and levels of the system. Secondly, M&E is not 
a stand-alone process and has no intrinsic value if separated 
from systems of decision-making. These are inextricably 
linked to budget and planning processes, and therefore 
efforts must continue to be directed towards integrating 
M&E into planning and budgeting processes (whether in 
state- or non-state-led interventions). The third lesson is that 
strong leadership and the championing of the M&E cause are 
catalytic to strengthen the performance and institutionalisation
<<<PAGE=7>>>
Page 7 of 8 Original Research
http://www.aejonline.org Open Access
of M&E systems at country level. We, therefore, need to 
foster networks and communities of practice so that we can 
build a cadre of leaders who can act as champions, who are 
bolstered by a growing professionalism and deeper learning 
in the sector. This includes supporting the growth of 
voluntary organisations for professional evaluation (VOPES), 
29 of which are registered with African Evaluation 
Association (AfrEA) across the continent. Other networks, 
such as Twende Mbele, represent a very unique network of 
countries cooperating to learn from each other, and others, 
such as the Africa Centre for Evidence and African 
Parliamentarians’ Network on Development Evaluation 
(APNODE), are driving evidence use by policymakers and 
decision-makers.
Fourthly, capacity building must be considered as a 
comprehensive, whole-of-system intervention, and not to be 
confined to training only (and especially not only of the 
‘supply side’). Training and other kinds of capacity-building 
processes also need to be customised and tailored to the 
context, as systems are not all alike, and different incentives 
and disincentives that are part of the enabling environment 
need to be considered. 
This links to the fifth takeaway, which is the need to support 
country governments in the development of indigenous 
policy frameworks that are crafted according to their 
particular governance and policy contexts. In recognition of 
the sui generis nature of governance systems, and the 
peculiarities of governance systems based on Africa’s colonial 
past and the historical legacies they had left behind, we 
need to recognise the hybridity of post-colonial governance 
systems and work more deliberately to empower and 
invigorate an appreciation of this context, and be an enabler 
and advocate for the indigenisation of localised responses to 
the challenges they face in terms of evidence production 
and use. We must be facilitators of a transformational 
approach to evaluation, where an Africanised, contextually 
relevant approach to M&E is honoured, welcomed, valued 
and used. 
In addition to experiencing the lessons, we have 
acknowledged the importance of reflection and learning 
from our work, and therefore we have prioritised research 
and learning (R&L) as a distinctive area of focus in CLEAR-
AA. This article is one example of the work that we continue 
to do in building a body of knowledge around Africa-centred 
approaches to establish NESs, which we hope will contribute 
to the strengthening of M&E across the continent. In 
conclusion, what we are learning in our collaborative work 
with country partners and other organisations has allowed 
room for growth, in that we recognise the need for much 
more sustained research – both theoretical and empirical – on 
these areas of work, so that we get better what we are doing. 
Much needs to be done in documenting and building a solid 
body of knowledge, including case studies and theoretical 
frameworks, upon which we can improve our strategies and 
interventions at a system level.
Acknowledgements
Competing interests
The authors declare that they have no financial or personal 
relationships that may have inappropriately influenced 
them in writing this article.
Authors’ contributions
D.I.F. and C.M. contributed equally to the writing of this 
research article.
Ethical considerations
This article followed all ethical standards for research 
without direct contact with human or animal subjects.
Funding information 
This research received no specific grant from any funding 
agency in the public, commercial or not-for-profit sectors.
Data availability
Data sharing is not applicable to this article as no new data 
were created or analysed in this study.
Disclaimer
The views and opinions expressed in this article are those of 
the authors and do not necessarily reflect the official policy or 
position of any affiliated agency of the authors.
References
Abrahams, M.A., 2015, ‘A review of the growth of monitoring and evaluation in South 
Africa: Monitoring and evaluation as a profession, an industry and a governance 
tool’, African Evaluation Journal 3(1), a142. https://doi.org/10.4102/aej.v3i1.142
Amisi, M.M., 2015, ‘Improving the use of evaluative evidence through effective 
communication: Lessons from implementing the South African evaluation system’, 
African Evaluation Journal 3(1), 7. https://doi.org/10.4102/aej.v3i1.109
Arnold, R.D. & Wade, J.P ., 2015, A definition of systems thinking: A systems approach, 
Steven’s Institute, Hoboken, NJ.
Blaser Mapitsa, C. & Khumalo, L., 2018, ‘Diagnosing monitoring and evaluation 
capacity in Africa’, African Evaluation Journal 6(1), a255. https://doi.org/10.4102/
aej.v6i1.255
Buckley, J., Archibald, T., Hargraves, M. & Trochim, W.M., 2018, ‘Defining and teaching 
evaluative thinking: Insights from research on critical thinking. American Journal 
of Evaluation 36(3), 375–388. https://doi.org/10.1177%2F1098214015581706
CLEAR-AA, 2013, Demand and supply: Monitoring, evaluation, and performance 
management information and services in Anglophone sub-Saharan Africa: A synthesis 
of nine studies, viewed 12 May 2020, from https://www.theclearinitiative.org/sites/
clearinitiative/files/2016-04/Demand_and_Supply_Anglophone_Africa_2013.pdf.
CLEAR-AA, 2019a, Compass: Tracking monitoring and evaluation developments in 
Anglophone Africa , University of the Witwatersrand, Johannesburg, viewed 
12  May 2020, from http://wiredspace.wits.ac.za/bitstream/handle/10539/28488/
CLEAR-AA%20Compass.pdf?sequence=1&isAllowed=y.
CLEAR-AA, 2019b, Monitoring and evaluation in five African countries , University of 
the Witwatersrand, Johannesburg, viewed 12 May 2020, from http://wiredspace.
wits.ac.za/bitstream/handle/10539/28232/CLEAR-AA_Diagnostics_Report_web.
pdf?sequence=1&isAllowed=y.
Department of Planning, Monitoring and Evaluation, 2017, ‘Evaluation of the National 
Evaluation System - Summary report’,  Department of Planning, Monitoring and 
Evaluation, Pretoria.
Fledderus, J., Brandsen, T. & Honing, M., 2014, ‘Restoring trust through the co-
production of public services: A theoretical elaboration’, Public Management 
Review 16(3), 424–443. https://doi.org/10.1080/14719037.2013.848920
Goldman, I., Byamugisha, A., Gounou, A., Smith, L.R., Ntakumba, S., Sossou, D. et al., 
2018, ‘The emergence of government evaluation systems in Africa: The case of 
Benin, Uganda and South Africa’, African Evaluation Journal 6(1), 1–11, viewed 
from https://aejonline.org/index.php/aej/article/view/253/419.
<<<PAGE=8>>>
Page 8 of 8 Original Research
http://www.aejonline.org Open Access
Lazaro, B., 2015, Comparative study on the institutionalisation of evaluation in 
Europe and Latin America, EUROsociAL, Brussels. 
Masuku, N.W.K., 2015, ‘A global overview of monitoring and evaluation (M&E) and 
its meaning in the local government context of South Africa’, Africa’s Public 
Service Delivery & Performance Review  3(2), a79. https://doi.org/10.4102/
apsdpr.v3i2.79
Mayne, J., 2008, ‘Building an evaluative culture for effective evaluation and results 
management’, in ILAC Brief No. 20 , Institutional Learning and Change (ILAC) 
Initiative, Rome.
Merkle, C., 2016, ‘UN women’s experience with strengthening evaluation systems in 
Africa: Enhancing quantity, quality and use of evaluation’, African Evaluation 
Journal 4(1), a127. https://doi.org/10.4102/aej.v4i1.127
Pazvakavambwa, A. & Steyn, G.M., 2014, ‘Implementing results-based management 
in the public sector of developing countries: What should be considered?’, 
Mediterranean Journal of Social Sciences  5(20), 245–257 https://pdfs.
semanticscholar.org/6060/666b4adae54349da3703a58db76a169c83d3.pdf.
Phillips, S., 2018, Twende Mbele: Diagnostic on the demand and supply of evaluators 
in South Africa, Diagnostic Report, viewed 04 May 2020, from https://www.dpme.
gov.za/keyfocusareas/gwmeSite/GovermentWide %20M %20and %20E/
Diagnostic %20report %20Twende %20Mbele %20demand %20and %20
supply%20of%20evaluation%2021%20January.pdf
Podems, D., Goldman, I. & Jacob, C., 2014, ‘Evaluator competencies: The South African 
government experience’, The Canadian Journal of Program Evaluation 28(3), 71–85.
Tsai, M., 1999, State power, state embeddedness, and national development in less 
developed countries: A cross-national analysis, Studies in Comparative International 
Development 33(4), 66–88. https://doi.org/10.1007/BF02687524
Twende Mbe le, 2018, Using M&E to improve government performance and 
accountability, viewed 12 May 2020, from http://www.twendembele.org/wp-
content/uploads/2018/04/Twendle_Mbele_Using_ME_to_improve_
government_performance_and_accountability_2018.pdf.
Twende Mbele, 2019a, Diagnostic on the supply and demand of evaluators in Uganda, 
Benin and South Africa , viewed 12 May 2020, from http://www.twendembele.
org/wp-content/uploads/2019/04/TWENDE-DS.pdf.
Twende Mbele, 2019b, Base study on the performance monitoring and evaluation 
culture in the public sector in Kenya , viewed 12 May 2020, from http://www.
twendembele.org/wp-content/uploads/2020/01/ME-Culture-Kenya.pdf.
Umlaw, F. & Chitepo, N., 2015, ‘State and use of monitoring and evaluation systems in 
national and provincial departments’, African Evaluation Journal  3(1), a134. 
https://doi.org/10.4102/ aej.v3i1.134
United Nations, c., 2020, High-level political forum on sustainable development 
sustainable development goals knowledge platform, viewed 04 May 2020, viewed 
from https://sustainabledevelopment.un.org/hlpf.
Winston, J., 1999, ‘Performance indicators – Promises unmet: A response to Perrin’, 
American Journal of Evaluation  20(1), 95–99. https://doi.org/10.1016/S1098-
2140(99)80111-8