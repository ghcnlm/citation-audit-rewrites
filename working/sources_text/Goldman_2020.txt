<<<PAGE=1>>>
Summary
This final chapter draws together findings and lessons from this study with 
reference to the analytical framework described in Chapter 3. We reflect on 
the evidence journeys of the cases in their individual contexts. Diverse sources 
of evidence were used in across the different cases, and a wide range of evi-
dence use interventions applied. Where an evidence system (such as a national 
evaluation system) existed, it helped to standardise many of these interventions. 
Building agreement and trust were key mechanisms leading to change in all the 
cases, spurring commitment to act. All the case studies resulted in changes in 
procedures, in some cases extending to changes in policies or budgets. A core 
message is that evidence use is complex and begins long before an evidence 
journey starts. Evidence use needs to be planned for and woven into the institu-
tional culture. This needs active facilitation of the process, often in a knowledge 
brokering role which manages both the supply of and the demand for evidence. 
Is evidence use the answer to African problems? On its own it is not, but it can 
make a contribution by helping to lessen the influence of partisan interests and 
providing some of the answers needed when decisions have to be taken.
Introduction
This book focuses on improving understanding of how using evidence can help 
inform and strengthen development policy, programmes and practice in Africa. 
We looked at the evidence journeys in eight cases, learning from the policy 
process and how this was accompanied by evidence interventions. The journeys 
included generation of evidence, activities to promote use and eventual changes 
(or not) in policy or practice informed by the evidence.
We analyse the processes which support or inhibit evidence use rather than 
focusing on the sources of evidence, of which much has been written. Four of 
the cases used evaluations and research synthesis as their key source of evidence 
and four focused on the role of citizen engagement and evidence from NGOs.
In this chapter we first summarise the findings against the analytical frame -
work (Figure
 13.1)1 and then reflect on lessons emerging around evidence 
use. We start by discussing how the contextual influencers and the demand for 
evidence influenced the way in which the evidence journeys played out across 
13 Lessons for using evidence 
in policy and practice
Ian Goldman and Mine Pabari
<<<PAGE=2>>>
Lessons for using evidence in policy 225
EVIDENCE 
GENERATION
USE 
INTERVENTION
CHANGE
MECHANISM
INDIVIDUAL / 
ORGANISA-
TIONAL /
SYSTEMS 
CHANGE
EVIDENCE USE DEVELOPMENT 
IMPACT      
CONTEXT
External dimension: Macro-context; intra- 
relationships with state/non-state agents 
Internal dimension: culture; organizational 
capacity; management; and core resources
Constant feedback between each step on the framework 
Demand for evidence 
- Instititutuonalised in 
system e.g. NEP) 
Examples of  
dimensions to 
consider:
• Type of 
evidence
• Quality/rigour
• Other e.g. 
timeliness
Examples to 
consider:
• Capacity-
  building 
• Awareness 
raising
• Access
• Champions/ 
mentors
• Org change
M1 - Awareness
M2 - Agree
M3 - Access
M4 - 
Interact/trust
M5 - Ability
M6 - 
Institutionalising /
formalising
• Motivation to 
use evidence
• Capability to 
use evidence
• Opportunity to 
use evidence
• Individual / 
organisational/ 
system 
behaviour 
change
• Instrumental 
• Conceptual
• Symbolic
• Process use
• Policy 
performance 
and impact                   
• Wider systems 
change         
Figure 13.1  The analytical framew ork showing the Context, Mechanism, Outcome relationships
Source: Langer et al. (2020).
<<<PAGE=3>>>
226 Ian Goldman and Mine Pabari
the case studies. We then mention the supply of evidence, evidence use inter-
ventions applied in the cases, the change mechanisms these triggered and how 
these led to immediate outcomes in terms of changes in capabilities, motiva -
tion and opportunities and to wider outcomes in terms of changes in policy 
and practice. Finally we draw out the key messages emerging for promoting 
evidence-informed policy and practice (EIPP).
Emerging findings
Contextual factors influencing use
As succinctly expressed by Weyrauch et al. (2016), ‘context matters’. Across all of the 
case studies, the context within which the evidence journey took place had a sig-
nificant bearing on how evidence was used. Table 13.1 summarises the contextual 
influencers identified from across the eight case studies, relating these to the origi-
nal framework for context. These are discussed in more detail following the table.
T able 13.1 Contextual influencers of evidence use emerg ing in the case studies
Category Dimension of Contextual Examples from case studies
context influencers identified 
in the cases
External Macro-context Significance of the Commitments made to international or 
policy challenge/ regional agreements
question High levels of financial investments
Legal requirement for legislative review
Broader political Timing, for example, proximity to 
and socio- election period
cultural Space for public participation and civil environment society engagement
Level of interest and engagement of 
stakeholders
Catalysts of change Crises
Intra and inter Pressure from development partners
institutional Pressure from civil societylinkages
Internal Culture Institutional Systems and processes
Organisational environment Evidence championscapacity LeadershipManagement & 
processes Mandates and capacities
Other resources Culture – learning and accountability
Linkages and relationships
Perceived significance of the policy challenge/question
The perceived level of significance of a policy challenge is an important consid-
eration in whether an investment in evidence is seen as worthwhile, and if so, the
<<<PAGE=4>>>
Lessons for using evidence in policy 227
types of use interventions that may be necessary to use to raise the profile of the 
policy issue. In all of the case studies in this book, countries already had high levels 
of commitment to the policy issue. For example, a number of the countries had 
signed international or regional agreements and there was pressure to meet their 
commitments.
2 The evidence itself can also help to inform judgements on the 
significance, such as the magnitude, distribution of effects and causality.
Political and socio-cultural environment
The broader political and socio-cultural environment influenced whether or 
not it was worth investing in sourcing and using evidence to support a change 
process.
3 For example, how power is distributed and decisions are made had a 
bearing on evidence use. In some of the cases, presidential proclamations were 
important in driving policy changes. In other cases, the macro-context enabled 
public participation and citizen engagement, which allows the decision-making 
space to be more inclusive. For example, in the agriculture case in Benin, the 
opening up of spaces to include non-state actors changed the power relation -
ships and resulted in a significant shift in the extent to which evidence was used 
in the sector to inform decision making and planning.
Perhaps of equal importance was the level of stakeholder engagement and inter-
est as well as the nature of relationships between stakeholders. Where stakeholders 
were highly fragmented and/or had polarised values and positions, this significantly 
influenced the level of effort and skill required to manage the evidence process (also 
discussed later in this section). In the Sanitation, Wildlife and Agriculture cases, citi-
zens felt strongly about the issue, were well organised, had strong capabilities as well 
as relationships and there was an enabling environment for participation. In these 
cases, civil society organisations (CSOs) and citizens were an important resource 
and citizen engagement helped to ensure evidence use.
Catalysers and influencers
In some cases particular events or actors triggered the need for change, thereby 
creating an environment conducive to ensuring that the evidence generated was 
taken seriously and, in these cases, used. For example, a poaching crisis in Kenya 
and a crisis of education in South Africa provided the impetus and created a 
sense of urgency which, in these instances, triggered the demand for evidence. 
In other cases, it was pressure from development partners to generate evidence 
that was the main trigger for lobbying and advocacy by civil society. We must 
also recognise that crises may lead to rapid decisions being taken without using 
the best available evidence, but rather based on beliefs and opinions.
Institutional environment
Across all the cases, the capabilities of the organisations involved in the evidence 
journey and the extent to which they were fit for purpose was an important influ-
encer of evidence use. Aspects of institutional capability included the following.
<<<PAGE=5>>>
228 Ian Goldman and Mine Pabari
Competent leadership emerged as important for ensuring that the opportu -
nities for evidence use within the wider context were utilised and barriers 
navigated. Examples of leadership characteristics identified as being significant 
included broad-based respect and trust across different stakeholder groups; rec-
ognised experience and knowledge of the sector; and having well-established 
networks and alliances and being seen as politically wise. Another factor was 
the stability of leadership.
Evidence champions were important in all cases, driving both the generation 
and use of evidence. Evidence champions were not always in senior leadership 
positions, although it was helpful when they were; in some cases, they were 
in civil society. An important lesson was the need for champions to remain in 
place and to be able to sustain their efforts, as the process of changing policy 
tends to be lengthy. Champions at the centre of government were important in 
the evaluations, particularly where the policy issue cuts across sectors, as in the 
violence case. Knowledge brokers also emerged as playing an important role.
4
Other important capabilities included skills and knowledge, for example, the abil-
ity to access and utilise evidence for decision making and action. Chapter 4 showed 
that in Benin, Uganda and South Africa, 25%–33% of managers do not have the 
skills to understand and use evaluation recommendations. The limited skills and 
ability of decision makers and other evidence stakeholders to access, absorb, analyse 
and synthesise information emerged as a barrier in several of the cases.
Appropriate structures and processes were also important. Organisational silos, com-
petition and overlapping mandates were identified as barriers to evidence use, 
particularly as coordination and positive relationships are important to enable the 
dialogue, debate and consensus building necessary for effective use of evidence.
Chapter 4 outlines issues in organisational culture around evidence use in 
Uganda, Benin and South Africa, indicating that around 50% of managers sup-
port evidence use, but report challenges around hierarchy and fear of punish -
ment for perceived failure. This was confirmed in the case studies where those 
more open to new ideas and encouraging of change were more likely to enable 
evidence use. Similarly organisations that are more deliberate in enabling learning 
and accountability were more likely to utilise evidence than those that do not, 
for example the Department of Social Development in the violence case study. 
This was linked to organisational incentives, which emerged as an issue either as a 
burden (as in the Rapid Response case) or as a motivator (the reward system in 
budgetary allocations for districts in Ghana).
Demand for evidence
The next element of the framework in Figure 13.1 is demand for evidence. This 
may come from government or from other stakeholders. The source of the 
demand had a bearing on the design of the evidence journey. In some cases 
demand was institutionalised, for example in a country’s national evaluation 
plans. Where donors were the key demanders, the significance of investing in 
national and local ownership emerged as being critical to evidence use. In the 
sanitation case study, civil society was the primary driver behind the demand
<<<PAGE=6>>>
Lessons for using evidence in policy 229
for evidence which led to lessons around the need to put time and energy into 
ensuring government trust, buy-in and ownership. In all these cases we see a 
demand for evidence from the evidence users rather than a research push.
Supply of evidence
Evidence generation is also a part of the framework but not a focus of this 
book. The different cases show examples of generation through evaluations, 
research, research synthesis and citizen engagement, and we draw lessons on 
evidence use across these different methods of generating evidence.
The evidence use interventions
Table 13.2 shows the range of evidence use interventions that we could see across 
the cases. In three of the countries there was an NES (national evaluation sys-
tem) which specified certain interventions and these have been distinguished 
T able 13.2  The range of evidence use interv entions, as part of, or external to, national evalu-
ation systems
Associated with a NES Elements seen outside the NES
• Demand from government • Demand from outside government, e.g. from 
• Evaluation Steering Committee, donors/other stakeholders
managing collaboratively the • Use of international standards and 
evaluation process conventions as a reference
• Process facilitation/knowledge • Creation of coalition to support, e.g. civil 
brokering by central government unit society coalition in Senegal to support action 
• Capacity-building of key stakeholders on tobacco taxation
around evaluation • Process facilitation/knowledge brokering role 
• Developing theory of change with of internal unit, either in government (eg 
stakeholders Procurement), Parliament (Wildlife) or CSO 
• Independent evaluators to ensure (Sanitation)
credibility • Scoping study/situation analysis
• Validation workshop with stakeholders • Frequent briefings of key stakeholders during 
• Simple evaluation report the process
• Management response/ improvement • Capacity-building of stakeholders e.g. CSOs
plan • Sharing drafts amongst stakeholders
• Quality assessment of the evaluation • Sharing evidence in accessible formats e.g. 
• Report public on website short evidence briefs
• Approval by Cabinet • Presenting and showcasing evaluation 
findings at different forums
• Ongoing dialogue in the sector
• Variety of dialogue methods including 
debates and 1:1 meetings
• T emplates and processes for stakeholder 
inputs
• Proactive outreach and engagement with 
communities
• Use of peer comparison to promote use
<<<PAGE=7>>>
230 Ian Goldman and Mine Pabari
from other interventions which varied by case. This table provides a useful (but 
not exhaustive) list to consider in promoting evidence use.
The evidence use interventions that we saw could be applied throughout the 
process (e.g. maintaining stakeholder involvement), prior to evidence generation 
(e.g ensuring demand), during the generation (e.g. checking quality and credibility 
of processes) or after the evidence generation (e.g. dissemination processes).
A key finding that emerges is the importance of facilitation of the evidence 
journey, often in a knowledge brokering role  which manages both supply and 
demand sides (discussed in 
Chapter 2). In all cases this brokering role was played 
by some organisation, sometimes internally, such as an internal monitoring and 
evaluation (M&E) unit, and sometimes externally, such as the Centre de la 
Recherche Economique et Social (CRES), the lead think tank in the tobacco 
case. Facilitation of the process to promote agreement, ownership, commitment and 
trust was critical in all the cases. Even where an external entity plays this role, it 
needs an internal counterpart to work with the evidence. This happens before, 
during and after the evidence generation process.
Examples from the case studies of these roles include the following:
• Deliberately convening forums and platforms  to enable dialogue and debate 
between the different stakeholder groups.
• Ensuring skilled facilitation, allowing all parties to have an equal voice and 
creating safe and trusted spaces for meaningful dialogue. In the case studies 
where this took place this included facilitating negotiation and consensus 
building, and managing conflict and power dynamics.
• Creating spaces for jointly making sense of the evidence and providing the 
opportunity for difficult conversations around beliefs and value systems.
• Awareness raising through informal and formal interactions, trainings, meet-
ings and so forth. Dialogue and interaction is also essential to build trust, for 
example by knowledge brokers with their policy clients – something that 
ideally needs to happen well before evidence is requested.
• Collaboration in planning and managing  the process, so co-creation of the 
evidence journey. Steps that could be seen were stakeholders working 
together to frame the problem, develop T oRs, finalise and approve of the 
methodological framework and timeline, and jointly manage contracts.
• Convening of regular meetings and working hand in hand with programme 
managers to ensure regular interaction and contact with decision makers, 
as well as validation workshops with stakeholders.
The change mechanisms triggered by the evidence use interventions
In order for capabilities/opportunities/motivation to use evidence to be acti -
vated, there has to be a change mechanism which inspires people and organisa-
tions to do things differently. The list of change mechanisms from Chapter 3 
is adapted in Table 13.3, based on what we have seen in this research. Drawing 
on the experiences of the case studies, we suggest a few changes to the original 
change mechanisms which are added to the table in italics.
<<<PAGE=8>>>
Lessons for using evidence in policy 231
Across the cases, building agreement and trust amongst the different players in 
the evidence journey was key and led to the commitment to act. In some cases, it 
was necessary to strengthen ability. For example, in the tobacco case, it was nec-
essary to strengthen the ability of technical staff to generate and use evidence, 
and of politicians to understand the evidence and make decisions. Understanding 
could also be seen as important in many cases, which links to the importance 
of conceptual, and not just instrumental, use of evidence.
Outcomes of evidence use in the cases
Immediate outcomes – changes in capabilities, opportunities  
and motivation to use evidence
Our analytical framework is based on a behaviour change model where a com-
bination of capability, opportunity and enhanced motivation to use evidence at 
T able 13.3 The change mechanisms
Mechanism Example of interventions to promote use arising in the cases
Awareness of the potential of Training senior managers in the public service in South 
evidence (M1) Africa, Benin and Uganda on evidence (Goldman et al., 
2019)
Training and awareness raising on the potential and value 
of evidence (e.g. Rapid Response Services)
Training of citizen groups in Ghana to analyse and utilise 
data to demand accountability and better sanitation 
services as well as in governance and accountability 
literacy more broadly
Agreement/understanding/ Establishing dialogue processes to build agreement and 
commitment commitment
(M2) Use of evaluation steering committees to formalise 
partnerships
Access to evidence Producing accessible short reports and policy briefs
(M3) Workshops
Knowledge repositories
Interaction and trust Dialogue processes
(M4) Knowledge brokering
Workshops/breakfast meetings
Networks and communities of practice
Ability and confidence Capacity-building (e.g. learning by doing, workshops and 
(M5) formal training courses)
Coaching/mentoring
Experiential learning
Online learning
Institutionalising/formalising Use of management responses and improvement plans to 
(M6) formalise action needed
Embedded support e.g. knowledge brokering
Institutionalisation of NES
Making public the analysis
<<<PAGE=9>>>
232 Ian Goldman and Mine Pabari
both individual and organisation level leads to behaviour change. In our ana-
lytical framework, this corresponds to the immediate outcomes of an evidence 
process, that is changes in behaviour at the individual, organisational and sys -
tems levels which manifest as changes in policy or practice.
In most of the cases strengthening the capability to use evidence emerged as 
a key component of change. Sometimes the capability was to generate and use 
evidence, but also we see examples of capacity to advocate for the programme 
or policy, or for funding and even for the evidence itself.
Motivation to use evidence is an antithesis of the compliance mindset that 
is common in all these countries. In 
Chapter 4 we found that around 50% of 
managers were motivated to learn and improve policy making, while around 
50% were not. In terms of motivation, Michie’s definitions suggest the differ-
ence between a reflective motivation based on knowledge and understanding, 
and an instinctive one, triggered by the topic (
Michie et al., 2011). We clearly 
see examples of increase in motivation of the producer association (PNOPPA) 
to take forward the agricultural policy in Benin, or the impact of the dialogue 
in strengthening motivation in the violence case.
In some of the cases with a NES, the institutionalisation of the system created 
opportunities to use evidence. For example, part of the institutionalisation in South 
Africa was that national evaluations would go to Cabinet, providing an opportu-
nity for Cabinet to endorse the findings, and this stimulated motivation for the 
custodian department to use the findings. Some of the mechanisms such as ‘trust, 
agreement, commitment’ are also important in opening up opportunities.
And in combination
In most cases it was the combination of increased capability, motivation and 
opportunity which made the evidence journey significant and sustained. For 
example, in the wildlife case, the opportunity to provide inputs into drafting 
the new Wildlife Act was taken up by a skilled civil society sector and thereafter 
matched by increased capability of the Kenyan Parliament to manage a partici-
patory process, and to supply and use evidence. The motivation is often driven 
by key champions, but also by the collective energy from stakeholders. In the 
Wildlife case, if the motivation of key champions or stakeholders had not been 
sustained, the Act might have passed, but the drive to take forward the key ele-
ments of the Act might have been compromised.
Wider outcomes – changes in policy and practice
The eight cases selected were purposely selected for being in some way influ-
ential, as we sought to understand how and why that influence occurred. The 
wider outcomes from the different processes resulted mainly from instrumental 
use of evidence and included policy change, changes in procedures and pro -
cesses, in budgets and other resources as well as changes in capacity.
Four of the cases showed changes in policies or legislation. In all cases there 
were changes at process or procedure level, such as guidelines, criteria, thresholds
<<<PAGE=10>>>
Lessons for using evidence in policy 233
for procurement and so forth. Direct evidence of changes in budget allocations 
was rarer, seen in only two to three of the cases, at least partly because resources 
to fund the recommendations were not available. In none of the cases were 
there recommendations to close whole programmes or elements, nor were 
there findings or recommendations that were significantly controversial/in 
contradiction to policy makers’ beliefs and values.
There were also unintended uses, sometimes arising where there has been 
conceptual or process use. Unintended uses can have significant long-term 
impact. For example, the 2009 evaluation of agricultural policy in Benin was 
not used instrumentally – but the improved understanding from the stakehold-
ers who participated led them to use the evidence in later evaluation and policy 
processes.
Other unintended uses included:
• The evidence being used to inform other work;
• The lessons being used to widen the work,  for example in the wildlife case 
from community participation in one sector to development of guidelines 
for public participation with Parliament more generally;
• Strengthening the capacity of particular stakeholders;
• Rebuilding trust between government and stakeholders;
• The evaluation being used for teaching;
• Promoting further research in the area.
What have we learned about promoting  
the use of evidence?
In a nutshell, our core message is this:
Evidence use is complex. It begins long before an evidence journey and 
needs to be planned for and woven into the individual and institutional 
culture. It is a worthwhile investment.
This research explored interventions to promote evidence use – actions not to 
generate the evidence but to enable and ensure use. These have to be thought 
through in an intentional way – what change do you wish to bring about, what 
change mechanisms need to be triggered and so what evidence use interven -
tions will be needed? Some of the key lessons that emerged in this regard are 
described below.
The analytical framework is valuable for strengthening evidence use
For evidence to be utilised, it is important to recognise that evidence use is a 
journey and not a set of activities focused solely around generation of evidence. 
The journey involves a series of interconnected processes that can be influ -
enced by the wider environment at all stages. Using the analytical framework, 
we were able to identify and understand the different stages of the journey and
<<<PAGE=11>>>
234 Ian Goldman and Mine Pabari
develop insights into the relationships between them. In doing so, we recog -
nised the potential of the framework to support evidence generators and users 
to be more purposive in designing an evidence journey towards ensuring use. 
Key is understanding the change mechanisms you wish to activate (e.g. agree-
ment/ownership), how this will build the capability/motivation of managers or 
the opportunity to use evidence, and the evidence use interventions you need 
to undertake to generate this change.
Evidence use takes place in multiple ways
We learned the importance of recognising the multiple uses of evidence that 
can take place (instrumental, conceptual, symbolic, process use, etc.) and the 
value of designing an evidence journey to be cognisant of these different uses. 
In focusing simply on evidence and instrumental use, valuable opportunities 
may be lost. In a number of cases, for example, process and conceptual use 
were key to bringing about transformational changes that ultimately created 
the space for positive and sustained impact. Later we discuss the importance of 
knowledge brokering and facilitation, particularly with regards to process and 
conceptual use.
Context matters – make sure you understand it
The evidence journey does not take place in a vacuum and there are multiple 
factors that influence this journey. We earlier quoted Carol Weiss stating that 
‘evaluation is a rational enterprise that takes place in a political context’ (Weiss, 
1993
, p. 94).  The case studies amplified the importance of understanding this 
wider context, in line with a core message expressed by Weyrauch et al. (2016). 
As described earlier, there are contexts where the prevailing political situation 
is unlikely to allow for evidence use and therefore the investment of an evi -
dence journey may simply not be worthwhile. In other cases, understanding the 
context can ensure that there is a clearer understanding of relevant entry points 
and opportunities in the policy process, the change mechanisms necessary to 
ensure evidence use and the interventions that are most likely to be effective in 
triggering these mechanisms.
Ensure there is demand
Much of the writing on EIPP has been by researchers seeking to push their 
research or evaluation. In this book we take a policy-maker perspective, where 
policy makers or other stakeholders have requested evidence. In the cases stud-
ies we saw a number of ways of ensuring demand:
• Through national evaluation systems requiring evaluations to be done;
• Through policy makers requesting research or research synthesis;
<<<PAGE=12>>>
Lessons for using evidence in policy 235
• Through parliaments requiring citizen inputs into development of legislation;
• Through civil society analysing government data, and the analysed data 
then being used by government.
The experiences in the cases demonstrate the importance of demand for evi -
dence originating from the evidence users, particularly policy makers. This 
ensured ownership, strengthened the alignment of the evidence to the policy 
needs and therefore, ultimately, evidence use.
Ensure credibility, quality and legitimacy in the evidence  
journey – often it is the messenger as well as the message
The cases provide examples of different ways in which the credibility of the evi-
dence journey was enhanced. The reputation and track record of the actors generat-
ing the evidence as well as those delivering it was extremely important. In a number 
of cases, consultants were contracted to carry out an evaluation as part of ensuring 
the independence of the evaluators. Peer reviewers or content experts were also 
used in several cases to comment on the evidence. The violence case showed the 
importance of legitimacy in terms of the cultural and racial makeup of the research 
team. Another important lesson was that transparency and effective communication 
were important in perceptions of legitimacy of process. A key role for internal and 
external knowledge brokers was ensuring the quality and credibility of the evi-
dence process, as did stakeholder structures such as steering committees.
Apply evidence use interventions to build capability and motivation
Passive provision of evidence does not work
Langer et al. (2016) reviewed the facilitators of research uptake and came to the 
conclusion that research use requires active steps to facilitate access to evidence, 
to enhance skills in understanding evidence, increase motivation to use evi -
dence, and the formalising of these steps in structures and processes. A  passive 
approach alone, such as seminars or policy briefs will be insufficient.
What we see in the case studies supports these findings. We see where the 
impact of formalising systems has made a significant contribution, for exam -
ple through an NES or a formalised citizen engagement process. We see how 
working to improve decision makers’ capability, understanding, motivation and 
commitment are essential ingredients. In no cases did isolated communication 
functions play a major role.
The process needs active facilitation and knowledge brokering
The experience from these cases would suggest that knowledge brokering 
(also described earlier) is important in the overall evidence journey. These
<<<PAGE=13>>>
236 Ian Goldman and Mine Pabari
roles include keeping policy makers and other stakeholders involved and 
informed in planning and implementation of the evidence generation pro -
cess, so keeping them committed and motivated. A key part of the facilitation 
role was building positive and trusting relationships between stakeholders and 
with the evidence generation teams. While structures such as steering com-
mittees were important, it was essential that they were facilitated effectively. 
Similarly, where the relationship with the researcher/evaluator was good, 
there was flexibility in delivery of the evidence, improving recommendations 
and so forth.
Overall, what emerges is that the process of knowledge brokering is com -
plex, sensitive, and requires strong facilitation skills, and linkages between 
governmental and non-government stakeholders. These roles currently tend 
to be under-appreciated and the functions of knowledge brokers in govern -
ment need to be reviewed to ensure they have the skills and mandates to be 
successful.
Establishing formal structures to manage the process and maintain  
ownership of stakeholders
In all but one of the case studies, committees were established to enable dif -
ferent types of engagement across the different stakeholders and sectors, which 
became a formal expression of the coalitions of stakeholders. These were meant 
to ensure ownership by key stakeholders in the evidence process. The committees 
included steering committees to provide overall guidance and decision mak -
ing and scientific or technical committees involving subject matter specialists 
from key evidence stakeholder groups (often including development partners). 
Other forums were sector-driven platforms, such as the Violence Prevention 
Forum facilitating ongoing dialogue on EIDM in violence prevention in South 
Africa.
These committees/forums were instrumental to the use of the evidence in 
a number of different ways. They enabled interaction and the building of rela-
tionships between the evidence generators and evidence users, strengthened 
the abilities of the evidence stakeholders to understand and make sense of the 
evidence, and helped to ensure the quality, relevance and responsiveness of the 
evidence, so ensuring a greater sense of ownership of the process as well as  
the evidence produced.
Build capacity of managers, decision makers and stakeholders
In a number of cases, investments were made in strengthening the abilities of 
stakeholders to use evidence. This helped them to play effective roles in the evi-
dence journey. For example, in the sanitation case, citizen groups were trained 
to analyse and utilise data to demand accountability and better services as well 
as governance and accountability literacy more broadly.
<<<PAGE=14>>>
Lessons for using evidence in policy 237
Package and communicate the evidence simply and effectively
Evidence was packaged and communicated in a number of ways to ensure it 
was appropriate, relevant and accessible to decision makers. Examples included:
• Ensuring the evidence was relevant to the policy concerns, the evidence 
stakeholders and the wider context;
• The evidence going beyond simply describing a problem to providing prac-
tical and realistic solutions;
• Evidence and recommendations being as specific as possible  – the more 
generic, the less likely they are to be used;
• The evidence recognising the values of its recipients. In the case of violence, 
for example, there was a disconnect in the underlying values of researchers 
and public servants. Recognising this, the researchers focused the find-
ings on systems and processes rather than engaging with beliefs and values, 
which, in turn, mitigated risks of rejection and enabled use;
• Formats of reports being readable and accessible , for example using a format 
for evaluation reports including a 1-page policy summary, 5-page execu -
tive summary and 25-page main report format, to ensure reports were 
readable.
There emerged a number of examples of sensitivity to the dynamics and the 
need for responsive communication throughout the process. Examples could 
be seen where findings and recommendations were discussed with higher-level 
decision makers prior to wider engagement, strengthening their ownership of 
the evidence and their comfort with the recommendations, so that they would 
be more likely to implement them.
The experiences of a few of the case studies demonstrate that wider dissemi-
nation of the evidence can be as important as the evidence itself, both in terms of 
how it is shared as well as with whom. In some of these cases, significant effort 
was made to share the evidence widely using multiple communication media 
and platforms targeting specific audiences. This included the use of reposito-
ries/websites, policy briefs, national dialogues, workshops and seminars. This 
in turn enabled transparency, ownership and uptake for implementation across 
multiple stakeholders. In a few of the cases, the evidence was given to trusted 
and respected individuals to present to stakeholders, as it was recognised that 
the messenger is often as important as the message itself.
Having an evidence system makes some of the elements automatic
Five of the eight cases5 are from Benin, Uganda and South Africa. These three 
countries had established a NES which formalise the use of evidence. This 
includes formalised requirements for evaluations, competencies and standards 
(benchmarks of evaluation quality, guidelines, peer review mechanisms, etc.).
<<<PAGE=15>>>
238 Ian Goldman and Mine Pabari
In addition, in South Africa formal management responses and improvement plans 
are required whereby different departments and stakeholders respond to find-
ings and outline how recommendations will be taken up and institutionalised. 
Developing of the improvement plan again involves stakeholders to ensure 
quality and ownership of the plans going forward.
Established systems and processes better enable evidence use to be antici -
pated which, in turn, can improve timely responses to demands.
Lessons on the analytical framework
The analytical framework we used in Chapter 3 was developed by Langer, 
deriving from his earlier work ( Langer et al., 2016), and that of Vanessa Wey-
rauch (Weyrauch et al., 2016b). The framework proved very useful in structur-
ing the research and analysing the findings. It evolved slightly in the use. It 
proved very helpful to be explicit about the behaviour change required for evi-
dence to be used, and to understand what leads to that change. The framework 
should be valuable for policy makers and practitioners seeking to expand the 
use of evidence in their work. The context matters framework proved complex 
to use, and we have simplified it somewhat in our analysis of the contextual 
influencers. We added additional words in the descriptors, such as commitment 
and understanding. The version at the beginning of this chapter includes these 
minor changes.
Conclusions
Is evidence use the answer to African problems? On its own it is not, but it can 
make a contribution by helping to lessen the influence of partisan interests in 
decision making and strengthen its empirical grounding. Evidence can link the 
implications of decisions to their likely impact on society and ensure that deci-
sions relating to the complex and emergent realities we face are supported or 
challenged by independent analysis and evaluation. By bringing evidence to the 
table in a systematic way, anticipating the evidence needs of policy makers, and 
developing and answering evidence agendas for organisations and the country, 
it can help to provide some of the answers needed when decisions have to be 
taken.
The cases we draw from in this book are all examples where evidence has 
contributed to decision making. They demonstrate that it is possible to use 
evidence to get improved policies and improved practice, though it is not yet 
possible to conclude that this results in improved longer-term societal and 
developmental impact.
The main aim of this research was to find out how can we best facilitate the 
use of evidence to improve policy and practice and facilitate social outcomes in 
an African context, and second to test out an analytical framework for under-
standing evidence use. We conclude that the key factors in the successful use of 
evidence to improve policy making include understanding context, involving
<<<PAGE=16>>>
Lessons for using evidence in policy 239
stakeholders continuously, ensuring demand for evidence and an appropriate 
supply, using change mechanisms, building capability and motivation, estab-
lishing buy-in at higher levels, and exploiting opportunities within the policy 
process.
T o make evidence more influential requires strengthening the role of knowl-
edge brokers internal and external to government, enabling trusted relation-
ships and creating stronger dialogue between government and stakeholders so 
that wider influences can inform policy and practice. This requires stronger 
process skills in government, as well as partnerships with external bodies such 
as think tanks which have the skills to facilitate and sustain processes.
T o do this effectively the key roles of process facilitation and knowledge 
brokering have to be given more weight, in centre of government and internal 
evidence/M&E units, and in the skill sets and job descriptions of the people 
employed there. This is also true for researchers who seek to influence policy 
and practice.
Postscript
Where next?
The book is part of a process to reflect on African experience and to apply this 
in policy processes and practice across the continent. The book accompanies 
other materials, notably videos and policy briefs, intended as resources to help 
these processes. We hope these resources will inform training and the practice 
of policy makers, practitioners, parliaments and knowledge brokers. We look 
forward to continuing the journey with these partners. A luta continua!
Limitations of the research
The research is built on eight case studies with between 8 and 20 interviews 
per case. In some cases the researcher of the case study had been involved in 
the case as a participant observer and so brought considerable richness to the 
analysis. Clearly, these numbers of interviews are limited. The case studies were 
undertaken by different researchers so there were some differences in interpre-
tation and how the research was conducted, and how the cases were written 
up, despite a common template. This has been minimised in that the co-editors 
then took the cases and turned them into chapters, with the content validated 
by the authors.
There are several cases of evidence from evaluation and citizen engagement, 
with only one example of the use of research and one which used research 
synthesis. However, what we sought to unpack was the process by which evi-
dence use happened, and deliberately take a diversity of evidence generation 
modalities.
There are some limits in how critical each chapter is, as policy makers 
involved were co-authors. It was a deliberate strategy to involve the policy
<<<PAGE=17>>>
240 Ian Goldman and Mine Pabari
makers to acknowledge their role and to bring in the richness of their direct 
experience, but also because the intention was not just to write a book, but 
to use the content to influence processes in the five countries and the region 
more widely. Hence the book itself is a change intervention meant to pro -
mote interaction and trust between researchers and policy makers, build 
awareness and commitment to take evidence more seriously in policy and 
practice, and to strengthen the institutionalisation of evidence. We hope in the 
process to have built the capability of these policy makers and of the research -
ers to understand the process by which change happens, increased the motiva-
tion of the policy makers to use evidence more actively, and in the remaining 
part of the project (to June  2020) to support them where opportunities occur 
to apply the learnings.
Notes
 1 The analytical framework is described in Chapter 1 and discussed in detail in Chapter 3.
 2 Such as the ECOWAS countries which had ratified the Frame work Convention on 
T obacco Control (Chapter 12); and Uganda’s commitment to the global guidelines as 
well as the East, Central and Southern Africa food fortification guidelines and regulatory 
manual (Chapter 8).
 3 In the wildlife case, for example , previous experiences had demonstrated that proximity 
to an election period meant that there were higher risks of influences and interests other 
than evidence dominating the decision-making spaces.
 4 In the education case, for example,  the Chief Directorate Strategic Planning, Research 
and Coordination had a good reputation as an entity that facilitated the use of evaluations 
within the Department of Basic Education. In the case of Kenya, on the other hand, there 
had been a loss of trust in the government during previous policy review processes which 
meant that there was scepticism around the sincerity of government in its invitation to 
the wider public to participate in the Wildlife Conservation and Management Act review 
process. In Benin there was a loss of trust as, while new policies had been developed in 
response to political changes and these were informed by evidence, these policies did not 
result in concrete changes in the sector.
 5 DBE, VAWC, Procurement, Rapid Response, and Benin.
References
Goldman, I., Deliwe, C.N., Taylor, S., Ishmail, Z., Smith, L., Masangu, T., Adams, C.,  
Wilson, G., Fraser, D., Griessel, A., Waller, C., Dumisa, S., Wyatt, A. and Robertsen, J. 2019. 
Evaluation2 – Evaluating the national evaluation system in South Africa: What has been 
achieved in the first 5 years? African Evaluation Journal, 7(1). https://doi.org/10.4102/aej.
v7i1.400
Langer, L., Goldman, I. and Pabari, M. 2020. Analytical framework used to guide case study 
research. In Using evidence for policy and practice  – Lessons from Africa . London: Routledge, 
Taylor & Francis Group.
Langer, L., Tripney, J. and Gough, D. 2016. The science of using science: Researching the use of 
research evidence in decision-making. EPPI-Centre, Social Science Research Unit, UCL Insti-
tute of Education, University College London EPPI Centre.
Michie, S., van Stralen, M.M. and West, R. 2011. The behaviour change wheel: A  new 
method for characterising and designing behaviour change interventions. Implementation 
Science, 6(1), 42. https://doi.org/10.1186/1748-5908-6-42
<<<PAGE=18>>>
Lessons for using evidence in policy 241
Weiss, C.H. 1993. Where politics and evaluation research meet. Evaluation Practice, 14(1), 
93–106.
Weyrauch, V ., Echt, L. and Suliman, S. 2016. Knowledge into policy: Going beyond ‘Context 
matters’. Politics & Ideas and the International Network for the Availability of Scientific 
Publications.